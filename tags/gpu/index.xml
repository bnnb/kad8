<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPU on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/tags/gpu/</link>
    <description>Recent content in GPU on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Fri, 01 Nov 2024 17:39:30 +0800</lastBuildDate><atom:link href="https://www.kad8.com/tags/gpu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Intel Chiplet Gpu Design Patents</title>
      <link>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</link>
      <pubDate>Fri, 01 Nov 2024 17:39:30 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</guid>
      <description>&lt;p&gt;Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。&lt;/p&gt;
&lt;p&gt;本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Intel-patents-chiplet-gpu-design-1.webp&#34; alt=&#34;Intel Patents Chiplet GPU design&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。&lt;/p&gt;
&lt;p&gt;通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。&lt;/p&gt;
&lt;p&gt;此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。&lt;/p&gt;
&lt;p&gt;这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。&lt;/p&gt;
&lt;p&gt;其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。&lt;/p&gt;
&lt;p&gt;而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。&lt;/p&gt;
&lt;p&gt;事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。&lt;/p&gt;
&lt;p&gt;在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/featured-Intel_Chiplet.jpg" />
    </item>
    
    <item>
      <title>数据中心GPU的寿命最多只有3年</title>
      <link>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</link>
      <pubDate>Sat, 26 Oct 2024 12:34:43 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</guid>
      <description>&lt;p&gt;据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。&lt;/p&gt;
&lt;p&gt;云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Engineer-GenAI-GPU.webp&#34; alt=&#34;Google GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。&lt;/p&gt;
&lt;p&gt;并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。&lt;/p&gt;
&lt;p&gt;无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。&lt;/p&gt;
&lt;p&gt;如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。
而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/featured-lifespan-data-center-gpu.webp" />
    </item>
    
    <item>
      <title>CPU与GPU的区别</title>
      <link>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</link>
      <pubDate>Mon, 21 Oct 2024 23:01:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</guid>
      <description>&lt;p&gt;GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./cpu-vs-gpu.webp&#34; alt=&#34;CPU vs GPU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;设计目的与功能 
    &lt;div id=&#34;%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/difference-between-cpu-and-gpu/featured-cpu-vs-gpu.webp" />
    </item>
    
  </channel>
</rss>
