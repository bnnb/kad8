<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPU on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/tags/gpu/</link>
    <description>Recent content in GPU on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sat, 14 Dec 2024 18:41:31 +0800</lastBuildDate><atom:link href="https://www.kad8.com/tags/gpu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>美国将限制中国经第三国购买GPU AI芯片</title>
      <link>https://www.kad8.com/news/us-plans-to-tighten-ai-chip-exports-to-china-via-thirdparty-countries/</link>
      <pubDate>Sat, 14 Dec 2024 18:41:31 +0800</pubDate>
      
      <guid>https://www.kad8.com/news/us-plans-to-tighten-ai-chip-exports-to-china-via-thirdparty-countries/</guid>
      <description>&lt;p&gt;据报道，美国政府计划在本月底前发布一项新规则，进一步升级对华芯片禁令，从而遏制中国公司从不受限制的第三方国家采购先进的&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;人工智能&lt;/a&gt;(AI) 芯片。&lt;/p&gt;
&lt;p&gt;据两位知情人士称，新的出口管制措施将侧重于用于AI模型训练的图形处理单元（GPU）的全球出货。&lt;/p&gt;
&lt;p&gt;此举在于监管美国产品的“扩散”，以确保美国保持全球AI领导地位。&lt;/p&gt;
&lt;p&gt;预计新措施将包括几项条款，以防止中企通过第三方国家获得GPU等受限硬件，比如将GPU的出货量限制在特定地点等等。&lt;/p&gt;
&lt;p&gt;由于该措施尚未最终确定，实施日期仍可能发生变化。&lt;/p&gt;
&lt;p&gt;报道称，如果得到证实，这将是美国在上一轮禁令基础上对华芯片限制的迅速升级。&lt;/p&gt;
&lt;p&gt;值得一提的是，继日前中国对NVIDIA达提出反垄断调查后，12日，这一人工智能芯片制造巨头再度卷入司法风波。&lt;/p&gt;
&lt;p&gt;美最高法院允许投资者对芯片制造商NVIDIA提起集体诉讼，并驳回了NVIDIA的上诉请求。&lt;/p&gt;
&lt;p&gt;这是继法国、欧盟、中国对NVIDIA展开“反垄断调查”以来，英伟达陷入的最新司法纠纷。&lt;/p&gt;
&lt;p&gt;本周，因NVIDIA公司涉嫌违反反垄断法 ，市场监管总局依法对NVIDIA公司开展立案调查。&lt;/p&gt;
&lt;p&gt;知情人士透露，NVIDIA早在2022年就因断供行为被举报，相关部门已对此展开调查。&lt;/p&gt;
&lt;p&gt;此次立案调查发生在美国对中国科技产业加大出口管制的背景下，业内人士认为，这不仅是对NVIDIA不当行为的回应，更是中国对美国单边主义出口管制政策的反制。&lt;/p&gt;
&lt;p&gt;值得一提的是，NVIDIA还发声明，称近日社交媒体上传NVIDIA断供中国为不实传闻。中国是NVIDIA重要的市场，未来将持续为中国客户提供高质量服务。&lt;/p&gt;
&lt;p&gt;NVIDIA官方还强调，NVIDIA凭借实力取胜，这反映在其基准测试结果和对客户的价值上，客户可以选择任何最适合他们的解决方案。&lt;/p&gt;
&lt;p&gt;“我们努力在每个地区提供最好的产品，并在我们开展业务的任何地方履行我们的承诺。我们很乐意回答监管机构对我们业务的任何问题。”&lt;/p&gt;
&lt;p&gt;另外，近日有关“NVIDIA已下架天猫官方旗舰店所有商品”话题登上热搜，店铺“宝贝”页显示“抱歉，没有相关宝贝”。&lt;/p&gt;
&lt;p&gt;对此，NVIDIA天猫官方旗舰店客服表示，本旗舰店仅用于展示包含NVIDIA GeForce品牌的终端产品，并不出售任何产品或服务，相关产品信息请以跳转后的店铺所发布的信息为准。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/news/us-plans-to-tighten-ai-chip-exports-to-china-via-thirdparty-countries/featured-us-tighten-ai-chip.jpg" />
    </item>
    
    <item>
      <title>什么是CPU、GPU、TPU</title>
      <link>https://www.kad8.com/ai/introduction-to-cpu-gpu-tpu/</link>
      <pubDate>Wed, 11 Dec 2024 12:35:03 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/introduction-to-cpu-gpu-tpu/</guid>
      <description>&lt;p&gt;Google今年发布了第六代自研芯片——&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;Tensor Processing Unit（TPU）&lt;/a&gt;，命名为Trillium。&lt;/p&gt;
&lt;p&gt;那到底什么是CPU、GPU、TPU？可能大部分人不知道吧。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;什么是CPU、GPU和TPU&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;它们都是处理计算任务的芯片，尽管CPU、GPU和TPU都是处理器，但它们的专用程度逐步增加。&lt;/p&gt;
&lt;p&gt;CPU是“中央处理单元”的缩写，这是一种通用芯片，可以处理各种任务。就像大脑一样，CPU对某些任务的处理时间可能更长，因为它并不专门针对特定领域。&lt;/p&gt;
&lt;p&gt;接下来是GPU，GPU已成为加速计算任务的主力，从图像渲染到AI工作负载。它属于ASIC（应用专用集成电路）的一种。集成电路通常使用硅制造，因此人们也常用“硅”来指代芯片，简单来说，ASIC是为单一、特定用途设计的。&lt;/p&gt;
&lt;p&gt;TPU，即Tensor Processing Unit，是Google自研的ASIC。Google设计TPU的初衷就是为了运行AI计算任务，使其比CPU和GPU更加专用。TPU驱动了许多Google的热门AI服务，包括搜索、YouTube和DeepMind的大语言模型。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;那么CPU、GPU和TPU都在哪里使用呢&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CPU和GPU都在日常生活中非常常见的设备中使用：几乎每部智能手机中都有CPU，而它们也存在于个人计算设备如笔记本电脑中。高端游戏系统或某些台式设备中可能会配备GPU，TPU则仅在Google的数据中心内使用&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Google为什么开始考虑研发TPU？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CPU是在20世纪50年代末发明的，GPU大约在90年代末出现。&lt;/p&gt;
&lt;p&gt;大约十年前，Google开始考虑研发TPU，当时语音识别服务质量显著提升，但数据中心计算机数量越来越大，需要一种比现有硬件更高效的解决方案，而且需要每个芯片具备更强的处理能力。&lt;/p&gt;
&lt;p&gt;“T”代表Tensor，Tensor是一种用于机器学习的数据结构名称。简单来说，许多数学运算在幕后支持着AI任务的实现。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;TPU Trillium&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最新的TPU Trillium提升了计算能力：与上一代TPU v5e相比，Trillium的单芯片峰值计算性能提高了4.7倍。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/introduction-to-cpu-gpu-tpu/featured-cpu-gpu-tpu.jpeg" />
    </item>
    
    <item>
      <title>GPU 与 LPU：哪个更适合 AI 工作负载</title>
      <link>https://www.kad8.com/ai/gpu-vs-lpu-which-is-better-for-ai-workloads/</link>
      <pubDate>Fri, 06 Dec 2024 23:10:01 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/gpu-vs-lpu-which-is-better-for-ai-workloads/</guid>
      <description>&lt;p&gt;当前，&lt;a href=&#34;https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/&#34; target=&#34;_blank&#34;&gt;生成式AI&lt;/a&gt;模型的参数规模已跃升至数十亿乃至数万亿之巨，远远超出了传统CPU的处理范畴。在此背景下，GPU凭借其出色的并行处理能力，已成为人工智能加速领域的中流砥柱。然而，就在GPU备受关注之时，一个新的竞争力量——LPU（Language Processing Unit，语言处理单元）已悄然登场，LPU专注于解决自然语言处理（NLP）任务中的顺序性问题，是构建AI应用不可或缺的一环。&lt;/p&gt;
&lt;p&gt;本文旨在探讨深度学习工作负载中GPU与LPU的主要差异，并深入分析它们的架构、优势及性能表现。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;GPU 架构 
    &lt;div id=&#34;gpu-%E6%9E%B6%E6%9E%84&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#gpu-%E6%9E%B6%E6%9E%84&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;GPU 的核心是计算单元（也称为执行单元），其中包含多个处理单元（在 NVIDIA GPU中称为流处理器或 CUDA 核心），以及共享内存和控制逻辑。在某些架构中，尤其是为图形渲染而设计的架构中，还可能存在其他组件，例如光栅引擎和纹理处理集群 (TPC)。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/gpu-vs-lpu-which-is-better-for-ai-workloads/featured-GPU-vs-LPU.png" />
    </item>
    
    <item>
      <title>英特尔获得 Chiplet GPU 设计专利</title>
      <link>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</link>
      <pubDate>Fri, 01 Nov 2024 17:39:30 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</guid>
      <description>&lt;p&gt;Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。&lt;/p&gt;
&lt;p&gt;本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Intel-patents-chiplet-gpu-design-1.webp&#34; alt=&#34;Intel Patents Chiplet GPU design&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。&lt;/p&gt;
&lt;p&gt;通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。&lt;/p&gt;
&lt;p&gt;此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。&lt;/p&gt;
&lt;p&gt;这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。&lt;/p&gt;
&lt;p&gt;其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。&lt;/p&gt;
&lt;p&gt;而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。&lt;/p&gt;
&lt;p&gt;事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。&lt;/p&gt;
&lt;p&gt;在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/featured-Intel_Chiplet.jpg" />
    </item>
    
    <item>
      <title>数据中心GPU的寿命最多只有3年</title>
      <link>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</link>
      <pubDate>Sat, 26 Oct 2024 12:34:43 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</guid>
      <description>&lt;p&gt;据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。&lt;/p&gt;
&lt;p&gt;云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Engineer-GenAI-GPU.webp&#34; alt=&#34;Google GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。&lt;/p&gt;
&lt;p&gt;并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。&lt;/p&gt;
&lt;p&gt;无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。&lt;/p&gt;
&lt;p&gt;如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。
而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/featured-lifespan-data-center-gpu.webp" />
    </item>
    
    <item>
      <title>CPU与GPU的区别</title>
      <link>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</link>
      <pubDate>Mon, 21 Oct 2024 23:01:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</guid>
      <description>&lt;p&gt;GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./cpu-vs-gpu.webp&#34; alt=&#34;CPU vs GPU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;设计目的与功能 
    &lt;div id=&#34;%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/difference-between-cpu-and-gpu/featured-cpu-vs-gpu.webp" />
    </item>
    
  </channel>
</rss>
