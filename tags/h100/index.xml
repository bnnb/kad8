<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>H100 on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/tags/h100/</link>
    <description>Recent content in H100 on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sat, 26 Oct 2024 12:34:43 +0800</lastBuildDate><atom:link href="https://www.kad8.com/tags/h100/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>数据中心GPU的寿命最多只有3年</title>
      <link>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</link>
      <pubDate>Sat, 26 Oct 2024 12:34:43 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</guid>
      <description>&lt;p&gt;据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。&lt;/p&gt;
&lt;p&gt;云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Engineer-GenAI-GPU.webp&#34; alt=&#34;Google GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。&lt;/p&gt;
&lt;p&gt;并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。&lt;/p&gt;
&lt;p&gt;无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。&lt;/p&gt;
&lt;p&gt;如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。
而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/featured-lifespan-data-center-gpu.webp" />
    </item>
    
    <item>
      <title>GDDR 与 HBM 内存之间的区别</title>
      <link>https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/</link>
      <pubDate>Thu, 17 Oct 2024 23:58:16 +0800</pubDate>
      
      <guid>https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;什么是GDDR内存？ 
    &lt;div id=&#34;%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;GDDR代表Graphics Double Data Rate ，是一种专门为显卡设计的内存。GDDR内存与大多数计算机使用的DDR内存相似，但它针对显卡的使用进行了优化。GDDR内存通常比DDR内存带宽更高，这意味着它可以一次传输更多数据。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/featured-GDDR-vs-HBM-Memory.png" />
    </item>
    
    <item>
      <title>Intel正式发布Gaudi 3 AI加速器</title>
      <link>https://www.kad8.com/hardware/intel-gaudi-3-ai-accelerator/</link>
      <pubDate>Tue, 15 Oct 2024 23:11:15 +0800</pubDate>
      
      <guid>https://www.kad8.com/hardware/intel-gaudi-3-ai-accelerator/</guid>
      <description>&lt;p&gt;早在4月份，Intel就宣布了新一代AI加速器Gaudi 3，现在它终于发布了，详细的规格参数也已出炉，竞争对手直指NVIDIA H100 GPU加速器，当然后者的Blackwell系列也要上量了。&lt;/p&gt;
&lt;p&gt;数据显示，预计到2030年，全球半导体市场规模将达1万亿美元，AI是主要推动力，不过在2023年，只有10％的企业能够成功将其AIGC项目产品化。&lt;/p&gt;
&lt;p&gt;Intel现有的Gaudi 2诞生于2022年5月，并于2023年7月正式引入中国，拥有极高的深度学习性能、效率，以及极高的性价比。&lt;/p&gt;
&lt;p&gt;它采用台积电7nm工艺制造，集成24个可编程的Tenor张量核心(TPC)、48MB SRAM缓存、21个10万兆内部互连以太网接口(ROCEv2 RDMA)、96GB HBM2E高带宽内存(总带宽2.4TB/s)、多媒体引擎等，支持PCIe 4.0 x16，最高功耗800W，可满足大规模语言模型、生成式AI模型的强算力需求。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Intel-Gaudi-3-AI-Accelerator-2.png&#34; alt=&#34;Intel Gaudi 3 AI Accelerator&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Gaudi 3的规格提升幅度堪称跨越式的，制造工艺从台积电7nm来到台积电5nm，MME(矩阵乘法引擎)从2个增加到8个，虽然每个MME内部的TPC(张量处理核心)从12个减少到8个，但是总数从24个大幅增加到了64个，另外媒体解码器差从8个增至14个。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/hardware/intel-gaudi-3-ai-accelerator/featured-Intel-Gaudi-3-AI-Accelerator-1.png" />
    </item>
    
  </channel>
</rss>
