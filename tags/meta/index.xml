<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Meta on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/tags/meta/</link>
    <description>Recent content in Meta on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sun, 24 Nov 2024 11:18:17 +0800</lastBuildDate><atom:link href="https://www.kad8.com/tags/meta/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Meta AI数据中心网络用了哪家的芯片</title>
      <link>https://www.kad8.com/network/open-future-networking-hardware-ai-ocp-2024-meta/</link>
      <pubDate>Sun, 24 Nov 2024 11:18:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/network/open-future-networking-hardware-ai-ocp-2024-meta/</guid>
      <description>&lt;p&gt;在Meta，我们相信开放的硬件会推动创新。在当今世界，越来越多的数据中心基础设施致力于支持新兴的AI技术，开放硬件在协助分解方面发挥着重要作用。通过将传统数据中心技术分解为其核心组件，我们可以构建更加灵活、可扩展和高效的新系统。&lt;/p&gt;
&lt;p&gt;自2011年帮助创建OCP以来，我们分享了数据中心和组件设计，并开源了网络编排软件，以激发自己的数据中心和整个行业的新想法。这些想法使Meta的数据中心成为世界上最具可持续性和效率的数据中心之一。现在，通过OCP，我们正在为数据中心和更广泛的行业带来新的开放的先进网络技术，用于先进的AI应用。&lt;/p&gt;
&lt;p&gt;我们宣布了数据中心的两个新的里程碑：下一代AI网络结构，以及与多家供应商密切合作开发的新网络硬件组合。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./OCP-2024-Meta-1.png&#34; alt=&#34;Disaggregated network fabrics&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;DSF：已分解并开放的结构 
    &lt;div id=&#34;dsf%E5%B7%B2%E5%88%86%E8%A7%A3%E5%B9%B6%E5%BC%80%E6%94%BE%E7%9A%84%E7%BB%93%E6%9E%84&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#dsf%E5%B7%B2%E5%88%86%E8%A7%A3%E5%B9%B6%E5%BC%80%E6%94%BE%E7%9A%84%E7%BB%93%E6%9E%84&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;网络性能和可用性在从AI训练集群中提取最佳性能方面起着重要作用。正是出于这个原因，我们一直在为AI集群推动后端网络结构的分解。在过去的一年里，我们为下一代AI集群开发了一个分解的计划结构（DSF），以帮助我们开发开放的、与供应商无关的系统，这些系统具有来自整个行业供应商的可互换的构建块。基于DSF允许我们构建大型、无阻塞的结构，以支持高带宽AI集群。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/network/open-future-networking-hardware-ai-ocp-2024-meta/featured-Meta-DSF.png" />
    </item>
    
    <item>
      <title>Marvell与Meta联手推出Meta FBNIC 4x 100G网卡</title>
      <link>https://www.kad8.com/network/marvell-and-meta-launch-meta-fbnic-4x-100g-network-adapter/</link>
      <pubDate>Sat, 23 Nov 2024 16:19:36 +0800</pubDate>
      
      <guid>https://www.kad8.com/network/marvell-and-meta-launch-meta-fbnic-4x-100g-network-adapter/</guid>
      <description>&lt;p&gt;2024年OCP（开放计算项目）峰会上，Marvell和Meta联合展示了一款全新的Meta FBNIC 4x 100G多主机适配器。&lt;/p&gt;
&lt;p&gt;这款产品是Meta对网络硬件控制的一次重大尝试，标志着 Meta 涉足网络适配器 ASIC 领域，具有里程碑意义。Meta FBNIC 采用多主机设计和 OCP NIC 3.0 标准，具备高效散热等技术特色，适用于 Meta 的大规模数据中心部署，可降低硬件成本及功耗。&lt;/p&gt;
&lt;p&gt;这种合作模式可能冲击传统网络硬件供应商，引领数据中心网络适配器技术演进，推动行业迈向高密度、低成本网络架构，这也是 Meta 硬件自主化进程的重要一步，可能引发其他互联网巨头加速硬件自主化步伐，推动全球数据中心硬件架构变革。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/network/marvell-and-meta-launch-meta-fbnic-4x-100g-network-adapter/featured-Meta-FBNIC-at-OCP-Summit.jpg" />
    </item>
    
    <item>
      <title>Meta的AI大模型基础设施</title>
      <link>https://www.kad8.com/ai/building-metas-genai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 12:05:24 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/building-metas-genai-infrastructure/</guid>
      <description>&lt;p&gt;作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。&lt;/p&gt;
&lt;p&gt;我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。&lt;/p&gt;
&lt;p&gt;这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。&lt;/p&gt;
&lt;p&gt;引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Meta的大规模AI集群 
    &lt;div id=&#34;meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/building-metas-genai-infrastructure/featured-meta-generative-ai.png" />
    </item>
    
  </channel>
</rss>
