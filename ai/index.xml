<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ais on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/ai/</link>
    <description>Recent content in Ais on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sat, 16 Nov 2024 23:21:32 +0800</lastBuildDate><atom:link href="https://www.kad8.com/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>英伟达和谷歌拥抱RISC-V</title>
      <link>https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/</link>
      <pubDate>Sat, 16 Nov 2024 23:21:32 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/</guid>
      <description>&lt;p&gt;Nvidia 在 10 月 22 日至 24 日举行的 RISC-V 峰会上讨论了如何使用 RISC-V 架构。这家 GPU 制造商已在使用 RISC-V CPU 架构九年之久。Nvidia 副总裁 Frans Sijstermans 于 10 月 22 日发表了 20 分钟的主题演讲，并透露更多细节。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/featured-nvidia-google.jpg" />
    </item>
    
    <item>
      <title>三星对中国断供7nm及以下芯片</title>
      <link>https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/</link>
      <pubDate>Sat, 16 Nov 2024 23:05:57 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/</guid>
      <description>&lt;p&gt;美国商务部已经给台积电发函，要求暂停中国大陆&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;芯片企业的7nm及以下先进制程芯片的代工服务，重新审核认证客户身份（KYC）流程，扩大代工产品审查范围。&lt;/p&gt;
&lt;p&gt;按照消息人士的说法，并非所有大陆IC设计公司从此以后都无法获得台积电的先进制程工艺支持，目前最新的管控仅限于AI/GPU相关，手机、汽车等芯片不在管辖范围内。&lt;/p&gt;
&lt;p&gt;至于具体哪些AI/GPU相关芯片，则需要等到台积电与美国商务部协商出台具体管控细则，符合条件的芯片依旧有望通过申请许可的方式在台积电继续流片生产。&lt;/p&gt;
&lt;p&gt;现在，三星似乎也采取了类似的行动，也已经向大陆客户发出了类似的通知。&lt;/p&gt;
&lt;p&gt;对此，三星官方回应称：“我们无法评论与客户相关的事宜。”&lt;/p&gt;
&lt;p&gt;另据一名算力芯片企业的股东人士称，三星与台积电近日向他所投资的企业发送邮件，要求客户配合核查投片资质。&lt;/p&gt;
&lt;p&gt;其实，在本月初就有报道称，三星已关闭平泽2号线（P2）、3号线（P3）超过30％的产能，而到年底将扩大至50％，涉及4nm、5nm、7nm工艺，以降低成本，防止进一步扩大亏损。&lt;/p&gt;
&lt;p&gt;但是，三星极有可能已经提前听闻了台积电“违规”为中国大陆客户代工的风声，而眼瞅着台积电断供，于是决定提前关闭部分自己的相关产线，以降低风险。&lt;/p&gt;
&lt;p&gt;不排除三星也已经收到了美国的通知，即便没有三星也有可能会主动采取措施，避免被美国喝令停止——毕竟韩国在美国面前是没有话语权的。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./samsung-cut-off-chip-supply-to-china-1.png&#34; alt=&#34;Samsung Cut Off Supply of Chip to China&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;虽然大家一说起代工，会第一时间想起台积电，但是三星的4/5/7nm代工业务有很大一部分都来自中国芯片设计企业。&lt;/p&gt;
&lt;p&gt;尤为值得一提的是，三星第一代3nm工艺迄今唯一的大客户，就是中国某加密货币厂商的ASIC芯片。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/featured-samsung-cut-off.webp" />
    </item>
    
    <item>
      <title>NVIDIA CUDA简介</title>
      <link>https://www.kad8.com/ai/introduction-to-nvidia-cuda/</link>
      <pubDate>Sat, 16 Nov 2024 12:18:33 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/introduction-to-nvidia-cuda/</guid>
      <description>&lt;p&gt;CUDA，作为现代图形处理器（GPU）的计算单元，在高性能计算领域扮演着日益重要的角色。通过将复杂的计算任务分解为数千个线程并行执行，CUDA 显著提升了计算速度，为人工智能、科学计算、高性能计算等领域带来了革命性的变革。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;CUDA 到底是什么 
    &lt;div id=&#34;cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;毋庸置疑，你一定听说过 CUDA，并了解这玩意与 NVIDIA GPU 密切相关。然而，关于 CUDA 的具体定义和功能，许多人仍然心存疑惑，一脸懵逼。CUDA 是一个与 GPU 进行通信的库吗？&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/introduction-to-nvidia-cuda/featured-nvidia-cuda.webp" />
    </item>
    
    <item>
      <title>OpenAI要自研芯片了</title>
      <link>https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/</link>
      <pubDate>Thu, 07 Nov 2024 00:41:58 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/</guid>
      <description>&lt;p&gt;据路透社引用知情人士的消息透露，&lt;a href=&#34;https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/&#34; target=&#34;_blank&#34;&gt;OpenAI首颗自研芯片&lt;/a&gt;即将亮相。据介绍，这颗芯片由博通研发，并使用台积电加以代工。并将于2026年首次亮相。&lt;/p&gt;
&lt;p&gt;报道指出，该公司已考虑过多种方式来使其芯片供应多样化并降低成本，包括为芯片制造工厂网络筹集资金。但据路透社报道，OpenAI 并没有放弃建立代工厂的计划（目前该计划已被放弃），而是专注于内部设计自己的芯片。&lt;/p&gt;
&lt;p&gt;如报道所说，OpenAI 与博通合作开发首款用于 AI推理的自有芯片已持续数月，尽管目前对 AI 训练芯片的需求较高，但分析师预计 AI 推理最终将占据主导地位。推理是在训练之后进行的，是经过训练的 AI 模型根据新数据进行预测的过程。&lt;/p&gt;
&lt;p&gt;两位知情人士告诉路透社，OpenAI 仍在决定是为其 AI 芯片开发还是收购其他功能，并可能寻找更多芯片制造合作伙伴。据路透社报道，OpenAI 已通过与博通的合作与台积电建立了制造能力。据报道，这家台湾芯片制造商可能在 2026 年之前推出 OpenAI 的第一款定制芯片，但目前还不确定。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/featured-openai-broadcom.png" />
    </item>
    
    <item>
      <title>为什么 CUDA 对深度学习至关重要</title>
      <link>https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/</link>
      <pubDate>Mon, 04 Nov 2024 23:23:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/</guid>
      <description>&lt;p&gt;本文介绍了人工智能生态相关技术 - 用于加速构建 AI 核心算力的 GPU 硬件技术。&lt;/p&gt;
&lt;p&gt;毫无疑问，你可能已经听说过 CUDA，并且知道它与 NVIDIA GPU 有关。但你可能对 CUDA 的确切含义和用途还不甚了解。究竟，&lt;a href=&#34;https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/&#34; target=&#34;_blank&#34;&gt;CUDA&lt;/a&gt; 是什么呢？它只是一个与 GPU 进行对话的库吗？如果是，它是一个 C++ 库，还是可以通过 Python 等高级语言进行调用？或者，CUDA 是为 GPU 编写代码的编译器？它是否是让操作系统与 GPU 进行通信的驱动程序？&amp;hellip;&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/featured-nvidia-cuda-ai-dl.webp" />
    </item>
    
    <item>
      <title>拥有10万块英伟达H100的数据中心长什么样</title>
      <link>https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/</link>
      <pubDate>Sun, 03 Nov 2024 21:23:39 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/</guid>
      <description>&lt;p&gt;近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的&lt;a href=&#34;https://www.gaitpu.com/category/data-center/server&#34; target=&#34;_blank&#34;&gt;数据中心&lt;/a&gt;内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Colossus的4U液冷服务器，强调为液冷而设计&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Colossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./mgx-hgx-dgx.webp&#34; alt=&#34;MGX HGX DGX&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI服务器&lt;/a&gt;。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。&lt;/p&gt;
&lt;p&gt;因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。&lt;/p&gt;
&lt;p&gt;Colossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./xAI-Colossus-Data-Center-Supermicro-Liquid-Cooled-Nodes-Low-Angle.jpg&#34; alt=&#34;XAI Colossus Data Center Supermicro Liquid Cooled Nodes Low Angle&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/featured-xAI-Colossus-Data-Center-Compute-Hall.jpg" />
    </item>
    
    <item>
      <title>OpenAI获得的DGX B200的具体信息</title>
      <link>https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/</link>
      <pubDate>Sun, 03 Nov 2024 15:19:18 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/</guid>
      <description>&lt;p&gt;OpenAI 将通过最新的 &lt;a href=&#34;https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/&#34; target=&#34;_blank&#34;&gt;DGX B200&lt;/a&gt; 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;DGX B200 
    &lt;div id=&#34;dgx-b200&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#dgx-b200&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./DGX-B200-1.webp&#34; alt=&#34;DGX B200&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/featured-OpenAI-DGX-B200.jpg" />
    </item>
    
    <item>
      <title>英伟达替代英特尔，成为道指成份股</title>
      <link>https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/</link>
      <pubDate>Sun, 03 Nov 2024 12:03:59 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/</guid>
      <description>&lt;p&gt;据CNBC报道，&lt;a href=&#34;https://www.gaitpu.com/data-center/server/difference-between-nvlink-version-and-pcie-version-for-nvidia-ai-server&#34; target=&#34;_blank&#34;&gt;英伟达&lt;/a&gt;将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。&lt;/p&gt;
&lt;p&gt;英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。&lt;/p&gt;
&lt;p&gt;与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。&lt;/p&gt;
&lt;p&gt;回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。&lt;/p&gt;
&lt;p&gt;而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。&lt;/p&gt;
&lt;p&gt;注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。&lt;/p&gt;
&lt;p&gt;道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。&lt;/p&gt;
&lt;p&gt;道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/featured-nvidia-dow.webp" />
    </item>
    
    <item>
      <title>英特尔获得 Chiplet GPU 设计专利</title>
      <link>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</link>
      <pubDate>Fri, 01 Nov 2024 17:39:30 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</guid>
      <description>&lt;p&gt;Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。&lt;/p&gt;
&lt;p&gt;本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Intel-patents-chiplet-gpu-design-1.webp&#34; alt=&#34;Intel Patents Chiplet GPU design&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。&lt;/p&gt;
&lt;p&gt;通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。&lt;/p&gt;
&lt;p&gt;此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。&lt;/p&gt;
&lt;p&gt;这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。&lt;/p&gt;
&lt;p&gt;其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。&lt;/p&gt;
&lt;p&gt;而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。&lt;/p&gt;
&lt;p&gt;事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。&lt;/p&gt;
&lt;p&gt;在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/featured-Intel_Chiplet.jpg" />
    </item>
    
    <item>
      <title>九大巨头，正式成立UALink联盟</title>
      <link>https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/</link>
      <pubDate>Fri, 01 Nov 2024 13:38:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/</guid>
      <description>&lt;p&gt;今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (&lt;code&gt;UALink&lt;/code&gt; ) 联盟正式成立，并向社区发出成员邀请。&lt;/p&gt;
&lt;p&gt;资料显示，&lt;code&gt;Ultra Accelerator Link(UALink)&lt;/code&gt; 是一种用于加速器到加速器通信的开放行业标准化互连。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./UALink-1.webp&#34; alt=&#34;UALink&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;UALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 &lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI 加速器&lt;/a&gt;（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/featured-NVLink-vs-UALink.png" />
    </item>
    
    <item>
      <title>HBM内存芯片: AI革命的无名英雄</title>
      <link>https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/</link>
      <pubDate>Sun, 27 Oct 2024 23:53:09 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/</guid>
      <description>&lt;p&gt;像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： &lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;人工智能&lt;/a&gt;(AI)  ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”&lt;/p&gt;
&lt;p&gt;三星电子已经成功地将其&lt;a href=&#34;https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/&#34; target=&#34;_blank&#34;&gt;高带宽内存(HBM)&lt;/a&gt;设备与英伟达的 H100 GPU  等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-AI-1.png&#34; alt=&#34;HBM in AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;SK海力士的HBM优势 
    &lt;div id=&#34;sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;SK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/featured-hbm-ai.jpg" />
    </item>
    
    <item>
      <title>爆炸性的HBM需求预计推动DDR5价格上涨20%</title>
      <link>https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/</link>
      <pubDate>Sun, 27 Oct 2024 22:05:20 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/</guid>
      <description>&lt;p&gt;在AI服务器需求剧增的情况下，&lt;a href=&#34;https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/&#34; target=&#34;_blank&#34;&gt;HBM&lt;/a&gt;正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，&lt;a href=&#34;https://www.gaitpu.com/data-center/storage/ddr4-vs-ddr5-ram-all-the-design-challenges-advantages&#34; target=&#34;_blank&#34;&gt;DDR5&lt;/a&gt;预计将上涨15%至20%。&lt;/p&gt;
&lt;p&gt;HBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。&lt;/p&gt;
&lt;p&gt;从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-DDR-1.png&#34; alt=&#34;HBM DDR&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。&lt;/p&gt;
&lt;p&gt;由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-DDR-2.png&#34; alt=&#34;HBM DDR&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/featured-hbm-ddr-gpu.jpg" />
    </item>
    
    <item>
      <title>Google发布开源AI文本水印工具</title>
      <link>https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/</link>
      <pubDate>Sun, 27 Oct 2024 21:41:29 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/</guid>
      <description>&lt;p&gt;10月24日消息，&lt;code&gt;Google&lt;/code&gt;宣布推出名为&lt;code&gt;SynthID Text&lt;/code&gt;的开源水印工具，旨在帮助开发人员识别&lt;a href=&#34;https://www.kad8.com/ai/&#34; target=&#34;_blank&#34;&gt;人工智能&lt;/a&gt;生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Synthid-text.webp&#34; alt=&#34;Google SynthID Text&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;SynthID Text的工作能力 
    &lt;div id=&#34;synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Google DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/featured-Google-SynthID-Text.webp" />
    </item>
    
    <item>
      <title>如何构建高效可靠的AI基础设施</title>
      <link>https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 19:56:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;AI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;概述 
    &lt;div id=&#34;%E6%A6%82%E8%BF%B0&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E6%A6%82%E8%BF%B0&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;AI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。&lt;/p&gt;
&lt;p&gt;然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。&lt;/p&gt;
&lt;p&gt;云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。&lt;/p&gt;
&lt;p&gt;要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/featured-enterprise-infrastructure-of-ai.png" />
    </item>
    
    <item>
      <title>生成式AI技术栈架构师指南</title>
      <link>https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/</link>
      <pubDate>Sat, 26 Oct 2024 12:46:02 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/</guid>
      <description>&lt;p&gt;现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。&lt;/p&gt;
&lt;p&gt;如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。&lt;/p&gt;
&lt;p&gt;本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./GenAI-Tech-Stack.jpg&#34; alt=&#34;GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;数据湖 
    &lt;div id=&#34;%E6%95%B0%E6%8D%AE%E6%B9%96&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E6%B9%96&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/featured-GenAI-Tech-Stack.jpg" />
    </item>
    
    <item>
      <title>数据中心GPU的寿命最多只有3年</title>
      <link>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</link>
      <pubDate>Sat, 26 Oct 2024 12:34:43 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</guid>
      <description>&lt;p&gt;据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。&lt;/p&gt;
&lt;p&gt;云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Engineer-GenAI-GPU.webp&#34; alt=&#34;Google GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。&lt;/p&gt;
&lt;p&gt;并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。&lt;/p&gt;
&lt;p&gt;无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。&lt;/p&gt;
&lt;p&gt;如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。
而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/featured-lifespan-data-center-gpu.webp" />
    </item>
    
    <item>
      <title>Meta的AI大模型基础设施</title>
      <link>https://www.kad8.com/ai/building-metas-genai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 12:05:24 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/building-metas-genai-infrastructure/</guid>
      <description>&lt;p&gt;作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。&lt;/p&gt;
&lt;p&gt;我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。&lt;/p&gt;
&lt;p&gt;这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。&lt;/p&gt;
&lt;p&gt;引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Meta的大规模AI集群 
    &lt;div id=&#34;meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/building-metas-genai-infrastructure/featured-meta-generative-ai.png" />
    </item>
    
    <item>
      <title>计算机算力单位简介</title>
      <link>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</link>
      <pubDate>Thu, 24 Oct 2024 22:39:07 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</guid>
      <description>&lt;p&gt;算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;算力的计算方式 
    &lt;div id=&#34;%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Computing-Power-1.png&#34; alt=&#34;Computer Computing Power&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/computer-computing-power-unit-introduction/featured-computing-power.webp" />
    </item>
    
    <item>
      <title>Nvidia Blackwell的几款机架服务器解决方案</title>
      <link>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</link>
      <pubDate>Thu, 24 Oct 2024 01:26:15 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</guid>
      <description>&lt;p&gt;最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;微软 
    &lt;div id=&#34;%E5%BE%AE%E8%BD%AF&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%BE%AE%E8%BD%AF&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/featured-nvidia-blackwell-datacenter.webp" />
    </item>
    
    <item>
      <title>CPU与GPU的区别</title>
      <link>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</link>
      <pubDate>Mon, 21 Oct 2024 23:01:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</guid>
      <description>&lt;p&gt;GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./cpu-vs-gpu.webp&#34; alt=&#34;CPU vs GPU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;设计目的与功能 
    &lt;div id=&#34;%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/difference-between-cpu-and-gpu/featured-cpu-vs-gpu.webp" />
    </item>
    
    <item>
      <title>英伟达投资光芯片公司，将互联带宽提高10倍</title>
      <link>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</link>
      <pubDate>Mon, 21 Oct 2024 00:21:19 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</guid>
      <description>&lt;p&gt;据传言，&lt;code&gt;Nvidia&lt;/code&gt; 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 &lt;code&gt;NVLink&lt;/code&gt; 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。&lt;/p&gt;
&lt;p&gt;由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/featured-xscape-photonics-logo.jpg" />
    </item>
    
  </channel>
</rss>
