<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ais on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/ai/</link>
    <description>Recent content in Ais on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sat, 23 Nov 2024 20:46:18 +0800</lastBuildDate><atom:link href="https://www.kad8.com/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NVIDIA 发布四核 Blackwell GB200的NVL4</title>
      <link>https://www.kad8.com/ai/nvidia-unveils-quad-blackwell-dual-grace-gb200-nvl4/</link>
      <pubDate>Sat, 23 Nov 2024 20:46:18 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-unveils-quad-blackwell-dual-grace-gb200-nvl4/</guid>
      <description>&lt;p&gt;今天，在超级计算 2024 大会上，许多公司宣布了他们最新的 &lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;、HPC 和超级计算产品。这些公司中首屈一指的当然是 N​​VIDIA，该公司最重大的新产品发布是 GB200 NVL4。不过，我们稍后会了解 GB200 NVL4 是什么；首先，让我们谈谈绿色团队还宣布用于 AI 和 HPC 应用的 H200 NVL。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./nvidia-gb200-nvl4-2.png&#34; alt=&#34;Nvidia Blackwell GB200 NVL4&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-unveils-quad-blackwell-dual-grace-gb200-nvl4/featured-nvidia-gb200-nvl4-1.png" />
    </item>
    
    <item>
      <title>三星推出可扩展的新型内存模块</title>
      <link>https://www.kad8.com/ai/samsung-introduces-new-memory-module-for-scalable/</link>
      <pubDate>Tue, 19 Nov 2024 20:39:40 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/samsung-introduces-new-memory-module-for-scalable/</guid>
      <description>&lt;p&gt;在Memcon 2024上，全球先进半导体技术领导者三星电子公布了其&lt;a href=&#34;https://www.kad8.com/hardware/cxl-memory-module-box-cmm-b/&#34; target=&#34;_blank&#34;&gt;CXL内存模块&lt;/a&gt;产品组合的扩展，并展示了其最新的HBM3E技术，加强了在AI应用的高性能、高容量解决方案方面的领导地位。&lt;/p&gt;
&lt;p&gt;在美国圣克拉拉计算机历史博物馆举行的主题演讲中，三星美国设备解决方案研究所常务副总裁 Jin-Hyeok Choi和三星DRAM产品及技术部常务副总裁 SangJoon Hwang介绍了新的存储解决方案，并讨论了如何在AI时代引领HBM和CXL创新。与三星一同登台的还有VMware by Broadcom的VCF部门产品团队副总裁Paul Turner和Red Hat的副总裁兼总经理Gunnar Hellekson，他们讨论了其软件解决方案如何与三星的硬件技术相结合，推动内存创新。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./samsung-cxl-memory-module-1.png&#34; alt=&#34;Samsung CXL Memory Module&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Choi表示：“如果没有存储技术的革新，AI的革新就无法继续。作为内存市场的领导者，三星很自豪能够继续推进创新，从业界最先进的CMM-B技术到强大的内存解决方案，如HBM3E，用于高性能计算和AI应用。我们致力于与合作伙伴合作，为客户服务，共同释放AI时代的全部潜力。”&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./samsung-cxl-memory-module-2.png&#34; alt=&#34;Samsung CXL Memory Module&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/samsung-introduces-new-memory-module-for-scalable/featured-cxl-memory-module.jpeg" />
    </item>
    
    <item>
      <title>PCIe Over Optics的样机展示</title>
      <link>https://www.kad8.com/ai/pcie-over-optics-demo/</link>
      <pubDate>Tue, 19 Nov 2024 20:15:36 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/pcie-over-optics-demo/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;生成式AI&lt;/a&gt;革命正在重塑所有行业，并重新定义日常生活方方面面的可能性。创新的快速步伐给数据中心基础设施带来了重大挑战，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于需要LLM（大型语言模型）同时处理大量多模态数据集（文本、图像、音频和视频），因此对AI处理资源的需求激增，这些资源必须在整个数据中心相互连接&lt;/li&gt;
&lt;li&gt;由于生成式AI应用的多样性和定制化，大量的平台架构正在以显著加快的年度升级节奏部署&lt;/li&gt;
&lt;li&gt;因为云计算供应商面临着巨大的财务压力，需要为大规模的资本支出提供可观的投资回报率，所以要求部署AI基础设施的利用率达到最大化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要满足现代AI模型的计算需求，只能将数千个GPU或AI加速器与专门为AI工作负载构建的专用网络/结构互连在一起。该网络通常称为“后端”网络，由“向上扩展”的加速器集群结构和“向外扩展”的网络结构组成。“向上扩展”结构通常是一种任意对任意的网状互连，针对最大吞吐量和紧密耦合加速器的能力进行了优化，以快速交换AI模型训练/推理数据。“向外扩展”的例子包括NVLink、Infinity Fabric、PCI Express®（PCIe®）、以太网等。这些技术用于连接多达数百个加速器。&lt;/p&gt;
&lt;p&gt;PCIe接口在AI加速器和GPU上是原生可用的，一些AI平台还利用PCIe或基于PCIe的协议来扩展结构。随着AI集群的规模从1-2个机架、数十个GPU扩展到跨越多个机架、数百个GPU的大型pod，互连长度迅速成为限制。在PCIe 5.0数据速率下，跨度达7米的有源电缆足以连接几个机架。然而，在更高的数据速率，如&lt;a href=&#34;https://www.vxworks.net/bus-protocol/1131-pci-sig-confirms-pcie-5-0-and-6-0-will-use-new-cable-design&#34; target=&#34;_blank&#34;&gt;PCIe 6.x&lt;/a&gt;和PCIe 7.x，对于跨多个机架的GPU集群，需要光解决方案。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./pcie-over-optics-1.png&#34; alt=&#34;PCIe over optics&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们很高兴能够继续Astera Labs在PCIe连接解决方案方面的领先地位，通过展示端到端PCIe/CXL®用于GPU集群的光学器件，为扩展生成式AI基础设施照亮了前进的道路！&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;应对AI互联的日常挑战 
    &lt;div id=&#34;%E5%BA%94%E5%AF%B9ai%E4%BA%92%E8%81%94%E7%9A%84%E6%97%A5%E5%B8%B8%E6%8C%91%E6%88%98&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%BA%94%E5%AF%B9ai%E4%BA%92%E8%81%94%E7%9A%84%E6%97%A5%E5%B8%B8%E6%8C%91%E6%88%98&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;自2017年以来，Astera Labs一直专注于释放AI和云基础设施的全部潜力，不断推出率先上市的高度创新的连接解决方案。我们的智能连接平台的基础是基于PCIe®，CXL®和以太网半导体的解决方案，以及我们的COSMOS软件套件的系统管理和优化工具。该平台提供了可扩展和可定制的软件定义架构。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/pcie-over-optics-demo/featured-PCIe-FireFly-Samtec.jpg" />
    </item>
    
    <item>
      <title>Nvidia Chip Server Overheats</title>
      <link>https://www.kad8.com/ai/nvidia-chip-server-overheats/</link>
      <pubDate>Tue, 19 Nov 2024 19:23:18 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-chip-server-overheats/</guid>
      <description>&lt;p&gt;11月17日，The Information突然报道，英伟达新一代&lt;a href=&#34;https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/&#34; target=&#34;_blank&#34;&gt;Blackwell芯片&lt;/a&gt;可能再次面临延期，重提4个月前所谓的配套服务器过热的技术难题，这使得一些客户担心他们没有足够时间来部署新的数据中心。&lt;/p&gt;
&lt;p&gt;报道援引知情人士称，当Blackwell GPU被连接在设计容纳多达72个芯片的服务器机架中时会出现过热现象。据参与该项目的英伟达员工以及了解情况的客户和供应商透露，芯片制造商已多次要求供应商更改机架设计以解决过热问题。对此，英伟达发言人在向路透社表示：&amp;ldquo;英伟达正在与主要云服务提供商密切合作，将其作为我们工程团队和流程的重要组成部分，工程迭代是正常且预期的。”&lt;/p&gt;
&lt;p&gt;两位订购了新芯片的大型云服务提供商高管向The Information表示，他们担心这些问题可能推迟明年GPU集群的部署时间。多位客户和供应商表示，尽管设计变更出现在生产后期，但英伟达可能仍能按原计划在明年上半年末交付机架，目前尚未通知客户有任何延迟。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./nvidia-chip-server.png&#34; alt=&#34;Nvidia Blackwell Chip Server&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;以下为数字开物汇总的此前英伟达芯片服务器过热的相关信息：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;满载情况下，这款72-GPU机架重达1.5吨、高度超过普通家用冰箱，英伟达将其宣传为实现芯片之间最快性能连接的最佳方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多位知情人士称，这款机架及其密集排列数十个 GPU 的设计是英伟达有史以来最为复杂的设计，在公开推出机架几个月后，英伟达工程师在测试中发现，机架无法正常工作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;据两位参与服务器生产的人士透露，过多高性能芯片的连接会导致过热，影响服务器的可靠性和性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两位了解内情的英伟达员工还表示，配套36芯片的小型服务器机架同样面临过热困扰，目前尚不清楚该公司是否已解决这一问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;据悉，由于处理器设计缺陷导致良率问题，Nvidia 不得不推迟 Blackwell 的量产计划。Nvidia 的 Blackwell B100 和 B200 GPU 采用 TSMC 的 CoWoS-L 封装技术来连接其两个芯片组 (chiplet)。这种设计包括一个配备本地硅互连桥的 RDL 互联层，可支持高达 10 TB/s 的数据传输速度。这些 LSI 桥的精确定位对于该技术的正常运行至关重要。然而，GPU 芯片组、LSI 桥、RDL 互联层和主板基板 (substrate) 的热膨胀特性不匹配，导致了变形和系统故障。为了解决这个问题，据报道 Nvidia 对 GPU 硅片的顶层金属结构和微凸点进行了改良，以提高生产可靠性。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-chip-server-overheats/featured-blackwell-chip.png" />
    </item>
    
    <item>
      <title>TensorFlow与PyTorch究竟谁更胜一筹</title>
      <link>https://www.kad8.com/ai/comparison-between-tensorflow-and-pytorch/</link>
      <pubDate>Mon, 18 Nov 2024 21:36:06 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/comparison-between-tensorflow-and-pytorch/</guid>
      <description>&lt;p&gt;关于TensorFlow与PyTorch，我知道你们在想什么：“这俩框架我都用过，但到底哪个更胜一筹呢？”别急，今天我们就来扒一扒这背后的小秘密。不管你是深度学习的新手，还是老司机，这篇文章都能给你带来一些新视角。准备好了吗？让我们开始这场有趣的“对决”吧！&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;江湖地位 
    &lt;div id=&#34;%E6%B1%9F%E6%B9%96%E5%9C%B0%E4%BD%8D&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E6%B1%9F%E6%B9%96%E5%9C%B0%E4%BD%8D&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;首先，让我们来聊聊这两位大侠的江湖地位。&lt;/p&gt;
&lt;p&gt;TensorFlow，这个由Google亲生的深度学习框架，自2015年横空出世以来，就以其强大的性能和广泛的应用场景，迅速占领了AI界的大片江山。它就像那个在武林大会上一鸣惊人的少侠，不仅有着深厚的内功（Google的技术支持），还有着广泛的人脉（全球开发者的支持）。&lt;/p&gt;
&lt;p&gt;TensorFlow的成长之路可谓是风光无限。从1.0版本的稳定发布，到2.0版本的革命性升级，每一步都走得坚实而有力。现在的TensorFlow，不仅支持静态图，还拥抱了动态图，让模型的构建和调试变得更加灵活。这种变革，就像是那个武林高手在不断的战斗中，不断学习新的招式，不断提升自己的武艺。&lt;/p&gt;
&lt;p&gt;而PyTorch，这个由Facebook支持的后起之秀，虽然起步稍晚，但凭借其独特的魅力和强大的实力，迅速在AI界崭露头角。PyTorch的动态计算图，就像是那个总是能给人带来惊喜的江湖奇才，它的灵活性和易用性，让无数研究者和开发者为之倾倒。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/comparison-between-tensorflow-and-pytorch/featured-tensorflow-and-pytorch.png" />
    </item>
    
    <item>
      <title>AMD 计划推出全新 Ryzen 200 系列APU</title>
      <link>https://www.kad8.com/ai/amd-plans-to-launch-new-ryzen-200-series-apus/</link>
      <pubDate>Sun, 17 Nov 2024 16:01:07 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/amd-plans-to-launch-new-ryzen-200-series-apus/</guid>
      <description>&lt;p&gt;AMD计划推出基于Hawk Point系列的全新Ryzen 200系列APU，准备进军入门级笔记本电脑市场，对抗英特尔即将更新的Core 200系列处理器。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./AMD-ryzen-200-apu.png&#34; alt=&#34;AMD APU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;据悉，AMD一直热衷于对现有的CPU产品线进行更新，以提供更具吸引力的SKU，填补预算领域的性能空白。最近，AMD的Phoenix系列（被认为是最受欢迎的产品之一）已经更新为Ryzen 8000系列的“Hawk Point”APU。此次更新中，最引人注目的是升级了&lt;code&gt;NPU&lt;/code&gt;，性能可达16 &lt;code&gt;TOPS&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;根据升级包的泄露信息，AMD计划基于相同的&lt;code&gt;Zen 4&lt;/code&gt;架构，推出采用Ryzen 200命名方案的Hawk Point刷新APU阵容，预计变化不大。泄露的信息虽然未透露太多关于功能或性能的细节，但提到该系列中的一款型号为“Ryzen 7 255H”，这可能是现有的“Hawk Point”Ryzen 7 8745HS APU的升级版。该SKU于数月前发布，但未配备NPU。消息称，传闻中的Ryzen 7 255H将直接与英特尔的Core Ultra 7 255H竞争，AMD可能会在命名方案上与英特尔保持一致，以减少市场混淆。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/amd-plans-to-launch-new-ryzen-200-series-apus/featured-amd-ryzen-200-apu.jpeg" />
    </item>
    
    <item>
      <title>谷歌ARM服务器芯片表现如何</title>
      <link>https://www.kad8.com/ai/how-google-arm-server-chips-perform/</link>
      <pubDate>Sun, 17 Nov 2024 12:09:02 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/how-google-arm-server-chips-perform/</guid>
      <description>&lt;p&gt;当搜索引擎巨头谷歌想要成为云计算的时候，几年后谷歌意识到客户还没有准备好购买掩盖底层硬件的全套平台服务，而是想要更低级别的基础设施服务，以便有更多的可选性和更多的责任，谷歌云不可避免地要从英特尔、AMD 和 Nvidia 购买计算引擎来充实其服务器群。&lt;/p&gt;
&lt;p&gt;而且英特尔过去在 CPU 领域占据的利润率，以及 AMD 现在在 GPU 领域占据的利润率，以及在可预见的未来英伟达仍然在 GPU 领域占据的利润率，也意味着谷歌不可避免地会创建自己的 CPU 和 AI 加速器，以试图降低其服务器群的 TCO，特别是对于搜索引擎索引、广告投放、视频投放和各种形式和超大规模的数据分析等内部工作。&lt;/p&gt;
&lt;p&gt;因此，每当 Google Cloud 活动举行时，我们都会获得更多关于 Google 在组装服务器群时购买或构建的计算引擎的信息。Google 不会像普通芯片供应商那样发布产品，不会发布大量芯片和封装图片，也不会发布大量进料、速度、插槽和功率。我们必须随着时间的推移将其拼凑起来，等待几年后发表的回顾性论文，才能知道 Google 现在到底在做什么。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/how-google-arm-server-chips-perform/featured-google-cloud-trillium-racks-node-logo.jpg" />
    </item>
    
    <item>
      <title>谷歌正在开发的两颗芯片</title>
      <link>https://www.kad8.com/ai/google-is-developing-two-chips/</link>
      <pubDate>Sun, 17 Nov 2024 11:50:24 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/google-is-developing-two-chips/</guid>
      <description>&lt;p&gt;谷歌的 Pixel Watch 系列一开始有点不顺。第一代智能手表比原计划晚了一年推出，其 Exynos SoC 已经过时，与当时的竞争对手相比，它速度慢、耗电。幸运的是，这一问题很快得到解决，Pixel Watch 2 换用了高通的骁龙 W5 Gen 1 平台。此后，谷歌发布了另一款使用相同芯片的手表Pixel Watch 3。由于高通没有推出新平台，这不禁让人想问：谷歌对未来的 Pixel 手表有什么计划？&lt;/p&gt;
&lt;p&gt;由于谷歌 gChips 部门的大量泄密，Android Authority看到了一些文件，其中描述了谷歌计划于 2026 年与 Pixel Watch 5 同时发布未来可穿戴 Tensor 芯片。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/google-is-developing-two-chips/featured-google-watch.png" />
    </item>
    
    <item>
      <title>英伟达和谷歌拥抱RISC-V</title>
      <link>https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/</link>
      <pubDate>Sat, 16 Nov 2024 23:21:32 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/</guid>
      <description>&lt;p&gt;Nvidia 在 10 月 22 日至 24 日举行的 RISC-V 峰会上讨论了如何使用 RISC-V 架构。这家 GPU 制造商已在使用 RISC-V CPU 架构九年之久。Nvidia 副总裁 Frans Sijstermans 于 10 月 22 日发表了 20 分钟的主题演讲，并透露更多细节。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/featured-nvidia-google.jpg" />
    </item>
    
    <item>
      <title>三星对中国断供7nm及以下芯片</title>
      <link>https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/</link>
      <pubDate>Sat, 16 Nov 2024 23:05:57 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/</guid>
      <description>&lt;p&gt;美国商务部已经给台积电发函，要求暂停中国大陆&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;芯片企业的7nm及以下先进制程芯片的代工服务，重新审核认证客户身份（KYC）流程，扩大代工产品审查范围。&lt;/p&gt;
&lt;p&gt;按照消息人士的说法，并非所有大陆IC设计公司从此以后都无法获得台积电的先进制程工艺支持，目前最新的管控仅限于AI/GPU相关，手机、汽车等芯片不在管辖范围内。&lt;/p&gt;
&lt;p&gt;至于具体哪些AI/GPU相关芯片，则需要等到&lt;a href=&#34;https://www.kad8.com/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/&#34; target=&#34;_blank&#34;&gt;台积电与美国商务部&lt;/a&gt;协商出台具体管控细则，符合条件的芯片依旧有望通过申请许可的方式在台积电继续流片生产。&lt;/p&gt;
&lt;p&gt;现在，三星似乎也采取了类似的行动，也已经向大陆客户发出了类似的通知。&lt;/p&gt;
&lt;p&gt;对此，三星官方回应称：“我们无法评论与客户相关的事宜。”&lt;/p&gt;
&lt;p&gt;另据一名算力芯片企业的股东人士称，三星与台积电近日向他所投资的企业发送邮件，要求客户配合核查投片资质。&lt;/p&gt;
&lt;p&gt;其实，在本月初就有报道称，三星已关闭平泽2号线（P2）、3号线（P3）超过30％的产能，而到年底将扩大至50％，涉及4nm、5nm、7nm工艺，以降低成本，防止进一步扩大亏损。&lt;/p&gt;
&lt;p&gt;但是，三星极有可能已经提前听闻了台积电“违规”为中国大陆客户代工的风声，而眼瞅着台积电断供，于是决定提前关闭部分自己的相关产线，以降低风险。&lt;/p&gt;
&lt;p&gt;不排除三星也已经收到了美国的通知，即便没有三星也有可能会主动采取措施，避免被美国喝令停止——毕竟韩国在美国面前是没有话语权的。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./samsung-cut-off-chip-supply-to-china-1.png&#34; alt=&#34;Samsung Cut Off Supply of Chip to China&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;虽然大家一说起代工，会第一时间想起台积电，但是三星的4/5/7nm代工业务有很大一部分都来自中国芯片设计企业。&lt;/p&gt;
&lt;p&gt;尤为值得一提的是，三星第一代3nm工艺迄今唯一的大客户，就是中国某加密货币厂商的ASIC芯片。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/featured-samsung-cut-off.webp" />
    </item>
    
    <item>
      <title>NVIDIA CUDA简介</title>
      <link>https://www.kad8.com/ai/introduction-to-nvidia-cuda/</link>
      <pubDate>Sat, 16 Nov 2024 12:18:33 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/introduction-to-nvidia-cuda/</guid>
      <description>&lt;p&gt;CUDA，作为现代图形处理器（GPU）的计算单元，在高性能计算领域扮演着日益重要的角色。通过将复杂的计算任务分解为数千个线程并行执行，CUDA 显著提升了计算速度，为人工智能、科学计算、高性能计算等领域带来了革命性的变革。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;CUDA 到底是什么 
    &lt;div id=&#34;cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;毋庸置疑，你一定听说过 CUDA，并了解这玩意与 NVIDIA GPU 密切相关。然而，关于 CUDA 的具体定义和功能，许多人仍然心存疑惑，一脸懵逼。CUDA 是一个与 GPU 进行通信的库吗？&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/introduction-to-nvidia-cuda/featured-nvidia-cuda.webp" />
    </item>
    
    <item>
      <title>曝台积电7nm芯片将停供中国大陆</title>
      <link>https://www.kad8.com/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/</link>
      <pubDate>Fri, 08 Nov 2024 23:58:15 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/</guid>
      <description>&lt;p&gt;援引多个消息源报道，台积电已向所有中国大陆AI芯片客户发送正式电子邮件，宣布自下周11月11日起，将暂停向中国大陆AI/GPU客户供应所有7nm及更先进工艺的芯片。&lt;/p&gt;
&lt;p&gt;分析称，在芯片大战愈演愈烈之际，台积电此举凸显了这家代工巨头在全球半导体供应链中的微妙地位。在新任总统特朗普声称台积电应该缴纳“保护费”的情况下，该公司的最新举动似乎是在努力与美国商务部保持一致。报道称，双方共同建立了一个严格的审查制度，以完全阻止中国获得先进制程技术。&lt;/p&gt;
&lt;p&gt;另一家媒体SEMICONVoice报道称，美国商务部已指示台积电采取这一行动，因为生产只能在经过美国商务部工业和安全局（BIS）审查和批准并获得许可证后才能进行。这将收紧中国所有AI芯片、GPU和自动驾驶ADAS系统获取先进7nm及以下制程的能力。&lt;/p&gt;
&lt;p&gt;据彭博社和路透社最新报道，台积电已几乎敲定了数十亿美元的资助和贷款协议，以支持其在美国的工厂，这可能使其很快能从美国政府获得资金。台积电4月宣布的援助计划包括66亿美元的资助和最高50亿美元的贷款，以援助亚利桑那州三座半导体工厂的建设。&lt;/p&gt;
&lt;p&gt;如果消息属实，对于中国大陆的&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;和GPU公司来说，这将是沉重的打击，他们将无法再使用台积电的先进工艺，这可能导致更高的成本和更长的上市时间，并严重影响其产品性能和市场竞争力。报道称，供应链重组可能随之而来，大陆的芯片设计公司可能需要寻求其他代工厂。&lt;/p&gt;
&lt;p&gt;据TrendForce数据，截至2024年第二季度，中芯国际保持5.7%的稳固市场份额，位居第三，台积电（62.3%）和三星（11.5%）分列前两位。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/featured-TSMC-halt-7nm.jpg" />
    </item>
    
    <item>
      <title>OpenAI要自研芯片了</title>
      <link>https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/</link>
      <pubDate>Thu, 07 Nov 2024 00:41:58 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/</guid>
      <description>&lt;p&gt;据路透社引用知情人士的消息透露，&lt;a href=&#34;https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/&#34; target=&#34;_blank&#34;&gt;OpenAI首颗自研芯片&lt;/a&gt;即将亮相。据介绍，这颗芯片由博通研发，并使用台积电加以代工。并将于2026年首次亮相。&lt;/p&gt;
&lt;p&gt;报道指出，该公司已考虑过多种方式来使其芯片供应多样化并降低成本，包括为芯片制造工厂网络筹集资金。但据路透社报道，OpenAI 并没有放弃建立代工厂的计划（目前该计划已被放弃），而是专注于内部设计自己的芯片。&lt;/p&gt;
&lt;p&gt;如报道所说，OpenAI 与博通合作开发首款用于 AI推理的自有芯片已持续数月，尽管目前对 AI 训练芯片的需求较高，但分析师预计 AI 推理最终将占据主导地位。推理是在训练之后进行的，是经过训练的 AI 模型根据新数据进行预测的过程。&lt;/p&gt;
&lt;p&gt;两位知情人士告诉路透社，OpenAI 仍在决定是为其 AI 芯片开发还是收购其他功能，并可能寻找更多芯片制造合作伙伴。据路透社报道，OpenAI 已通过与博通的合作与台积电建立了制造能力。据报道，这家台湾芯片制造商可能在 2026 年之前推出 OpenAI 的第一款定制芯片，但目前还不确定。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/featured-openai-broadcom.png" />
    </item>
    
    <item>
      <title>为什么 CUDA 对深度学习至关重要</title>
      <link>https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/</link>
      <pubDate>Mon, 04 Nov 2024 23:23:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/</guid>
      <description>&lt;p&gt;本文介绍了人工智能生态相关技术 - 用于加速构建 AI 核心算力的 GPU 硬件技术。&lt;/p&gt;
&lt;p&gt;毫无疑问，你可能已经听说过 CUDA，并且知道它与 NVIDIA GPU 有关。但你可能对 CUDA 的确切含义和用途还不甚了解。究竟，&lt;a href=&#34;https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/&#34; target=&#34;_blank&#34;&gt;CUDA&lt;/a&gt; 是什么呢？它只是一个与 GPU 进行对话的库吗？如果是，它是一个 C++ 库，还是可以通过 Python 等高级语言进行调用？或者，CUDA 是为 GPU 编写代码的编译器？它是否是让操作系统与 GPU 进行通信的驱动程序？&amp;hellip;&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/featured-nvidia-cuda-ai-dl.webp" />
    </item>
    
    <item>
      <title>拥有10万块英伟达H100的数据中心长什么样</title>
      <link>https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/</link>
      <pubDate>Sun, 03 Nov 2024 21:23:39 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/</guid>
      <description>&lt;p&gt;近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的&lt;a href=&#34;https://www.gaitpu.com/category/data-center/server&#34; target=&#34;_blank&#34;&gt;数据中心&lt;/a&gt;内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Colossus的4U液冷服务器，强调为液冷而设计&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Colossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./mgx-hgx-dgx.webp&#34; alt=&#34;MGX HGX DGX&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI服务器&lt;/a&gt;。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。&lt;/p&gt;
&lt;p&gt;因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。&lt;/p&gt;
&lt;p&gt;Colossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./xAI-Colossus-Data-Center-Supermicro-Liquid-Cooled-Nodes-Low-Angle.jpg&#34; alt=&#34;XAI Colossus Data Center Supermicro Liquid Cooled Nodes Low Angle&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/featured-xAI-Colossus-Data-Center-Compute-Hall.jpg" />
    </item>
    
    <item>
      <title>OpenAI获得的DGX B200的具体信息</title>
      <link>https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/</link>
      <pubDate>Sun, 03 Nov 2024 15:19:18 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/</guid>
      <description>&lt;p&gt;OpenAI 将通过最新的 &lt;a href=&#34;https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/&#34; target=&#34;_blank&#34;&gt;DGX B200&lt;/a&gt; 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;DGX B200 
    &lt;div id=&#34;dgx-b200&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#dgx-b200&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./DGX-B200-1.webp&#34; alt=&#34;DGX B200&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/specific-system-spec-about-dgx-b200/featured-OpenAI-DGX-B200.jpg" />
    </item>
    
    <item>
      <title>英伟达替代英特尔，成为道指成份股</title>
      <link>https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/</link>
      <pubDate>Sun, 03 Nov 2024 12:03:59 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/</guid>
      <description>&lt;p&gt;据CNBC报道，&lt;a href=&#34;https://www.gaitpu.com/data-center/server/difference-between-nvlink-version-and-pcie-version-for-nvidia-ai-server&#34; target=&#34;_blank&#34;&gt;英伟达&lt;/a&gt;将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。&lt;/p&gt;
&lt;p&gt;英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。&lt;/p&gt;
&lt;p&gt;与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。&lt;/p&gt;
&lt;p&gt;回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。&lt;/p&gt;
&lt;p&gt;而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。&lt;/p&gt;
&lt;p&gt;注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。&lt;/p&gt;
&lt;p&gt;道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。&lt;/p&gt;
&lt;p&gt;道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nvidia-to-join-the-dow-jones-industrial-average/featured-nvidia-dow.webp" />
    </item>
    
    <item>
      <title>英特尔获得 Chiplet GPU 设计专利</title>
      <link>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</link>
      <pubDate>Fri, 01 Nov 2024 17:39:30 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/</guid>
      <description>&lt;p&gt;Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。&lt;/p&gt;
&lt;p&gt;本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Intel-patents-chiplet-gpu-design-1.webp&#34; alt=&#34;Intel Patents Chiplet GPU design&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。&lt;/p&gt;
&lt;p&gt;通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。&lt;/p&gt;
&lt;p&gt;此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。&lt;/p&gt;
&lt;p&gt;这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。&lt;/p&gt;
&lt;p&gt;其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。&lt;/p&gt;
&lt;p&gt;而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。&lt;/p&gt;
&lt;p&gt;事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。&lt;/p&gt;
&lt;p&gt;在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/intel-chiplet-gpu-design-patents/featured-Intel_Chiplet.jpg" />
    </item>
    
    <item>
      <title>九大巨头，正式成立UALink联盟</title>
      <link>https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/</link>
      <pubDate>Fri, 01 Nov 2024 13:38:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/</guid>
      <description>&lt;p&gt;今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (&lt;code&gt;UALink&lt;/code&gt; ) 联盟正式成立，并向社区发出成员邀请。&lt;/p&gt;
&lt;p&gt;资料显示，&lt;code&gt;Ultra Accelerator Link(UALink)&lt;/code&gt; 是一种用于加速器到加速器通信的开放行业标准化互连。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./UALink-1.webp&#34; alt=&#34;UALink&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;UALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 &lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI 加速器&lt;/a&gt;（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/nine-giants-established-the-ualink-alliance/featured-NVLink-vs-UALink.png" />
    </item>
    
    <item>
      <title>HBM内存芯片: AI革命的无名英雄</title>
      <link>https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/</link>
      <pubDate>Sun, 27 Oct 2024 23:53:09 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/</guid>
      <description>&lt;p&gt;像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： &lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;人工智能&lt;/a&gt;(AI)  ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”&lt;/p&gt;
&lt;p&gt;三星电子已经成功地将其&lt;a href=&#34;https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/&#34; target=&#34;_blank&#34;&gt;高带宽内存(HBM)&lt;/a&gt;设备与英伟达的 H100 GPU  等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-AI-1.png&#34; alt=&#34;HBM in AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;SK海力士的HBM优势 
    &lt;div id=&#34;sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;SK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/featured-hbm-ai.jpg" />
    </item>
    
    <item>
      <title>爆炸性的HBM需求预计推动DDR5价格上涨20%</title>
      <link>https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/</link>
      <pubDate>Sun, 27 Oct 2024 22:05:20 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/</guid>
      <description>&lt;p&gt;在AI服务器需求剧增的情况下，&lt;a href=&#34;https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/&#34; target=&#34;_blank&#34;&gt;HBM&lt;/a&gt;正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，&lt;a href=&#34;https://www.gaitpu.com/data-center/storage/ddr4-vs-ddr5-ram-all-the-design-challenges-advantages&#34; target=&#34;_blank&#34;&gt;DDR5&lt;/a&gt;预计将上涨15%至20%。&lt;/p&gt;
&lt;p&gt;HBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。&lt;/p&gt;
&lt;p&gt;从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-DDR-1.png&#34; alt=&#34;HBM DDR&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端&lt;a href=&#34;https://www.gaitpu.com&#34; target=&#34;_blank&#34;&gt;AI&lt;/a&gt;应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。&lt;/p&gt;
&lt;p&gt;由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./HBM-DDR-2.png&#34; alt=&#34;HBM DDR&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/featured-hbm-ddr-gpu.jpg" />
    </item>
    
    <item>
      <title>Google发布开源AI文本水印工具</title>
      <link>https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/</link>
      <pubDate>Sun, 27 Oct 2024 21:41:29 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/</guid>
      <description>&lt;p&gt;10月24日消息，&lt;code&gt;Google&lt;/code&gt;宣布推出名为&lt;code&gt;SynthID Text&lt;/code&gt;的开源水印工具，旨在帮助开发人员识别&lt;a href=&#34;https://www.kad8.com/ai/&#34; target=&#34;_blank&#34;&gt;人工智能&lt;/a&gt;生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Synthid-text.webp&#34; alt=&#34;Google SynthID Text&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;SynthID Text的工作能力 
    &lt;div id=&#34;synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Google DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/featured-Google-SynthID-Text.webp" />
    </item>
    
    <item>
      <title>如何构建高效可靠的AI基础设施</title>
      <link>https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 19:56:51 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;AI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;概述 
    &lt;div id=&#34;%E6%A6%82%E8%BF%B0&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E6%A6%82%E8%BF%B0&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;AI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。&lt;/p&gt;
&lt;p&gt;然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。&lt;/p&gt;
&lt;p&gt;云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。&lt;/p&gt;
&lt;p&gt;要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/setting-direction-for-enterprise-ai-infrastructure/featured-enterprise-infrastructure-of-ai.png" />
    </item>
    
    <item>
      <title>生成式AI技术栈架构师指南</title>
      <link>https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/</link>
      <pubDate>Sat, 26 Oct 2024 12:46:02 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/</guid>
      <description>&lt;p&gt;现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。&lt;/p&gt;
&lt;p&gt;如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。&lt;/p&gt;
&lt;p&gt;本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./GenAI-Tech-Stack.jpg&#34; alt=&#34;GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;数据湖 
    &lt;div id=&#34;%E6%95%B0%E6%8D%AE%E6%B9%96&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E6%B9%96&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/featured-GenAI-Tech-Stack.jpg" />
    </item>
    
    <item>
      <title>数据中心GPU的寿命最多只有3年</title>
      <link>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</link>
      <pubDate>Sat, 26 Oct 2024 12:34:43 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/</guid>
      <description>&lt;p&gt;据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。&lt;/p&gt;
&lt;p&gt;云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Google-Engineer-GenAI-GPU.webp&#34; alt=&#34;Google GenAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。&lt;/p&gt;
&lt;p&gt;并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。&lt;/p&gt;
&lt;p&gt;无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。&lt;/p&gt;
&lt;p&gt;如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。
而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/featured-lifespan-data-center-gpu.webp" />
    </item>
    
    <item>
      <title>Meta的AI大模型基础设施</title>
      <link>https://www.kad8.com/ai/building-metas-genai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 12:05:24 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/building-metas-genai-infrastructure/</guid>
      <description>&lt;p&gt;作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。&lt;/p&gt;
&lt;p&gt;我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。&lt;/p&gt;
&lt;p&gt;这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。&lt;/p&gt;
&lt;p&gt;引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Meta的大规模AI集群 
    &lt;div id=&#34;meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/building-metas-genai-infrastructure/featured-meta-generative-ai.png" />
    </item>
    
    <item>
      <title>计算机算力单位简介</title>
      <link>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</link>
      <pubDate>Thu, 24 Oct 2024 22:39:07 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</guid>
      <description>&lt;p&gt;算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;算力的计算方式 
    &lt;div id=&#34;%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Computing-Power-1.png&#34; alt=&#34;Computer Computing Power&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/computer-computing-power-unit-introduction/featured-computing-power.webp" />
    </item>
    
    <item>
      <title>Nvidia Blackwell的几款机架服务器解决方案</title>
      <link>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</link>
      <pubDate>Thu, 24 Oct 2024 01:26:15 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</guid>
      <description>&lt;p&gt;最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;微软 
    &lt;div id=&#34;%E5%BE%AE%E8%BD%AF&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%BE%AE%E8%BD%AF&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/featured-nvidia-blackwell-datacenter.webp" />
    </item>
    
    <item>
      <title>CPU与GPU的区别</title>
      <link>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</link>
      <pubDate>Mon, 21 Oct 2024 23:01:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</guid>
      <description>&lt;p&gt;GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./cpu-vs-gpu.webp&#34; alt=&#34;CPU vs GPU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;设计目的与功能 
    &lt;div id=&#34;%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/difference-between-cpu-and-gpu/featured-cpu-vs-gpu.webp" />
    </item>
    
    <item>
      <title>英伟达投资光芯片公司，将互联带宽提高10倍</title>
      <link>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</link>
      <pubDate>Mon, 21 Oct 2024 00:21:19 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</guid>
      <description>&lt;p&gt;据传言，&lt;code&gt;Nvidia&lt;/code&gt; 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 &lt;code&gt;NVLink&lt;/code&gt; 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。&lt;/p&gt;
&lt;p&gt;由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/featured-xscape-photonics-logo.jpg" />
    </item>
    
  </channel>
</rss>
