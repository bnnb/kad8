<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ais on Kontronn Asia Design Center</title>
    <link>https://www.kad8.com/ai/</link>
    <description>Recent content in Ais on Kontronn Asia Design Center</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© 2024 </copyright>
    <lastBuildDate>Sat, 26 Oct 2024 12:05:24 +0800</lastBuildDate><atom:link href="https://www.kad8.com/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building Metas Genai Infrastructure</title>
      <link>https://www.kad8.com/ai/building-metas-genai-infrastructure/</link>
      <pubDate>Sat, 26 Oct 2024 12:05:24 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/building-metas-genai-infrastructure/</guid>
      <description>&lt;p&gt;作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。&lt;/p&gt;
&lt;p&gt;我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。&lt;/p&gt;
&lt;p&gt;这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。&lt;/p&gt;
&lt;p&gt;引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Meta的大规模AI集群 
    &lt;div id=&#34;meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/building-metas-genai-infrastructure/featured-meta-generative-ai.png" />
    </item>
    
    <item>
      <title>计算机算力单位简介</title>
      <link>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</link>
      <pubDate>Thu, 24 Oct 2024 22:39:07 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/computer-computing-power-unit-introduction/</guid>
      <description>&lt;p&gt;算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;算力的计算方式 
    &lt;div id=&#34;%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./Computing-Power-1.png&#34; alt=&#34;Computer Computing Power&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/computer-computing-power-unit-introduction/featured-computing-power.webp" />
    </item>
    
    <item>
      <title>Nvidia Blackwell的几款机架服务器解决方案</title>
      <link>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</link>
      <pubDate>Thu, 24 Oct 2024 01:26:15 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/</guid>
      <description>&lt;p&gt;最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;微软 
    &lt;div id=&#34;%E5%BE%AE%E8%BD%AF&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%BE%AE%E8%BD%AF&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/featured-nvidia-blackwell-datacenter.webp" />
    </item>
    
    <item>
      <title>CPU与GPU的区别</title>
      <link>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</link>
      <pubDate>Mon, 21 Oct 2024 23:01:17 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/difference-between-cpu-and-gpu/</guid>
      <description>&lt;p&gt;GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。&lt;/p&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;./cpu-vs-gpu.webp&#34; alt=&#34;CPU vs GPU&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;设计目的与功能 
    &lt;div id=&#34;%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD&#34; aria-label=&#34;锚点&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/difference-between-cpu-and-gpu/featured-cpu-vs-gpu.webp" />
    </item>
    
    <item>
      <title>英伟达投资光芯片公司，将互联带宽提高10倍</title>
      <link>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</link>
      <pubDate>Mon, 21 Oct 2024 00:21:19 +0800</pubDate>
      
      <guid>https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/</guid>
      <description>&lt;p&gt;据传言，&lt;code&gt;Nvidia&lt;/code&gt; 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 &lt;code&gt;NVLink&lt;/code&gt; 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。&lt;/p&gt;
&lt;p&gt;由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/featured-xscape-photonics-logo.jpg" />
    </item>
    
  </channel>
</rss>
