
[{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/ai/","section":"Ais","summary":"","title":"Ais","type":"ai"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/hardware/","section":"Tags","summary":"","title":"Hardware","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"创新的AI硬件有潜力推动卓越的能力，并彻底改变人们与技术和周围世界的互动方式。你有没有想过，一个比拇指指甲还小的芯片，是如何模仿人类思维过程的？AI背后的硬件是使这一切成为可能的动力，这是一个令人兴奋的事实。\n当探索AI硬件世界时，我们将发现GPU， TPU和NPU如何强大地塑造AI的景观。\n本文将讨论AI硬件的复杂性，它在推动现代创新中的关键作用、所使用的技术、优点和缺点、它们的使用以及其他细节。\n什么是AI硬件 # AI硬件由驱动AI技术的特殊部件组成。创建这些部分是为了管理识别模式、做出决策和分析数据所需的复杂计算。我们可以把它们想象成支撑AI大脑功能的强壮肌肉。\nAI硬件的核心在于处理器，如图形处理单元（GPU）、张量处理单元（TPU）和神经处理单元（NPU）。\nGPU：它们最初是为渲染图形而设计的。由于GPU在并行处理中表现出色，因此它们非常适合训练AI模型。 TPU：谷歌专门为加速AI计算而开发的TPU，在深度学习任务中表现尤为出色。 NPU：它们可以处理涉及神经网络的任务，模仿人类大脑中的神经连接。 上述所有硬件组件协同工作，处理和分析大量数据，使人工智能系统能够学习、适应和做出预测。\nAI硬件技术 # 让我们来探索一下这首科技交响乐中的关键部分。\nGPU # GPU最初是为在电子游戏中渲染复杂的图形而设计的，现在却出人意料地在AI领域找到了自己的位置。它们在AI领域能力的关键在于并行处理，即同时处理多个计算的能力。\n与传统处理器不同，GPU擅长快速处理大量数据，这使其成为训练复杂AI模型的理想选择。它们令人印象深刻的处理能力加快了数据处理和模型训练的速度，大大减少了训练AI系统所需的时间。\nTPU # TPU被设计成一个单一的目的——增强特定的AI工作负载，特别是那些涉及神经网络的工作负载。TPU的一个显著方面是其卓越的效率，因为在完成这些任务时，与传统的CPU和GPU相比，TPU功耗更小。\n深度学习（DL） # 深度学习（DL）是机器学习的一个分支，体现了人类思维吸收和理解信息的方式，但是以数字形式。该技术采用多层神经网络对数据进行逐步抽象和操作。深度学习是现代AI背后的驱动力，推动着它取得越来越复杂的成就。\n专用集成电路（ASIC） # ASIC是AI硬件领域的定制套装。这些芯片经过精心设计，可以在AI计算的特定任务中发挥作用，表现出非凡的效率。与通用处理器不同，ASIC的设计非常精确，专注于特定类型的计算。这种专注的方法为AI工作负载提供了卓越的速度和能源效率。\n现场可编程门阵列（FPGA） # 如果你的电脑硬件具有非凡的转换能力会怎样？这种独特的特性定义了FPGA（现场可编程门阵列）。\n与传统处理器不同，FPGA可以在制造后重新配置，以适应和优化其特定任务的性能。这种非凡的灵活性使它们像AI硬件的瑞士军刀一样，在ASIC的效率和传统处理器的多功能性之间提供了平衡。\n神经形态芯片 # 想象一下这样一个世界：计算机芯片的功能就像我们的大脑一样，有着复杂的连接和快速的信号。\n神经形态芯片与普通芯片不同。这些非凡的创造物擅长多任务处理和对事件的快速反应。因此，神经形态芯片非常适合在AI系统中节约能源，以及处理需要速度和效率的实时任务。\n在这些AI硬件技术中选择一种时，公司通常倾向于使用GPU和传感器处理单元TPU来完成他们的AI任务。\nGPU提供并行处理能力和多功能性，使它成为一个受欢迎的选择，特别是对于训练复杂的AI模型。同样，Google开发的TPU也因其加速神经网络任务的能力而脱颖而出，兼具效率和速度。这两种选择受到青睐，因为它们在处理现代AI应用的高计算需求方面表现出色。\nAI硬件vs.普通硬件 # 理解AI硬件和普通硬件之间的区别需要你了解驱动AI惊人能力的组件。以下是AI硬件与常规或传统硬件的区别。\n复杂的计算：AI任务包括模式识别、数据分析、决策、预测事件等复杂的计算。AI硬件旨在有效地处理这些复杂的计算。 并行处理能力：AI硬件，如GPU和TPU，擅长并行处理或同时执行多个任务，同时保证性能。这可以实现更快的数据处理和模型训练，这对于AI应用程序至关重要，因为可以更快地部署解决方案。 专门的架构：AI硬件是专门为特定的AI工作负载而构建的，比如神经网络和深度学习算法。这种专门的架构确保了AI特定任务的有效执行，缺乏这种定制设计的常规硬件无法保证这一点。 能源效率：由于AI任务的耗电特性，AI硬件强调能源效率。它经过优化，可以使用更少的功率执行AI计算，延长设备的使用寿命并降低运营成本。 定制和适应性：常规硬件是通用的，但缺乏像ASIC和FPGA这样的AI硬件所能达到的定制水平。AI硬件的设计是为了满足特定的AI任务，提高性能和效率。 创业公司如何采用AI硬件 # 将AI硬件集成到运营中已经成为初创公司在数字领域的战略路径，可以增强运营并推动创新。让我们来探索一下初创公司如何利用AI硬件的力量。\n数据处理：初创公司使用GPU和TPU等AI硬件来加速数据处理和模型训练。这反过来又使他们能够更快地执行任务，迅速做出明智的决定，并创造出开箱即用的解决方案。 成本效益：AI硬件的并行处理能力使初创公司能够在利用更多资源的情况下完成更多任务。这最终有助于优化成本并产生更好的ROI。 定制：在创业公司的世界里，找到定制的解决方案通常是必要的。原因是每个企业都有不同的目标、需求和限制。因此，他们需要一个可以轻松定制的解决方案，使其适合他们的使用。这就是人工智能硬件发挥作用的时候。专用设计的组件，如ASIC和FPGA，很容易定制以匹配特定的AI工作负载。这提供了更高的操作效率并提高了性能。 边缘计算：许多初创公司都是关于边缘的，实时处理很重要。像神经形态芯片这样的AI硬件可以通过事件驱动的通信来满足这种需求。 创新促进：通过整合AI硬件，初创公司可以获得竞争优势。这项技术使他们能够开发创新的AI驱动产品和服务，使他们在市场上处于领先地位。 最佳AI硬件供应商 # 现在，让我们来看看市场上最好的AI硬件供应商。\n英伟达 # 英伟达是人工智能计算领域的全球领导者，凭借其创新的硬件，站在了改变行业的最前沿。它开创了加速计算，这是AI功能的一个不可或缺的概念。\n不再局限于图形，他们的GPU作为AI操作背后的大脑，驱动着推动其成功的计算。无论是为数据中心、云计算还是个人设备供电，英伟达的硬件都能为AI应用提供必要的计算能力。\n英伟达的尖端产品，如H100 GPU，是专门为解决复杂的AI任务而设计的，巩固了它们在AI硬件领域的关键作用。\n英特尔 # 英特尔提供广泛的AI硬件选择，从数据预处理到训练、推理和部署。无论您需要数据科学工作站还是先进的机器学习和深度学习工具，英特尔都可以简化AI部署的过程。\n其中一个突出的产品是他们的Xeon可扩展处理器，它提供加速的AI功能和增强的安全性，以便在全球数据中心轻松实施。\nGraphcore # Graphcore是一家创新公司，率先开发了一种专门为机器智能制作的新型处理器。IPU是专门为处理AI所需的复杂计算而设计的，超越了传统硬件，表现出非凡的性能。\nGraphcore全面的硬件和软件解决方案涵盖金融、医疗保健和科学研究等不同领域，使这些行业能够有效地利用AI的力量。\nCerebras # Cerebras通过其WSE(Wafer Scale Engine)对AI硬件做出了重大贡献。GPU集群在扩展深度学习中的传统使用通常需要大量的工程时间，这对许多希望利用大规模AI潜力的人构成了实际障碍。\nCerebras的WSE消除了这一障碍，它提供了一个集群规模的AI计算资源，与单个桌面机器一样容易编程。这意味着您可以使用-TensorFlow或PyTorch等标准工具，而无需进行复杂的调整。\nEdge TPU # Edge TPU由谷歌开发，是一款专用于在边缘运行AI的专用集成电路。\n由于考虑到隐私、延迟和带宽限制，在边缘设备上部署在云中训练的AI模型的需求日益增长，这种技术的出现是对这种需求的回应。\n凭借其紧凑的物理尺寸和低功耗要求，Edge TPU提供了卓越的性能，同时实现了高精度的AI部署。它不仅仅是一个硬件解决方案；它将定制硬件与开放式软件和先进的AI算法相结合。\nAmazon EC2 G4 Instances # 在探索AI硬件世界时，不要忘记考虑亚马逊EC2 G4 Instances，因为它也是行业中的重要参与者。\nG4 Instances提供了一种经济实惠且灵活的选择，这使得它们非常适合使用需要大量图形的机器学习模型和应用程序。它们是专门设计用来处理诸如图像分类、对象检测、语音再识别等任务的。\n您可以选择NVIDIA或AMD GPU，每个GPU都有自己独特的优势。因此，它可以成为你的AI硬件工具包中的一个有价值的工具。\nQualcomm # 高通无疑是无线技术领域的全球领导者，在AI硬件领域取得了重大进展。他们目前正在开发可应用于各种产品和行业的节能型AI技术。高通的AI解决方案带来了几个优势，比如用户隐私保护、可靠性提高和网络带宽的有效利用。\n凭借他们的AI引擎，高通正在推动互联智能边缘的进步。这意味着这些解决方案可以帮助增强不同设备的用户体验。\nAI硬件的进步和创新 # AI硬件行业正在经历快速发展和突破性创新，正在重塑AI的格局。让我们来看看这个动态领域的一些令人兴奋的进展。\nAI专用芯片：谷歌和苹果等科技巨头正在用创新的解决方案应对AI的复杂需求。他们正在通过率先开发专门用于执行AI任务的专用芯片来彻底改变这一领域。 神经形态计算：神经形态芯片提供了AI硬件领域的尖端技术。它们模拟了人类大脑复杂的神经连接，为前所未有的进步铺平了道路。这个新形态计算的新时代结合了效率和大脑启发的设计，塑造了一个AI可以达到令人难以置信的高度的未来。 量子计算：量子计算机处理复杂问题的潜力远远超过了传统计算机的能力。虽然我们正处于目睹量子计算在AI中的实际应用的初始阶段，但它将对AI硬件产生深远的影响。 边缘AI加速：边缘计算的兴起正被专门为实时、节能处理而设计的AI硬件加速。这一技术进步具有重要意义，特别是对于物联网传感器和可穿戴设备等设备。 存储创新：你熟悉AI算法的工作原理吗？它们可能非常占用内存，这意味着它们需要大量的存储空间。幸运的是，我们有创新的解决方案来解决这个问题。两种新兴的存储技术——电阻式RAM （ReRAM）和相变存储器（PCM）正在填补这一空白。 使用AI硬件的利弊 # 通过整合AI硬件，企业和行业可以有效地利用AI的力量。但重要的是要了解使用AI硬件的利弊。\n优点 # 增强的性能：AI硬件可以处理复杂的AI任务，与传统硬件相比，提供更快、更高效的处理。\n效率：一些AI芯片，如TPU和神经形态芯片，都是高效节能的。通过使用这些专门的芯片，可以节省费用，并对环境更友好。\n速度：AI硬件显著加快了数据处理和模型训练的速度，能够在各种场景中获得更快的见解并做出实时决策。\n解决复杂问题：量子计算是一种人工智能硬件，它以前所未有的速度解决复杂问题的能力令人难以置信。\n可扩展性：AI硬件可以适应和扩展，以适应与不断增长的数据量和不断发展的AI应用程序相关的不断增长的需求。\n缺点 # 成本：AI硬件的初始投资，包括开发、部署和维护成本，可能会很高。\n缺乏通用性：一些AI硬件，如ASIC，是针对特定任务进行优化的，限制了更广泛应用的通用性。\n复杂的实现：集成AI硬件需要专业知识和资源，这可能会给实施过程中的小型企业带来挑战。\n结论 # AI硬件具有颠覆不同行业的非凡能力。使用AI硬件执行繁重的AI任务对企业和个人都是有利的。它不仅可以提高效率，加快解决问题的速度，还可以创建可扩展的、未来的AI解决方案。\n随着AI硬件的发展，它有望在技术领域释放机会并突破界限。无论你是商业领袖，还是只是对技术感到好奇，了解AI硬件的各个方面，都能让你瞥见由创新技术引领的令人兴奋的未来。\n","date":"2024-11-23","externalUrl":null,"permalink":"/ai/a-brief-introduction-to-the-hardware-behind-ai/","section":"Ais","summary":"\u003cp\u003e创新的AI硬件有潜力推动卓越的能力，并彻底改变人们与技术和周围世界的互动方式。你有没有想过，一个比拇指指甲还小的芯片，是如何模仿人类思维过程的？AI背后的硬件是使这一切成为可能的动力，这是一个令人兴奋的事实。\u003c/p\u003e\n\u003cp\u003e当探索\u003ca href=\"https://www.kad8.com/ai/a-brief-introduction-to-the-hardware-behind-ai/\" target=\"_blank\"\u003eAI硬件\u003c/a\u003e世界时，我们将发现GPU， TPU和NPU如何强大地塑造AI的景观。\u003c/p\u003e\n\u003cp\u003e本文将讨论AI硬件的复杂性，它在推动现代创新中的关键作用、所使用的技术、优点和缺点、它们的使用以及其他细节。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e什么是AI硬件 \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFai%E7%A1%AC%E4%BB%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFai%E7%A1%AC%E4%BB%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eAI硬件由驱动AI技术的特殊部件组成。创建这些部分是为了管理识别模式、做出决策和分析数据所需的复杂计算。我们可以把它们想象成支撑AI大脑功能的强壮肌肉。\u003c/p\u003e","title":"人工智能背后的硬件简介","type":"ai"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/calyptra/","section":"Tags","summary":"","title":"Calyptra","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/rust/","section":"Tags","summary":"","title":"Rust","type":"tags"},{"content":"这篇文章主要介绍了Rust是如何进入计算机芯片的，以及为什么像英伟达、AMD、谷歌和微软这样的公司都在投资由Rust固件驱动的安全硬件。\n英伟达、AMD、谷歌和微软一直在悄悄开展一个名为calyptra的项目，这是一项安全计划，通过提供基于rust的关键信任根组件的实现，来强化计算机芯片以抵御黑客攻击。\n下面介绍什么是信任根，信任根（简称Ro）是一个独立的硬件安全组件，以及运行它的固件。它负责验证底层引导代码是真实的，没有被篡改。类似于你如何验证下载文件的校验和，以确保它们没有被篡改。\n如果没有 Ro， 你的计算机系统基本上就像一个前门没有锁的房子，黑客可以很容易地修改启动过程，这将允许他们绕过安全检查，安装恶意软件和病毒。即使你擦除硬盘驱动器并将计算机重置为出厂设置，黑客仍然可以对你的计算机系统进行控制。\n那么，为什么像英伟达和AMD这样的计算机芯片公司要合作开发一种新的基于Rust的信任根呢？\n当前的信任根实现存在三个主要问题：\n首先是碎片化问题，不同的硬件平台有不同的Ro实现，这会导致安全功能不一致，并且很难在不同设备之间实现统一的安全性。 其次是透明度的问题，传统的Ro实现都是黑盒子，你可以看到输入和输出，但是你看不到里面是什么。这使得审计和验证其安全性变得困难。 第三，数据中心需要一个信任的根源解决方案，不仅安全，而且在分布式环境中具有高度可扩展性和可管理性，这一点尤其重要，因为人工智能推动了对更多基础设施的需求。 而这三个挑战正是calyptra想要解决的，那么Rust是如何融入这一切的呢？calyptra提供了两件事：首先是RO硬件设计的知识产权，包括cpu、gpu、dpu等，其次是calyptra提供开源固件来管理硬件。\n如果我们看一下固件仓库，我们可以看到代码是用Rust编写的，这一点也不奇怪，微软已经在另一个专有的Ro实现中使用了Rust，叫做pluton， Azure的CTO也非常直言不讳地说要在云基础设施中使用Rust而不是C++，谷歌已经使用Rust开发底层的Android软件。\n通过使用Rust，calyptra 显著减少了内存安全漏洞，旨在创建一个更健壮、更安全、可维护的信任根实现，该项目与增强现代计算机环境安全性的目标非常吻合。\n据报道，谷歌和微软计划最快在2024年在他们自己的芯片上实现calyptra。AMD的目标是在2026年实现产品集成，这意味着我们可以在未来几年内在AMD的服务器和消费芯片上看到基于calyptra的安全功能。\n现在，当calyptra在计算机芯片安全领域掀起波浪时，rust也获得了关注。在嵌入式系统的其他领域，特别是汽车行业，梅赛德斯-奔驰、宝马、丰田、福特、博世和大众都在使用rust。\n在最近一篇关于沃尔沃使用rust的文章中，沃尔沃汽车的一位首席工程师说，他们使用rust来实现ECU芯片的固件。这些芯片是管理汽车电气系统各个方面的关键部件，这不仅仅是一些概念上的证明，这些使用rust开发的芯片的动力汽车已经上路了，沃尔沃的ex90和pstar 3车型就是这些例子。\n事实上，嵌入式软件是rust的核心应用领域之一，Rust在嵌入式系统中的使用会继续显著增长。\n","date":"2024-11-23","externalUrl":null,"permalink":"/software/rust-is-secretly-taking-over-chip-development/","section":"Softwares","summary":"\u003cp\u003e这篇文章主要介绍了\u003ca href=\"https://www.gaitpu.com/os/vxworks/using-rust-in-vxworks7\" target=\"_blank\"\u003eRust\u003c/a\u003e是如何进入计算机芯片的，以及为什么像英伟达、AMD、谷歌和微软这样的公司都在投资由Rust固件驱动的安全硬件。\u003c/p\u003e\n\u003cp\u003e英伟达、AMD、谷歌和微软一直在悄悄开展一个名为calyptra的项目，这是一项安全计划，通过提供基于rust的关键信任根组件的实现，来强化计算机芯片以抵御黑客攻击。\u003c/p\u003e\n\u003cp\u003e下面介绍什么是信任根，信任根（简称Ro）是一个独立的硬件安全组件，以及运行它的固件。它负责验证底层引导代码是真实的，没有被篡改。类似于你如何验证下载文件的校验和，以确保它们没有被篡改。\u003c/p\u003e\n\u003cp\u003e如果没有 Ro， 你的计算机系统基本上就像一个前门没有锁的房子，黑客可以很容易地修改启动过程，这将允许他们绕过安全检查，安装恶意软件和病毒。即使你擦除硬盘驱动器并将计算机重置为出厂设置，黑客仍然可以对你的计算机系统进行控制。\u003c/p\u003e\n\u003cp\u003e那么，为什么像英伟达和AMD这样的计算机芯片公司要合作开发一种新的基于Rust的信任根呢？\u003c/p\u003e\n\u003cp\u003e当前的信任根实现存在三个主要问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e首先是碎片化问题，不同的硬件平台有不同的Ro实现，这会导致安全功能不一致，并且很难在不同设备之间实现统一的安全性。\u003c/li\u003e\n\u003cli\u003e其次是透明度的问题，传统的Ro实现都是黑盒子，你可以看到输入和输出，但是你看不到里面是什么。这使得审计和验证其安全性变得困难。\u003c/li\u003e\n\u003cli\u003e第三，数据中心需要一个信任的根源解决方案，不仅安全，而且在分布式环境中具有高度可扩展性和可管理性，这一点尤其重要，因为人工智能推动了对更多基础设施的需求。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e而这三个挑战正是calyptra想要解决的，那么Rust是如何融入这一切的呢？calyptra提供了两件事：首先是RO硬件设计的知识产权，包括cpu、gpu、dpu等，其次是calyptra提供开源固件来管理硬件。\u003c/p\u003e\n\u003cp\u003e如果我们看一下固件仓库，我们可以看到代码是用Rust编写的，这一点也不奇怪，微软已经在另一个专有的Ro实现中使用了Rust，叫做pluton， Azure的CTO也非常直言不讳地说要在云基础设施中使用Rust而不是C++，谷歌已经使用Rust开发底层的Android软件。\u003c/p\u003e\n\u003cp\u003e通过使用Rust，calyptra 显著减少了内存安全漏洞，旨在创建一个更健壮、更安全、可维护的信任根实现，该项目与增强现代计算机环境安全性的目标非常吻合。\u003c/p\u003e\n\u003cp\u003e据报道，谷歌和微软计划最快在2024年在他们自己的芯片上实现calyptra。AMD的目标是在2026年实现产品集成，这意味着我们可以在未来几年内在AMD的服务器和消费芯片上看到基于calyptra的安全功能。\u003c/p\u003e\n\u003cp\u003e现在，当calyptra在计算机芯片安全领域掀起波浪时，rust也获得了关注。在嵌入式系统的其他领域，特别是汽车行业，梅赛德斯-奔驰、宝马、丰田、福特、博世和大众都在使用rust。\u003c/p\u003e\n\u003cp\u003e在最近一篇关于沃尔沃使用rust的文章中，沃尔沃汽车的一位首席工程师说，他们使用rust来实现ECU芯片的固件。这些芯片是管理汽车电气系统各个方面的关键部件，这不仅仅是一些概念上的证明，这些使用rust开发的芯片的动力汽车已经上路了，沃尔沃的ex90和pstar 3车型就是这些例子。\u003c/p\u003e","title":"Rust正在秘密接管芯片开发","type":"software"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/software/","section":"Softwares","summary":"","title":"Softwares","type":"software"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/hardware/","section":"Hardwares","summary":"","title":"Hardwares","type":"hardware"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/raid-5/","section":"Tags","summary":"","title":"Raid 5","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/raid-6/","section":"Tags","summary":"","title":"Raid 6","type":"tags"},{"content":"RAID5 和 RAID6 是两种最常见的 RAID 配置，它们通过冗余数据的方式提供容错能力。然而，两者在数据安全性方面存在显著的差异。本文将详细分析 RAID5 和 RAID6 的数据安全性，并为选择哪种技术提供参考依据。\nRAID5 和 RAID6 的基本原理 # RAID5 原理 # RAID5 是一种基于块级条带化（striping）的磁盘阵列，它将数据和奇偶校验数据分散存储在多个硬盘上。\nRAID5 至少需要 3 块磁盘，具有以下特点：\n数据和校验分散存储：RAID5 不像 RAID1 那样直接复制整个数据，而是将每个数据块和相应的校验数据分散到所有磁盘中。每个条带的奇偶校验信息存储在一个磁盘上，但这一块磁盘会轮流变化。 奇偶校验（Parity）：RAID5 通过奇偶校验技术保护数据。在任意一个磁盘损坏的情况下，剩下的磁盘可以通过校验数据恢复丢失的数据。 RAID5 的最大优势在于它提供了较高的存储利用率，同时能容忍单一磁盘故障。然而，RAID5 只能在一个磁盘损坏时进行数据恢复，第二个磁盘损坏将导致数据丢失。\nRAID6 原理 # RAID6 是 RAID5 的扩展版本，与 RAID5 类似，它也使用块级条带化和奇偶校验，但增加了第二个校验块，因此可以同时应对两块磁盘的故障。\nRAID6 至少需要 4 块磁盘。其特点包括：\n双奇偶校验：RAID6 使用两种独立的校验算法生成两组校验数据（P 和 Q），这两组校验数据存储在不同的磁盘上。通过双重校验，RAID6 能在两块磁盘同时故障时恢复数据。 提高容错能力：与 RAID5 相比，RAID6 的容错能力显著提升，能够防止第二个磁盘在修复第一个磁盘时出现故障导致的数据丢失。 RAID6 提供更高的安全性，但代价是写入性能的下降和较高的计算复杂性。\n数据安全性对比：RAID5 和 RAID6 # 数据冗余与容错能力 # RAID 的核心功能之一是数据冗余，通过存储校验信息，在磁盘故障时恢复数据。对于 RAID5 和 RAID6，两者的容错机制有所不同：\nRAID5：通过奇偶校验保护数据，能够容忍单个磁盘故障。在一个磁盘故障后，RAID5 会通过校验信息重新生成丢失的数据块。然而，如果第二块磁盘在修复过程中损坏，则会导致整个阵列的数据丢失。 RAID6：增加了第二个校验块，能够同时容忍两块磁盘故障。在 RAID6 中，即使在修复一个故障磁盘时，另一块磁盘也损坏，系统仍然可以通过剩余的校验数据恢复数据。这使得 RAID6 在应对多块磁盘故障时显著优于 RAID5。 在数据冗余和容错能力方面，RAID6 明显更具优势。它提供了双重数据校验，可以应对双磁盘故障，这是 RAID5 无法实现的。因此，RAID6 在面对大容量磁盘和多磁盘系统时，能够提供更高的数据安全性。\n重建过程中面临的风险 # RAID 阵列的一个关键问题是磁盘重建过程中的数据安全性。在磁盘故障后，系统需要通过校验数据重建丢失的数据块。然而，这一过程可能耗费较长时间，尤其是在使用大容量磁盘时，重建时间可能达到数小时甚至数天。在此期间，阵列的容错能力大大下降，系统处于高风险状态。\nRAID5：在重建过程中，如果另一块磁盘故障，整个 RAID 阵列将崩溃，导致数据不可恢复。因此，在重建期间，RAID5 面临着较大的数据丢失风险。 RAID6：由于其可以同时容忍两块磁盘故障，即使在重建过程中出现第二块磁盘故障，RAID6 仍能保证数据的完整性。重建过程中的安全性显著提升。 因此，随着磁盘容量的增加，RAID5 在重建过程中的风险显著增加，而 RAID6 则能够更好地应对这一挑战，确保数据安全。\nURE（不可恢复读取错误） # 随着磁盘容量的不断增加，URE（不可恢复读取错误，Unrecoverable Read Error）成为 RAID 数据安全中的一个关键问题。URE 指的是在磁盘读取过程中发生无法纠正的错误，通常以每读取10的14次方或16次方位的读取操作来描述。\nRAID5：如果在数据重建时遇到 URE 错误，重建过程将会失败，导致数据无法恢复。因此，RAID5 尤其容易受到 URE 影响，特别是在大容量磁盘和高密度数据存储环境中。 RAID6：由于 RAID6 提供双校验，遇到 URE 错误时仍有足够的信息进行数据恢复，因此对 URE 的容忍度更高。 随着磁盘技术的发展和容量的增加，URE 错误的概率逐渐上升，这使得 RAID6 在抵御 URE 错误时更为可靠。\n磁盘容量与数据安全性 # 磁盘容量的增长直接影响到 RAID 系统的重建时间、故障风险以及 URE 错误的概率。近年来，企业级存储逐渐转向大容量磁盘（例如 10TB、20TB 或更高），这对 RAID5 的数据安全性提出了严峻的挑战。\nRAID5：在大容量磁盘中，RAID5 的数据重建时间会显著增加，且重建过程中的数据丢失风险增加。随着磁盘容量的增长，RAID5 在数据安全性方面的劣势更加明显。 RAID6：尽管 RAID6 在磁盘重建过程中也面临重建时间长的问题，但其双校验机制使其在面对大容量磁盘时更加安全。 因此，对于大容量磁盘，RAID6 提供了更可靠的解决方案，能够有效减少因磁盘容量增加带来的故障风险。\nRAID5 和 RAID6 性能对比 # 读写性能 # RAID5 和 RAID6 在读写性能上有显著差异，特别是在写入操作时，RAID6 因为多了一个校验块，写入速度较 RAID5 更慢。\nRAID5：RAID5 的读取性能较好，因为数据块可以分布在多个磁盘上并行读取。写入操作时，由于需要计算奇偶校验信息并将其写入磁盘，因此写入速度相对较慢，但整体性能仍然优于 RAID6。 RAID6：由于 RAID6 需要同时生成两个校验块（P 和 Q），写入操作的计算复杂度增加，因此写入性能较 RAID5 更低。尤其在处理大量小数据块的随机写入时，RAID6 的写入速度会显著下降。 在对性能要求较高的环境中，如果以读取为主，RAID5 和 RAID6 的差别不大，但在频繁写入操作的场景中，RAID6 的写入性能可能成为瓶颈。\nRAID 控制器复杂度 # RAID6 的双校验计算要求 RAID 控制器具备更高的处理能力。因此，与 RAID5 相比，RAID6 对 RAID 控制器的要求更高，成本也相对较高。在某些情况下，较复杂的 RAID 控制器可能会增加系统的成本和维护难度。\n硬盘利用率 # 硬盘利用率是指可用于存储实际数据的磁盘空间占总磁盘空间的比例。\nRAID5：硬盘利用率为 (n-1)/n，其中 n 为总磁盘数量。即在使用 8 块磁盘的情况下，RAID5 的硬盘利用率为 (n-1)/n，即 87.5% 的存储空间用于数据存储，其余部分用于存储奇偶校验数据。在磁盘数量较少时，RAID5 的硬盘利用率较高。 RAID6：硬盘利用率为 (n-2)/n，即两块磁盘空间用于存储校验数据。例如，使用 8 块磁盘时，RAID6 的硬盘利用率为 75%。因此，RAID6 的硬盘利用率相对 RAID5 较低，因为它需要额外的一个校验磁盘空间来存储第二组校验信息。 从硬盘利用率的角度来看，RAID5 优于 RAID6，特别是在磁盘数量较少时。但随着磁盘数量的增加，RAID6 的利用率损失相对较小，而其提供的额外容错能力能够有效弥补这一劣势。\n成本与复杂性对比 # 硬件成本 # RAID6 在硬件成本上通常高于 RAID5，主要体现在以下几个方面：\n磁盘需求：RAID6 需要至少 4 块磁盘，而 RAID5 仅需要 3 块磁盘。同时，随着磁盘数量增加，RAID6 的校验磁盘占用更多的存储空间，这意味着在相同存储容量下，RAID6 需要更多的磁盘。 RAID 控制器成本：RAID6 的双校验计算需要更高性能的 RAID 控制器，因此 RAID6 配置的系统成本往往高于 RAID5。 维护成本 # RAID5 和 RAID6 在维护上的主要差异体现在重建过程的复杂性和时间成本上：\nRAID5：由于其只能容忍单磁盘故障，一旦某块磁盘出现故障，必须尽快进行重建。如果重建期间再次发生磁盘故障，整个 RAID5 阵列将崩溃。因此，RAID5 在维护过程中要求更快的响应速度，以减少多磁盘故障的风险。 RAID6：能够容忍两块磁盘故障，维护人员在发现单块磁盘故障后，拥有更多时间进行修复，降低了紧急维护的压力。 因此，RAID6 在维护上相对更为简单和安全，但由于更复杂的控制器和较高的磁盘需求，维护成本也会更高。\nRAID5 和 RAID6 哪个更安全 # 在数据安全性方面，RAID6 明显优于 RAID5。主要体现在以下几点：\n容错能力：RAID6 由于双校验的设计，能够同时容忍两块磁盘故障，而 RAID5 只能容忍一块磁盘故障。因此，在面对多磁盘故障时，RAID6 提供了更高的数据安全性。 重建过程中风险：RAID5 在重建过程中，如果发生第二块磁盘故障，整个阵列会崩溃。而 RAID6 能够在重建期间继续容忍第二块磁盘故障，显著降低了数据丢失的风险。 URE 错误：随着磁盘容量的增加，URE 错误的风险增大。RAID6 对 URE 错误的容忍度更高，因此更适合大容量存储系统。 应用场景：RAID6 更适合大容量、高密度存储系统，特别是在需要长时间重建或关键数据保护的场景下。而 RAID5 则更适合中小型企业和以读取为主的应用。 然而，RAID6 的安全性优势是以牺牲部分性能和存储利用率为代价的。在选择 RAID5 还是 RAID6 时，用户需要根据具体的应用场景、数据安全性要求、系统性能以及成本预算做出权衡。如果系统需要更高的容错能力和更好的数据保护，RAID6 是更安全的选择；而如果预算有限且对容错要求相对较低，RAID5 也可以提供不错的性能和数据冗余。\n总之，RAID5 和 RAID6 各有优劣，在数据安全性和成本之间取得平衡是选择它们的关键。\n","date":"2024-11-23","externalUrl":null,"permalink":"/hardware/comparison-between-raid-5-and-raid-6/","section":"Hardwares","summary":"\u003cp\u003eRAID5 和 RAID6 是两种最常见的 \u003ca href=\"https://www.gaitpu.com/data-center/storage/how-to-replace-disks-for-raid\" target=\"_blank\"\u003eRAID 配置\u003c/a\u003e，它们通过冗余数据的方式提供容错能力。然而，两者在数据安全性方面存在显著的差异。本文将详细分析 RAID5 和 RAID6 的数据安全性，并为选择哪种技术提供参考依据。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eRAID5 和 RAID6 的基本原理 \n    \u003cdiv id=\"raid5-%E5%92%8C-raid6-%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#raid5-%E5%92%8C-raid6-%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\n\n\u003ch3 class=\"relative group\"\u003eRAID5 原理 \n    \u003cdiv id=\"raid5-%E5%8E%9F%E7%90%86\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#raid5-%E5%8E%9F%E7%90%86\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003eRAID5 是一种基于块级条带化（striping）的磁盘阵列，它将数据和奇偶校验数据分散存储在多个硬盘上。\u003c/p\u003e","title":"RAID5和RAID6的对比","type":"hardware"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/altera/","section":"Tags","summary":"","title":"Altera","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/lattice/","section":"Tags","summary":"","title":"Lattice","type":"tags"},{"content":"知情人士透露，莱迪思半导体公司 (Lattice Semiconductor Corp.) 正考虑对英特尔公司旗下的 Altera 发出全部收购要约，这一变化可能会使英特尔出售该部门少数股权的计划变得复杂。\n据不愿透露姓名的知情人士透露，总部位于俄勒冈州希尔斯伯勒的 Lattice 公司正在与顾问合作并寻求私募股权支持者，以探索潜在的收购机会。\n知情人士称，Francisco Partners、贝恩资本和银湖资本等收购公司也一直在研究对 Altera 的投资意向。他们还补充道，Altera 还可能吸引其他半导体公司的兴趣。\n知情人士称，对 Altera 的收购要约将于下周周四美国感恩节假期之前提出。\n由于收购方规模相对较小，莱迪思控制 Altera 的任何尝试都可能很难实现。莱迪思的市值为 74.8 亿美元，不到英特尔 2015 年收购 Altera 时支付的约 170 亿美元盈亏平衡所需金额的一半。\n据知情人士透露，收购 Altera 股份的报价可能需要经过严格结构化，Altera 的多用途芯片主要部署在电信网络中。知情人士称，私募股权公司正在考虑投资约 30 亿美元，可能以结构化工具的形式进行。他们表示，这可能导致估值低于英特尔收购 Altera 时支付的价格。\n总部位于加州圣克拉拉的英特尔上个月重申，它将考虑将 Altera 的部分股份出售给投资者，然后再进行首次公开募股 (IPO)——这是该芯片制造商扭转业务局面的更广泛计划的一部分。\n据知情人士透露，英特尔本周将召开例行董事会，Altera 的未来是会议议程之一。他们表示，英特尔更愿意出售 Altera 的少数股权，而不是整个部门。\n英特尔首席执行官帕特·基辛格 (Pat Gelsinger) 表示，公司计划于明年初完成 Altera 业务的收购，同时还在评估其他产品组合的选择。\n知情人士称，审议仍在进行中，目前还不确定莱迪思或任何私募股权公司是否会决定继续对 Altera 提出收购要约。\n英特尔、Francisco Partners、贝恩资本和银湖资本的代表均拒绝置评。莱迪思的发言人没有回应置评请求。路透社早些时候报道了这三家私募股权公司对此表示感兴趣。\nLattice 的首席执行官是福特·塔默 (Ford Tamer)，他是一位经验丰富的半导体运营商，曾担任 Inphi Corp. 的总裁兼首席执行官，直至该公司与 Marvell Technology Inc. 的合并（于 2021 年完成）。他还与 Francisco Partners 有合作关系，曾在那里担任高级运营合伙人，今年 9 月加入 Lattice。\n","date":"2024-11-23","externalUrl":null,"permalink":"/hardware/lattice-semiconductor-considers-acquiring-altera/","section":"Hardwares","summary":"\u003cp\u003e知情人士透露，莱迪思半导体公司 (Lattice Semiconductor Corp.) 正考虑对英特尔公司旗下的 Altera 发出全部收购要约，这一变化可能会使英特尔出售该部门少数股权的计划变得复杂。\u003c/p\u003e\n\u003cp\u003e据不愿透露姓名的知情人士透露，总部位于俄勒冈州希尔斯伯勒的 Lattice 公司正在与顾问合作并寻求私募股权支持者，以探索潜在的收购机会。\u003c/p\u003e\n\u003cp\u003e知情人士称，Francisco Partners、贝恩资本和银湖资本等收购公司也一直在研究对 Altera 的投资意向。他们还补充道，\u003ca href=\"https://www.vxworks.net/fpga/1179-introduction-to-fpga-chip-manufacturers\" target=\"_blank\"\u003eAltera\u003c/a\u003e 还可能吸引其他半导体公司的兴趣。\u003c/p\u003e\n\u003cp\u003e知情人士称，对 Altera 的收购要约将于下周周四美国感恩节假期之前提出。\u003c/p\u003e\n\u003cp\u003e由于收购方规模相对较小，莱迪思控制 Altera 的任何尝试都可能很难实现。莱迪思的市值为 74.8 亿美元，不到英特尔 2015 年收购 Altera 时支付的约 170 亿美元盈亏平衡所需金额的一半。\u003c/p\u003e","title":"重磅，Lattice考虑收购Altera","type":"hardware"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/almalinux-9.5/","section":"Tags","summary":"","title":"AlmaLinux 9.5","type":"tags"},{"content":"AlmaLinux 是一个免费的开源企业级 Linux 发行版，由社区主导，旨在提供 Red Hat Enterprise Linux (RHEL) 的完全兼容替代品。它的特点包括稳定性、高性能和对企业环境的支持，同时提供与 RHEL 一致的功能和体验。\nAlmaLinux 的核心特点： # 社区驱动: 由 AlmaLinux OS 基金会维护，确保其开发和决策的开放透明 与 RHEL 的兼容性: 提供 1:1 的二进制兼容性，这意味着用户可以在不修改现有 RHEL 应用程序的情况下迁移到 AlmaLinux 多架构支持: 支持 x86_64、ARM64、IBM PowerPC 和 IBM Z 等主流硬件架构 企业级特性: 稳定的更新周期和长期支持 丰富的开发工具和安全增强功能 适用场景：从服务器、云计算到容器化应用，覆盖多种使用场景 历史背景 # AlmaLinux 起源于 CentOS 项目方向调整后，为满足用户对稳定性和开源的需求而创建。2021 年初首次发布，逐渐成为许多企业迁移 CentOS 后的首选。\nAlmaLinux 9.5 # AlmaLinux 9.5（代号Teal Serval）最近发布，为开发者和企业用户带来了显著的更新和增强。该版本基于 Red Hat Enterprise Linux (RHEL) 9.5，包含以下主要特点：\n关键功能： # 更新的内核和架构支持 使用 Linux Kernel 5.14 支持多种架构，包括 x86_64、ARM64、IBM PowerPC (ppc64le) 和 IBM Z (s390x) 增强的开发工具 更新了编译器工具集：GCC Toolset 14、LLVM Toolset 18.1、Rust Toolset 1.79 和 Go Toolset 1.22 性能调试工具更新：包括 GDB 14.2、Valgrind 3.23.0 和 SystemTap 5.1 应用流刷新 包括 Apache HTTP Server 2.4.62 和 Node.js 22 的新版本 引入了 .NET 9.0 和 BIND 9.18（DNS 服务） 安全性改进 OpenSSL 升级至 3.2.2，支持证书压缩和新的加密算法 SELinux 政策更新，增强了 QEMU 客户代理的安全配置 这些更新进一步巩固了 AlmaLinux 作为企业级环境中强大、开源替代品的地位，同时保持了与 RHEL 的 1:1 二进制兼容性。\n用户可通过运行命令 sudo dnf upgrade -y 将 9.x 系列升级到最新版本。更多详情请参阅官方发布说明或社区讨论。\n","date":"2024-11-23","externalUrl":null,"permalink":"/software/almalinux-9-5-released/","section":"Softwares","summary":"\u003cp\u003eAlmaLinux 是一个免费的开源企业级 Linux 发行版，由社区主导，旨在提供 Red Hat Enterprise Linux (RHEL) 的完全兼容替代品。它的特点包括稳定性、高性能和对企业环境的支持，同时提供与 RHEL 一致的功能和体验。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eAlmaLinux 的核心特点： \n    \u003cdiv id=\"almalinux-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#almalinux-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e社区驱动: 由 \u003ca href=\"https://www.kad8.com/software/almalinux-9-5-released/\" target=\"_blank\"\u003eAlmaLinux\u003c/a\u003e OS 基金会维护，确保其开发和决策的开放透明\u003c/li\u003e\n\u003cli\u003e与 RHEL 的兼容性: 提供 1:1 的二进制兼容性，这意味着用户可以在不修改现有 RHEL 应用程序的情况下迁移到 AlmaLinux\u003c/li\u003e\n\u003cli\u003e多架构支持: 支持 x86_64、ARM64、IBM PowerPC 和 IBM Z 等主流硬件架构\u003c/li\u003e\n\u003cli\u003e企业级特性:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e稳定的更新周期和长期支持\u003c/li\u003e\n\u003cli\u003e丰富的开发工具和安全增强功能\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003e适用场景：从服务器、云计算到容器化应用，覆盖多种使用场景\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e历史背景 \n    \u003cdiv id=\"%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eAlmaLinux 起源于 \u003ca href=\"https://www.vxworks.net/news/1035-the-centos-project-claims-to-be-open-to-all\" target=\"_blank\"\u003eCentOS\u003c/a\u003e 项目方向调整后，为满足用户对稳定性和开源的需求而创建。2021 年初首次发布，逐渐成为许多企业迁移 CentOS 后的首选。\u003c/p\u003e","title":"AlmaLinux 9.5 重磅发布","type":"software"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/gb200/","section":"Tags","summary":"","title":"GB200","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/nvidia/","section":"Tags","summary":"","title":"Nvidia","type":"tags"},{"content":"今天，在超级计算 2024 大会上，许多公司宣布了他们最新的 AI、HPC 和超级计算产品。这些公司中首屈一指的当然是 N​​VIDIA，该公司最重大的新产品发布是 GB200 NVL4。不过，我们稍后会了解 GB200 NVL4 是什么；首先，让我们谈谈绿色团队还宣布用于 AI 和 HPC 应用的 H200 NVL。\nH200 NVL 是 PCIe 附加卡，带有 H200 Hopper 加速器，顶部带有 NVLink 连接器。这样你就可以使用 NVLink 桥接器——就像我们以前对 SLI 显卡所做的那样——重点是使用 900 GB/秒的 NVLink 连接可以让最多四个 GPU 保持内存一致性，换句话说，你可以将所有四个 GPU 的内存组合成一个大池，而不必复制每张卡本地内存中的数据来处理它。\nNVIDIA 将 H200 NVL 描述为“主流企业服务器的 AI 加速”，并表示四个 GPU（每个 GPU 有 141 GB 的 RAM）的封装将“适合任何数据中心”。正如 NVIDIA 自己指出的那样，超过 70% 的企业部署都是风冷的，功率低于 20 千瓦，这使得部署大量夹层 GPU（如 H200 的 SXM 版本）变得更加困难。因此，我们有这些 600W GPU 用于标准 PCIe 插槽。\nNVIDIA 的全新 GB200 NVL4 模块 # 既然我们已经讨论了 H200 NVL，那么让我们来谈谈 GB200 NVL4。GB200 NVL4 几乎是 H200 NVL 的典型对立面——它将两个 Grace CPU 和四个 Blackwell B200 GPU，以及每个处理器的各自内存和电源传输硬件组合到单个 PCB 上。每个处理器都通过 NVLink 连接到所有其他处理器，总共提供 768GB 的​​ HBM3 内存。与 Grace CPU 的 960GB LPDDR5X RAM 相结合，每个主板总共有 1.5TB 的 RAM。\n虽然与现有的 GB200 超级芯片相比，这似乎是一种更优越的解决方案，因为它本质上是两个连接在一起的，但有一个关键的区别，那就是 GB200 NVL4 没有板外 NVLink 功能。GB200 超级芯片可以与其他 GB200 超级芯片一起部署，形成一种超级 GPU，使用板之间的 NVLink 连接来保持内存一致性。\nGB200 NVL4 没有这种能力。相反，板外通信由 Infiniband 或以太网处理，可能是 NVIDIA 自己的 Spectrum-X 以太网。如果我们要推测，这可能是 NVIDIA 为更好地与拥有自己的互连技术的 HPC 提供商（如 HPE）集成而采取的举措。\n不过，这些 GPU 的功能并不比原来的 GB200 弱。 GB200 NVL4 的总板功率预计为 5,400 瓦，即 5.4 千瓦。将其中几个放在机架中，您就已经突破了 20 千瓦的障碍。NVIDIA 表示，与 GH200 NVL4 部件相比，GB200 NVL4 板的模拟能力提升了 120%，AI 训练和推理工作负载提升了 80%。\nNVIDIA 在 Supercomputing 2024 上发布了许多其他公告，但它们大多是涵盖广泛市场和用例的软件更新。如果您是 AI 开发人员，您可能已经知道它们，但可以说最大的一个是 NVIDIA 有一个流行的 NumPy 库的嵌入式 GPU 加速替代品，称为 CuPyNumeric，它声称为 SLAC 国家加速器实验室的数值分析提供了 6 倍的性能提升。\nNVIDIA 强调，其发布周期为一年，明年计划发布 Blackwell Ultra，这是现有 Blackwell GPU 的修订版，板载 HBM3e 内存增加了一倍，并含糊地承诺“更多 AI FLOPS”。明年显然还会发布升级的网络硬件，而我们显然会在 2026 年看到 Grace 和 Blackwell 的继任者，即 Vera CPU 和 Rubin GPU。\n","date":"2024-11-23","externalUrl":null,"permalink":"/ai/nvidia-unveils-quad-blackwell-dual-grace-gb200-nvl4/","section":"Ais","summary":"\u003cp\u003e今天，在超级计算 2024 大会上，许多公司宣布了他们最新的 \u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI\u003c/a\u003e、HPC 和超级计算产品。这些公司中首屈一指的当然是 N​​VIDIA，该公司最重大的新产品发布是 GB200 NVL4。不过，我们稍后会了解 GB200 NVL4 是什么；首先，让我们谈谈绿色团队还宣布用于 AI 和 HPC 应用的 H200 NVL。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./nvidia-gb200-nvl4-2.png\" alt=\"Nvidia Blackwell GB200 NVL4\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"NVIDIA 发布四核 Blackwell GB200的NVL4","type":"ai"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/nvl4/","section":"Tags","summary":"","title":"NVL4","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/fbnic/","section":"Tags","summary":"","title":"FBNIC","type":"tags"},{"content":"2024年OCP（开放计算项目）峰会上，Marvell和Meta联合展示了一款全新的Meta FBNIC 4x 100G多主机适配器。\n这款产品是Meta对网络硬件控制的一次重大尝试，标志着 Meta 涉足网络适配器 ASIC 领域，具有里程碑意义。Meta FBNIC 采用多主机设计和 OCP NIC 3.0 标准，具备高效散热等技术特色，适用于 Meta 的大规模数据中心部署，可降低硬件成本及功耗。\n这种合作模式可能冲击传统网络硬件供应商，引领数据中心网络适配器技术演进，推动行业迈向高密度、低成本网络架构，这也是 Meta 硬件自主化进程的重要一步，可能引发其他互联网巨头加速硬件自主化步伐，推动全球数据中心硬件架构变革。\nMeta 与 Marvell 的合作有望成为数据中心硬件行业风向标。\nMeta FBNIC的诞生背景：\nMeta与Marvell的联合开发 # Meta在数据中心建设和网络硬件领域的快速发展，使其对高性能网络适配器的需求不断上升。Meta选择与Marvell合作开发Meta FBNIC，这不仅是Meta进一步掌控数据中心硬件供应链的举措，也是Marvell拓展高端网络适配器市场的契机。\nMeta FBNIC的推出标志着Meta首次涉足网络适配器ASIC（专用集成电路）领域，具备显著的里程碑意义。通过定制网络适配器ASIC，Meta希望优化适配器的性能，以满足其独特的数据中心需求。\n这也为Marvell带来了重要的技术合作机会，帮助其进一步提升自身在网络硬件领域的市场地位。\nMeta FBNIC采用了4x 100G多主机设计，适配器最多可连接四个主机，每个主机可以支持100Gbps的带宽，提升了网络适配器的资源利用效率，尤其适合Meta的大规模数据中心架构。\nOCP NIC 3.0标准： Meta FBNIC遵循OCP NIC 3.0标准，采用紧凑的SFF外形并带有弹出闩锁设计。OCP NIC 3.0的设计允许用户从机箱前端方便地移除或更换NIC，这极大地提高了数据中心的维护效率。\n该标准的普及推动了数据中心硬件的模块化与标准化，促进了其与其他OCP成员企业的兼容性。\nPCIe Gen5 x4连接： Meta FBNIC在设计上配备了最多四条PCIe Gen5 x4连接，保证每台主机的100Gbps传输速度。\n这使得适配器在高并发、高流量的工作负载下仍然能够稳定、高效地运行，满足了Meta数据中心日益增长的数据传输需求。\n高效散热设计： Meta FBNIC使用了大型散热器，特别是在光学笼上，通过增强的冷却效果来适应严苛的工作环境。\n这表明Meta对适配器在气流和环境温度方面提出了更高的耐受性要求，多主机适配器的散热需求较高。高效的散热设计是保障适配器在高性能条件下长期稳定运行的关键。\nMeta FBNIC的应用场景：\n数据中心的多主机适配器 # Meta FBNIC设计之初即面向Meta的大规模数据中心部署。\nMeta的数据中心通常需要数以万计的网络适配器，通过提升每块适配器的连接密度，Meta可以显著减少适配器的数量，从而降低硬件成本及功耗。\n传统的单主机适配器逐渐暴露出空间占用大、维护成本高的问题。 Meta FBNIC通过“一卡多主机”的创新模式，实现了资源整合和空间节省。 其多主机设计尤其适合服务器密集的机架部署，不仅能够提升带宽利用率，还能降低整体维护成本。\nMeta FBNIC是Meta和Marvell合作的产物，Meta摆脱对传统网络硬件供应商依赖的一个重要转折。\nMeta通过Meta FBNIC的开发展示了其自主设计网络硬件的实力，预计将对传统网络硬件供应商产生一定冲击，也或许会促使更多互联网巨头效仿Meta的硬件策略。\n此项目将帮助Marvell进一步进入互联网数据中心市场，并借此强化自身在高性能NIC领域的技术积累和市场竞争力。\nMarvell可以利用Meta FBNIC这一产品展示其在高带宽、低延迟多主机适配器方面的研发能力，为未来拓展数据中心市场奠定基础。\nMeta FBNIC的推出体现了多主机适配器在数据中心的广阔应用前景，多主机适配器在硬件成本、能效和空间利用率等方面具有显著优势，将引领数据中心网络适配器的技术演进，并带动整个网络硬件市场的发展。\n随着数据中心流量的急剧增长，多主机适配器的发展需求愈发迫切。特别是对于云计算和互联网巨头而言，如何高效管理网络资源、优化网络硬件性能已成为关键挑战之一。Meta FBNIC的成功或将促使更多企业关注多主机适配器，预计这一技术将加速普及，推动整个行业迈向高密度、低成本的网络架构。\nMeta FBNIC的发布不仅是一项硬件创新，也是Meta硬件自主化进程中的重要一步。\nMeta通过设计并部分生产自身所需的关键硬件，从而降低对第三方供应商的依赖，这一策略在技术和成本方面均具有显著的优势。未来，Meta或将继续深入开发自主硬件，逐步实现从软件到硬件的全栈控制。\n其他互联网巨头如谷歌、微软等可能也会加速其硬件自主化的步伐，自主硬件设计的浪潮或将逐步推动全球数据中心的硬件架构变革，从而引发传统网络硬件市场的新一轮竞争。\nMeta FBNIC 4x 100G多主机适配器不仅展示了Meta和Marvell在高性能网络硬件领域的创新能力，还展示了多主机适配器在数据中心应用中的巨大潜力。通过整合Marvell的ASIC技术与Meta的网络适配器需求，Meta FBNIC在高带宽、多主机支持、紧凑设计等方面树立了新的行业标杆。\n小结 # 随着Meta FBNIC逐步在Meta数据中心实现大规模部署，这一产品将对数据中心架构、成本控制、硬件自主化等方面产生深远的影响 。\n","date":"2024-11-23","externalUrl":null,"permalink":"/network/marvell-and-meta-launch-meta-fbnic-4x-100g-network-adapter/","section":"Networks","summary":"\u003cp\u003e2024年OCP（开放计算项目）峰会上，Marvell和Meta联合展示了一款全新的Meta FBNIC 4x 100G多主机适配器。\u003c/p\u003e\n\u003cp\u003e这款产品是Meta对网络硬件控制的一次重大尝试，标志着 Meta 涉足网络适配器 ASIC 领域，具有里程碑意义。Meta FBNIC 采用多主机设计和 OCP NIC 3.0 标准，具备高效散热等技术特色，适用于 Meta 的大规模数据中心部署，可降低硬件成本及功耗。\u003c/p\u003e\n\u003cp\u003e这种合作模式可能冲击传统网络硬件供应商，引领数据中心网络适配器技术演进，推动行业迈向高密度、低成本网络架构，这也是 Meta 硬件自主化进程的重要一步，可能引发其他互联网巨头加速硬件自主化步伐，推动全球数据中心硬件架构变革。\u003c/p\u003e","title":"Marvell与Meta联手推出Meta FBNIC 4x 100G网卡","type":"network"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/meta/","section":"Tags","summary":"","title":"Meta","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/network/","section":"Networks","summary":"","title":"Networks","type":"network"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/ocp/","section":"Tags","summary":"","title":"OCP","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/amd/","section":"Tags","summary":"","title":"AMD","type":"tags"},{"content":"据最新专利申请显示，AMD正在研究一种全新的芯片堆叠技术，计划在未来的Ryzen SoC中采用“多芯片堆叠”方案，以实现芯片的可扩展性和性能提升。\n该专利透露，AMD计划在较大的芯片下方部分重叠较小的芯片，所有芯片集成在一个封装内。这种“重叠”堆叠方法的目的是通过为更多额外的芯片腾出空间，扩大芯片设计，从而在单个芯片上集成更多功能。\n通过这种技术，AMD可以在不增加芯片尺寸的情况下，整合更多核心数量、更大的缓存和更高的内存带宽，从而提升性能。此外，重叠的芯片可以缩短组件之间的距离，减少互连延迟，加快通信速度。\n这种设计还在电源管理方面具有优势。由于芯片之间的隔离，电源门控可以更有效地控制各个单元，有助于降低能耗和改善散热。\nAMD一直是“多芯片”方法的先驱，不仅在其处理器中应用，也在GPU领域有所探索。此前，该公司率先在处理器中引入了专用的“3D V-Cache”模块，即“X3D”产品线，已经在玩家群体收到热烈追捧。\n面对友商的竞争，AMD需要在CPU领域保持持续创新。通过采用新的多芯片堆叠设计，AMD有望在CPU设计和实现方面取得优势，进一步巩固其市场地位。\n目前尚不清楚这项技术何时会应用于主流的Ryzen SoC，但可以预见，AMD将继续致力于推动芯片技术的进步，为消费者带来性能更强大的产品。\n","date":"2024-11-23","externalUrl":null,"permalink":"/hardware/amd-patent-filing-reveals-unique-chip-stacking-method/","section":"Hardwares","summary":"\u003cp\u003e据最新专利申请显示，AMD正在研究一种全新的芯片堆叠技术，计划在未来的\u003ca href=\"https://www.kad8.com/ai/amd-plans-to-launch-new-ryzen-200-series-apus/\" target=\"_blank\"\u003eRyzen SoC\u003c/a\u003e中采用“多芯片堆叠”方案，以实现芯片的可扩展性和性能提升。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-patent-chip-stacking-1.png\" alt=\"AMD Patent Chip Stacking\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e该专利透露，AMD计划在较大的芯片下方部分重叠较小的芯片，所有芯片集成在一个封装内。这种“重叠”堆叠方法的目的是通过为更多额外的芯片腾出空间，扩大芯片设计，从而在单个芯片上集成更多功能。\u003c/p\u003e\n\u003cp\u003e通过这种技术，AMD可以在不增加芯片尺寸的情况下，整合更多核心数量、更大的缓存和更高的内存带宽，从而提升性能。此外，重叠的芯片可以缩短组件之间的距离，减少互连延迟，加快通信速度。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-patent-chip-stacking-2.png\" alt=\"AMD Patent Chip Stacking\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e这种设计还在电源管理方面具有优势。由于芯片之间的隔离，电源门控可以更有效地控制各个单元，有助于降低能耗和改善散热。\u003c/p\u003e\n\u003cp\u003eAMD一直是“多芯片”方法的先驱，不仅在其处理器中应用，也在GPU领域有所探索。此前，该公司率先在处理器中引入了专用的“\u003ca href=\"https://www.kad8.com/hardware/amd-ryzen-9000x-3d-cache-has-changed/\" target=\"_blank\"\u003e3D V-Cache\u003c/a\u003e”模块，即“X3D”产品线，已经在玩家群体收到热烈追捧。\u003c/p\u003e\n\u003cp\u003e面对友商的竞争，AMD需要在CPU领域保持持续创新。通过采用新的多芯片堆叠设计，AMD有望在CPU设计和实现方面取得优势，进一步巩固其市场地位。\u003c/p\u003e\n\u003cp\u003e目前尚不清楚这项技术何时会应用于主流的Ryzen SoC，但可以预见，AMD将继续致力于推动芯片技术的进步，为消费者带来性能更强大的产品。\u003c/p\u003e","title":"AMD 多芯片堆叠专利曝光","type":"hardware"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/chip-stack/","section":"Tags","summary":"","title":"Chip Stack","type":"tags"},{"content":"","date":"2024-11-23","externalUrl":null,"permalink":"/tags/patent/","section":"Tags","summary":"","title":"Patent","type":"tags"},{"content":"","date":"2024-11-21","externalUrl":null,"permalink":"/tags/intel/","section":"Tags","summary":"","title":"Intel","type":"tags"},{"content":"","date":"2024-11-21","externalUrl":null,"permalink":"/tags/server-chip/","section":"Tags","summary":"","title":"Server Chip","type":"tags"},{"content":"二十多年来，英特尔一直是数据中心 CPU 市场无可争议的领导者。英特尔的 Xeon 处理器为绝大多数服务器提供动力，而 AMD 的处理器在七八年前仅占据个位数的市场份额。然而，情况发生了巨大变化。虽然英特尔的 Xeon CPU 仍然为大多数服务器提供动力，但现在最昂贵的机器使用的是 AMD 的 EPYC 处理器。这就是 AMD 数据中心业务部门现在的销量超过英特尔数据中心和 AI 业务部门的原因，正如 SemiAnalysis观察到的那样。\n事实上，AMD 数据中心部门的收入 在第三季度达到了35.49 亿美元，而英特尔数据中心和 AI 部门的收入在 2024 年第三季度为33 亿美元 。就在两年前，英特尔的 DCAI 部门每季度的收入为 50 亿至 60 亿美元。但随着 AMD 的 EPYC 处理器相对于英特尔的 Xeon CPU 获得了竞争优势，英特尔不得不以大幅折扣出售其服务器芯片，这降低了公司的收入和利润率。\n值得注意的是，英特尔旗舰级 128 核 Xeon 6980P “Granite Rapids” 处理器售价 17,800 美元，是该公司有史以来最昂贵的标准 CPU。相比之下，AMD 最昂贵的 96 核 EPYC 6979P 处理器售价为 11,805 美元。如果对英特尔 Xeon 6900 系列处理器的需求仍然很高，并且该公司能够大量供应这些 CPU，那么英特尔的数据中心收入可能会重回正轨并超过 AMD 的数据中心销售额。然而，英特尔仍需提高其 Granite Rapids 产品的产量。\n虽然英特尔和 AMD 目前每季度通过销售数据中心 CPU 赚取约 30 至 35 亿美元，但 Nvidia 从其数据中心 GPU 和网络芯片中赚取的利润要高得多，这些芯片是使 AI 处理器在数据中心协同工作所必需的。事实上，在该公司 2025 财年第二季度，Nvidia 的网络产品销售额总计 36.68 亿美元。\n与此同时，计算 GPU 销售额在 2025 财年第二季度达到 226.04 亿美元，远远超过英特尔和 AMD 数据中心硬件的总销售额。总体而言，Nvidia 在今年上半年销售了价值近 420 亿美元的 AI 和 HPC GPU，该公司很可能在下半年销售更多的数据中心处理器。\nAMD 和英特尔的盈利的重要趋势 # 随着科技行业财报季全面开始，两家竞争对手芯片制造商英特尔公司和超威半导体公司的业绩将为投资者提供除人工智能之外的另一个重要趋势如何转变的数据。\n两家公司命运的剧烈转变在其市值上表现得非常明显，英特尔 市值 今年已暴跌至约 960 亿美元，而 AMD 市值 则逐步攀升至 2480 亿美元。\n这种转变在一定程度上与市场对每家芯片制造商在人工智能芯片热潮中所处位置的看法有关。但它们在数据中心市场中的角色变化是另一个大问题，这个问题对英特尔来说已经变得如此重要，以至于它在这个曾经几乎控制的市场中收入下降，损害了它为合同制造战略提供资金的努力。\n诚然，“整个 x86 服务器市场都承受着压力，”Bernstein Research 分析师 Stacy Rasgon 表示，他指的是英特尔设计的行业标准处理器技术。但即使在市场增长放缓的情况下，由于 Nvidia Corp. 在 AI 加速器上的支出已经从新数据中心处理器的资金中抽走，AMD 的表现也比其长期竞争对手好得多。\nTirias Research 首席分析师 Kevin Krewell 在一封电子邮件中表示：“AMD 的 EPYC 提供了比英特尔 Xeon 更好的性价比解决方案。超大规模企业（云）对 EPYC 的采用尤其强劲。”\n萨斯奎哈纳金融 (Susquehanna Financial) 分析师克里斯托弗·罗兰 (Christopher Rolland) 在最近的一份报告中表示，AMD 也看到了企业采用的加速——它曾经是英特尔的一大支柱——而他最近的检查也表明，对 AMD 下一代服务器芯片（代号为 Genoa）的需求强劲。\nMercury Research的数据显示，以出货量计算，第二季度AMD在x86服务器市场的份额从一年前的18.6%上升至24.1%，而英特尔的份额则从一年前的81.4%下滑至75.9%。\n投资者都知道，英特尔目前处于低迷状态，因为它仍在努力为其合同制造业务争取大客户，而且其服务器和 PC 芯片市场都已放缓。根据 FactSet 的数据，预计其整体收入将下降 8%，至 130 亿美元。\n就其数据中心业务而言，华尔街预计其收入将下降 15.2% 至 34 亿美元。这比其最近的峰值（即 2021 年第四季度）下降了近 54%，当时英特尔的数据中心业务占据主导地位，收入为 73 亿美元。\n投资者可能希望从英特尔身上看到一线希望，比如为其仍在苦苦挣扎的代工业务找到新客户，或者在削减成本和精简对利润率的影响方面传出一些好消息。作为 100 亿美元成本削减战略的一部分，该公司正在裁员 15,000 人。业界一直充斥着传言和报道，称高通等公司正在试探 ， 或正在洽谈将其制造资产出售给第一大芯片制造商台积电。\n“我们继续主张避免这种情况\u0026hellip;\u0026hellip;从根本上说，情况可能还会持续一段时间，”伯恩斯坦的拉斯冈在 9 月份给客户的一份报告中写道，此前该公司在备受期待的董事会会议上决定维持其目前的制造战略。\n这两家公司至少有一个共同点：个人电脑市场低迷，因为人们期待已久的个人电脑行业革新即将到来，目前销售低迷。\n随着新款 AI PC 的推出，两家公司可能会谈论第四季度及以后 PC 业务有望回升，但问题仍然是新机器上的 AI Copilots 是否有助于新一轮升级周期，而新版 Microsoft Windows 也将推动这一周期。随着高通进入 PC 市场，两家公司也面临着新的竞争对手。\n不过，投资者仍然对蓬勃发展的人工智能领域更感兴趣，该领域为半导体行业带来了新的投资者，比如英伟达公司 。在人工智能领域，英特尔和 AMD 在另一个领域也有一些共同之处，这两家公司在人工智能方面都落后于英伟达，并希望迎头赶上。\n不过，英特尔进军人工智能芯片领域的努力并没有像 AMD 那样带来那么多的收入。AMD 在最近的人工智能更新中表示，预计今年其 MI300 系列（一组与 Nvidia 竞争的人工智能加速器芯片）的收入将达到 45 亿美元，到 2025 年将达到更高的收入。即便如此，华尔街仍然对 AMD 的人工智能努力感到困惑，因为这是其数据中心业务的一部分。\n“服务器行业看起来并不好，但他们正在占据一些市场份额，而且他们的 ASP（平均销售价格）也在上涨，而且他们确实有人工智能的故事可以提供帮助，”拉斯贡说。“英特尔现在真的没有太多的人工智能故事。”\n英特尔最新的 AI 加速器芯片 Gaudi 3 于 9 月推出，IBM 公司 表示 将于明年初在其云端使用该芯片。英特尔预计今年 Gaudi 的收入为 5 亿美元，与 AI 芯片巨头 Nvidia 相比，这只是九牛一毛。分析师预计 Nvidia 10 月季度仅数据中心收入就将达到 289 亿美元，这一数字超过了英特尔和 AMD 第三季度收入的总和。\n半导体行业的形势已经发生逆转，但这不仅仅发生在人工智能领域。对于 AMD 来说，其不断增长的数据中心业务至少有助于抵消个人电脑和人工智能方面的一些失望。本季度将是一个很好的例子，让我们看看这两个长期竞争对手之间到底发生了多大的变化。\n","date":"2024-11-21","externalUrl":null,"permalink":"/hardware/for-the-first-time-ever-amd-outsells-intel-in-the-datacenter/","section":"Hardwares","summary":"\u003cp\u003e二十多年来，英特尔一直是\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003e数据中心 CPU\u003c/a\u003e 市场无可争议的领导者。英特尔的 Xeon 处理器为绝大多数服务器提供动力，而 AMD 的处理器在七八年前仅占据个位数的市场份额。然而，情况发生了巨大变化。虽然英特尔的 Xeon CPU 仍然为大多数服务器提供动力，但现在最昂贵的机器使用的是 AMD 的 EPYC 处理器。这就是 AMD 数据中心业务部门现在的销量超过英特尔数据中心和 AI 业务部门的原因，正如 SemiAnalysis观察到的那样。\u003c/p\u003e\n\u003cp\u003e事实上，AMD 数据中心部门的收入  在第三季度达到了35.49 亿美元，而英特尔数据中心和 AI 部门的收入在 2024 年第三季度为33 亿美元 。就在两年前，英特尔的 DCAI 部门每季度的收入为 50 亿至 60 亿美元。但随着 AMD 的 EPYC 处理器相对于英特尔的 Xeon CPU 获得了竞争优势，英特尔不得不以大幅折扣出售其服务器芯片，这降低了公司的收入和利润率。\u003c/p\u003e","title":"服务器芯片，AMD首超英特尔","type":"hardware"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/cxl/","section":"Tags","summary":"","title":"CXL","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/kioxia/","section":"Tags","summary":"","title":"Kioxia","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/nand/","section":"Tags","summary":"","title":"Nand","type":"tags"},{"content":"随着人工智能和机器学习应用的兴起，需要扩大内存容量和数据带宽。通过传统的DIMM接口进行内存扩展具有局限性，因此业界采用了一种新的基于PCIe的接口CXL。利用CXL接口，KIOXIA正在探索利用基于NAND的CXL的更高容量和更低成本优势，扩大现有存储和内存应用中FLASH存储器的使用方法。\n什么是CXL # 最近，一种基于PCIe的互连技术CXL（Compute Express Link）已经标准化，并在服务器和数据中心应用中获得了发展。CXL技术旨在为CPU、GPU、加速器和其他设备之间的高效内存共享提供低延迟、高带宽的连接。\n闪存可以扩展语义墙吗 # Flash与DRAM相比具有密度优势。然而，在DRAM和Flash之间存在巨大的语义墙。到目前为止，应用Flash实现低成本的存储器扩展一直是人们的梦想。新出现的CXL接口使得Flash可以跳过这个语义墙，从而提供高容量和低成本的内存。\n对于需要巨大内存空间和高带宽来发送数据到CPU / GPU的应用程序，将大容量的BiCS FLASH 3D闪存模块连接到CXL接口，为CPU/GPU提供高密度、高带宽的数据。\nXL- FLASH适用于要求随机读写性能，数据量小，延迟低的应用。与低密度的传统DRAM设备相比，使用低延迟的XL - FLASH将内存模块连接到CXL接口提供了一种经济有效的解决方案。\n数据创建没有放缓的迹象，人工智能和推理的出现正在推动对更高密度解决方案的需求。此外，数据中心在努力满足性能要求的同时，也迫切需要提高电力效率。NAND闪存与CXL接口相结合，提供了一种具有成本效益的基于NAND的存储解决方案，其性能超越了语义墙，并有效地与低密度、高功耗的DRAM竞争。\n","date":"2024-11-20","externalUrl":null,"permalink":"/hardware/kioxia-nand-flash-memory-based-on-cxl-interface/","section":"Hardwares","summary":"\u003cp\u003e随着\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003e人工智能\u003c/a\u003e和机器学习应用的兴起，需要扩大内存容量和数据带宽。通过传统的DIMM接口进行内存扩展具有局限性，因此业界采用了一种新的基于PCIe的接口CXL。利用CXL接口，KIOXIA正在探索利用基于NAND的CXL的更高容量和更低成本优势，扩大现有存储和内存应用中FLASH存储器的使用方法。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e什么是CXL \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFcxl\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFcxl\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e最近，一种基于PCIe的互连技术\u003ca href=\"https://www.kad8.com/hardware/cxl-memory-module-box-cmm-b/\" target=\"_blank\"\u003eCXL（Compute Express Link）\u003c/a\u003e已经标准化，并在服务器和数据中心应用中获得了发展。CXL技术旨在为CPU、GPU、加速器和其他设备之间的高效内存共享提供低延迟、高带宽的连接。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./nand-flash-cxl-1.png\" alt=\"Nand Flash based on CXL\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"基于CXL接口的NAND闪存","type":"hardware"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/apple/","section":"Tags","summary":"","title":"Apple","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/series/hardware/","section":"Series","summary":"","title":"Hardware","type":"series"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/m4-ultra/","section":"Tags","summary":"","title":"M4 Ultra","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"苹果Mac产品行销副总裁Tom Boger和平台架构副总裁Tim Millet在接受采访时，分享了其自研芯片Apple Silicon成功的秘诀。\nMillet指出，竞争对手的芯片制造商“无法直接采用第二代、三nm等最新尖端技术，但我们从中获益匪浅，我们认为这样做是值得的，它为我们、我们的产品和我们的客户带来了好处。”\nMillet表示，自行开发的芯片为苹果带来了“巨大的战略优势”，他指出，尽管苹果不是芯片公司，但自研芯片避免了在整体性能上的妥协。\nBoger也强调，没有其他平台可以达到苹果的每瓦功率性能，这对用户来说是一个显著的优势。\n两位高层还提到，Apple Silicon的成功不仅在于以最小的能耗实现高速度，并充分利用了架构、设计和制程技术这三大要素。\n而真正的秘密武器，则是苹果与系统团队和产品设计师共同设计这些芯片的能力。\n根据此前消息，YouTube Max Tech频道的Vadim Yuryev预测，M4 Ultra在Geekbench 6的OpenCL测试中的得分有望超过330000分，高于RTX 4090目前的317162分，意味着其图形性能有望超越RTX 4090。\n不可忽视的是，Apple M4系列处理器不是一般的强，而且通用性也不是一般的广，从iPad到MacBook，再到iMac甚至iMac mini都有所配备。\n虽然M4系列处理器体现苹果对于Intelligence无比重视，但性能方面能直面Intel和AMD的桌面级处理器，这才是它的强大之处。\n这要从多个维度来讨论，首先多核性能方面。\n苹果M4的10个CPU内核由4个性能核心和6个效率核心组成，这与Intel和AMD桌面产品相比处于劣势。\n不过现在Apple Silicon M系列芯片中，Max和Ultra型号在多核性能方面已经有了很大提升，M4也达到了M3 Pro的水平，基本具备与Intel和AMD的高级桌面处理器掰手腕的实力。\nCPU拥有多达10个核心，还拥有苹果有史以来最快的神经引擎，算力高达38 TOPS。虽然低于第二代英特尔酷睿Ultra，但却远超上一代Intel酷睿Ultra以及AMD锐龙7000系列。\n其次是单核性能方面，甚至都无需苹果Apple Silicon M，哪怕iPhone15Pro配备的A17 Pro都足以应对。\nGeekbench 6测试中以3.78GHz的频率就能跑到3000以上，而M4的单核性能比A17 Pro 还要高出28%，比Intel酷睿i9-14900K高24%。\n第三就是GPU性能。\n苹果M4系列光线追踪引擎的速度获得了提升，专业3D渲染器也能以更高效率输出高品质视觉画面，现在已经能运行很多的主流3A大作。\n有人已经在配备的A17 Pro的iPhone 15 Pro上运行了《刺客信条：幻景》等作品，因此M4的图形性能在游戏方面的表现会更优秀，然而并没有多少人拿它来玩游戏而已。\n最后就是效能。\nM4系列芯片堪称逆天的存在，搭配M4处理器的MacBook甚至能提供长达24小时的电池续航时间，真正解决了用户的续航焦虑，出门真正告别的充电器。\n现在M4系列新品都已经上线，然而最值得购买的竟然是Mac mini，它不仅体型更小，统一内存更是增加到了16GB，而且价格相对于M2的产品几乎没有涨价。\n那么，你会去买么？\n","date":"2024-11-20","externalUrl":null,"permalink":"/hardware/apple-reveals-the-secrets-behind-the-success-of-its-self-developed-chips/","section":"Hardwares","summary":"\u003cp\u003e苹果Mac产品行销副总裁Tom Boger和平台架构副总裁Tim Millet在接受采访时，分享了其自研芯片Apple Silicon成功的秘诀。\u003c/p\u003e\n\u003cp\u003eMillet指出，竞争对手的芯片制造商“无法直接采用第二代、三nm等最新尖端技术，但我们从中获益匪浅，我们认为这样做是值得的，它为我们、我们的产品和我们的客户带来了好处。”\u003c/p\u003e\n\u003cp\u003eMillet表示，自行开发的芯片为苹果带来了“巨大的战略优势”，他指出，尽管苹果不是芯片公司，但自研芯片避免了在整体性能上的妥协。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./apple-m4-ultra-1.png\" alt=\"Apple M4 Ultra\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eBoger也强调，没有其他平台可以达到苹果的每瓦功率性能，这对用户来说是一个显著的优势。\u003c/p\u003e\n\u003cp\u003e两位高层还提到，Apple Silicon的成功不仅在于以最小的能耗实现高速度，并充分利用了架构、设计和制程技术这三大要素。\u003c/p\u003e\n\u003cp\u003e而真正的秘密武器，则是苹果与系统团队和产品设计师共同设计这些芯片的能力。\u003c/p\u003e\n\u003cp\u003e根据此前消息，YouTube Max Tech频道的Vadim Yuryev预测，M4 Ultra在Geekbench 6的OpenCL测试中的得分有望超过330000分，高于RTX 4090目前的317162分，意味着其图形性能有望超越RTX 4090。\u003c/p\u003e","title":"苹果揭秘自研芯片成功原因","type":"hardware"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/astera-labs/","section":"Tags","summary":"","title":"Astera Labs","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/cxl-memory/","section":"Tags","summary":"","title":"CXL Memory","type":"tags"},{"content":"","date":"2024-11-20","externalUrl":null,"permalink":"/tags/lenovo/","section":"Tags","summary":"","title":"Lenovo","type":"tags"},{"content":"在 2024 年 OCP 峰会上，我们看到了另一款 CXL 怪兽——Lenovo ThinkSystem SR860 V3。Lenovo网站上列出的该系统具有“64x 插槽中高达 16TB 的 TruDDR5 内存”。在 2024 年 OCP 峰会上，我们看到了这款怪兽，以及 Lenovo 如何在 CXL 和 Astera Labs Leo 的帮助下做到这一点。\nLenovo推出配备 128 个 128GB DDR5 DIMM 的 CXL 内存怪兽\n具有四颗CPU插槽服务器的想法并不新鲜。然而，一个挑战是，使用 8 通道 Intel Xeon 时，DDR5 DIMM 插槽数量有限。每个 8 通道 Xeon 支持每通道 2 个 DIMM (2DPC)，每颗CPU支持 16 根 DIMM。四个CPU插槽为我们提供多达 64 个 DDR5 SODIMM。用 128GB DDR5 RDIMM 填充这些DIMM插槽只能获得微不足道的 8TB 内存。对于某些应用场景来说，大型消费级 SSD 大小的内存容量根本不够用。\nLenovo ThinkSystem SR860 V3 CXL Astera Labs 在 2024 年 OCP 峰会上，我们看到了 Lenovo 给出的解决方案，即在系统中添加另外 64 个 DIMM。\nLenovo ThinkSystem SR860 V3 CXL Astera Labs 通过使用带有 Astera Labs Leo CXL 控制器的扩展板，Lenovo 能够为系统添加许多内存插槽。\nLenovo ThinkSystem SR860 V3 CXL Astera Labs 更确切地说，最多 64 个 DDR5 DIMM 插槽。每个 Astera Labs Leo CXL 内存控制器最多可处理四个 DDR5 DIMM。\nLenovo ThinkSystem SR860 V3 CXL Astera Labs 安装此选项后，机箱顶部将变成一个巨大的内存森林。四个 CPU 位于底部的主板上，每个 CPU 都有 16 个 DDR5 DIMM 插槽。在其上方，是这个 CXL 内存森林，还有另外 64 个 DIMM 插槽。\n64 个 DIMM 直接连接到 Xeon CPU，然后通过 CXL 内存扩展连接 64 个额外的 DIMM 插槽。这样我们就有 128 个 DIMM 插槽。使用 128GB RDIMM，内存容量为 16TB。\n这里的巧妙之处在于，具有四个 CPU 和 128 个 DIMM 的配置还可以支持四个双宽 GPU。\n这使得这些系统非常庞大。\n写在最后\n对于需要大量内存容量的某些扩展工作负载，使用 CXL Type-3 内存等解决方案可以创建原本不可能实现的拓扑。最近的 AI 建设推迟了 CXL 的部署，但这些解决方案即将到来。更重要的是，借助 CXL 2.0（或真正的 CXL 3.1），愿景是未来可以将多个内存扩展架（如 Inventec 96 DIMM CXL 扩展盒）连接到 CXL 交换机，构建大量内存池，然后在不同系统之间分配和共享它们。\n","date":"2024-11-20","externalUrl":null,"permalink":"/hardware/lenovo-has-a-cxl-memory-monster-based-on-astera-labs-leo/","section":"Hardwares","summary":"\u003cp\u003e在 2024 年 OCP 峰会上，我们看到了另一款 CXL 怪兽——Lenovo ThinkSystem SR860 V3。Lenovo网站上列出的该系统具有“64x 插槽中高达 16TB 的 TruDDR5 内存”。在 2024 年 OCP 峰会上，我们看到了这款怪兽，以及 Lenovo 如何在 CXL 和 Astera Labs Leo 的帮助下做到这一点。\u003c/p\u003e","title":"Lenovo推出配备 128 个 128GB DDR5 DIMM 的 CXL Memory 解决方案","type":"hardware"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/cxl-memory-module/","section":"Tags","summary":"","title":"CXL Memory Module","type":"tags"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/samsung/","section":"Tags","summary":"","title":"Samsung","type":"tags"},{"content":"在Memcon 2024上，全球先进半导体技术领导者三星电子公布了其CXL内存模块产品组合的扩展，并展示了其最新的HBM3E技术，加强了在AI应用的高性能、高容量解决方案方面的领导地位。\n在美国圣克拉拉计算机历史博物馆举行的主题演讲中，三星美国设备解决方案研究所常务副总裁 Jin-Hyeok Choi和三星DRAM产品及技术部常务副总裁 SangJoon Hwang介绍了新的存储解决方案，并讨论了如何在AI时代引领HBM和CXL创新。与三星一同登台的还有VMware by Broadcom的VCF部门产品团队副总裁Paul Turner和Red Hat的副总裁兼总经理Gunnar Hellekson，他们讨论了其软件解决方案如何与三星的硬件技术相结合，推动内存创新。\nChoi表示：“如果没有存储技术的革新，AI的革新就无法继续。作为内存市场的领导者，三星很自豪能够继续推进创新，从业界最先进的CMM-B技术到强大的内存解决方案，如HBM3E，用于高性能计算和AI应用。我们致力于与合作伙伴合作，为客户服务，共同释放AI时代的全部潜力。”\n三星推出了尖端的CXL DRAM内存池产品CMM-B，突显了CXL生态圈的发展势头。三星CMM-B可以容纳8台E3.S外形的CMM-D设备，提供高达2TB的容量。巨大内存容量支持每秒60 GB/s带宽和596 ns延迟，可以服务于需要高容量内存的各种应用，如AI，内存数据库（IMDB），数据分析等。\n三星还与即插即用机架级IT解决方案的全球领导者美超微合作，展示了业界首个机架级内存解决方案，用于高度可扩展和可组合的分解基础设施。这种先进的解决方案利用三星的CMM-B来增加内存容量和带宽，使数据中心能够处理大量工作负载，不像标准架构缺乏现代应用程序所需的灵活性和效率。增加的内存容量和每台服务器高达60GB/s带宽的高性能可以增强需要高容量内存的各种应用，如AI，IMDB，数据分析等。\n三星和博通VMware还介绍了Peaberry项目，这是世界上第一个基于FPGA的分层存储解决方案，用于管理程序，称为CXL分层存储混合模块。这种混合解决方案将DRAM和NAND介质结合在外接卡中，以应对内存管理挑战，减少停机时间，优化分层内存的调度，并最大限度地提高性能，同时显着降低总拥有成本（total cost of ownership ，简称TCO）。\nPaul Turner表示：“博通旗下的VMware很高兴与三星合作，在内存领域带来新的创新。三星在内存技术方面的领先地位和VMware在软件内存分层方面的领先地位，使CXL实现了新的创新，并具有显着的TCO优势，更好地利用昂贵的DRAM资源，改进了服务器资源的整合，同时提供了出色的性能。”\n此外，三星还展示了将三星的DRAM技术与CXL开放标准接口集成在一起的CMM-D技术，从而实现了CPU和内存扩展设备之间高效、低延迟的连接。全球开源软件解决方案的领军企业 Red Hat去年在业界首次成功验证了三星电子的CMM-D设备。两家公司将通过三星内存研究所继续合作，开发CXL开源和参考模型，并在一系列其他存储和内存产品上进行合作。\n三星还为2024年Memcon与会者展示其最新的HBM3E 12H芯片，这是世界上第一个12层HBM3E DRAM，标志着HBM技术有史以来最高容量的突破。HBM3E 12H采用了该公司先进的TC NCF技术，与前代产品相比，芯片的垂直密度提高了20%以上，同时也提高了产品良率。\n","date":"2024-11-19","externalUrl":null,"permalink":"/ai/samsung-introduces-new-memory-module-for-scalable/","section":"Ais","summary":"\u003cp\u003e在Memcon 2024上，全球先进半导体技术领导者三星电子公布了其\u003ca href=\"https://www.kad8.com/hardware/cxl-memory-module-box-cmm-b/\" target=\"_blank\"\u003eCXL内存模块\u003c/a\u003e产品组合的扩展，并展示了其最新的HBM3E技术，加强了在AI应用的高性能、高容量解决方案方面的领导地位。\u003c/p\u003e\n\u003cp\u003e在美国圣克拉拉计算机历史博物馆举行的主题演讲中，三星美国设备解决方案研究所常务副总裁 Jin-Hyeok Choi和三星DRAM产品及技术部常务副总裁 SangJoon Hwang介绍了新的存储解决方案，并讨论了如何在AI时代引领HBM和CXL创新。与三星一同登台的还有VMware by Broadcom的VCF部门产品团队副总裁Paul Turner和Red Hat的副总裁兼总经理Gunnar Hellekson，他们讨论了其软件解决方案如何与三星的硬件技术相结合，推动内存创新。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./samsung-cxl-memory-module-1.png\" alt=\"Samsung CXL Memory Module\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eChoi表示：“如果没有存储技术的革新，AI的革新就无法继续。作为内存市场的领导者，三星很自豪能够继续推进创新，从业界最先进的CMM-B技术到强大的内存解决方案，如HBM3E，用于高性能计算和AI应用。我们致力于与合作伙伴合作，为客户服务，共同释放AI时代的全部潜力。”\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./samsung-cxl-memory-module-2.png\" alt=\"Samsung CXL Memory Module\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"三星推出可扩展的新型内存模块","type":"ai"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/pcie-over-optics/","section":"Tags","summary":"","title":"PCIe Over Optics","type":"tags"},{"content":"生成式AI革命正在重塑所有行业，并重新定义日常生活方方面面的可能性。创新的快速步伐给数据中心基础设施带来了重大挑战，包括：\n由于需要LLM（大型语言模型）同时处理大量多模态数据集（文本、图像、音频和视频），因此对AI处理资源的需求激增，这些资源必须在整个数据中心相互连接 由于生成式AI应用的多样性和定制化，大量的平台架构正在以显著加快的年度升级节奏部署 因为云计算供应商面临着巨大的财务压力，需要为大规模的资本支出提供可观的投资回报率，所以要求部署AI基础设施的利用率达到最大化 要满足现代AI模型的计算需求，只能将数千个GPU或AI加速器与专门为AI工作负载构建的专用网络/结构互连在一起。该网络通常称为“后端”网络，由“向上扩展”的加速器集群结构和“向外扩展”的网络结构组成。“向上扩展”结构通常是一种任意对任意的网状互连，针对最大吞吐量和紧密耦合加速器的能力进行了优化，以快速交换AI模型训练/推理数据。“向外扩展”的例子包括NVLink、Infinity Fabric、PCI Express®（PCIe®）、以太网等。这些技术用于连接多达数百个加速器。\nPCIe接口在AI加速器和GPU上是原生可用的，一些AI平台还利用PCIe或基于PCIe的协议来扩展结构。随着AI集群的规模从1-2个机架、数十个GPU扩展到跨越多个机架、数百个GPU的大型pod，互连长度迅速成为限制。在PCIe 5.0数据速率下，跨度达7米的有源电缆足以连接几个机架。然而，在更高的数据速率，如PCIe 6.x和PCIe 7.x，对于跨多个机架的GPU集群，需要光解决方案。\n我们很高兴能够继续Astera Labs在PCIe连接解决方案方面的领先地位，通过展示端到端PCIe/CXL®用于GPU集群的光学器件，为扩展生成式AI基础设施照亮了前进的道路！\n应对AI互联的日常挑战 # 自2017年以来，Astera Labs一直专注于释放AI和云基础设施的全部潜力，不断推出率先上市的高度创新的连接解决方案。我们的智能连接平台的基础是基于PCIe®，CXL®和以太网半导体的解决方案，以及我们的COSMOS软件套件的系统管理和优化工具。该平台提供了可扩展和可定制的软件定义架构。\n面对生成式AI基础设施建设的主要挑战，所有主要的超大规模企业和AI平台供应商都使用我们的智能连接平台，该平台已被证明：\n提供远距离和规模化的可靠连接，包括芯片对芯片、盒对盒、机架对机架；现在，我们提供了将其扩展到通过光学器件的PCIe到行的能力，以加速必须跨数据中心扩展的最大GPU集群的部署 通过我们的软件定义架构和对云规模的前期互操作性测试的巨大投资，加快了各种AI平台的部署时间 通过深度诊断、遥测和车队管理，实现对不断增加的连接链路的前所未有的可见性，从而最大限度地延长了昂贵的AI基础设施的正常运行时间和系统利用率 支撑我们智能连接平台的产品系列包括：\nAries®PCIe®/CXL®智能DSP retimer经过现场测试，所有主要的超大规模厂商和平台供应商都广泛部署。我们的第三代Aries 6 Retimers将带宽提高了一倍，达到每通道64GT/s。Aries PCIe/CXL智能电缆模块™（SCM）提供业界首创的7米有源电缆，用于机架到机架的PCIe连接 Taurus以太网智能电缆模块（SCM）支持每通道高达100Gb/s的以太网速率，支持交换机到交换机和交换机到服务器连接应用中坚固、纤薄和灵活的电缆 Leo CXL®智能内存控制器是业界首个支持CXL®内存扩展、池化和共享的解决方案。经过优化，可以在低延迟下满足生成式AI工作负载不断增长的计算需求 我们在技术周期的早期引入、提供解决方案以最大化平台利用率方面有着丰富的历史。这包括首次上市的PCIe和CXL®解决方案，以及全面的云规模互操作实验室的扩展，这使我们有信心大规模部署先进的解决方案。\n无缝AI连接的新范式 # 随着AI基础设施的扩展超出了单个机架的范围，并且超出了传统无源直接连接电缆(简称DAC)的范围，必须开发新的连接解决方案。更高速度下的信号丢失也限制了无源解决方案的有效性，要求新的有源电缆具有更好的覆盖范围和路由，以补充无源解决方案。\nAries PCIe/CXL®SCM™通过有源电缆(简称AEC)提供7米的覆盖范围，解决了DAC的限制。这些具有低延迟的经济高效的AEC使细布线能够轻松扩展到机架以外的AI加速器集群。\n随着数据速率增加到PCIe 6.x (64GT/s), PCIe 7.x (128GT/s)及以上，传统的无源和有源电缆将仅限于单个机架。新的解决方案，如PCIe over optics，包括有源光缆(简称AOC)，将在机架到机架的连接中发挥更大的作用，以维护和发展这些AI集群。\nPCIe光连接 # 光纤链路已经成为高速以太网连接的骨干，提供长距离数据连接，覆盖超大规模数据中心。这些优势可以通过开发新的PCIe over optics解决方案（包括AOC）应用于PCIe连接，与铜缆相比，该解决方案将PCIe连接扩展到机架集群，并改进了电缆管理。\nPCIe/CXL®在光学器件上的应用通常是由相对于以太网的低延迟需求驱动的，例如缓存一致内存事务和GPU之间的并行处理工作负载。这些应用还要求通过使用专门的软件对链路进行全面管理，以确保完全符合协议和可靠性。\nAstera Labs提供经过现场验证的软件定义连接解决方案，开发了多代PCIe规范，可以通过光学无缝集成PCIe。我们已经在端到端、完全兼容的链接连接中演示了这一点，这些连接代表了AI基础设施部署用例。基于光连接的PCIe 演示包括一个CPU作为RC连接到一个目标GPU和一个目标远程分解内存系统。首次在多个设备之间演示一个长距离、完全兼容的PCIe光学链路的能力，为高速PCIe光学等新产品铺平了道路。此外，该解决方案利用COSMOS软件套件的综合诊断、遥测和车队管理功能，有助于加快部署时间，并促进优化基础设施利用率。\n总而言之，Astera实验室将继续创新和执行新的连接解决方案，以支持AI平台的加速部署，促进下一代生成式AI应用程序的快速发展。利用通用COSMOS软件套件的软件定义架构提供解决方案，实现灵活可靠的连接，跨越芯片到芯片，箱到箱，机架到机架，现在，通过光学器件的PCIe演示，跨数据中心的行到行应用程序。\n这对于超大规模企业和AI平台供应商来说是有价值的，因为基础设施管理的诊断和遥测集成是一项重大投资，可以充分利用最新的基于光连接的PCIe技术。我们很高兴成为第一个展示完整的端到端光学演示的公司，使用基于PCIe的光模块将PCIe 5.0 GPU和CXL 2.0内存扩展器连接到RC。\n","date":"2024-11-19","externalUrl":null,"permalink":"/ai/pcie-over-optics-demo/","section":"Ais","summary":"\u003cp\u003e\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003e生成式AI\u003c/a\u003e革命正在重塑所有行业，并重新定义日常生活方方面面的可能性。创新的快速步伐给数据中心基础设施带来了重大挑战，包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e由于需要LLM（大型语言模型）同时处理大量多模态数据集（文本、图像、音频和视频），因此对AI处理资源的需求激增，这些资源必须在整个数据中心相互连接\u003c/li\u003e\n\u003cli\u003e由于生成式AI应用的多样性和定制化，大量的平台架构正在以显著加快的年度升级节奏部署\u003c/li\u003e\n\u003cli\u003e因为云计算供应商面临着巨大的财务压力，需要为大规模的资本支出提供可观的投资回报率，所以要求部署AI基础设施的利用率达到最大化\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e要满足现代AI模型的计算需求，只能将数千个GPU或AI加速器与专门为AI工作负载构建的专用网络/结构互连在一起。该网络通常称为“后端”网络，由“向上扩展”的加速器集群结构和“向外扩展”的网络结构组成。“向上扩展”结构通常是一种任意对任意的网状互连，针对最大吞吐量和紧密耦合加速器的能力进行了优化，以快速交换AI模型训练/推理数据。“向外扩展”的例子包括NVLink、Infinity Fabric、PCI Express®（PCIe®）、以太网等。这些技术用于连接多达数百个加速器。\u003c/p\u003e\n\u003cp\u003ePCIe接口在AI加速器和GPU上是原生可用的，一些AI平台还利用PCIe或基于PCIe的协议来扩展结构。随着AI集群的规模从1-2个机架、数十个GPU扩展到跨越多个机架、数百个GPU的大型pod，互连长度迅速成为限制。在PCIe 5.0数据速率下，跨度达7米的有源电缆足以连接几个机架。然而，在更高的数据速率，如\u003ca href=\"https://www.vxworks.net/bus-protocol/1131-pci-sig-confirms-pcie-5-0-and-6-0-will-use-new-cable-design\" target=\"_blank\"\u003ePCIe 6.x\u003c/a\u003e和PCIe 7.x，对于跨多个机架的GPU集群，需要光解决方案。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./pcie-over-optics-1.png\" alt=\"PCIe over optics\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e我们很高兴能够继续Astera Labs在PCIe连接解决方案方面的领先地位，通过展示端到端PCIe/CXL®用于GPU集群的光学器件，为扩展生成式AI基础设施照亮了前进的道路！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e应对AI互联的日常挑战 \n    \u003cdiv id=\"%E5%BA%94%E5%AF%B9ai%E4%BA%92%E8%81%94%E7%9A%84%E6%97%A5%E5%B8%B8%E6%8C%91%E6%88%98\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BA%94%E5%AF%B9ai%E4%BA%92%E8%81%94%E7%9A%84%E6%97%A5%E5%B8%B8%E6%8C%91%E6%88%98\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e自2017年以来，Astera Labs一直专注于释放AI和云基础设施的全部潜力，不断推出率先上市的高度创新的连接解决方案。我们的智能连接平台的基础是基于PCIe®，CXL®和以太网半导体的解决方案，以及我们的COSMOS软件套件的系统管理和优化工具。该平台提供了可扩展和可定制的软件定义架构。\u003c/p\u003e","title":"PCIe Over Optics的样机展示","type":"ai"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/database/","section":"Tags","summary":"","title":"Database","type":"tags"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"Mysql","type":"tags"},{"content":"MySQL是一个广泛使用的开源关系数据库管理系统，它常用于各种规模的应用，从个人博客到大型企业级系统。在使用MySQL的过程中，数据备份是一项至关重要的任务，它能够确保在发生数据丢失或系统故障时，我们可以恢复和重新部署数据库。在本文中，我们将介绍如何使用mysql命令行工具备份数据库，并包含几个具体的示例。\nImage\nmysql命令行工具和备份数据库的重要性 # MySQL命令行工具是一个强大的工具，它允许用户执行各种数据库管理任务，包括创建、修改、删除表，插入、更新、删除数据等。除此之外，它还可以用来备份和恢复数据库。备份数据库可以确保在意外发生时，我们能够恢复数据并继续正常的业务操作。此外，备份也是验证和验证数据库完整性的重要手段。\n备份数据库的基本步骤 # 打开终端或命令提示符\n使用mysql命令登录到MySQL服务器\n执行备份命令\n输入密码（如果需要的话）\n等待备份完成\n示例 # 使用mysql命令行工具备份数据库到指定目录 mysqldump -u username -p database_name \u0026gt; /path/to/backup/directory/backup.sql 在这个命令中，username是你的MySQL用户名，database_name是要备份的数据库名。/path/to/backup/directory/是你要保存备份文件的目录。执行这个命令后，会要求你输入密码。输入密码后，等待备份完成。\n使用mysql命令行工具备份数据库为指定格式 除了直接输出到SQL文件，mysqldump也支持将数据库备份为其他格式，如CSV。以下是一个示例：\nmysqldump --skip-extended-insert --skip-opt --compact --no-create-info your_database your_table.csv 这个命令将数据库your_database中的表your_table备份为CSV格式，并直接输出到终端。你可以根据需要修改表名和数据库名。\n使用mysql命令行工具备份数据库并添加元数据信息 有时，我们可能希望在备份中包含关于备份本身的元数据，例如备份的时间、使用的MySQL版本等。我们可以使用\u0026ndash;comments选项来实现这个需求：\nmysqldump --comments --user=username --password=password dbname \u0026gt; dbname_dump_include_metadata.sql 这个命令将在备份文件中添加注释，包括备份的时间、MySQL版本等信息。\n使用mysql命令行工具备份数据库并实现自动备份 对于需要定期备份的数据库，我们可以使用cron等工具来实现自动备份。以下是一个简单的crontab示例，它将每天凌晨3点自动备份数据库：\n0 3 * * * /usr/bin/mysqldump -u username -p password database_name \u0026gt; /path/to/backup/directory/backup_$(date +%Y%m%d%H%M%S).sql 这个命令将在每天的凌晨3点执行，并将数据库备份到指定的目录。每次备份的文件名将包含备份的时间，以方便我们识别和管理。\n总结 # 通过以上示例，我们可以看到mysql命令行工具在备份数据库时的灵活性和便利性。使用mysqldump工具，我们可以轻松地将数据库导出到各种格式的文件中，包括SQL、CSV等，而且还可以实现定期自动备份。此外，它还允许我们在备份文件中添加元数据，以方便我们跟踪和管理备份。总的来说，mysql命令行工具是一个强大的工具，它可以帮助我们有效地管理和备份数据库。\n","date":"2024-11-19","externalUrl":null,"permalink":"/software/backing-up-a-mysql-database-using-command-line/","section":"Softwares","summary":"\u003cp\u003eMySQL是一个广泛使用的开源关系数据库管理系统，它常用于各种规模的应用，从个人博客到大型企业级系统。在使用MySQL的过程中，数据备份是一项至关重要的任务，它能够确保在发生数据丢失或系统故障时，我们可以恢复和重新部署数据库。在本文中，我们将介绍如何使用mysql命令行工具备份数据库，并包含几个具体的示例。\u003c/p\u003e\n\u003cp\u003eImage\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003emysql命令行工具和备份数据库的重要性 \n    \u003cdiv id=\"mysql%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E5%92%8C%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#mysql%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E5%92%8C%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eMySQL命令行工具是一个强大的工具，它允许用户执行各种数据库管理任务，包括创建、修改、删除表，插入、更新、删除数据等。除此之外，它还可以用来备份和恢复数据库。备份数据库可以确保在意外发生时，我们能够恢复数据并继续正常的业务操作。此外，备份也是验证和验证数据库完整性的重要手段。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e备份数据库的基本步骤 \n    \u003cdiv id=\"%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e打开终端或命令提示符\u003c/p\u003e","title":"使用命令行备份MySQL数据库","type":"software"},{"content":"11月17日，The Information突然报道，英伟达新一代Blackwell芯片可能再次面临延期，重提4个月前所谓的配套服务器过热的技术难题，这使得一些客户担心他们没有足够时间来部署新的数据中心。\n报道援引知情人士称，当Blackwell GPU被连接在设计容纳多达72个芯片的服务器机架中时会出现过热现象。据参与该项目的英伟达员工以及了解情况的客户和供应商透露，芯片制造商已多次要求供应商更改机架设计以解决过热问题。对此，英伟达发言人在向路透社表示：\u0026ldquo;英伟达正在与主要云服务提供商密切合作，将其作为我们工程团队和流程的重要组成部分，工程迭代是正常且预期的。”\n两位订购了新芯片的大型云服务提供商高管向The Information表示，他们担心这些问题可能推迟明年GPU集群的部署时间。多位客户和供应商表示，尽管设计变更出现在生产后期，但英伟达可能仍能按原计划在明年上半年末交付机架，目前尚未通知客户有任何延迟。\n以下为数字开物汇总的此前英伟达芯片服务器过热的相关信息：\n满载情况下，这款72-GPU机架重达1.5吨、高度超过普通家用冰箱，英伟达将其宣传为实现芯片之间最快性能连接的最佳方案。\n多位知情人士称，这款机架及其密集排列数十个 GPU 的设计是英伟达有史以来最为复杂的设计，在公开推出机架几个月后，英伟达工程师在测试中发现，机架无法正常工作。\n据两位参与服务器生产的人士透露，过多高性能芯片的连接会导致过热，影响服务器的可靠性和性能。\n两位了解内情的英伟达员工还表示，配套36芯片的小型服务器机架同样面临过热困扰，目前尚不清楚该公司是否已解决这一问题。\n据悉，由于处理器设计缺陷导致良率问题，Nvidia 不得不推迟 Blackwell 的量产计划。Nvidia 的 Blackwell B100 和 B200 GPU 采用 TSMC 的 CoWoS-L 封装技术来连接其两个芯片组 (chiplet)。这种设计包括一个配备本地硅互连桥的 RDL 互联层，可支持高达 10 TB/s 的数据传输速度。这些 LSI 桥的精确定位对于该技术的正常运行至关重要。然而，GPU 芯片组、LSI 桥、RDL 互联层和主板基板 (substrate) 的热膨胀特性不匹配，导致了变形和系统故障。为了解决这个问题，据报道 Nvidia 对 GPU 硅片的顶层金属结构和微凸点进行了改良，以提高生产可靠性。\nBlackwell GPU 的最终版本直到十月底才开始量产，这意味着 Nvidia 将从2025年一月底开始发货这些处理器。\n","date":"2024-11-19","externalUrl":null,"permalink":"/ai/nvidia-chip-server-overheats/","section":"Ais","summary":"\u003cp\u003e11月17日，The Information突然报道，英伟达新一代\u003ca href=\"https://www.kad8.com/ai/several-rack-solutions-for-nvidia-blackwell-platform/\" target=\"_blank\"\u003eBlackwell芯片\u003c/a\u003e可能再次面临延期，重提4个月前所谓的配套服务器过热的技术难题，这使得一些客户担心他们没有足够时间来部署新的数据中心。\u003c/p\u003e\n\u003cp\u003e报道援引知情人士称，当Blackwell GPU被连接在设计容纳多达72个芯片的服务器机架中时会出现过热现象。据参与该项目的英伟达员工以及了解情况的客户和供应商透露，芯片制造商已多次要求供应商更改机架设计以解决过热问题。对此，英伟达发言人在向路透社表示：\u0026ldquo;英伟达正在与主要云服务提供商密切合作，将其作为我们工程团队和流程的重要组成部分，工程迭代是正常且预期的。”\u003c/p\u003e\n\u003cp\u003e两位订购了新芯片的大型云服务提供商高管向The Information表示，他们担心这些问题可能推迟明年GPU集群的部署时间。多位客户和供应商表示，尽管设计变更出现在生产后期，但英伟达可能仍能按原计划在明年上半年末交付机架，目前尚未通知客户有任何延迟。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./nvidia-chip-server.png\" alt=\"Nvidia Blackwell Chip Server\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e以下为数字开物汇总的此前英伟达芯片服务器过热的相关信息：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e满载情况下，这款72-GPU机架重达1.5吨、高度超过普通家用冰箱，英伟达将其宣传为实现芯片之间最快性能连接的最佳方案。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e多位知情人士称，这款机架及其密集排列数十个 GPU 的设计是英伟达有史以来最为复杂的设计，在公开推出机架几个月后，英伟达工程师在测试中发现，机架无法正常工作。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e据两位参与服务器生产的人士透露，过多高性能芯片的连接会导致过热，影响服务器的可靠性和性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e两位了解内情的英伟达员工还表示，配套36芯片的小型服务器机架同样面临过热困扰，目前尚不清楚该公司是否已解决这一问题。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e据悉，由于处理器设计缺陷导致良率问题，Nvidia 不得不推迟 Blackwell 的量产计划。Nvidia 的 Blackwell B100 和 B200 GPU 采用 TSMC 的 CoWoS-L 封装技术来连接其两个芯片组 (chiplet)。这种设计包括一个配备本地硅互连桥的 RDL 互联层，可支持高达 10 TB/s 的数据传输速度。这些 LSI 桥的精确定位对于该技术的正常运行至关重要。然而，GPU 芯片组、LSI 桥、RDL 互联层和主板基板 (substrate) 的热膨胀特性不匹配，导致了变形和系统故障。为了解决这个问题，据报道 Nvidia 对 GPU 硅片的顶层金属结构和微凸点进行了改良，以提高生产可靠性。\u003c/p\u003e","title":"Nvidia Chip Server Overheats","type":"ai"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/nvlink/","section":"Tags","summary":"","title":"NVLink","type":"tags"},{"content":"","date":"2024-11-19","externalUrl":null,"permalink":"/tags/ualink/","section":"Tags","summary":"","title":"UALink","type":"tags"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/pytorch/","section":"Tags","summary":"","title":"Pytorch","type":"tags"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/tensorflow/","section":"Tags","summary":"","title":"Tensorflow","type":"tags"},{"content":"关于TensorFlow与PyTorch，我知道你们在想什么：“这俩框架我都用过，但到底哪个更胜一筹呢？”别急，今天我们就来扒一扒这背后的小秘密。不管你是深度学习的新手，还是老司机，这篇文章都能给你带来一些新视角。准备好了吗？让我们开始这场有趣的“对决”吧！\n江湖地位 # 首先，让我们来聊聊这两位大侠的江湖地位。\nTensorFlow，这个由Google亲生的深度学习框架，自2015年横空出世以来，就以其强大的性能和广泛的应用场景，迅速占领了AI界的大片江山。它就像那个在武林大会上一鸣惊人的少侠，不仅有着深厚的内功（Google的技术支持），还有着广泛的人脉（全球开发者的支持）。\nTensorFlow的成长之路可谓是风光无限。从1.0版本的稳定发布，到2.0版本的革命性升级，每一步都走得坚实而有力。现在的TensorFlow，不仅支持静态图，还拥抱了动态图，让模型的构建和调试变得更加灵活。这种变革，就像是那个武林高手在不断的战斗中，不断学习新的招式，不断提升自己的武艺。\n而PyTorch，这个由Facebook支持的后起之秀，虽然起步稍晚，但凭借其独特的魅力和强大的实力，迅速在AI界崭露头角。PyTorch的动态计算图，就像是那个总是能给人带来惊喜的江湖奇才，它的灵活性和易用性，让无数研究者和开发者为之倾倒。\nPyTorch的发展，就像是那个在江湖中不断历练的侠客，从最初的Torch框架，到今天的PyTorch，每一步都走得稳健而坚定。它的社区虽然起步较晚，但增长迅猛，尤其是在学术界，PyTorch的影响力不容小觑。它的动态图和Pythonic风格，让它在快速原型设计和研究中占据了一席之地。\n性能对比 # 训练速度比拼 # 在AI界的“速度与激情”中，TensorFlow和PyTorch可是两大主角。咱们先来聊聊训练速度，这可是衡量框架性能的重要指标之一。\n根据最新的基准测试，TensorFlow和PyTorch在GPU上的跑步速度可谓是不相上下。但如果你细看，会发现TensorFlow在静态图模式下，由于其图优化的特性，可能会比PyTorch的动态图稍微快那么一点点。这就好比是在说，大师内力深厚，一招一式都经过精心计算，自然效率更高。\n不过，PyTorch也不是吃素的。它的动态图让模型调整变得灵活自如，虽然可能在速度上稍有牺牲，但这种灵活性在研究和开发中可是无价的。就像那个江湖中的奇才，虽然速度不是最快，但招式变化多端，让人防不胜防。\n内存使用效率 # 说到内存使用效率，这就得提提两位大侠的内功心法了。\nTensorFlow，这位内力深厚的大师，以其图形优化在内存使用上表现得更为高效。尤其是在大型模型和复杂任务中，TensorFlow能够更加精打细算，不浪费一丝一毫的内存资源。这就像是那位大侠在战斗中，每一分力量都用在刀刃上，绝不浪费。\n而PyTorch，虽然动态图让它在灵活性上更胜一筹，但在内存使用上可能会稍显奢侈。这就好比是那位江湖奇才，招式华丽，但每一招都需要更多的内力支持。不过，随着技术的进步，PyTorch也在不断优化，力求在保持灵活性的同时，也能提高内存使用效率。\n总之，TensorFlow和PyTorch在性能上各有千秋。TensorFlow在训练速度和内存使用上可能稍占优势，而PyTorch则在灵活性和易用性上更胜一筹。这场PK大赛，没有绝对的胜者，只有最适合你的需求的那个框架。\n易用性与灵活性 # TensorFlow易用性改进 # 说到TensorFlow，可能很多人的印象还停留在那个需要提前定义计算图、编程模式略显繁琐的框架。但是，TensorFlow 2.0的问世，可以说是给这个老大哥来了一次“逆生长”。现在的TensorFlow，不仅保留了静态图的高效性能，还引入了动态图的概念，让整个框架变得更加亲民和易用。\nTensorFlow 2.0的Eager Execution模式，让代码的执行变得更加直观，就像我们在普通的Python代码中一样，可以立即看到操作的结果，这对于调试和快速迭代来说，简直是福音。而且，TensorFlow 2.0还进一步简化了API，比如tf.function的出现，让我们可以轻松地将普通函数转换为可优化的TensorFlow图，这种灵活性在以前的版本中是难以想象的。\n此外，TensorFlow 2.0还更加注重用户体验，提供了更多的预构建模型和工具，以及更加丰富的文档和教程资源。这些改进，无疑降低了深度学习的门槛，让更多的新手能够快速上手。\nPyTorch动态图优势 # 而说到PyTorch，它的动态图可谓是其最大的卖点之一。在PyTorch的世界里，我们可以像编写普通Python代码一样定义模型，这种即时执行的方式，让模型的修改和调试变得异常简单。\nPyTorch的动态图，就像是给了我们一支笔，让我们可以边想边画，随时调整我们的思路。这种灵活性，在处理复杂的神经网络架构或者进行研究探索时，显得尤为重要。比如，在自然语言处理中，我们可能需要根据句子的长度动态地调整模型的结构，这时候PyTorch的动态图就大显身手了。\n而且，PyTorch的动态图还带来了另一个好处——调试变得异常简单。我们可以在任何时候打断点，查看变量的状态，甚至在运行时修改代码。这种交互式的编程体验，对于追求快速迭代的研究者来说，无疑是一大利器。\n当然，PyTorch也没有忽视性能。虽然动态图在某些情况下可能会带来一些性能开销，但PyTorch通过JIT编译器等技术，也在不断提升其执行效率。而且，PyTorch的社区也在不断壮大，提供了大量的工具和库，让我们在使用动态图的同时，也能享受到高效的性能。\n总之，TensorFlow和PyTorch在易用性和灵活性上各有千秋。TensorFlow 2.0的易用性改进，让其在工业界的应用更加广泛；而PyTorch的动态图，则让其在研究领域更加受欢迎。这场PK大赛，没有绝对的胜者，只有最适合你需求的那个框架。\n社区支持与资源 # TensorFlow社区生态 # 说到TensorFlow的社区，那可真是AI界的“大佬圈”。这个由Google领衔的社区，不仅有着全球开发者的广泛支持，还有着丰富的资源和工具，让人眼花缭乱。\n首先，TensorFlow的论坛就是个宝藏，无论你是遇到技术难题还是想分享最佳实践，这里都是你的舞台。而且，TensorFlow还有着遍布全球的开发者社区，各种地方性活动和协作项目层出不穷，让你感受到什么是“全球同步”。\n更厉害的是，TensorFlow的RFC（Request for Comments）流程，让每个人都能为TensorFlow的发展出谋划策。这种开放式的协作，让TensorFlow始终保持着活力和创新。\n当然，说到贡献，TensorFlow的GitHub仓库可是热闹非凡。无论是报告bug还是提出新功能，这里都是你的发声地。而且，TensorFlow的博客和YouTube频道，也是获取最新动态和学习资源的好去处。\nPyTorch社区活跃度 # 而PyTorch的社区，虽然起步稍晚，但增长速度可是坐了火箭。这个由Facebook支持的框架，在学术界和研究领域尤其受欢迎，其社区活跃度不容小觑。\nPyTorch的社区以快速增长著称，尤其是那些追求灵活性和动态图的研究者，对PyTorch社区的贡献热情高涨。无论是在论坛上讨论代码问题，还是在GitHub上贡献代码，PyTorch社区的活跃度都显示出其框架的受欢迎程度。\n而且，PyTorch的社区活动也是丰富多彩。从线上的讨论会到线下的Meetup，PyTorch社区的成员们都在积极地交流和学习。这种活跃的社区氛围，不仅推动了PyTorch的发展，也为AI研究带来了新的活力。\n总的来说，TensorFlow和PyTorch的社区都各有特色。TensorFlow的社区生态更加成熟和全面，而PyTorch的社区则更加活跃和迅速增长。不管你是喜欢稳重的“老大哥”，还是追求新鲜感的“小鲜肉”，这两个社区都能给你带来不同的体验和收获。\n应用场景 # TensorFlow工业级应用 # 说到TensorFlow在工业界的应用，这位老大哥可是一点都不含糊。它的足迹遍布各行各业，从自动驾驶汽车到智能语音助手，再到金融风险控制，TensorFlow的身影无处不在。\n自动驾驶汽车：TensorFlow在自动驾驶技术中的应用可谓是风生水起。比如，Waymo利用TensorFlow进行车辆的环境感知和决策制定，让无人驾驶汽车能够在复杂的城市环境中安全行驶。据报道称，Waymo的自动驾驶汽车在没有人类干预的情况下，已经行驶了数百万英里，这背后TensorFlow的算法优化功不可没。\n智能语音助手：Google Assistant就是TensorFlow在智能家居领域的代表作。它能够理解用户的语音指令，并提供相应的服务。TensorFlow的高性能和可扩展性，让Google Assistant能够处理海量的数据请求，同时保持快速响应。\n金融风险控制：在金融领域，TensorFlow也被用来构建复杂的风险评估模型。比如，JPMorgan使用TensorFlow来预测市场趋势和交易风险，帮助银行更好地管理资产和风险。这种大规模的应用，展示了TensorFlow在处理复杂金融数据方面的强大能力。\nPyTorch学术研究应用 # 而PyTorch在学术界的应用，就像是那个在实验室里不断带来惊喜的科学家。它的灵活性和动态图特性，让研究者们在探索新领域时如鱼得水。\n自然语言处理（NLP）：在NLP领域，PyTorch的应用可谓是如火如荼。比如，Transformer模型就是基于PyTorch实现的，它在机器翻译、文本摘要等任务上取得了突破性进展。PyTorch的动态图特性，让研究者能够轻松地调整模型结构，进行各种创新实验。\n计算机视觉：在计算机视觉领域，PyTorch也是大放异彩。例如，Facebook AI Research（FAIR）团队使用PyTorch开发了多种视觉识别模型，包括图像分类、目标检测等任务。PyTorch的灵活性，让研究者能够快速迭代模型，推动视觉识别技术的发展。\n强化学习：在强化学习领域，PyTorch的动态图特性同样大受欢迎。比如，DeepMind的AlphaGo就是使用PyTorch进行训练的，它在围棋等复杂游戏中战胜了人类顶尖选手。PyTorch的动态图让强化学习算法的实现变得更加直观和灵活。\n总之，TensorFlow和PyTorch在各自的应用场景中都展现出了强大的实力。TensorFlow在工业界的广泛应用，展示了它在大规模部署和性能优化方面的优势；而PyTorch在学术研究中的应用，则体现了它在灵活性和易用性方面的魅力。这场PK大赛，没有绝对的胜者，只有最适合你需求的那个框架。\n未来展望 # TensorFlow发展趋势 # TensorFlow，这位AI界的“老大哥”，未来的发展势头依然强劲。从最新的动态来看，TensorFlow正朝着以下几个方向大步迈进。\n更广泛的生态系统整合：TensorFlow正在不断深化与云服务、物联网、大数据平台的整合，形成端到端的AI解决方案。Google Cloud的TensorFlow Extended (TFX) 工具包就是这一趋势的典型代表，它覆盖了从数据准备、模型训练、部署到监控的整个机器学习生命周期。\n量子计算与深度学习的交叉：随着TensorFlow Quantum的发布，量子计算与经典机器学习的融合趋势愈发明显。未来，TensorFlow可能会提供更多工具和API，支持量子电路的构建、模拟及量子神经网络的训练，为探索量子优势提供强大支撑。\n自动机器学习(AutoML)的深化：AutoML旨在降低机器学习的入门门槛，使非专业人士也能构建高效模型。TensorFlow AutoML和Keras Tuner等工具将不断优化，提供更智能的特征选择、模型架构搜索、超参数优化等功能，加速AI应用的开发周期。\n强化对隐私保护的支持：面对日益增长的数据隐私和安全需求，TensorFlow将加强对隐私保护技术的支持，比如联邦学习、同态加密等。TensorFlow Privacy库的持续发展，将帮助企业构建既保护用户隐私又保持模型性能的解决方案。\nPyTorch发展方向 # 而PyTorch，这位AI界的“小鲜肉”，未来的发展同样值得期待。PyTorch的发展方向主要集中在以下几个领域。\n性能优化：随着数据量和计算需求的增加，性能优化将成为一个重要的挑战。PyTorch需要继续优化其性能，以满足不断增加的计算需求。这包括对CPU和GPU的优化，以及对分布式训练和推理的支持。\n多设备支持：随着AI技术的发展，多设备支持将成为一个重要的趋势。PyTorch需要继续扩展其多设备支持，以满足不同设备的需求，特别是在移动和边缘计算领域。\n易用性和灵活性：PyTorch的易用性和灵活性是其主要优势，但仍然有待提高。未来的发展趋势是继续提高PyTorch的易用性和灵活性，以满足不断增加的研究和应用需求。\n生态系统建设：PyTorch团队计划进一步扩大PyTorch的生态系统，包括支持更多的硬件平台和框架，以及与更多的开源项目进行集成。这将有助于提高PyTorch的灵活性和互操作性，使其成为更多开发者的首选深度学习框架。\n研究支持：PyTorch团队一直致力于支持深度学习研究的发展。在2024年下半年，他们计划推出更多的工具和资源，以帮助研究人员更高效地进行实验和探索。这包括对新算法和模型的支持，以及对可解释性和鲁棒性等研究方向的关注。\n总之，TensorFlow和PyTorch都在不断进化，它们都在为成为AI界的“最佳武器”而努力。未来，这两个框架将如何发展，我们拭目以待。不过，有一点可以肯定，它们都将为我们带来更多的惊喜和可能。\n","date":"2024-11-18","externalUrl":null,"permalink":"/ai/comparison-between-tensorflow-and-pytorch/","section":"Ais","summary":"\u003cp\u003e关于TensorFlow与PyTorch，我知道你们在想什么：“这俩框架我都用过，但到底哪个更胜一筹呢？”别急，今天我们就来扒一扒这背后的小秘密。不管你是深度学习的新手，还是老司机，这篇文章都能给你带来一些新视角。准备好了吗？让我们开始这场有趣的“对决”吧！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e江湖地位 \n    \u003cdiv id=\"%E6%B1%9F%E6%B9%96%E5%9C%B0%E4%BD%8D\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%B1%9F%E6%B9%96%E5%9C%B0%E4%BD%8D\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e首先，让我们来聊聊这两位大侠的江湖地位。\u003c/p\u003e\n\u003cp\u003eTensorFlow，这个由Google亲生的深度学习框架，自2015年横空出世以来，就以其强大的性能和广泛的应用场景，迅速占领了AI界的大片江山。它就像那个在武林大会上一鸣惊人的少侠，不仅有着深厚的内功（Google的技术支持），还有着广泛的人脉（全球开发者的支持）。\u003c/p\u003e\n\u003cp\u003eTensorFlow的成长之路可谓是风光无限。从1.0版本的稳定发布，到2.0版本的革命性升级，每一步都走得坚实而有力。现在的TensorFlow，不仅支持静态图，还拥抱了动态图，让模型的构建和调试变得更加灵活。这种变革，就像是那个武林高手在不断的战斗中，不断学习新的招式，不断提升自己的武艺。\u003c/p\u003e\n\u003cp\u003e而PyTorch，这个由Facebook支持的后起之秀，虽然起步稍晚，但凭借其独特的魅力和强大的实力，迅速在AI界崭露头角。PyTorch的动态计算图，就像是那个总是能给人带来惊喜的江湖奇才，它的灵活性和易用性，让无数研究者和开发者为之倾倒。\u003c/p\u003e","title":"TensorFlow与PyTorch究竟谁更胜一筹","type":"ai"},{"content":" 在Linux世界中，Shell脚本是一种强大的工具，它可以帮助我们自动化任务、处理数据和执行复杂的命令序列。以下是一些Shell脚本的小技巧，这些技巧不仅可以提高你的工作效率，还能让你的脚本更加强大和灵活。\n条件判断 # 使用if语句可以对条件进行判断，例如检查文件是否存在或变量是否满足特定条件。例如：\nif [ -f \u0026#34;myfile.txt\u0026#34; ]; then echo \u0026#34;File exists.\u0026#34; else echo \u0026#34;File does not exist.\u0026#34; fi 循环遍历 # for循环可以用来遍历文件、目录或数组。例如，打印当前目录下的所有文件：\nfor file in *; do echo \u0026#34;Processing $file\u0026#34; done 函数定义 # 定义函数可以重用代码块，使脚本更加模块化。例如，定义一个函数来检查磁盘使用情况：\ncheck_disk_usage() { df -h | grep -vE \u0026#39;^Filesystem|tmpfs|cdrom\u0026#39; } 参数扩展 # Shell脚本中的参数扩展可以用于创建动态变量名或从文件名中提取特定部分。例如，从文件名中提取扩展名：\nfilename=\u0026#34;example.txt\u0026#34; extension=\u0026#34;${filename##*.}\u0026#34; echo \u0026#34;The file extension is: $extension\u0026#34; 输入重定向 # 使用\u0026lt;可以将文件内容作为命令的输入，而\u0026gt;和\u0026raquo;可以将命令的输出重定向到文件。例如，将命令输出保存到文件：\nls \u0026gt; filelist.txt 管道 # 管道|可以将一个命令的输出作为另一个命令的输入，实现命令之间的数据流。例如，查找文件并列出详细信息：\nfind / -name \u0026#34;*.log\u0026#34; -print | xargs ls -l 错误处理 # 使用set -e可以让脚本在遇到错误时立即退出，而set -o pipefail可以确保管道命令中的任何错误都能被捕捉。例如：\nset -e # 脚本中的命令 调试技巧 # 使用set -x可以在执行脚本时打印每条命令及其参数，这对于调试非常有用。例如：\nset -x # 脚本中的命令 环境变量 # 环境变量可以在脚本中设置并使用，它们可以影响脚本的行为或传递配置信息。例如，设置时区：\nexport TZ=\u0026#34;America/New_York\u0026#34; 脚本参数 # 通过位置参数$1, $2等，脚本可以接受命令行输入。例如，接受两个参数并执行操作：\n#!/bin/bash echo \u0026#34;First argument: $1\u0026#34; echo \u0026#34;Second argument: $2\u0026#34; 这些技巧只是Shell脚本能力的一部分。掌握它们可以帮助你写出更加高效、灵活和强大的脚本。记住，实践是学习的最佳方式，所以不要犹豫，开始编写你自己的Shell脚本吧！\n","date":"2024-11-18","externalUrl":null,"permalink":"/software/10-tips-of-linux-shell-script/","section":"Softwares","summary":"\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./linux-shell-script.png\" alt=\"Linux Shell\" /\u003e\n      \n    \u003c/figure\u003e\n\n在Linux世界中，\u003ca href=\"https://www.vxworks.net/linux/442-linux-sheel-simplified-user-guide\" target=\"_blank\"\u003eShell脚本\u003c/a\u003e是一种强大的工具，它可以帮助我们自动化任务、处理数据和执行复杂的命令序列。以下是一些Shell脚本的小技巧，这些技巧不仅可以提高你的工作效率，还能让你的脚本更加强大和灵活。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e条件判断 \n    \u003cdiv id=\"%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e使用if语句可以对条件进行判断，例如检查文件是否存在或变量是否满足特定条件。例如：\u003c/p\u003e","title":"10个必知的Linux Shell脚本小技巧","type":"software"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/shell/","section":"Tags","summary":"","title":"Shell","type":"tags"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/linux-device-driver/","section":"Tags","summary":"","title":"Linux Device Driver","type":"tags"},{"content":"","date":"2024-11-18","externalUrl":null,"permalink":"/tags/mellanox/","section":"Tags","summary":"","title":"Mellanox","type":"tags"},{"content":"在旧版本的Linux操作系统中（如Cenos7.4），部分网卡不能被识别出来，需要手动安装驱动。\n查看网卡 # BMC界面查看安装了7张网卡，共13个网口，如下图\n在系统中使用lspci也可以看到13个网口\n[root@localhost ~]# lspci | grep Mellanox 04:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5] 04:00.1 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5] 08:00.0 Ethernet controller: Mellanox Technologies MT27710 Family [ConnectX-4 Lx] 08:00.1 Ethernet controller: Mellanox Technologies MT27710 Family [ConnectX-4 Lx] 2d:00.0 Ethernet controller: Mellanox Technologies MT27800 Family [ConnectX-5] 5b:00.0 Ethernet controller: Mellanox Technologies MT28841 5b:00.1 Ethernet controller: Mellanox Technologies MT28841 5c:00.0 Ethernet controller: Mellanox Technologies MT28841 5c:00.1 Ethernet controller: Mellanox Technologies MT28841 96:00.0 Ethernet controller: Mellanox Technologies MT28841 96:00.1 Ethernet controller: Mellanox Technologies MT28841 97:00.0 Ethernet controller: Mellanox Technologies MT28841 97:00.1 Ethernet controller: Mellanox Technologies MT28841 但是使用命令查看网口，只可以看到5个ens网口，有8个没有，需要手动安装驱动\n[root@localhost ~]# ip add 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 2: ens19f0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 3: ens19f1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 4: ens21f0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 5: ens21f1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 6: ens12: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 7: virbr0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN qlen 1000 8: virbr0-nic: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN qlen 安装驱动 # 下载驱动 # 驱动下载地址：\nhttps://developer.nvidia.com/networking/ethernet-software\nEN版本只包含网卡驱动，OFED版本既有驱动还有部分配套软件，建议下载OFED版本。\n然后选择对应的系统和架构，下载安装包\n查看操作系统版本\n[root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) 安装驱动-EN # 解压安装包 # [root@localhost Downloads]# ls mlnx-en-23.10-3.2.2.0-rhel7.4-x86_64.tgz [root@localhost Downloads]# tar -vxf mlnx-en-23.10-3.2.2.0-rhel7.4-x86_64.tgz 安装程序 # 进入目录，执行安装程序\n[root@localhost Downloads]# cd mlnx-en-23.10-3.2.2.0-rhel7.4-x86_64/ [root@localhost mlnx-en-23.10-3.2.2.0-rhel7.4-x86_64]# ls common_installers.pl common.pl create_mlnx_ofed_installers.pl distro install is_kmp_compat.sh LICENSE mlnx_add_kernel_support.sh RPM-GPG-KEY-Mellanox RPMS RPMS_ETH src uninstall.sh [root@localhost mlnx-en-23.10-3.2.2.0-rhel7.4-x86_64]# ./install Logs dir: /tmp/mlnx-en.55110.logs General log file: /tmp/mlnx-en.55110.logs/general.log Verifying KMP rpms compatibility with target kernel... This program will install the mlnx-en package on your machine. Note that all other Mellanox, OEM, OFED, RDMA or Distribution IB packages will be removed. Those packages are removed due to conflicts with mlnx-en, do not reinstall them. # 这里输入y即可 Do you want to continue?[y/N]:y 重新加载新驱动 # 等安装完，需要执行提示命令，重新加载新驱动\n/etc/init.d/mlnx-en.d restart 注意，重新加载驱动后，网卡名会变化，对应的网卡配置文件也要修改才行\n# 如，ens19f0变为ens19f0np0 9: ens19f0np0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 查看网卡信息 # 重新查看网卡数量，可以看到变为13个，恢复正常。\n9: ens19f0np0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 10: ens19f1np1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 11: ens21f0np0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 12: ens21f1np1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 13: ens12np0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 14: ens13f0np0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 15: ens13f1np1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 16: ens14f0np0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 17: ens14f1np1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 18: ens15f0np0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 19: ens15f1np1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 20: ens16f0np0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 21: ens16f1np1: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc mq state DOWN qlen 1000 安装驱动-OFED # 解压后执行安装程序\n[root@localhost ~]# tar -vxf MLNX_OFED_LINUX-23.10-3.2.2.0-rhel7.4-x86_64 [root@localhost ~]# cd MLNX_OFED_LINUX-23.10-3.2.2.0-rhel7.4-x86_64/ [root@localhost MLNX_OFED_LINUX-23.10-3.2.2.0-rhel7.4-x86_64]# ./mlnxofedinstall 如果缺少依赖，按提示安装\nGeneral log file: /tmp/MLNX_OFED_LINUX.74618.logs/general.log Error: One or more required packages for installing MLNX_OFED_LINUX are missing. Please install the missing packages using your Linux distribution Package Management tool. Run: yum install tcl tk 然后继续安装，输入y即可\n[root@localhost MLNX_OFED_LINUX-23.10-3.2.2.0-rhel7.4-x86_64]# ./mlnxofedinstall Logs dir: /tmp/MLNX_OFED_LINUX.75823.logs General log file: /tmp/MLNX_OFED_LINUX.75823.logs/general.log Verifying KMP rpms compatibility with target kernel... This program will install the MLNX_OFED_LINUX package on your machine. Note that all other Mellanox, OEM, OFED, RDMA or Distribution IB packages will be removed. Those packages are removed due to conflicts with MLNX_OFED_LINUX, do not reinstall them. Do you want to continue?[y/N]:y 安装完也一样重新加载驱动\nLog File: /tmp/Fpnr9q8X6m Real log file: /tmp/MLNX_OFED_LINUX.75823.logs/fw_update.log Failed to update Firmware. See /tmp/MLNX_OFED_LINUX.75823.logs/fw_update.log To load the new driver, run: /etc/init.d/openibd restart 后记 # Mellanox网卡在系统下执行ip link set down命令后link灯依然点亮，而intel的网卡是熄灭的。经过测试排查，总结记录一下处理过程如下：\n需要将网卡的KEEP_ETH_LINK_UP配置项关闭\nmellanox的MFT工具需要提前安装下载并安装,可以从以下网址下载(https://www.mellanox.com/products/adapter-software/firmware-tools）\n以下是具体处理过程：\n[root@localhost ~]#mst start [root@localhost ~]#mst status [root@localhost ~]#mlxconfig –d /dev/mst/**** s KEEP_ETH_LINK_UP_P1=0 (其中***部分为上一步命令的输出。) [root@localhost ~]#mlxconfig –d /dev/mst/**** s KEEP_ETH_LINK_UP_P2=0 [root@localhost ~]#reboot 原因是Mellanox的网卡在 执行ip link set down命令之后，网口link灯依然是亮的，是由于网卡的KEEP_ETH_LINK_UP配置项是默认开启的。\n该配置项可以保证网卡的PHY在部分在没有物理断连的情况下一只保持的link状态。\n在后期的实验室中实测，将KEEP_ETH_LINK_UP配置关闭，执行ip link set down命令之后，link灯可以熄灭。\n","date":"2024-11-18","externalUrl":null,"permalink":"/network/install-linux-device-driver-for-mellanox-network-adapter/","section":"Networks","summary":"\u003cp\u003e在旧版本的\u003ca href=\"https://www.vxworks.net/linux/1219-top-10-things-to-do-after-installing-kali-linux\" target=\"_blank\"\u003eLinux\u003c/a\u003e操作系统中（如Cenos7.4），部分网卡不能被识别出来，需要手动安装驱动。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e查看网卡 \n    \u003cdiv id=\"%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eBMC界面查看安装了7张网卡，共13个网口，如下图\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./mellanox-linux-device-driver-1.png\" alt=\"Mellanox Network List\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"在Linux系统下安装Mellanox网卡驱动","type":"network"},{"content":"本文介绍一下在服务器中安装，配置，调试CXL Memory Expansion Card的详细的过程，步骤和流程，注意事项，以及可能碰到的各种问题和解决方法，以及匹配的服务器所必需的前提条件。\n安装、配置和调试CXL（Compute Express Link）内存扩展卡是一个复杂的过程，需要对硬件和软件环境进行精确配置，以确保性能和稳定性。以下是详细的步骤、注意事项以及可能遇到的问题和解决方法。\n预先准备 # 在安装CXL内存扩展卡之前，确保以下条件和设备到位：\n兼容的服务器：您的服务器必须支持CXL 1.1或2.0规范，这需要在主板和CPU架构上支持CXL协议，例如最新的英特尔Xeon或AMD EPYC处理器。\n固件和BIOS更新：将服务器的BIOS和固件升级到最新版本，以确保兼容性和功能支持。CXL支持通常在最新固件中提供。\n操作系统支持：确保操作系统（如Linux内核版本）支持CXL协议。某些分布版本如RHEL、Ubuntu、SUSE等可能已经具备对CXL设备的支持。 所需工具：螺丝刀、电防静电腕带、操作手册。\n安装CXL内存扩展卡 # 步骤\n关机并断电：在安装硬件之前，关闭服务器并断开所有电源连接，佩戴防静电腕带以避免静电损坏 打开机箱：使用螺丝刀小心地拆开服务器机箱，找到合适的PCIe插槽 插入CXL内存扩展卡：将CXL卡插入合适的PCIe插槽（通常为PCIe Gen5插槽，确保它们与主板兼容），用螺丝固定扩展卡 像上述Samsung这类使用EDSFF接口的CXL内存扩展卡，需要使用SerialCables公司的Gen5 E3/AIC转接卡转接后才能插入标准 PCIe Gen5插槽。感兴趣可以下载参考《PCIe5\u0026amp;6.0, CXL, NVMeNVMoF, SSD, NAND, DDR5, 800GE测试技术和工具白皮书_ver11.11》参考chapter 5.4.1.3和chapter 11.1.5。参见下图：\n连接辅助电源（如有需要）：某些CXL内存扩展卡可能需要额外的电源连接，确保按照手册说明进行连接 配置BIOS设置 # 启动服务器并进入BIOS设置：在开机过程中，按下指定的键（如F2或Del）进入BIOS界面 启用CXL支持：在BIOS设置中，找到“PCIe配置”或“CXL配置”选项，确保CXL功能被启用。如果支持内存映射，需要根据具体需求进行配置 调整内存配置：根据CXL内存的特性，可以配置内存的用途，如用于内存扩展、缓存等 保存并退出：保存BIOS设置并重启服务器 操作系统配置 # 安装必要的驱动程序：某些CXL设备可能需要特定的驱动程序。使用服务器厂商或CXL卡厂商提供的软件安装包，完成驱动程序安装。 确认内存识别：使用lspci或dmesg等命令检查CXL设备是否被正确识别。例如： lspci | grep CXL dmesg | grep CXL 调整内存管理：配置系统内存管理，使操作系统能够正确识别和利用CXL内存扩展卡。例如，调整内存分区、虚拟内存映射等。\n调试和优化 # 监控内存性能：使用内存监控工具（如free -m、top或专用的内存监控软件）检查CXL内存的使用情况，观察是否有性能瓶颈或异常情况。 测试负载：运行高内存占用的负载测试，观察系统稳定性和性能表现。如果发现问题，可以调整BIOS设置或内存管理配置。 注意事项 # CXL版本兼容性：确保所有组件支持相同的CXL版本，否则可能无法正常通信 散热问题：高性能内存扩展卡可能会产生大量热量，必须提供足够的散热措施，如增加风扇或调整气流设计 电源要求：一些高功率CXL卡可能会增加系统功耗，确保电源单元（PSU）足够强大 常见问题及解决方法 # CXL卡无法识别： # 检查BIOS中CXL功能是否启用，更新BIOS和固件。 确认PCIe插槽是否工作正常，尝试换一个插槽安装。\n性能不佳或系统不稳定： # 调整BIOS设置，优化内存时序或禁用不必要的选项。 检查是否有冲突的驱动程序，重新安装或更新。\n设备无法加载驱动： # 查看内核日志（使用dmesg）以获取详细错误信息，更新操作系统或使用不同内核版本。\n温度过高： # 增加额外的散热措施，定期清理灰尘以保持良好气流。\n通过这些步骤，您可以成功安装和调试CXL内存扩展卡，并将其用于内存密集型工作负载，以提高服务器的性能和内存容量。\n","date":"2024-11-17","externalUrl":null,"permalink":"/hardware/install-and-configure-cxl-memory-expansion-card-on-server/","section":"Hardwares","summary":"\u003cp\u003e本文介绍一下在服务器中安装，配置，调试\u003ca href=\"https://www.kad8.com/hardware/cxl-memory-module-box-cmm-b/\" target=\"_blank\"\u003eCXL Memory Expansion Card\u003c/a\u003e的详细的过程，步骤和流程，注意事项，以及可能碰到的各种问题和解决方法，以及匹配的服务器所必需的前提条件。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./CXL-Memory-1.png\" alt=\"CXL Memory Expansion\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./CXL-Memory-2.png\" alt=\"CXL Memory Expansion\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e安装、配置和调试CXL（Compute Express Link）内存扩展卡是一个复杂的过程，需要对硬件和软件环境进行精确配置，以确保性能和稳定性。以下是详细的步骤、注意事项以及可能遇到的问题和解决方法。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e预先准备 \n    \u003cdiv id=\"%E9%A2%84%E5%85%88%E5%87%86%E5%A4%87\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E9%A2%84%E5%85%88%E5%87%86%E5%A4%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在安装CXL内存扩展卡之前，确保以下条件和设备到位：\u003c/p\u003e","title":"CXL内存扩展卡在服务器上如何安装和配置","type":"hardware"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/memory-expansion/","section":"Tags","summary":"","title":"Memory Expansion","type":"tags"},{"content":"AMD计划推出基于Hawk Point系列的全新Ryzen 200系列APU，准备进军入门级笔记本电脑市场，对抗英特尔即将更新的Core 200系列处理器。\n据悉，AMD一直热衷于对现有的CPU产品线进行更新，以提供更具吸引力的SKU，填补预算领域的性能空白。最近，AMD的Phoenix系列（被认为是最受欢迎的产品之一）已经更新为Ryzen 8000系列的“Hawk Point”APU。此次更新中，最引人注目的是升级了NPU，性能可达16 TOPS。\n根据升级包的泄露信息，AMD计划基于相同的Zen 4架构，推出采用Ryzen 200命名方案的Hawk Point刷新APU阵容，预计变化不大。泄露的信息虽然未透露太多关于功能或性能的细节，但提到该系列中的一款型号为“Ryzen 7 255H”，这可能是现有的“Hawk Point”Ryzen 7 8745HS APU的升级版。该SKU于数月前发布，但未配备NPU。消息称，传闻中的Ryzen 7 255H将直接与英特尔的Core Ultra 7 255H竞争，AMD可能会在命名方案上与英特尔保持一致，以减少市场混淆。\n预计AMD将推出以下型号：\nRyzen 7 255H（Ryzen 7 8745HS的升级版） Ryzen 7 265H（Ryzen 7 8845HS的升级版） 对于这款Hawk Point的更新版本，不太可能有性能上的明显提升，所以不足以称之为代际升级。但可能的改进点在于[AI性能](https://www.gaitpu.com，因为Hawk Point系列并未配备像Ryzen AI 300系列那样的“AI TOPS”。鉴于AMD在APU更新方面的一贯做法，我们预计整体核心数量和集成显卡配置将保持不变。\nRyzen 200系列APU有望填补针对中低端工作负载的设备市场空白，特别是手持设备和迷你电脑。在手持设备领域，AMD尚未能复制“Phoenix” APU的热度，因此Ryzen 200系列APU可能会是一个理想的选择。\n至于发布日期，我们可以预计Ryzen 200系列SKU将在今年晚些时候推出，正值英特尔发布其Core 200“Raptor Lake Refresh”系列之际。\n","date":"2024-11-17","externalUrl":null,"permalink":"/ai/amd-plans-to-launch-new-ryzen-200-series-apus/","section":"Ais","summary":"\u003cp\u003eAMD计划推出基于Hawk Point系列的全新Ryzen 200系列APU，准备进军入门级笔记本电脑市场，对抗英特尔即将更新的Core 200系列处理器。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-ryzen-200-apu.png\" alt=\"AMD APU\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e据悉，AMD一直热衷于对现有的CPU产品线进行更新，以提供更具吸引力的SKU，填补预算领域的性能空白。最近，AMD的Phoenix系列（被认为是最受欢迎的产品之一）已经更新为Ryzen 8000系列的“Hawk Point”APU。此次更新中，最引人注目的是升级了\u003ccode\u003eNPU\u003c/code\u003e，性能可达16 \u003ccode\u003eTOPS\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e根据升级包的泄露信息，AMD计划基于相同的\u003ccode\u003eZen 4\u003c/code\u003e架构，推出采用Ryzen 200命名方案的Hawk Point刷新APU阵容，预计变化不大。泄露的信息虽然未透露太多关于功能或性能的细节，但提到该系列中的一款型号为“Ryzen 7 255H”，这可能是现有的“Hawk Point”Ryzen 7 8745HS APU的升级版。该SKU于数月前发布，但未配备NPU。消息称，传闻中的Ryzen 7 255H将直接与英特尔的Core Ultra 7 255H竞争，AMD可能会在命名方案上与英特尔保持一致，以减少市场混淆。\u003c/p\u003e","title":"AMD 计划推出全新 Ryzen 200 系列APU","type":"ai"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/apu/","section":"Tags","summary":"","title":"APU","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/evpn/","section":"Tags","summary":"","title":"EVPN","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/vxlan/","section":"Tags","summary":"","title":"VXLAN","type":"tags"},{"content":"随着云计算和虚拟化技术的迅猛发展，传统网络架构逐渐暴露出难以满足大规模、高灵活性云数据中心需求的短板。为了应对这一挑战，Overlay网络的概念应运而生，其核心理念在于通过网络虚拟化技术构建一层逻辑网络，以更灵活、高效地管理网络资源。在众多Overlay网络技术中，VXLAN因其出色的扩展性和隔离能力脱颖而出。与此同时，EVPN也开始在数据中心和企业园区网络中展现出非凡的潜力。\n传统企业园区设计 # 传统上，许多企业园区网络都是采用三层架构设计的，包括接入层、汇聚层和核心层。规模较小的地点会采用扁平化核心模型，即两层架构，将核心层和汇聚层合并为一层。对于大型地点来说，典型的网络设计如下所示：\n图 1 - 传统三层网络 请注意，有些链接是 L2（红色），而其他的则是 L3（绿色）。在这种设计中，我们通常会遇到哪些问题？\n并非所有链路都在转发。 缺少等价多路径 (ECMP) 路径。 接入层到汇聚层易受桥接环路影响。 使用生成树协议（STP）及其保护特性（如BPDU Guard、Root Guard、PortFast等）设计复杂。 收敛速度可能较慢。 与 VLAN 数量和 STP 实例相关的可扩展性问题。 需要第一跳路由协议 (FHRP)，如热备份路由协议（HSRP）来提供汇聚层的冗余。 故障排除困难。 如果设计得当，这种类型的网络架构可以很好地工作，但也存在许多潜在的陷阱。相信大家在职业生涯中的某个时刻，都尝试过查找桥接环路的来源。正如前文所提到的，接入层缺乏 ECMP，因为并非所有链路都可以利用。下图移除了通常会因 STP 而被阻塞的链路：\n图 2 – 具有阻塞链路的传统三层网络 在这个拓扑结构中，DS01 是根桥，这就是通向 DS02 的链路被阻塞的原因。这不仅意味着没有 ECMP，还意味着如果通向 DS01 的链路出现问题，只能依赖 STP 进行收敛。使用 802.1D STP 构建网络的话，可能需要 30-50 秒，而使用 802.1w STP，可以实现亚秒级的收敛。\nVXLAN 和 EVPN 可以帮助解决其中一些问题。接下来，我们一步一步来分析。\nVXLAN 的兴起 # 我们经常将 VXLAN 和 EVPN 放在一起讨论，就好像它们是同一种技术一样。然而，EVPN 最初主要用于服务提供商网络，以向客户提供更好的 L2 服务，而 VXLAN 主要用于数据中心。VXLAN是根据2014年发布的RFC 7348定义的，它原本是一项独立的技术，并没有与EVPN配对。它是一种数据平面封装技术，旨在克服传统L2网络的挑战：\n可扩展性问题：IEEE 802.1Q中定义的VLAN ID只有12个比特，这意味着最多有 4096 个 VLAN。此外，通常还会预留一些VLAN，使得实际可用的数量更少。这对于大规模网络（如数据中心和一些大型园区环境）来说是不够的。 缺乏 ECMP：前文提到 STP 会阻塞链路，这意味着网络中昂贵的链路没有得到有效地使用。有些工作负载需要大量带宽。在数据中心使用三层架构可能会造成hotspot，导致某些链路/节点过载。 缺乏多租户：使用传统设计很难构建多租户网络，主要与无法扩展有关。 那么 VXLAN 是如何解决这些问题的？\nVXLAN 在报头中有一个 24 位字段，称为虚拟网络标识符 (VNI)，提供了 16777216 个潜在虚拟网络。与 4096这个数字相比，是一个相当大的进步！\nVXLAN 能够同时执行桥接和路由。它是一种在物理网络之上运行的协议，我们通常称之为Overlay。可以把它想象成一个隧道，其中隧道的两端点被称为VXLAN隧道端点（VTEP）。由于 VXLAN 是一种隧道形式，尽管它是无状态的，但只要有 L3 连接，它就可以在任何拓扑和底层协议之上运行。这意味着可以构建所谓Underlay网络，它是一个完全路由的设计。这就消除了与 L2 相关的几乎所有挑战，并提供了 ECMP、快速收敛等功能。\n由于 VXLAN 的扩展性更好，这也提供了多租户支持的能力。\n下面是一个叶脊拓扑的示例：\n图 3 - 采用 VXLAN 的叶脊拓扑 此拓扑中的所有链路都是 L3，并且它们将执行转发操作。通常，Underlay会使用如OSPF或IS-IS这样的内部网关协议（IGP）来提供VTEP之间的L3连接。\n当然，提供这些强大功能是需要付出代价的。这里说的代价不是金钱成本，而是封装和开销。VXLAN 是一种 MAC-over-IP/UDP 协议，它会将以太网帧进行封装，并添加一个VXLAN头部、UDP头部以及外部IP和MAC头部。这会增加50字节或54字节的开销，具体取决于是否保留完整的802.1Q头部。如下所示：\n图 4 - VXLAN 封装 VXLAN头部主要提供VNI，以便在数据平面中将数据包转发到正确的虚拟网络。 当帧被 VTEP 封装时，最常见的做法是移除802.1Q头部。 当原始帧被修改时，会计算一个新的 CRC（循环冗余校验），并丢弃旧的 CRC。由于旧的 CRC 被丢弃，所以新的 CRC 不会增加任何额外的开销。 添加一个 UDP 报头，其中目标端口通常为 4789，而源端口则根据内部报头中的字段生成。UDP 报头增加了熵，以便底层可以更好地利用 ECMP 路径。 外部 IP 报头包含源和目标 VTEP 的源 IP 和目标 IP。 外部以太网报头用于通过以太网链路逐跳转发帧。 需要注意的是，没有 EVPN 支持的 VXLAN 会利用泛洪和学习行为，这与传统交换机的行为类似。如果它不知道目标 MAC，它会泛洪该帧，并在收到响应时学习 MAC，这被称为未知单播。没有 EVPN 的 VTEP 行为类似。如果它尚未学习 MAC，它将使用底层网络的多播或入口复制将其泛洪到所有其他相关 VTEP。\n泛洪和学习机制显然不是最优选择，那么如何解决这一问题呢？这就需要用到EVPN了。\nEVPN的引入 # EVPN是一种用于二层网络互联的VPN技术，采用类似于BGP/MPLS IP VPN的机制，在BGP协议的基础上定义了一种新的NLRI（网络层可达信息）即EVPN NLRI，EVPN NLRI定义了几种新的BGP EVPN路由类型，用于处在二层网络的不同站点之间的MAC地址学习和发布。\n前文提到，原有的VXLAN实现方案没有控制平面，是通过数据平面的流量泛洪进行VTEP发现和主机信息（包括IP地址、MAC地址、VNI、网关VTEP IP地址）学习的，这种方式导致数据中心网络存在很多泛洪流量。为了解决这一问题，VXLAN引入了EVPN作为控制平面，通过在VTEP之间交换BGP EVPN路由实现VTEP的自动发现、主机信息相互通告等特性，从而避免了不必要的数据流量泛洪。\n与独立 VXLAN 相比，EVPN 提供了以下优势：\n通过 BGP 消息发现 VTEP，而不是基于接收 VXLAN 封装的帧。这比盲目接受所有 VXLAN 封装的帧更安全。 广播 MAC 和 MAC/主机 IP 路由、入口复制 VTEP、IP 前缀和以太网段。 减少泛洪量。 像ARP抑制这样的特性依赖于通过EVPN学习到的路由。 EVPN 具备很多优势，那么如何启用它呢？需要配置BGP并启用EVPN。通常情况下，叶子节点（Leaf）被配置为路由反射器客户端，而骨干节点（Spine）充当路由反射器。如下所示：\n图 5 - BGP EVPN 拓扑 对于了解MPLS 的人来说，EVPN路由中有很多熟悉的部分，例如路由目标 (RT)、路由区分符 (RD)、MPLS 标签等。下面列出了一些最常见的 EVPN 路由类型及其提供的内容：\n图 6 - EVPN 路由类型 通过EVPN通告VTEP所知的MAC和IP地址，就无需依赖泛洪和学习行为。\n总而言之，在构建能够扩展且快速收敛的健壮网络方面，传统的三层网络设计面临诸多挑战。通过利用VXLAN和EVPN构建叶脊拓扑，不仅可以显著提高网络的灵活性和可靠性，还能有效解决扩展性、多租户支持等问题，同时实现快速收敛和等价多路径传输。\n","date":"2024-11-17","externalUrl":null,"permalink":"/network/why-vxlan-needs-evpn/","section":"Networks","summary":"\u003cp\u003e随着云计算和虚拟化技术的迅猛发展，传统网络架构逐渐暴露出难以满足大规模、高灵活性云数据中心需求的短板。为了应对这一挑战，Overlay网络的概念应运而生，其核心理念在于通过网络虚拟化技术构建一层逻辑网络，以更灵活、高效地管理网络资源。在众多Overlay网络技术中，\u003ca href=\"https://www.kad8.com/network/introduction-to-vxlan/\" target=\"_blank\"\u003eVXLAN\u003c/a\u003e因其出色的扩展性和隔离能力脱颖而出。与此同时，EVPN也开始在数据中心和企业园区网络中展现出非凡的潜力。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e传统企业园区设计 \n    \u003cdiv id=\"%E4%BC%A0%E7%BB%9F%E4%BC%81%E4%B8%9A%E5%9B%AD%E5%8C%BA%E8%AE%BE%E8%AE%A1\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BC%A0%E7%BB%9F%E4%BC%81%E4%B8%9A%E5%9B%AD%E5%8C%BA%E8%AE%BE%E8%AE%A1\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e传统上，许多企业园区网络都是采用三层架构设计的，包括接入层、汇聚层和核心层。规模较小的地点会采用扁平化核心模型，即两层架构，将核心层和汇聚层合并为一层。对于大型地点来说，典型的网络设计如下所示：\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./vxlan-evpn-1.jpeg\" alt=\"Why VXLAN need EVPN\" /\u003e\n      \u003cfigcaption\u003e图 1 - 传统三层网络\u003c/figcaption\u003e\n    \u003c/figure\u003e\n\u003c/p\u003e","title":"VXLAN为什么需要EVPN","type":"network"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/arm/","section":"Tags","summary":"","title":"ARM","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/google-cloud/","section":"Tags","summary":"","title":"Google Cloud","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/server/","section":"Tags","summary":"","title":"Server","type":"tags"},{"content":"当搜索引擎巨头谷歌想要成为云计算的时候，几年后谷歌意识到客户还没有准备好购买掩盖底层硬件的全套平台服务，而是想要更低级别的基础设施服务，以便有更多的可选性和更多的责任，谷歌云不可避免地要从英特尔、AMD 和 Nvidia 购买计算引擎来充实其服务器群。\n而且英特尔过去在 CPU 领域占据的利润率，以及 AMD 现在在 GPU 领域占据的利润率，以及在可预见的未来英伟达仍然在 GPU 领域占据的利润率，也意味着谷歌不可避免地会创建自己的 CPU 和 AI 加速器，以试图降低其服务器群的 TCO，特别是对于搜索引擎索引、广告投放、视频投放和各种形式和超大规模的数据分析等内部工作。\n因此，每当 Google Cloud 活动举行时，我们都会获得更多关于 Google 在组装服务器群时购买或构建的计算引擎的信息。Google 不会像普通芯片供应商那样发布产品，不会发布大量芯片和封装图片，也不会发布大量进料、速度、插槽和功率。我们必须随着时间的推移将其拼凑起来，等待几年后发表的回顾性论文，才能知道 Google 现在到底在做什么。\n这确实有点烦人。但谷歌一直都很保密，因为 IT 绝对是该公司的竞争优势，但它也有点两极分化，因为它想吹嘘自己的独创性，因为这是吸引公司下一轮创新者的原因。所有的超大规模企业和大型云建设者都是这样的。如果你有如此坚定的竞争对手，而且为了保护和发展你的业务而付出了如此多的代价，你也会这样。\n话虽如此，让我们来了解一下谷歌在其主题演讲中透露的有关其计算引擎的内容，首先从“Trillium”TPU v6 自主研发的 AI 加速器开始。\n早在 6 月份，我们就对 Trillium 加速器进行了分析，这似乎是很久以前的事了，它提供了我们能找到的有关谷歌第六代自主研发 AI 加速器的详细信息。正如我们当时指出的那样，关于 TPU v6 设备及其使用系统的疑问比答案多得多。但现在，我们有了一些推理和训练的相对性能数据，以及 TPU v5e 和 TPU v6 计算引擎之间的相对性价比。\n曾在 Google 负责网络工作、现任机器学习、系统和云 AI 总经理的 Amin Vahdat 在 Google Cloud App Dev \u0026amp; Infrastructure Summit 的主题演讲中重申了 Trillium TPU 的一些关键方面。TPUv6 的峰值性能比其在产品线中（某种程度上）取代的 TPU v5e 高出 4.7 倍，HBM 内存容量和带宽是其两倍，系统中相邻 TPU 之间的芯片间互连 (ICI) 带宽是其两倍。\nGoogle 还提供了用于训练和推理的一些实际基准，这些基准很有用。以下是 TPU v5e 和 TPU v6 之间的训练比较：\n在这五个不同的训练基准测试中，当前 TPU 与倒数第二个 TPU 之间的平均性能提升为 3.85 倍，Google 在其演示文稿中将其四舍五入为 4 倍。我们添加了每个基准测试在基准测试中获得的峰值性能份额，相对于芯片固有的 4.7 倍。\n对于推理，谷歌仅展示了 Trillium 与 TPU v5e 在 Stability AI 的 Stable Diffusion XL 文本转图像模型上的性能，该模型于 7 月底刚刚发布，是最先进的：\n该代码的新颖性可能是为什么 TPU v5e 和 TPU v6 之间的性能差异不到峰值性能 4.7 倍差异的三分之二的原因。\n如果能看到一些不同的推理基准测试就更好了。例如，谷歌自己的 JetStream 推理引擎的基准测试结果在哪里？此外，TPU v5p 与 Trillium 芯片的比较测试在哪里？\n在其描述基准测试的博客中，谷歌确实说过：“我们设计 TPU 是为了优化性价比，Trillium 也不例外，与 v5e 相比，其性价比提高了近 1.8 倍，与 v5p 相比，其性价比提高了约 2 倍。这使得 Trillium 成为我们迄今为止性价比最高的 TPU。”\n我们开始尝试使用这些数据来反向计算 TPU v6 的定价，但结果却不合理。首先，谷歌在这些价格/性能比较中谈论的是训练还是推理，它使用的是真实基准还是峰值理论性能。鉴于 TPU v5p 和 TPU v5e 实例的定价不同，很难想象它们在 TPU v6 带来的价值倍数上如此接近。我们四处寻找，发现尽管 Trillium 实例仅在技术预览中，但定价已经公布。因此，我们更新了我们的 TPU 功能和定价表。请看一看：\n与往常一样，红色斜体部分是我们在没有实际数据的情况下做出的估计。\n需要注意的是，如果你签订的是三年合同而不是一年合同，那么基本上你可以免费获得三年中的第三年，这是一年价格的一半。这似乎相当慷慨。\n从该表中可以看出，TPU v5p 的 pod 尺寸比 TPU v5e 大得多，HBM 内存带宽也高得多，在 INT8 和 BF16 浮点精度下的性能只有 TPU v6 的一半。据我们所知，TPU v6 pod 尺寸在单个图像中为 256 个加速器，在 INT8 精度下峰值为 474 petaops。Vahdat 证实了这一点，然后推断出了 pod 之外的情况。\n“Trillium 可以从单个 256 芯片、高带宽、低延迟、ICI 域扩展到由每秒多 PB 的数据中心网络互连的楼宇级超级计算机中的数万个芯片，”Vahdat 解释道。“Trillium 在单个集群中提供前所未有的 91 exaflops，是我们使用上一代 TPU 构建的最大集群的四倍。客户喜欢我们的 Trillium TPU，我们看到对第六代产品的需求空前高涨。”我们不确定他指的是 BF16 精度下的“exaflops”，还是 INT8 精度下的“exaops”，并像我们在本报道中最初所做的那样说“exaflops”。\n考虑到 TPU v6 实例仅处于技术预览阶段，所以给予赞扬的肯定是少数非常重要的客户。\nVahdat 还展示了一些 Trillium 设备的图片。这是一块 TPU v6 系统板，上面有四个 TPU v6 计算引擎：\n这里有一些这种 Trillium 铁的架子，架子前面露出一个暗示性的节点。\n现在，转向 Nvidia GPU 基础设施，Google Cloud 必须构建该基础设施，以便公司可以在云基础设施上部署 Nvidia AI Enterprise 软件堆栈，并且 Google 和 Nvidia 也在对其进行调整，以运行 Google 首选的 JAX 框架（以 Python 编写）和其 XLA 跨平台编译器，该编译器可以流畅地使用 TPU 和 GPU。\nGoogle 已经推出了基于 Nvidia “Hopper” H100 GPU 加速器的 A3 和 A3 Mega 实例，这些加速器具有 80 GB 和 96 GB 的 HBM3 内存，而 Vahdat 则借此机会预览了即将在 Google Cloud 上推出的基于 Hopper H200 GPU 的全新 A3 Ultra 实例，该实例具有更大的 141 GB HBM3E 内存。A3 Ultra 实例将于“今年晚些时候”推出，它们将包括 Google 自己的“Titanium”卸载引擎和 Nvidia ConnectX-7 SmartNIC，后者将使用 Google 的 RoCE 以太网交换调整，以 3.2 Tb/秒的带宽将集群中的 GPU 互连起来。\nVahdat 并未对 Nvidia 已发布和即将推出的“Blackwell” GPU 透露太多信息，但表示该公司“拥有几个正常运行的 Nvidia GB200 NVL72 机架，并正在积极致力于将这项技术带给我们的客户”。\nVahdat 还补充说，基于 Google 自己的“Cypress”Axion Arm 服务器 CPU 的 C4A 实例现已普遍可用。Google早在 4 月就宣布了第一款 Axion 芯片，但显然还有两款芯片正在研发中，另一款代号为“Maple”，基于 Marvell 和 Cypress 授权的 Neoverse V2 内核技术。Axion 处理器还与 Titanium 卸载引擎配对。\n谷歌表示，C4A 实例在 SPEC 整数基准测试中的性价比比“当前一代基于 X86 的实例”高出 64%，能源效率比“当前一代基于 X86 的实例”高出 60%，但没有具体说明这些实例是什么。他补充说，C4A 实例的性能比其他云上的其他 Arm 实例高出 10%。他没有说明 Axion 处理器的性能与英特尔“Granite Rapids”Xeon 6 或 AMD“Turin”Epyc 9005 CPU 相比如何。\n为了好玩，谷歌展示了这张性价比图表：\n到目前为止，我们还不知道 Axion C4A 实例是什么样子，因此这里是 C4A 实例标准版的速度和馈送，每个 vCPU 有 4 GB：\nAxion C4A 实例有高 CPU 配置，每个 vCPU 有 2 GB 内存，也有高内存配置，每个 vCPU 有 8 GB 内存。正如细则所述，Axion 芯片中的这些 V2 核心不支持同时多线程，因此核心就是线程，也就是 vCPU。\n以下是 Google 北弗吉尼亚 (US-East-4) 地区标准实例的每小时定价：\nC4A 实例已在美国中部 1（爱荷华州）、美国东部 4（弗吉尼亚）、美国东部 1（南卡罗来纳州）、欧盟西部 1（比利时）、欧盟西部 4（荷兰）、欧盟西部 3（法兰克福）和亚洲东南部 1（新加坡）地区推出；预计很快将在其他地区推出。\n我们期待对在各个云中运行的 AWS Graviton 4、Google Cloud C4A 和 Microsoft Azure Cobalt 100 Arm 服务器芯片进行比较。\n","date":"2024-11-17","externalUrl":null,"permalink":"/ai/how-google-arm-server-chips-perform/","section":"Ais","summary":"\u003cp\u003e当搜索引擎巨头谷歌想要成为云计算的时候，几年后谷歌意识到客户还没有准备好购买掩盖底层硬件的全套平台服务，而是想要更低级别的基础设施服务，以便有更多的可选性和更多的责任，谷歌云不可避免地要从英特尔、AMD 和 Nvidia 购买计算引擎来充实其服务器群。\u003c/p\u003e\n\u003cp\u003e而且英特尔过去在 CPU 领域占据的利润率，以及 AMD 现在在 GPU 领域占据的利润率，以及在可预见的未来英伟达仍然在 GPU 领域占据的利润率，也意味着谷歌不可避免地会创建自己的 CPU 和 AI 加速器，以试图降低其服务器群的 TCO，特别是对于搜索引擎索引、广告投放、视频投放和各种形式和超大规模的数据分析等内部工作。\u003c/p\u003e\n\u003cp\u003e因此，每当 Google Cloud 活动举行时，我们都会获得更多关于 Google 在组装服务器群时购买或构建的计算引擎的信息。Google 不会像普通芯片供应商那样发布产品，不会发布大量芯片和封装图片，也不会发布大量进料、速度、插槽和功率。我们必须随着时间的推移将其拼凑起来，等待几年后发表的回顾性论文，才能知道 Google 现在到底在做什么。\u003c/p\u003e","title":"谷歌ARM服务器芯片表现如何","type":"ai"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/google/","section":"Tags","summary":"","title":"Google","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/pixel-watch/","section":"Tags","summary":"","title":"Pixel Watch","type":"tags"},{"content":"","date":"2024-11-17","externalUrl":null,"permalink":"/tags/tensor/","section":"Tags","summary":"","title":"Tensor","type":"tags"},{"content":"谷歌的 Pixel Watch 系列一开始有点不顺。第一代智能手表比原计划晚了一年推出，其 Exynos SoC 已经过时，与当时的竞争对手相比，它速度慢、耗电。幸运的是，这一问题很快得到解决，Pixel Watch 2 换用了高通的骁龙 W5 Gen 1 平台。此后，谷歌发布了另一款使用相同芯片的手表Pixel Watch 3。由于高通没有推出新平台，这不禁让人想问：谷歌对未来的 Pixel 手表有什么计划？\n由于谷歌 gChips 部门的大量泄密，Android Authority看到了一些文件，其中描述了谷歌计划于 2026 年与 Pixel Watch 5 同时发布未来可穿戴 Tensor 芯片。\n不幸的是，我们看到的谷歌硅片路线图只包含非常基本的信息，但我们仍然可以从中推断出很多信息。该芯片的代号为“NPT”，我们猜测它代表“纽波特海滩”，以符合加州海滩的主题（例如 Tensor G5 是“LGA”——拉古纳海滩）。预计发布日期是 2026 年，与 Tensor G6 同时发布，但由于该文件的日期是 2023 年初，因此日期可能仍会发生变化。\n我们明确给出的唯一其他细节是核心配置——1x Arm Cortex-A78 + 2x Arm Cortex-A55。一份说明还表示，谷歌正在评估 RISC-V 作为一种潜在的替代方案，尽管最近Android 内核不再支持该选项，但这种可能性似乎较小。\n这里的 CPU 内核选择似乎有些奇怪——它们都很古老，Cortex-A55 可以追溯到 2017 年！然而，这似乎是可穿戴设备的发展方向，因为三星和高通（仅存的两家 Android 可穿戴 SoC 制造商）似乎都走在了同样的路线上，在现代工艺节点上使用较旧的内核（例如，高通最近的骁龙 W5 Gen 1 在相对较新的 4 nm 节点上使用可追溯到 2012 年的 Cortex-A53 内核）。说到这一点，NPT 的配置类似于三星最近的Exynos W1000，它有 1 个 Cortex-A78 和 4 个 Arm Cortex-A55。\n我们不确定的一个重要因素是所使用的工艺节点技术，但考虑到芯片的背景，我们可以做出预测。由于可穿戴芯片需要高效率，而与 NPT 一起发布的谷歌 Tensor G6 是基于 3 纳米工艺节点构建的，因此这款芯片很可能也将如此。\n另一个未知数是调制解调器。智能手表芯片通常配备片上调制解调器以降低功耗，但据我们所知，谷歌目前没有调制解调器可以集成，这留下了一个有趣的问题：它将做什么。\n不过，有一件事我们可以肯定，那就是谷歌将利用这款新芯片让其手表更加智能。普通可穿戴 SoC 通常没有强大的处理能力，这使得它们的通用性大大降低，但谷歌可以根据需要添加任意数量的特定于应用程序的硬件。这款芯片将带来哪些新体验，值得期待。\n谷歌还有一颗手机芯片\n谷歌的 Tensor G5 预计将于明年推出Pixel 10，它可能是该系列迄今为止最受期待的芯片。谷歌首次完全内部设计该芯片，而不依赖三星完成大部分工作。人们预计这将使其更具竞争力，因为之前甚至现在的 Tensor 型号都落后于其他芯片组制造商。但这真的会发生吗？到目前为止，我们还没有听到有关新芯片规格的任何消息，但今天这种情况终于发生了变化。\n得益于谷歌 gChips 部门的大量揭秘，Android Authority看到了有关 Tensor G5 设计末尾的可靠文件，这些文件向我们透露了有关谷歌下一代芯片的一切。\nPixel 9 的 Tensor G4 与其前代产品相比，采用了升级的 CPU 集群——至少在纸面上是如此，因为在实践中，性能只是略有提高——在我们的多核测试中仅提高了 6%。这是因为谷歌放弃了一个中间集群核心，可能是为了降低功耗。\nTensor G5 再次升级了 CPU 集群，但升级方式可能与您预期的有所不同。谷歌决定保留相同的单个 Arm Cortex-X4 主核心，这是一个有趣的选择，因为新的Cortex-X925有望带来一些重大改进。它还决定再次调整核心集群：中间集群现在有五个 Cortex-A725 核心，而不是 Tensor G4 上的三个 Cortex-A720，小集群也相应缩小到只有两个 Cortex-A520 核心。我整理了以下规格：\n显然，仅凭规格很难预测性能，但这样的变化应该至少会给 Tensor G5 带来不错的多核性能提升。然而，看到再次使用相同的 Cortex-X4 令人失望。\n在查看文档时，Tensor G5 让我特别惊讶的一个方面是 GPU。提供 GPU IP 的供应商并不多，而谷歌过去的所有 Tensor 芯片都使用 Arm Mali，那么为什么现在会改变呢？好吧，我不知道，但确实如此。Tensor G5 配备了 Imagination Technologies（或 IMG）的 GPU——运行频率为 1.1 GHz 的DXT-48-1536。\n不幸的是，除了两个有趣的细节外，我们对新 GPU 知之甚少：首先，它将支持光线追踪，这是谷歌芯片的新功能，谷歌芯片通常会跳过此类“游戏”功能。第二个也许同样重要的细节是对 GPU 虚拟化的支持，允许在虚拟机中使用加速图形。谷歌一直在研究各种基于虚拟化的功能，因此将其包括在内是合情合理的。\n我在下表中整理了新的 GPU 规格：\n谷歌的手机一直都具有出色的 AI 功能，而 AI 显然是 Tensor 芯片存在的主要原因之一。通过加入定制设计的 TPU，谷歌可以获得比使用现成芯片更令人印象深刻的体验。\n与 Tensor G4（本身与 Tensor G3 完全相同）相比，Tensor G5 配备了速度稍快的 TPU。TOPS（每秒万亿次操作）值几乎大了 40%，但这并不能很好地转化为实际性能。谷歌的内部基准测试表明，新的 TPU 仅快了 14%。改进后的 TPU 还为谷歌的开发人员带来了一些新功能，例如小型嵌入式 RISC-V 内核，允许运行未在硬件中实现的操作，以及对设备上训练的支持。我在下面整理了新的 TPU 规格：\n正如我们已经透露的那样，Tensor G5 采用台积电3 纳米级 N3E 工艺节点制造，类似于 Apple 的 A18 Pro。有趣的是，芯片尺寸为 121 平方毫米，而 Apple A18 Pro 的芯片尺寸仅为 105 平方毫米，这使得 G5 的芯片明显更大。\n虽然谷歌即将推出的 Tensor G5 的规格在纸面上看起来并不令人印象深刻，但值得记住的是，它仍然是 Pixel 手机中的一款芯片，而软件可能比硬件更重要。看看谷歌如何利用新硬件为 Pixel 10 系列带来新功能将会很有趣。\n","date":"2024-11-17","externalUrl":null,"permalink":"/ai/google-is-developing-two-chips/","section":"Ais","summary":"\u003cp\u003e谷歌的 Pixel Watch 系列一开始有点不顺。第一代智能手表比原计划晚了一年推出，其 Exynos SoC 已经过时，与当时的竞争对手相比，它速度慢、耗电。幸运的是，这一问题很快得到解决，Pixel Watch 2 换用了高通的骁龙 W5 Gen 1 平台。此后，谷歌发布了另一款使用相同芯片的手表Pixel Watch 3。由于高通没有推出新平台，这不禁让人想问：谷歌对未来的 Pixel 手表有什么计划？\u003c/p\u003e\n\u003cp\u003e由于谷歌 gChips 部门的大量泄密，Android Authority看到了一些文件，其中描述了谷歌计划于 2026 年与 Pixel Watch 5 同时发布未来可穿戴 Tensor 芯片。\u003c/p\u003e","title":"谷歌正在开发的两颗芯片","type":"ai"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/risc-v/","section":"Tags","summary":"","title":"RISC-V","type":"tags"},{"content":"Nvidia 在 10 月 22 日至 24 日举行的 RISC-V 峰会上讨论了如何使用 RISC-V 架构。这家 GPU 制造商已在使用 RISC-V CPU 架构九年之久。Nvidia 副总裁 Frans Sijstermans 于 10 月 22 日发表了 20 分钟的主题演讲，并透露更多细节。\n谷歌员工，包括软件工程师 Cliff Young（他是 TPU 的设计者之一）将讨论 RISC-V 在 AI 芯片中的优势。TPU 基于 RISC-V 架构。\n在去年的 RISC-V 峰会上，高通在与 ARM 的法律纠纷中宣布了对 RISC-V 的长期承诺，而 Meta 分享了有关如何使用 RISC-V 设计的更多细节。\n随着各大公司寻求更便宜、更快捷的 CPU 设计方法，RISC-V 的影响力每年都在增长。RISC-V 开放指令集架构可免费授权，并为客户提供在芯片中加入其功能的灵活性。客户还可以使用专有扩展来完善它。\n与 Nvidia 一样，Apple 也在其 M 系列 CPU 中使用 RISC-V 微控制器。在最近的开发者峰会上，三星表示已将其 TizenOS 移植到 RISC-V，该操作系统用于其电视。大多数硬件和云提供商都支持 RISC-V。\nRISC-V 正试图占领一个客户市场，这个市场的客户已经厌倦了 x86 和 ARM 等专有选项。x86 正显示出复苏的迹象，其能效有所提高，英特尔和 AMD 之间也结成了新的联盟，以保护 x86 的利益。\n谷歌、微软和 AWS 都开发了基于 ARM 的自主处理器。\n研究公司 Omdia 预测，到 2030 年，基于 RISC-V 的处理器出货量可能达到 170 亿颗。该研究公司表示，其中约 46% 将是汽车使用的芯片。\n负责架构开发的 RISC-V International 相信它将应用于服务器和 PC。但许多人承认这可能需要数年时间。\nRISC-V 峰会上的讨论还将包括 AI、GPU 和服务器规格更新。RISC-V 的软件支持较差，一些讨论将集中在对软件包和操作系统的支持上。\n进入峰会，RISC-V 也面临一些问题。去年没有安全问题，今年安全问题被提上议程。RISC-V 安全会议有很多，涵盖机密计算、加密扩展和安全模块。\n今年早些时候，研究人员披露了一种名为“Ghostwrite”的 RISC-V 相关黑客攻击，该攻击允许用户绕过保护并访问阿里巴巴 RISC-V Xuantie C910 芯片设计中的特权内存。该芯片已发布多年。\n阿里巴巴是今年RISC-V峰会的赞助商，8月份发布了R908，这是一款针对嵌入式设备的芯片，具有许多新的安全扩展。\nRISC-V 也引起了美国政界人士的关注，他们担心中国在该架构上的加倍投入。\n安全研究人员担心，中国公司可能会将带有后门的 RISC-V 芯片运往美国设备，从而使这些设备易受攻击。RISC-V 芯片很难修补，因为与 x86 芯片不同，它没有微码功能。\n围绕 RISC-V 的政治阴谋并不在议程之内。\n一些公司已经讨论过销售 RISC-V 芯片，但在 RISC-V 峰会上不会广泛讨论制造问题。\n","date":"2024-11-16","externalUrl":null,"permalink":"/ai/nvidia-google-to-speak-about-risc-v-use-at-annual-summit/","section":"Ais","summary":"\u003cp\u003eNvidia 在 10 月 22 日至 24 日举行的 RISC-V 峰会上讨论了如何使用 RISC-V 架构。这家 GPU 制造商已在使用 RISC-V CPU 架构九年之久。Nvidia 副总裁 Frans Sijstermans 于 10 月 22 日发表了 20 分钟的主题演讲，并透露更多细节。\u003c/p\u003e","title":"英伟达和谷歌拥抱RISC-V","type":"ai"},{"content":"美国商务部已经给台积电发函，要求暂停中国大陆AI芯片企业的7nm及以下先进制程芯片的代工服务，重新审核认证客户身份（KYC）流程，扩大代工产品审查范围。\n按照消息人士的说法，并非所有大陆IC设计公司从此以后都无法获得台积电的先进制程工艺支持，目前最新的管控仅限于AI/GPU相关，手机、汽车等芯片不在管辖范围内。\n至于具体哪些AI/GPU相关芯片，则需要等到台积电与美国商务部协商出台具体管控细则，符合条件的芯片依旧有望通过申请许可的方式在台积电继续流片生产。\n现在，三星似乎也采取了类似的行动，也已经向大陆客户发出了类似的通知。\n对此，三星官方回应称：“我们无法评论与客户相关的事宜。”\n另据一名算力芯片企业的股东人士称，三星与台积电近日向他所投资的企业发送邮件，要求客户配合核查投片资质。\n其实，在本月初就有报道称，三星已关闭平泽2号线（P2）、3号线（P3）超过30％的产能，而到年底将扩大至50％，涉及4nm、5nm、7nm工艺，以降低成本，防止进一步扩大亏损。\n但是，三星极有可能已经提前听闻了台积电“违规”为中国大陆客户代工的风声，而眼瞅着台积电断供，于是决定提前关闭部分自己的相关产线，以降低风险。\n不排除三星也已经收到了美国的通知，即便没有三星也有可能会主动采取措施，避免被美国喝令停止——毕竟韩国在美国面前是没有话语权的。\n虽然大家一说起代工，会第一时间想起台积电，但是三星的4/5/7nm代工业务有很大一部分都来自中国芯片设计企业。\n尤为值得一提的是，三星第一代3nm工艺迄今唯一的大客户，就是中国某加密货币厂商的ASIC芯片。\n据了解，随着台积电断供，确实有一些中国厂商与三星接触，希望获得代工服务。\n毕竟，除了台积电，三星是获得先进工艺的唯一机会，Intel虽然也在做代工，但还没有获得客户的足够信任，尚未形成规模。\n根据台积电公布的收入数据，2023全年、2024年前三季度中国大陆客户的贡献比例大约为11-13％。\n随着7nm及以下制程断供，预计台积电会损失至少5-8％的收入。\n但是单纯从技术角度上讲，三星工艺确实很拉胯！\n这几年，三星代工一直不顺利，要么进展延期，要么性能不达标，宣传上天的最新3nm更是步履坎坷，一直在为良品率发愁。\n三星3nm工艺首次引入了GAA全环绕晶体管，分为一代3GAE、二代3GAP两个版本。\n据悉，三星内部设定的量产良品率最低标准是70％，但是初代3GAE目前只能达到50-60％，仍旧无法投入大规模量产。\n第二代3GAP更惨，良品率只有可怜的20％，也就是每产出5颗芯片，只有1颗完好能用。\n如此差劲的表现自然留不住客户，高通的骁龙8至尊版就完全交给台积电N3E 3nm工艺生产。\n更糟糕的是，有多家一直采用三星工艺的韩国本土企业，也纷纷投奔台积电。\n尽管如此，三星也不会轻易放弃，一方面改善3nm，一方面也在推进2nm。\n据说，三星会在2027年拿出2nm工艺的Exynos处理器，代号Ulysses(尤利西斯)，用于Galaxy S27系列。\n就这水平，还对中国大陆客户断供呢……\n三星工艺路线图 台积电工艺路线图 ","date":"2024-11-16","externalUrl":null,"permalink":"/ai/samsung-cuts-off-supply-of-7nm-and-below-chips-to-china/","section":"Ais","summary":"\u003cp\u003e美国商务部已经给台积电发函，要求暂停中国大陆\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI\u003c/a\u003e芯片企业的7nm及以下先进制程芯片的代工服务，重新审核认证客户身份（KYC）流程，扩大代工产品审查范围。\u003c/p\u003e\n\u003cp\u003e按照消息人士的说法，并非所有大陆IC设计公司从此以后都无法获得台积电的先进制程工艺支持，目前最新的管控仅限于AI/GPU相关，手机、汽车等芯片不在管辖范围内。\u003c/p\u003e\n\u003cp\u003e至于具体哪些AI/GPU相关芯片，则需要等到\u003ca href=\"https://www.kad8.com/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/\" target=\"_blank\"\u003e台积电与美国商务部\u003c/a\u003e协商出台具体管控细则，符合条件的芯片依旧有望通过申请许可的方式在台积电继续流片生产。\u003c/p\u003e\n\u003cp\u003e现在，三星似乎也采取了类似的行动，也已经向大陆客户发出了类似的通知。\u003c/p\u003e\n\u003cp\u003e对此，三星官方回应称：“我们无法评论与客户相关的事宜。”\u003c/p\u003e\n\u003cp\u003e另据一名算力芯片企业的股东人士称，三星与台积电近日向他所投资的企业发送邮件，要求客户配合核查投片资质。\u003c/p\u003e\n\u003cp\u003e其实，在本月初就有报道称，三星已关闭平泽2号线（P2）、3号线（P3）超过30％的产能，而到年底将扩大至50％，涉及4nm、5nm、7nm工艺，以降低成本，防止进一步扩大亏损。\u003c/p\u003e\n\u003cp\u003e但是，三星极有可能已经提前听闻了台积电“违规”为中国大陆客户代工的风声，而眼瞅着台积电断供，于是决定提前关闭部分自己的相关产线，以降低风险。\u003c/p\u003e\n\u003cp\u003e不排除三星也已经收到了美国的通知，即便没有三星也有可能会主动采取措施，避免被美国喝令停止——毕竟韩国在美国面前是没有话语权的。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./samsung-cut-off-chip-supply-to-china-1.png\" alt=\"Samsung Cut Off Supply of Chip to China\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e虽然大家一说起代工，会第一时间想起台积电，但是三星的4/5/7nm代工业务有很大一部分都来自中国芯片设计企业。\u003c/p\u003e\n\u003cp\u003e尤为值得一提的是，三星第一代3nm工艺迄今唯一的大客户，就是中国某加密货币厂商的ASIC芯片。\u003c/p\u003e","title":"三星对中国断供7nm及以下芯片","type":"ai"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/vlan/","section":"Tags","summary":"","title":"VLAN","type":"tags"},{"content":"传统的网络分段技术，如VLAN（虚拟局域网），已经使用了几十年，但随着数据中心规模的扩大和多租户需求的增加，这些技术的局限性逐渐显现出来。为了应对这些挑战，VXLAN（虚拟扩展局域网）技术应运而生。\n什么是VXLAN # VXLAN（Virtual Extensible LAN）是一种网络虚拟化技术，它通过在三层网络之上创建二层网络覆盖，实现了比传统VLAN更大的灵活性和可扩展性。VXLAN的主要设计目标是解决传统VLAN在规模和跨数据中心等方面的局限性。\nVLAN的局限性 # 传统VLAN采用12位标识符，最多支持4096个VLAN ID。这一限制对于小型网络可能足够，但对于大型数据中心来说就显得不足。此外，VLAN的广播域范围通常仅限于同一物理交换机或设备，这使得跨数据中心或广域网络的二层网络连接变得非常复杂和不现实。\nVXLAN的引入 # VXLAN使用24位的VXLAN网络标识符（VNI），能够支持多达1600万个虚拟网络。这极大地扩展了网络的可扩展性，尤其适用于需要大量虚拟网络隔离的大型数据中心和云计算环境。此外，VXLAN通过在三层网络上封装二层以太网帧，允许二层网络跨越不同的三层网络，这增强了网络的灵活性。\nVXLAN的工作原理 # VXLAN的核心是VXLAN隧道终端（VTEP，VXLAN Tunnel Endpoint），VTEP负责VXLAN数据包的封装和解封。VTEP设备将VXLAN VNI映射到物理网络接口，允许不同网络之间的通信。\nVXLAN封装过程 # 在VXLAN中，源设备发送的以太网帧首先到达VTEP，VTEP将该帧封装为VXLAN数据包。VXLAN数据包由以下部分组成：\n原始以太网帧：需要传输的数据。 VXLAN头：包含24位的VNI，用于标识不同的VXLAN段。 UDP头：VXLAN使用UDP作为传输协议。 IP头：包含源和目的VTEP的IP地址。 外部以太网头：用于在物理网络上传输封装的数据包。 数据包的传输与解封 # 封装后的VXLAN数据包通过三层网络（即IP网络）传输。由于VXLAN数据包被封装在UDP中，因此它们可以在任何支持IP的网络基础设施上传输。当数据包到达目的VTEP时，VTEP对数据包进行解封，提取出原始以太网帧，并将其转发到目的设备，实现二层网络在三层网络中的扩展。\nVXLAN控制平面 # 尽管最初的VXLAN标准并没有指定控制平面，但现代的VXLAN实现通常使用如BGP EVPN（边界网关协议以太网虚拟私有网络）这样的协议来分发MAC地址和IP信息。这种方法提高了网络的效率和可扩展性，减少了网络中的泛洪流量。\nVLAN与VXLAN的对比 # VLAN和VXLAN都是网络虚拟化技术，旨在提高网络资源的利用率和管理效率，但它们在技术实现、应用场景和扩展能力上存在显著差异。\n标识空间 # VLAN使用12位VLAN ID，最多支持4096个VLAN。对于小型和中型网络，这种规模通常是足够的。\n相比之下，VXLAN使用24位的VNI，能够支持多达1600万个虚拟网络。这使得VXLAN非常适合大规模的云计算和数据中心环境。\n工作原理与封装方式 # VLAN通过在以太网帧中插入802.1Q标签，在数据链路层（第二层）实现网络的逻辑隔离。而VXLAN通过将原始以太网帧封装在UDP数据包中，并通过三层网络传输，这允许VXLAN跨越不同的网络段，从而提供了更广泛的网络虚拟化能力。\n网络规模与隔离 # VLAN的隔离通常基于物理交换机的端口配置，限制在一个广播域内。相比之下，VXLAN通过隧道技术在多个物理交换机之间创建二层网络，允许更加灵活的逻辑隔离和跨子网通信。\n带宽效率与网络时延 # VLAN在传统网络中可能受到生成树协议（STP）的限制，导致某些网络路径被阻塞，从而影响带宽的利用率。而VXLAN可以绕过生成树协议的限制，充分利用所有的网络路径，尽管封装过程会引入一定的时延，但在现代高速网络中这一影响通常是可以接受的。\n应用场景 # VLAN适用于较小规模的网络分段，例如企业内部的部门隔离。而VXLAN更适合云服务提供商和大型数据中心，特别是在需要大量租户隔离和跨数据中心的虚拟网络扩展时。\nVXLAN如何解决传统VLAN的问题 # VXLAN通过提供更灵活和可扩展的网络虚拟化解决方案，解决了传统VLAN在大规模网络中的许多问题。以下是VXLAN在各方面的改进：\n扩展能力 # VXLAN使用24位的VNI，支持多达1600万个唯一的标识符，远远超过了传统VLAN的4096个ID限制。这使得VXLAN能够满足大规模数据中心和云环境中网络分段的需求。\n配置与管理复杂性 # VXLAN可以与BGP EVPN等控制平面协议配合使用，自动化地分发MAC地址和IP地址，简化网络的配置与管理。这减少了手动配置错误的可能性，同时降低了管理的复杂性。\n多租户环境 # VXLAN提供了高达1600万个VNI，可以为每个租户创建独立的虚拟网络，确保不同租户之间的流量隔离，增强了安全性。在多租户环境中，VXLAN更容易实施网络管理和安全策略。\n网络拓扑限制 # VXLAN通过封装二层以太网帧在三层IP包中，使得二层网络能够跨越三层网络基础设施。这意味着网络可以扩展到不同的数据中心和地理位置，而不再受到物理网络拓扑的限制。\n虚拟机迁移问题 # 由于VXLAN能够在跨数据中心的二层网络中工作，虚拟机可以在不同的物理主机之间无缝迁移，而无需更改IP地址和网络配置。这大大简化了虚拟机迁移的过程，减少了网络中断的风险。\n冗余与负载均衡复杂性 # VXLAN利用IP网络的负载均衡和冗余功能，减少了对生成树协议（STP）的依赖，从而简化了网络配置，提高了网络的弹性和性能。\n广播域扩展问题 # VXLAN可以通过控制平面协议（如BGP EVPN）优化对广播、未知单播和多播流量的处理，减少泛洪流量，从而提高了网络性能和稳定性。\n管理与监控难度 # VXLAN支持更高级的网络管理和监控工具，提供了更好的网络可见性和故障排除能力。通过使用控制平面协议，可以集中管理MAC地址和IP地址信息，简化了故障排查过程。\n记忆小技巧 # VXLAN（Virtual eXtensible Local Area Network，虚拟扩展局域网）是一种网络虚拟化技术，旨在解决传统VLAN在大规模数据中心中的扩展性问题。\nVXLAN通过在L3网络上建立L2隧道，将以太网帧封装在UDP报文中进行传输。这种封装方式被称为MAC-in-UDP。\nVXLAN隧道的起点和终点设备，负责封装和解封VXLAN报文。\n类似于VLAN ID的网络标识符，由24比特组成，理论上可支持多达16M的VXLAN段。\n","date":"2024-11-16","externalUrl":null,"permalink":"/network/introduction-to-vxlan/","section":"Networks","summary":"\u003cp\u003e传统的网络分段技术，如VLAN（虚拟局域网），已经使用了几十年，但随着数据中心规模的扩大和多租户需求的增加，这些技术的局限性逐渐显现出来。为了应对这些挑战，\u003ca href=\"https://www.kad8.com/network/introduction-to-vxlan/\" target=\"_blank\"\u003eVXLAN（虚拟扩展局域网）\u003c/a\u003e技术应运而生。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e什么是VXLAN \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFvxlan\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFvxlan\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eVXLAN（Virtual Extensible LAN）是一种网络虚拟化技术，它通过在三层网络之上创建二层网络覆盖，实现了比传统VLAN更大的灵活性和可扩展性。VXLAN的主要设计目标是解决传统VLAN在规模和跨数据中心等方面的局限性。\u003c/p\u003e\n\n\n\u003ch3 class=\"relative group\"\u003eVLAN的局限性 \n    \u003cdiv id=\"vlan%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#vlan%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e传统VLAN采用12位标识符，最多支持4096个VLAN ID。这一限制对于小型网络可能足够，但对于大型数据中心来说就显得不足。此外，VLAN的广播域范围通常仅限于同一物理交换机或设备，这使得跨数据中心或广域网络的二层网络连接变得非常复杂和不现实。\u003c/p\u003e","title":"VXLAN 简介","type":"network"},{"content":"今天给大家介绍一下 Google 的 glog，真的是一个非常棒的日志库，目前已经有 7000+ star。\n下面是该库的一些简单介绍\nglog 是为了提供高性能的日志记录而设计的，是为了尽可能减少对程序性能的影响。\n该库多个日志级别，可以根据需求选择适当的级别记录日志信息，方便调试和排查问题。\n另外 glog 被设计为多线程安全的，可以在多线程环境下安全地使用，避免日志输出竞争条件。\n该库支持根据文件大小或时间等条件自动切换日志文件，避免单个日志文件过大。可以自定义日志的格式，包括时间戳、日志级别、文件名、行号等信息，满足不同需求。\nglog 可以记录发生日志记录的位置的栈跟踪信息，有助于定位问题。\n另外该库还是跨平台的可以在多个操作系统上运行，包括 Linux、Windows、Mac 等。\n以下是一个简单的代码示例\n#include \u0026lt;glog/logging.h\u0026gt; int main(int argc, char* argv[]) { // 初始化 google::InitGoogleLogging(argv[0]); google::SetLogDestination(google::GLOG_INFO, \u0026#34;logs/info_\u0026#34;); google::SetLogDestination(google::GLOG_WARNING, \u0026#34;logs/warning_\u0026#34;); google::SetLogDestination(google::GLOG_ERROR, \u0026#34;logs/error_\u0026#34;); google::SetLogDestination(google::GLOG_FATAL, \u0026#34;logs/fatal_\u0026#34;); LOG(INFO) \u0026lt;\u0026lt; \u0026#34;这是一个信息日志\u0026#34;; LOG(WARNING) \u0026lt;\u0026lt; \u0026#34;这是一个警告日志\u0026#34;; LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;这是一个错误日志\u0026#34;; LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;这是一个致命错误日志，程序将终止\u0026#34;; // 关闭 Google 日志库 google::ShutdownGoogleLogging(); return 0; } ","date":"2024-11-16","externalUrl":null,"permalink":"/software/introduction-to-google-logging-library/","section":"Softwares","summary":"\u003cp\u003e今天给大家介绍一下 \u003ca href=\"https://www.kad8.com/software/introduction-to-google-logging-library/\" target=\"_blank\"\u003eGoogle 的 glog\u003c/a\u003e，真的是一个非常棒的日志库，目前已经有 7000+ star。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./google-logging-library.webp\" alt=\"Google Logging Library\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e下面是该库的一些简单介绍\u003c/p\u003e\n\u003cp\u003eglog 是为了提供高性能的日志记录而设计的，是为了尽可能减少对程序性能的影响。\u003c/p\u003e\n\u003cp\u003e该库多个日志级别，可以根据需求选择适当的级别记录日志信息，方便调试和排查问题。\u003c/p\u003e\n\u003cp\u003e另外 glog 被设计为多线程安全的，可以在多线程环境下安全地使用，避免日志输出竞争条件。\u003c/p\u003e\n\u003cp\u003e该库支持根据文件大小或时间等条件自动切换日志文件，避免单个日志文件过大。可以自定义日志的格式，包括时间戳、日志级别、文件名、行号等信息，满足不同需求。\u003c/p\u003e\n\u003cp\u003eglog 可以记录发生日志记录的位置的栈跟踪信息，有助于定位问题。\u003c/p\u003e\n\u003cp\u003e另外该库还是跨平台的可以在多个操作系统上运行，包括 Linux、Windows、Mac 等。\u003c/p\u003e","title":"C++日志库glog简介","type":"software"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/glog/","section":"Tags","summary":"","title":"Glog","type":"tags"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"在Linux环境中使用Docker时，端口映射是一个常见的需求，它允许你将容器内部的端口映射到宿主机上，从而实现外部访问容器内运行的服务。以下是端口映射的详细解释和实战案例。\n端口映射的概念 # 端口映射是指将容器内部的端口映射到宿主机的端口上，这样外部可以通过宿主机的IP地址和指定的端口访问容器内的服务。\n实现端口映射 # Docker提供了两种方式来实现端口映射：\n随机映射：使用 -P 参数，Docker会随机映射一个端口到容器开放的网络端口。可以通过 docker ps 查看映射的端口\n指定端口映射：使用 -p 参数，可以指定要映射的端口。格式支持 IP:hostPort:containerPort | IP::containerPort | hostPort:containerPort\n实战案例 # 随机映射端口 # $ docker run -d -P training/webapp python app.py 运行上述命令后，Docker会随机映射一个端口，并可以通过 docker ps 查看映射详情。\n指定端口映射 # $ docker run -d -p 5000:5000 training/webapp python app.py 这个命令将宿主机的5000端口映射到容器的5000端口。\n映射到特定地址的指定端口 # $ docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py 这个命令将localhost的5000端口映射到容器的5000端口。\n映射到特定地址的任意端口 # $ docker run -d -p 127.0.0.1::5000 training/webapp python app.py 这个命令将localhost的任意端口映射到容器的5000端口。\n查看映射端口配置 # $ docker port nostalgic_morse 5000 127.0.0.1:49155 通过 docker port 命令可以查看端口映射配置。\n注意事项 # 一个指定的端口上只能绑定一个容器 可以使用 docker inspect 命令获取容器的详细信息，包括内部网络和IP地址 如果需要映射UDP端口，可以在 -p 后面添加 /udp 标记 常见问题 # 访问映射端口出现404 # 如果访问映射端口时出现404错误，可能是因为容器内部的服务没有正确启动，或者访问的路径不正确。可以通过 docker logs [容器ID] 查看容器日志来诊断问题。\n如何给运行中的容器设置端口映射 # 可以通过以下两种方法给运行中的容器设置端口映射：\n使用iptables\n获取容器IP：docker inspect [容器名称] | grep IPAddress\niptables转发端口：例如将容器的8000端口映射到宿主机的8001端口：\niptables -t nat -A DOCKER -p tcp --dport 8001 -j DNAT --to-destination [容器IP]:8000 提交容器为镜像并重新运行\n提交容器为镜像：docker commit [容器ID] [新镜像名称]:[标签] 运行新镜像并添加端口映射：docker run -d -p [外部端口]:[内部端口] [新镜像名称]:[标签] 通过这些步骤，你可以灵活地配置Docker容器的端口映射，实现外部对容器内服务的访问。\n","date":"2024-11-16","externalUrl":null,"permalink":"/software/linux-docker-port-mapping/","section":"Softwares","summary":"\u003cp\u003e在Linux环境中使用\u003ca href=\"https://www.kad8.com/software/limit-memory-and-cpu-using-docker-compose/\" target=\"_blank\"\u003eDocker\u003c/a\u003e时，端口映射是一个常见的需求，它允许你将容器内部的端口映射到宿主机上，从而实现外部访问容器内运行的服务。以下是端口映射的详细解释和实战案例。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e端口映射的概念 \n    \u003cdiv id=\"%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E7%9A%84%E6%A6%82%E5%BF%B5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E7%9A%84%E6%A6%82%E5%BF%B5\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e端口映射是指将容器内部的端口映射到宿主机的端口上，这样外部可以通过宿主机的IP地址和指定的端口访问容器内的服务。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e实现端口映射 \n    \u003cdiv id=\"%E5%AE%9E%E7%8E%B0%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%AE%9E%E7%8E%B0%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eDocker提供了两种方式来实现端口映射：\u003c/p\u003e","title":"Linux下的docker端口映射","type":"software"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/rs485/","section":"Tags","summary":"","title":"RS485","type":"tags"},{"content":" 引言 # 1983 年，电子工业协会 (EIA) 批准了一个新的平衡传输标准，称之为 RS-485。调查发现，RS-485 备受赞誉并被广泛应用到工业、医疗和消费类产品，成为了工业接口的主力规范。\n本应用报告为那些对RS-485标准不熟的工程师提供设计指南，帮助他们在最短的时间内完成稳健而可靠的数据传输设计。\n本应用报告为那些对 RS-485 标准不熟的工程师提供设计指南，帮助他们在最短的时间内完成稳健而可靠的数据传输设计。\n标准和特性 # RS-485 仅是一个电气标准。与定义功能、机械和电气规格的完整接口标准相比，RS-485 仅定义了使用平衡多点传输线的驱动器和接收器的电气特性。\n但是，很多更高级别的标准将 RS-485 规定为引用标准，例如中国的电能表通讯协议标准 DL/T645 就明确指定以RS-485 作为物理层标准。\nRS-485 的主要特性：\n平衡接口 多点采用单一 5V 电源 –7V 至 +12V 总线共模范围 多达 32 个单位负载 10Mbps 最大数据速率（距离为 40 英尺） 4000 英尺的最大电缆长度（速率为 100kbps） 网络拓扑 # RS-485 标准建议使用菊花链连接其节点，也称为合用线或总线拓扑（请参阅图 3-1）。在这种拓扑结构中，所使用的驱动器、接收器和收发器通过短网存根接入主干线。接口总线可被设计用于全双工或半双工传输（请参阅图3-2）。\n全双工实现需要两个信号对（四根电线），以及全双工收发器，其具有用于发送器和接收器的单独总线访问线路。全双工模式允许节点在一个对上发送数据，同时在另一个对上接收数据。\n在半双工模式下，仅使用一对信号，并要求在不同的时间驱动和接收数据。两种实现方式都需要通过方向控制信号（例如驱动器/接收器使能信号）对所有节点进行控制，确保在任何时候总线上只有一个驱动器处于工作状态。多个驱动器同时访问总线会导致总线争用，这在任何时候都必须通过软件控制来加以避免。\n信号电平 # 符合 RS-485 标准的驱动器可在 54Ω 负载上提供不小于 1.5V 的差分输出，而符合该标准的接收器可检测到低至200mV 的差分输入。即使在电缆和连接器的信号严重衰减的情况下，这两个值仍能为高可靠性的数据传输提供了充足的余量。这种稳健性是 RS-485 非常适合在嘈杂环境中进行长距离联网的主要原因。\n电缆类型 # 在双绞线上传输差分信号对 RS-485 应用是有利的，因为外部干扰源会以共模方式均等的耦合到两根信号线上，这些噪声会被差分接收器过滤掉。\n工业 RS-485 电缆分为有保护套、无保护套、双绞线、非屏蔽双绞线，符合 22-24AWG 线规的电缆特性阻抗为120Ω。图 5-1 所示为四线对电缆的横截面，这种非屏蔽双绞线通常用于 2 个全双工网络。两对和单对版本的类似电缆可用于低成本的半双工系统设计。\n除网络布线外，RS-485 标准强制设备的印制电路板布局和连接器要与网络的电器特性保持一致，可以通过使印制电路板上的两根信号线尽可能靠近并等长来实现。\n总线终端和存根长度 # 为避免信号反射，数据传输线应始终端接，并且存根应尽可能的短。正确的端接需要终端电阻 RT 和传输电缆的特性阻抗 Z0 匹配。RS-485 标准建议采用 Z0 = 120W 的电缆，因此电缆干线通常与 120 电阻端接，线缆的末尾处各一个（请参阅图 6-1 左半部分）。\n在噪声环境下的应用通常将 120Ω 电阻替换为两个 60Ω 电阻，组成一个低通滤波器，用于提供额外的共模噪声滤除能力（请参阅图 6-1 右半部分）。请务必匹配电阻值（宜使用精度为 1% 的电阻），确保两个滤波器的频率降幅相等。较大的电阻容限（即 20%）会导致滤波器转折频率不同，并且共模噪声会转换为差分噪声，从而使接收器的抗扰性降低。\n存根的电气长度（收发器与电缆干线之间的距离）应小于驱动器输出上升时间的 1/10，并通过以下公式得出：\n表 6-1 列出了图 5-1 中（78% 速率）与各个驱动器上升时间对应的最大存根长度。\n失效保护 # 失效保护使得接收器在缺少输入信号时有能力输出一个确定的状态。\n有三种可能的原因会导致信号丢失 (LOS):\n开路：线缆中断或者收发器从总线断开 短路：差分对的导线因绝缘层失效而接触在一起 总线空闲：所有总线驱动器均未处于活动状态时，会发生这种情况 上述条件下，当输入信号为零时，会使传统的接收器输出随机状态，现在的收发器内部都包含一个偏置电路，可以对开路、短路和总线空闲进行保护，即使信号丢失时，接收器也能强制输出一个确定的状态。\n这些失效保护设计的缺点是最坏情况下的噪声容限仅为 10mV，因此在干扰环境中，要增加外部失效保护电路以增加噪声容限。\n外部失效保护电路由一个电阻分压器组成，可以产生足够的总线差分电压，以驱动接收器产生一个确定的输出状态。为了确保有足够的噪声容限，除了 200mV 的接收器输入阈值外，VAB 还必须包括测得的最大差分噪声，VAB= 200mV + V 噪声。\n最小总线电压为 4.75V、(5V – 5%)、VAB = 0.25V 和 Z0 = 120W 时，RB 为 528W。向 RT 插入两个 523W 串联电阻器会建立如图 7-1 所示的失效保护电路。\n总线负载 # 驱动器的输出取决于其必须提供给负载的电流，因此在总线上增加收发器和失效防护电路会增加所需的总负载电流。为了估算可能的最大总线负载数，RS-485 指定了一个单位负载 (UL) 的假设项，它表示大约 12kW 的负载阻抗。符合标准的驱动器必须能够驱动这些单位负载中的 32 个。现如今使用的收发器通常可以减少单位负载，例如1/8 UL，从而在总线上连接多达 256 个收发器。\n失效防护偏置可贡献多达 20 个单位的总线负载，因此收发器的最大数量 N 减少为：\n因此，当使用 1/8-UL 收发器时，最多可将 96 个器件连接到总线。\n9 数据速率与总线长度\n在给定数据速率下，最大总线长度受到传输线损耗和信号抖动的限制。当波特周期的抖动为 10% 或以上时，数据可靠性会急剧下降，图 9-1 则显示了传统 RS-485 电缆在 10% 信号抖动下的电缆长度与数据速率的关系曲线。\n最小节点间距 # RS-485 总线是一种分布式参数电路，其电气特性主要由沿物理介质（包括互连电缆和印刷电路板轨线）分布的电感和电容决定。\n以器件及其互连的形式向总线添加电容会降低总线阻抗，并导致总线的介质和负载部分阻抗不匹配。当输入信号到达这些位置时，会有部分反射回信号源，造成驱动器输出信号失真。\n要确保从驱动器输出的第一个信号传输到接收器输入端时电压电平仍有效，需要总线上任何一处的最小负载阻抗Z\u0026rsquo;\u0026gt; 0.4 x Z0 ，这可以通过在总线节点之间保持最小距离 d 来实现：\n其中 CL 是集总负载电容，C 是每单位长度的介质电容（电缆或 PCB 轨线）。\n方程式 4 显示了最小器件间距与分布式介质和集总负载电容的函数关系；图 10-1 以图形方式展示了这种关系。\n负载电容来自线路电路总线引脚、连接器触点、印刷电路板轨线、保护器件以及与干线的任何其他物理连接。因此，总线到收发器（存根区域）的电气距离要尽可能短。 下面介绍了各个电容的容值：\n5V 收发器的电容通常为 7pF，而 3V 收发器的电容约为 16pF 的两倍。电路板轨线视其结构而定，每厘米大约增加 0.5~0.8pF 电容。连接器和抑制器件的电容可能范围会很大。介质分布式电容范围是 40pF/m（低电容非屏蔽双绞线电缆）至 70pF/m（背板）。\n接地和隔离 # 设计远程数据链路时，设计人员必须假定存在很大的接地电势差 (GPD)。这些电压 Vn 会以共模干扰的形式叠加到传输线上。即使总叠加信号在接收器输入共模范围内，依靠本地接地作为可靠地电流回路也是很危险的（请参阅图 11-1a）。\n由于远程节点可能会从电气装置的不同部分汲取功率，当对这类装置进行修改（即在维护工作期间）时，会使接地电势差超出接收器的输入共模范围。因此，今天可正常工作的数据链路可能会在将来的某个时候停止运行。\n建议也不要通过接地线直接连接远端地（请参阅图 11-1b），这是因为大的环路地电流会以共模噪声的形式驾到信号线上。\n为了直接连接远端地，RS485 标准建议通过插入电阻器将器件地与本地系统地隔离开（见图 11-1c）。尽管这个方法减小了环路电流，但是大环路地的存在仍使数据链路对环路沿线某处产生的噪声敏感。因此，到现在为止，尚未建立一个强健的数据链路。\n一个可以容忍数千伏接地电势差并且强健的可长距离传输的 RS-485 数据链路方法是信号及供电电源隔离（请参阅图 11-2）。\n在这种情况下，电源隔离器（例如隔离的直流/直流转换器）和信号隔离器（例如数字电容隔离器）可防止电流在远程系统地之间流动，并避免产生环路电流。\n而图 11-2 仅显示了两个收发器节点的详细连接，图 11-3 给出了多个隔离收发器的示例。除一个收发器外，所有收发器均通过隔离接入总线。左侧的非隔离收发器为整个总线提供了单接地基准。\n","date":"2024-11-16","externalUrl":null,"permalink":"/hardware/rs485-design-guide/","section":"Hardwares","summary":"\u003ch2 class=\"relative group\"\u003e引言 \n    \u003cdiv id=\"%E5%BC%95%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BC%95%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e1983 年，电子工业协会 (EIA) 批准了一个新的平衡传输标准，称之为 \u003ca href=\"https://www.vxworks.net/bsp/349-design-and-implementation-of-rs485-mvb-gateway-based-on-vxworks\" target=\"_blank\"\u003eRS-485\u003c/a\u003e。调查发现，RS-485 备受赞誉并被广泛应用到工业、医疗和消费类产品，成为了工业接口的主力规范。\u003c/p\u003e","title":"RS485设计指南","type":"hardware"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/uart/","section":"Tags","summary":"","title":"UART","type":"tags"},{"content":"Linux 是一个强大的操作系统，有许多实用的命令和技巧可以帮助你更高效地使用它。\n查看文件校验值 # 在文件进行拷贝或者进行传输的时候，可能有损坏或者被修改的可能，这时候可以查看校验值来确认一下。\n比如我们平时工作需要用到其它组给我们提供的一些对接的程序，每次程序运行不符合他们的预期的时候，我们都会对一下两边的md5校验值。\n生成文件的校验值的方法有很多种，常用的有md5sum校验、crc校验、sum校验等。\n命令分别为：\nmd5sum file_name cksum file_name sum 算法参数 file_name 例如：\n我们以一个test.txt文件为例：\nmd5sum校验 md5sum test.txt crc校验 cksum test.txt sum校验 sum校验有两种算法，我们可以通过参数进行配置：\n-r：表示使用system v算法。 -s：表示使用BSD算法。 我们不进行配置时，默认用的是system v算法。\nsum -r test.txt sum -s test.txt 查找文件位置 # locate # 查找文件大家一般都习惯用find吧，但我觉得有时候locate更快一些，所以我一般都会先使用locate。\nlocate 与 find 不同: find 是去硬盘找，locate 只在 /var/lib/slocate 资料库中找。locate 的速度比 find 快，它并不是真的查找，而是查数据库。\n有些系统可能不带有locate，需要自己安装。比如，Ubuntu可以输入如下命令进行安装：\napt-get update apt-get install mlocate locate查找文件的命令很简单：\nlcoate file_name find # find命令可以用名字、类型、所属人、大小等来进行搜索。\n搜索文件基本语法：\nfind path -option file_name 如使用名字来搜索stdio.h文件：\nfind / -name stdio.h 命令行编辑技巧 # 我们在终端里误输入了一些比较长的内容：\nit@vxworks:~$ dsfdsfdddddddddddddddddddddddddddddddddddfsgadgdsgasdgsdhfdkshfkjdshflksdhfkldshfkj 怎么比较快的删除掉呢？疯狂地按退格键当然可以达到目的。但是有更快速的方法：\n输入快捷键 ctrl+u 即可把光标前面的内容全删掉。除此之外，还有如下几个实用且常用的快捷键：\nctrl+k：把光标后面的内容全删掉 ctrl+a：光标移到开头处 ctrl+e：光标移动到末尾处 除此之外，命令行还有很多实用常用、实用不常用的快捷方式，感兴趣的小伙伴可以自己去学习。\n查看某个进程的pid # 命令：\npidof process_name 查看某些进程的一些运行情况 # top命令可以查看进程的一些信息，但是系统运行的进程过多，不利于我们查看某些进程的运行情况\n这时候我们可以通过如下命令查看指定进程的运行情况，例如：\n查看kcalc进程的情况，命令：\ntop -p `pidof kcalc` 这就简洁多了。\n注意：\n这里的\u0026quot;`号\u0026quot;并不是单引号！\n这个符号在键盘上感叹号!键的左边。\n查看多个进程，如：\ntop -p `pidof kcalc` -p `pidof test_x86` 除了上述的一些小技巧，还有诸如下面的实用技巧，这里先简单列出来，后面再做详细介绍。\n查看命令历史：你可以使用 history 命令查看近期使用过的命令，还可以通过管道和 grep 命令过滤以某字符串开头的命令 文件同步：使用 rsync 命令可以在本地和远程之间同步文件，它比 cp 或 scp 命令更强大、更灵活 查看文件内容：使用 less 或 tail 命令可以查看文件的内容，less 可以向前翻页，而 tail 可以查看文件的最后几行 查看进程：使用 ps 命令可以查看当前运行的进程，你可以使用 grep 命令过滤出以某字符串开头的进程 端口转发：使用 ssh 命令可以做端口转发，将远程主机的某个端口映射到本地的一个端口 数据备份：可以使用 tar 命令将目录或文件打包成 tar 包，然后使用 cpio 或 dd 命令将 tar 包备份到另一个位置 系统监控：使用 top 或 htop 命令可以实时查看系统的 CPU、内存、网络等的使用情况 网络测试：使用 ping 和 traceroute 命令可以测试网络连通性和路由路径 文本处理：使用 awk、sed、grep 等命令可以处理文本数据，进行数据筛选、替换、排序等操作 以上只是一些 Linux 实用小技巧的一些例子，实际上 Linux 有很多功能强大的命令和工具，希望本文能够对你有所帮助。\n","date":"2024-11-16","externalUrl":null,"permalink":"/software/linux-practical-tips/","section":"Softwares","summary":"\u003cp\u003e\u003ca href=\"https://www.vxworks.net/linux/1231-compile-linux-kernel\" target=\"_blank\"\u003eLinux\u003c/a\u003e 是一个强大的操作系统，有许多实用的命令和技巧可以帮助你更高效地使用它。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e查看文件校验值 \n    \u003cdiv id=\"%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%80%BC\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%80%BC\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在文件进行拷贝或者进行传输的时候，可能有损坏或者被修改的可能，这时候可以查看校验值来确认一下。\u003c/p\u003e\n\u003cp\u003e比如我们平时工作需要用到其它组给我们提供的一些对接的程序，每次程序运行不符合他们的预期的时候，我们都会对一下两边的md5校验值。\u003c/p\u003e\n\u003cp\u003e生成文件的校验值的方法有很多种，常用的有md5sum校验、crc校验、sum校验等。\u003c/p\u003e","title":"Linux实用小技巧","type":"software"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/cuda/","section":"Tags","summary":"","title":"CUDA","type":"tags"},{"content":"CUDA，作为现代图形处理器（GPU）的计算单元，在高性能计算领域扮演着日益重要的角色。通过将复杂的计算任务分解为数千个线程并行执行，CUDA 显著提升了计算速度，为人工智能、科学计算、高性能计算等领域带来了革命性的变革。\nCUDA 到底是什么 # 毋庸置疑，你一定听说过 CUDA，并了解这玩意与 NVIDIA GPU 密切相关。然而，关于 CUDA 的具体定义和功能，许多人仍然心存疑惑，一脸懵逼。CUDA 是一个与 GPU 进行通信的库吗？\n如果是，它属于 C++ 还是 Python 库？或者，CUDA 实际上是一个用于 GPU 的编译器？了解这些问题有助于更好地掌握 CUDA 的核心特性及其在 GPU 加速中的作用。\nCUDA，全称为 “ Compute Unified Device Architecture ”，即“计算统一设备架构”，是 NVIDIA 推出的一套强大并行计算平台和编程模型框架，为开发人员提供了加速计算密集型应用的完整解决方案。CUDA 包含运行时内核、设备驱动程序、优化库、开发工具和丰富的 API 组合，使得开发人员能够在支持 CUDA 的 GPU 上运行代码，大幅提升应用程序的性能。这一平台尤为适合用于处理大规模并行任务，如深度学习、科学计算以及图像处理等领域。\n通常而言，“CUDA” 不仅指平台本身，也可指为充分利用 NVIDIA GPU 的计算能力而编写的代码，这些代码多采用 C++ 和 Python 等语言编写，以充分发挥 GPU 加速的优势。借助 CUDA，开发人员能够更加轻松地将复杂的计算任务转移至 GPU 运行，极大提升应用程序的运行效率。\n因此，总结起来，我们可以得出如下结论：\nCUDA 不仅仅是一个简单的库，它是一个完整的平台，为开发者提供了利用 GPU 进行高效并行计算的全方位支持。这个平台的核心组件包括：\nCUDA C/C++：这是 CUDA 为并行编程所扩展的 C++ 语言，专为在 GPU 上编写并行代码而设计。开发者可以使用熟悉的 C++ 语法结构，通过特定的编程模型定义 GPU 任务，让代码更高效地在多线程环境中执行。\nCUDA 驱动程序：这一组件连接操作系统与 GPU，提供底层硬件访问接口。驱动程序的主要作用是管理 CPU 与 GPU 之间的数据传输，并协调它们的计算资源。它确保了硬件和操作系统的兼容性，是 CUDA 代码高效运行的基础。\nCUDA 运行时库（cudart）：运行时库为开发者提供了丰富的 API，便于管理 GPU 内存、启动 GPU 内核（即并行任务）、同步线程等。它简化了开发者的工作流程，使得在 GPU 上运行并行程序的流程更加流畅和高效。\nCUDA 工具链（ctk）：包括编译器、链接器、调试器等工具，这些工具用于将 CUDA 代码编译成 GPU 可执行的二进制指令。工具链中的编译器将 C++ 代码和 CUDA 内核代码一同处理，使其适应 GPU 的架构；而调试器和分析工具帮助开发者优化性能和排查问题。\n相关的环境变量可参考如下：\n$CUDA_HOME是系统CUDA的路径，看起来像/usr/local/cuda，它可能链接到特定版本/usr/local/cuda-X.X $LD_LIBRARY_PATH是一个帮助应用程序查找链接库的变量。您可能想要包含$CUDA_HOME/lib的路径 $PATH应该包含一个通往$CUDA_HOME/bin的路径 借助这一完整的开发平台，开发者能够充分挖掘 NVIDIA GPU 的计算潜力，将复杂的并行计算任务高效地分配至 GPU 上执行，从而实现应用程序性能的极大提升。\nCUDA 是如何工作的 # 现代 GPU 由数千个小型计算单元组成，这些单元被称为 CUDA 核心。CUDA 核心能够高效并行工作，使 GPU 能够快速处理那些可以分解为多个小型独立操作的任务。这种架构使得 GPU 不仅适用于图形渲染任务，也适用于计算密集型的科学计算和机器学习等非图形任务。\n作为 NVIDIA 提供的一个计算平台和编程模型，CUDA 专门为 GPU 开放了这些强大的并行处理能力。通过 CUDA，开发者可以编写代码，将复杂的计算任务移交给 GPU。以下是 CUDA 的工作原理：\n并行处理 CUDA 将计算任务分解为多个可以独立运行的小任务，并将这些任务分配到多个 CUDA 核心上并行执行。这样一来，与传统 CPU 顺序执行的模式相比，GPU 可以在相同时间内完成更多的计算，从而极大地提升计算效率。\n线程和块的架构 在 CUDA 编程模型中，计算任务被进一步划分为线程，每个线程独立处理一部分数据。这些线程被组织成块，每个块中包含一定数量的线程。这种层次化结构不仅便于管理海量线程，还提高了执行效率。多个线程块可以同时运行，使得整个任务可以快速并行完成。\nSIMD 架构 CUDA 核心采用单指令多数据（Single Instruction, Multiple Data，简称 SIMD）架构。这意味着单条指令可以对多个数据元素同时执行操作。例如，可以用一条指令对大量数据元素进行相同的计算，从而加快数值计算的速度。这种架构对矩阵运算、向量处理等高并行任务极为高效，特别适用于深度学习模型训练、图像处理和模拟仿真等领域。\n基于这些特性，CUDA 不仅为高性能并行计算提供了直接途径，也将 NVIDIA GPU 的强大计算潜力拓展至科学计算、人工智能、图像识别等领域，为开发者实现复杂计算任务的加速提供了强有力的支持。\nCUDA 编程模型 # 在 CUDA 编程中，开发者通常需要编写两部分代码：主机代码（Host Code）和设备代码（Device Code）。\n主机代码在 CPU 上运行，负责与 GPU 进行交互，包括数据传输和资源管理；而设备代码则在 GPU 上执行，承担主要计算任务。二者相互配合，充分利用 CPU 和 GPU 的协同处理能力，以达到高效并行计算的目的。\n主机代码：主机代码运行在 CPU 上，负责控制整个程序的逻辑流程。它管理 CPU 和 GPU 之间的数据传输，分配和释放 GPU 资源，并配置 GPU 内核参数。这部分代码不仅定义了如何组织数据并将其发送到 GPU，还包含了启动设备代码的指令，从而让 GPU 接管计算密集的任务。主机代码起到管理和协调的作用，确保 CPU 与 GPU 之间的高效协作。 此部分包括数据传输、内存管理、以及启动 GPU 内核等，具体功能可参考如下所示：\n数据传输管理：主机代码负责在 CPU 和 GPU 之间传输数据。由于 CPU 和 GPU 通常使用不同的内存系统，主机代码需要在两者之间复制数据。例如，将需要处理的数据从主机内存（CPU 内存）传输到设备内存（GPU 内存），并在处理完成后将结果从 GPU 内存传回 CPU 内存。这种数据传输是耗时的，因此在实际应用中需要尽量减少传输频率，并优化数据大小，以降低延迟。\n内存分配与管理：主机代码分配 GPU 内存空间，为后续的计算提供储存资源。CUDA API 提供了多种内存管理函数（如 cudaMalloc 和 cudaFree），允许开发者在 GPU 上动态分配和释放内存。合理的内存分配策略可以有效提高内存使用效率，防止 GPU 内存溢出。\n内核配置与调度：在主机代码中，开发者可以配置内核启动参数（如线程数和线程块数）并决定内核在 GPU 上的执行方式。通过优化这些参数，主机代码能够显著提升程序的执行效率\n设备代码：设备代码编写的核心部分是在 GPU 上执行的计算函数，通常被称为内核（Kernel）。每个内核函数在 GPU 的众多 CUDA 核心上并行执行，能够快速处理大量数据。设备代码专注于数据密集型的计算任务，在执行过程中充分利用 GPU 的并行计算能力，使得计算速度比传统的串行处理有显著提升。 设备代码定义了 GPU 的计算逻辑，使用 CUDA 内核来并行处理大量数据。\n内核函数（Kernel Function）：设备代码的核心是内核函数，即在 GPU 的多个线程上同时执行的函数。内核函数由 global 关键字标识，表示该函数将在设备端（GPU）执行。内核函数与普通的 C/C++ 函数不同，它必须是无返回值的，因为所有输出结果都要通过修改传入的指针或 GPU 内存来传递。\n线程和线程块的组织：在设备代码中，计算任务被分解为多个线程，这些线程组成线程块（Block），多个线程块组成一个线程网格（Grid）。CUDA 提供了 threadIdx、blockIdx 等内置变量来获取线程的索引，从而让每个线程在数据中找到属于自己的计算任务。这种方式使得设备代码可以非常高效地并行处理数据集中的每个元素。\n并行算法优化：在设备代码中，CUDA 编程可以实现多个并行优化技术，例如减少分支、优化内存访问模式（如减少全局内存访问和提高共享内存利用率），这些优化有助于最大化利用 GPU 计算资源，提高设备代码的执行速度。\n内核启动：内核启动是 CUDA 编程的关键步骤，由主机代码启动设备代码内核，在 GPU 上触发执行。内核启动参数指定了 GPU 上线程的数量和分布方式，使内核函数可以通过大量线程并行运行，从而加快数据处理速度。通过适当配置内核，CUDA 编程能以更优的方式利用 GPU 资源，提高应用的计算效率。 在整个体系中，这一步骤至关重要，它控制了设备代码的并行性、效率及运行行为。具体可参考如下：\n内核启动语法：CUDA 使用特殊的语法 \u0026laquo;\u0026lt;Grid, Block\u0026raquo;\u0026gt; 启动内核函数。例如：kernel\u0026laquo;\u0026lt;numBlocks, threadsPerBlock\u0026raquo;\u0026gt;(parameters);，其中 numBlocks 表示线程块的数量，threadsPerBlock 表示每个线程块中包含的线程数。开发者可以根据数据集的大小和 GPU 的计算能力选择合适的线程块和线程数量。\n并行化控制：通过指定线程块数和线程数，内核启动控制了 GPU 的并行粒度。较大的数据集通常需要更多的线程和线程块来充分利用 GPU 的并行能力。合理配置内核启动参数，可以平衡 GPU 的并行工作负载，避免资源浪费或过载现象。\n同步与异步执行：内核启动后，GPU 可以异步执行任务，CPU 继续进行其他操作，直至需要等待 GPU 完成。开发者可以利用这种异步特性，使程序在 CPU 和 GPU 间并行执行，达到更高的并行效率。此外，CUDA 提供了同步函数（如 cudaDeviceSynchronize），确保 CPU 在需要时等待 GPU 完成所有操作，避免数据不一致的问题。\n通过有效协调这三者，CUDA 编程能够实现对数据密集型任务的高速并行处理，为高性能计算提供了一个极具扩展性的解决方案。\nCUDA 内存层次结构体系 # 在 CUDA 编程中，GPU 内存的结构是多层次的，具有不同的速度和容量特性。CUDA 提供了多种内存类型，用于不同的数据存储需求。合理利用这些内存可以显著提升计算效率。以下是各类内存的详细描述：\n全局内存（Global Memory） 全局内存是 GPU 上容量最大的存储空间，通常为几 GB，并且是 GPU 的主要数据存储区。全局内存可以被所有线程访问，也可以与 CPU 共享数据，但其访问速度相对较慢（相对于其他 GPU 内存类型而言），因此需要避免频繁访问。数据传输操作也较耗时，因此全局内存常用于存储较大的数据集，但会优先考虑数据访问的批处理或其他缓存策略来减少其频繁调用。\n通常而言，全局内存主要适用于存储程序的大部分输入输出数据，尤其是需要 GPU 和 CPU 共享的大容量数据。\n示例：在矩阵乘法中，两个矩阵的元素可以存储在全局内存中，以便所有线程都可以访问。\n__global__ void matrixMultiplication(float *A, float *B, float *C, int N) { int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; float sum = 0.0; for (int i = 0; i \u0026lt; N; ++i) { sum += A[row * N + i] * B[i * N + col]; } C[row * N + col] = sum; } 共享内存（Shared Memory） 共享内存是分配在 GPU 每个线程块内部的高速缓存，其访问速度远高于全局内存，但容量较小（通常为每块 48 KB 或更少）。共享内存是线程块内线程共享的，适合存储需要在一个线程块内频繁访问的数据。由于它存储在各自的块内，每个块内的线程可以在共享内存中快速读写数据，从而减少对全局内存的访问。\n相对于全局内存，共享内存更多适用于多线程间的数据交换，尤其是需在一个线程块内反复使用的数据。\n示例：在矩阵乘法中，A 和 B 的子块可以加载到共享内存中，以便线程块中的所有线程都可以快速访问。\n__shared__ float sharedA[TILE_SIZE][TILE_SIZE]; __shared__ float sharedB[TILE_SIZE][TILE_SIZE]; 本地内存（Local Memory） 本地内存是分配给每个线程的私有内存，主要用于存储线程的私有变量。尽管称为“本地”，它实际上是分配在全局内存中，因此访问速度较慢，接近全局内存的访问速度。由于本地内存容量有限且其访问开销较高，建议只在必要时使用。\n通常情况下，本地内存适用于存储线程的临时变量、私有数据或不适合在寄存器中保存的数据。\n示例：对于复杂计算中的中间变量，可以放置在本地内存中，以便线程之间不发生冲突。\nint localVariable = 0; // 本地内存中的变量 常量和纹理内存（Constant and Texture Memory） 常量内存和纹理内存分别是 CUDA 提供的专用于只读数据的内存类型，具有特殊的缓存机制，能够在特定访问模式下加快数据读取。常量内存用于存储不会更改的常量数据，而纹理内存适合存储二维或三维数据，通过纹理缓存可以提高访问速度。\n常量内存（Constant Memory）：仅可由 CPU 写入，但可被所有 GPU 线程读取。适合存储小规模的、不变的数据（如配置信息、系数等）。\n纹理内存（Texture Memory）：专门优化以支持二维或三维数据的读取，对于非顺序或稀疏访问模式的数据（如图像数据）具有较高的访问效率。\n示例：在图像处理应用中，将像素数据加载到纹理内存中，让 GPU 利用其特定的缓存机制来优化访问效率。\n__constant__ float constData[256]; // 常量内存 cudaArray* texArray; cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc\u0026lt;float\u0026gt;(); cudaMallocArray(\u0026amp;texArray, \u0026amp;channelDesc, width, height); // 纹理内存 CUDA平台为开发人员提供了对CUDA GPU并行计算资源的深度访问，允许直接操作GPU的虚拟指令集和内存。通过使用CUDA，GPU可以高效地处理数学密集型任务，从而释放CPU的计算资源，使其能够专注于其他任务。这种架构与传统GPU的3D图形渲染功能有着本质的区别，开创了GPU在计算领域的新用途。\n在CUDA平台的架构中，CUDA核心是其核心组成部分。每个CUDA核心都是一个独立的并行处理单元，负责执行各种计算任务。GPU中的CUDA核心数量越多，它能够并行处理的任务就越多，从而显著提升计算性能。通过这种并行计算，CUDA平台能够在复杂的计算过程中实现大规模任务的并行处理，提供卓越的性能和高效性。\n","date":"2024-11-16","externalUrl":null,"permalink":"/ai/introduction-to-nvidia-cuda/","section":"Ais","summary":"\u003cp\u003eCUDA，作为现代图形处理器（GPU）的计算单元，在高性能计算领域扮演着日益重要的角色。通过将复杂的计算任务分解为数千个线程并行执行，CUDA 显著提升了计算速度，为人工智能、科学计算、高性能计算等领域带来了革命性的变革。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eCUDA 到底是什么 \n    \u003cdiv id=\"cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#cuda-%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e毋庸置疑，你一定听说过 CUDA，并了解这玩意与 NVIDIA GPU 密切相关。然而，关于 CUDA 的具体定义和功能，许多人仍然心存疑惑，一脸懵逼。CUDA 是一个与 GPU 进行通信的库吗？\u003c/p\u003e","title":"NVIDIA CUDA简介","type":"ai"},{"content":"","date":"2024-11-16","externalUrl":null,"permalink":"/tags/cmm-b/","section":"Tags","summary":"","title":"CMM-B","type":"tags"},{"content":"三星提供的内存选项已经变得更容易、更高效。三星电子开发出了在存储机架中占用专有槽位的CMM-B（CXL Memory Module-Box）。CMM-B集成到超微即插即用机架规模解决方案中，可以在降低TCO的同时更快地提高生产率。\n机架级可组合内存池解决方案是业界首个机架级内存解决方案，用于高度可扩展和可组合的分解内存基础设施。它通过利用CMM-B和内存池来无缝扩展内存容量和带宽，从而提供灵活的内存资源分配。使用这种可组合的内存架构，可以避免内存搁浅，并启用按需内存容量和带宽扩展。该解决方案由机架级内存库（CMM-B）、多个应用程序主机和三星Cognos管理控制台以及ToR交换机组成。机架规模解决方案加快了CMM-B集成机架规模解决方案的运行时间。该解决方案是通过三星和超微的大力合作共同开发的。\n什么是CMM-B # 它是用于机架计算的内存池设备，利用Compute Express Link (简称CXL)。CMM-B通过支持最多24个E3的连接来实现灵活的内存资源分配。S CXL内存模块- DRAM (CMM-D)连接在机架设备中。该技术创建了一个内存架构，提供以下功能：\n分解内存分配——将分解内存池中的可用内存容量作为内存池公开，并通过CXL在多个服务器之间共享。这种架构将可用的计算资源和内存资源解耦，从而在机架集群中实现独立的资源分配。 可组合的内存编排——允许在多个主机之间组合和共享内存池。 可扩展内存扩展——支持将可用内存组合在一起，以便创建更大的内存池并将其分配到需要的地方。 CMM-B可以与三星的Cognos Management Console (简称SCMC)软件一起使用，该软件预装了一个易于使用的直观界面。这样可以快速设置Rack-Scale服务器设备并加快操作时间。\nCMM-B的特点和优点 # Rack-Scale硬件包括TOR交换机、CMM-B设备、应用服务器和Samsung Cognos Management Console。它为完整的内存服务器解决方案提供了基础结构。\n将所有硬件和软件放在一个机架空间中可以实现快速、易于使用的内存分配。但是，这只是CMM-B的众多好处之一。\n机架规模管理 # 三星Cognos Management Console与Rack-Scale Management解决方案（例如，Supermicro的SuperCloud Composer）的集成使CMM-B具有可组合性。\n高级内存池 # CMM-B实现了专为利用Compute Express Link (CXL)技术的计算环境设计的高级内存池解决方案。它与CXL1.1和CXL 2.0协议兼容，CXL1.1和CXL 2.0协议允许设备连接到主机，并在连接到SCMC控制台时通过REST API进行管理。\n可扩展的设备配置 # 可以通过从CMM-B分配更多内存来扩展容量和带宽。它可以集成容量高达24TB的CMM-D设备，最多支持3台主机，并具有扩展容量和带宽的能力。\n提高电源效率 # SoC交换芯片通过CXL 1.1和CXL 2.0协议保证电源效率。SoC芯片通过将功耗保持在最低水平有助于降低总拥有成本TCO。\n动态内存分配 # CMM-B的一个突出特性是Samsung Cognos Management Console SCMC软件。该软件具有独立于它所连接的服务器分配内存的能力。SCMC代理在应用程序模块上的无缝集成确保了在需要满足系统和应用程序需求的地方灵活地分配内存。SCMC提供具有REST API的一致GUI的能力，该特性不仅最大限度地减少了配置和管理内存所需的工作量，而且还支持异构内存设备的编排。\n内存分配分析 # SCMC代理安装在机架级配置的应用模块上。该软件配备了一个仪表板，允许可视化CMM设备，开关和主机，允许准确描述如何平衡和有效地分配内存。这些分析将给出可能需要更改内存配置的准确图像。\n易于使用的软件 # CMM-B附带的软件工具是最先进的，允许在机架级配置中动态发现和轻松利用CXL内存堆栈。在这个新的AI时代，更多的数据处理并将其放置在内存模块内或周围，正在重塑计算的方式。三星的内存模块解决方案正在扩展，使其比以往任何时候都更容易管理、扩展和充分利用当今数据中心的内存资源。\n","date":"2024-11-16","externalUrl":null,"permalink":"/hardware/cxl-memory-module-box-cmm-b/","section":"Hardwares","summary":"\u003cp\u003e三星提供的内存选项已经变得更容易、更高效。三星电子开发出了在存储机架中占用专有槽位的CMM-B（CXL Memory Module-Box）。CMM-B集成到超微即插即用机架规模解决方案中，可以在降低TCO的同时更快地提高生产率。\u003c/p\u003e\n\u003cp\u003e机架级可组合内存池解决方案是业界首个机架级内存解决方案，用于高度可扩展和可组合的分解内存基础设施。它通过利用CMM-B和内存池来无缝扩展内存容量和带宽，从而提供灵活的内存资源分配。使用这种可组合的内存架构，可以避免内存搁浅，并启用按需内存容量和带宽扩展。该解决方案由机架级内存库（CMM-B）、多个应用程序主机和三星Cognos管理控制台以及ToR交换机组成。机架规模解决方案加快了CMM-B集成机架规模解决方案的运行时间。该解决方案是通过三星和超微的大力合作共同开发的。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Samsung-CMM-B.png\" alt=\"Samsung CXL Memory Module-Box\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e什么是CMM-B \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFcmm-b\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFcmm-b\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e它是用于机架计算的内存池设备，利用\u003ca href=\"https://www.gaitpu.com/data-center/server/cxl-protocol-evolution\" target=\"_blank\"\u003eCompute Express Link\u003c/a\u003e (简称CXL)。CMM-B通过支持最多24个E3的连接来实现灵活的内存资源分配。S CXL内存模块- DRAM (CMM-D)连接在机架设备中。该技术创建了一个内存架构，提供以下功能：\u003c/p\u003e","title":"三星公司的CXL内存模块解决方案","type":"hardware"},{"content":"","date":"2024-11-08","externalUrl":null,"permalink":"/tags/7nm/","section":"Tags","summary":"","title":"7nm","type":"tags"},{"content":"","date":"2024-11-08","externalUrl":null,"permalink":"/tags/tsmc/","section":"Tags","summary":"","title":"TSMC","type":"tags"},{"content":"援引多个消息源报道，台积电已向所有中国大陆AI芯片客户发送正式电子邮件，宣布自下周11月11日起，将暂停向中国大陆AI/GPU客户供应所有7nm及更先进工艺的芯片。\n分析称，在芯片大战愈演愈烈之际，台积电此举凸显了这家代工巨头在全球半导体供应链中的微妙地位。在新任总统特朗普声称台积电应该缴纳“保护费”的情况下，该公司的最新举动似乎是在努力与美国商务部保持一致。报道称，双方共同建立了一个严格的审查制度，以完全阻止中国获得先进制程技术。\n另一家媒体SEMICONVoice报道称，美国商务部已指示台积电采取这一行动，因为生产只能在经过美国商务部工业和安全局（BIS）审查和批准并获得许可证后才能进行。这将收紧中国所有AI芯片、GPU和自动驾驶ADAS系统获取先进7nm及以下制程的能力。\n据彭博社和路透社最新报道，台积电已几乎敲定了数十亿美元的资助和贷款协议，以支持其在美国的工厂，这可能使其很快能从美国政府获得资金。台积电4月宣布的援助计划包括66亿美元的资助和最高50亿美元的贷款，以援助亚利桑那州三座半导体工厂的建设。\n如果消息属实，对于中国大陆的AI和GPU公司来说，这将是沉重的打击，他们将无法再使用台积电的先进工艺，这可能导致更高的成本和更长的上市时间，并严重影响其产品性能和市场竞争力。报道称，供应链重组可能随之而来，大陆的芯片设计公司可能需要寻求其他代工厂。\n据TrendForce数据，截至2024年第二季度，中芯国际保持5.7%的稳固市场份额，位居第三，台积电（62.3%）和三星（11.5%）分列前两位。\n","date":"2024-11-08","externalUrl":null,"permalink":"/ai/tsmc-reportedly-to-halt-7nm-and-below-chip-shipments-to-china/","section":"Ais","summary":"\u003cp\u003e援引多个消息源报道，台积电已向所有中国大陆AI芯片客户发送正式电子邮件，宣布自下周11月11日起，将暂停向中国大陆AI/GPU客户供应所有7nm及更先进工艺的芯片。\u003c/p\u003e\n\u003cp\u003e分析称，在芯片大战愈演愈烈之际，台积电此举凸显了这家代工巨头在全球半导体供应链中的微妙地位。在新任总统特朗普声称台积电应该缴纳“保护费”的情况下，该公司的最新举动似乎是在努力与美国商务部保持一致。报道称，双方共同建立了一个严格的审查制度，以完全阻止中国获得先进制程技术。\u003c/p\u003e\n\u003cp\u003e另一家媒体SEMICONVoice报道称，美国商务部已指示台积电采取这一行动，因为生产只能在经过美国商务部工业和安全局（BIS）审查和批准并获得许可证后才能进行。这将收紧中国所有AI芯片、GPU和自动驾驶ADAS系统获取先进7nm及以下制程的能力。\u003c/p\u003e\n\u003cp\u003e据彭博社和路透社最新报道，台积电已几乎敲定了数十亿美元的资助和贷款协议，以支持其在美国的工厂，这可能使其很快能从美国政府获得资金。台积电4月宣布的援助计划包括66亿美元的资助和最高50亿美元的贷款，以援助亚利桑那州三座半导体工厂的建设。\u003c/p\u003e\n\u003cp\u003e如果消息属实，对于中国大陆的\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI\u003c/a\u003e和GPU公司来说，这将是沉重的打击，他们将无法再使用台积电的先进工艺，这可能导致更高的成本和更长的上市时间，并严重影响其产品性能和市场竞争力。报道称，供应链重组可能随之而来，大陆的芯片设计公司可能需要寻求其他代工厂。\u003c/p\u003e\n\u003cp\u003e据TrendForce数据，截至2024年第二季度，中芯国际保持5.7%的稳固市场份额，位居第三，台积电（62.3%）和三星（11.5%）分列前两位。\u003c/p\u003e","title":"曝台积电7nm芯片将停供中国大陆","type":"ai"},{"content":"","date":"2024-11-07","externalUrl":null,"permalink":"/tags/broadcom/","section":"Tags","summary":"","title":"Broadcom","type":"tags"},{"content":"","date":"2024-11-07","externalUrl":null,"permalink":"/tags/openai/","section":"Tags","summary":"","title":"OpenAI","type":"tags"},{"content":"据路透社引用知情人士的消息透露，OpenAI首颗自研芯片即将亮相。据介绍，这颗芯片由博通研发，并使用台积电加以代工。并将于2026年首次亮相。\n报道指出，该公司已考虑过多种方式来使其芯片供应多样化并降低成本，包括为芯片制造工厂网络筹集资金。但据路透社报道，OpenAI 并没有放弃建立代工厂的计划（目前该计划已被放弃），而是专注于内部设计自己的芯片。\n如报道所说，OpenAI 与博通合作开发首款用于 AI推理的自有芯片已持续数月，尽管目前对 AI 训练芯片的需求较高，但分析师预计 AI 推理最终将占据主导地位。推理是在训练之后进行的，是经过训练的 AI 模型根据新数据进行预测的过程。\n两位知情人士告诉路透社，OpenAI 仍在决定是为其 AI 芯片开发还是收购其他功能，并可能寻找更多芯片制造合作伙伴。据路透社报道，OpenAI 已通过与博通的合作与台积电建立了制造能力。据报道，这家台湾芯片制造商可能在 2026 年之前推出 OpenAI 的第一款定制芯片，但目前还不确定。\nOpenAI、台积电和博通均未立即回应置评请求。\n芯片从设计到生产的过程漫长而昂贵。OpenAI 不太关注图形处理单元，这种芯片用于训练和构建生成式 AI 模型，而这一市场已被 Nvidia垄断。相反，它正在寻找一种专门的芯片来运行软件并响应用户请求，这一过程称为推理。投资者和分析师预计，随着越来越多的科技公司使用 AI 模型来处理更复杂的任务，对支持推理的芯片的需求只会增长。\n一位知情人士表示，OpenAI 可能会继续研究建立自己的代工厂或芯片工厂网络，但这家初创公司已经意识到，与合作伙伴合作开发定制芯片是目前一条更快、更可行的道路。路透社早些时候报道称，OpenAI 正在放弃建立自己的芯片制造能力的努力。\n周二，博通股价在纽约交易中收盘上涨 4.2%，至 179.24 美元。即使在最新涨幅之前，今年该股也上涨了 54%。台积电在美国交易的股票收盘上涨逾 1%。\n博通是最大的专用集成电路设计商——专为满足客户指定的单一用途而设计的芯片。该公司在该领域的最大客户是 Alphabet Inc. 的谷歌。博通还与 Meta Platforms Inc. 和 TikTok 所有者字节跳动有限公司合作。\n上个月，当被问及鉴于对 AI 训练的巨大需求，他是否有新客户时，博通首席执行官 Hock Tan 表示，只有当项目达到批量出货量时，他才会增加客户名单。\n“对于任何客户来说，这都不是一个容易部署的产品，因此我们不将概念验证视为生产量，”他在一次财报电话会议上表示。\nOpenAI 的服务需要大量计算能力来开发和运行——其中大部分来自 Nvidia 芯片。为了满足需求，业界一直在努力寻找 Nvidia 的替代品。其中包括采用 Advanced Micro Devices Inc. 的处理器并开发内部版本。\nOpenAI 还积极规划数据中心的投资和合作，而数据中心最终将成为此类 AI 芯片的所在地。这家初创公司的领导层已经向美国政府宣传了建立更大规模数据中心的必要性，首席执行官 Sam Altman 也已经向全球投资者（包括一些中东投资者）征求意见，希望他们能为该项目提供资金。\nOpenAI 首席财务官 Sarah Friar 周一对彭博电视台表示：“这肯定是件很艰难的事。从资本角度来看，这很艰难，但我自己也学到了很多东西。坦率地说，我们都在这个领域学习：基础设施就是命运。”\n","date":"2024-11-07","externalUrl":null,"permalink":"/ai/openai-reportedly-is-making-its-first-ai-chip/","section":"Ais","summary":"\u003cp\u003e据路透社引用知情人士的消息透露，\u003ca href=\"https://www.kad8.com/ai/openai-reportedly-is-making-its-first-ai-chip/\" target=\"_blank\"\u003eOpenAI首颗自研芯片\u003c/a\u003e即将亮相。据介绍，这颗芯片由博通研发，并使用台积电加以代工。并将于2026年首次亮相。\u003c/p\u003e\n\u003cp\u003e报道指出，该公司已考虑过多种方式来使其芯片供应多样化并降低成本，包括为芯片制造工厂网络筹集资金。但据路透社报道，OpenAI 并没有放弃建立代工厂的计划（目前该计划已被放弃），而是专注于内部设计自己的芯片。\u003c/p\u003e\n\u003cp\u003e如报道所说，OpenAI 与博通合作开发首款用于 AI推理的自有芯片已持续数月，尽管目前对 AI 训练芯片的需求较高，但分析师预计 AI 推理最终将占据主导地位。推理是在训练之后进行的，是经过训练的 AI 模型根据新数据进行预测的过程。\u003c/p\u003e\n\u003cp\u003e两位知情人士告诉路透社，OpenAI 仍在决定是为其 AI 芯片开发还是收购其他功能，并可能寻找更多芯片制造合作伙伴。据路透社报道，OpenAI 已通过与博通的合作与台积电建立了制造能力。据报道，这家台湾芯片制造商可能在 2026 年之前推出 OpenAI 的第一款定制芯片，但目前还不确定。\u003c/p\u003e","title":"OpenAI要自研芯片了","type":"ai"},{"content":"","date":"2024-11-07","externalUrl":null,"permalink":"/tags/bain-capital/","section":"Tags","summary":"","title":"Bain Capital","type":"tags"},{"content":"","date":"2024-11-07","externalUrl":null,"permalink":"/tags/silver-lake/","section":"Tags","summary":"","title":"Silver Lake","type":"tags"},{"content":"最新消息消息显示，收购公司 Silver Lake 和贝恩资本是可能竞购 Altera 少数股权的潜在竞购者之一。Altera 是英特尔的控股公司之一，该公司于 2015 年以近 170 亿美元的价格收购了该公司。\n消息人士称，英特尔已采取措施将 Altera 分拆为一家独立公司，并于最近几周启动了出售该部门股权的程序。消息人士还称，谈判尚处于早期阶段，英特尔准备在未来几周内接受潜在买家的初步出价。\n据一位消息人士称，私募股权公司 Francisco Partners 也对收购 Altera 股份表现出了兴趣，并且有可能成为竞标者之一。\n由于此事属机密，消息人士要求匿名，并警告称，交易并不能保证达成。\n消息人士称，英特尔希望对 Altera 的估值大致相当于2015 年收购时支付的价格。消息人士补充说，目前尚不清楚英特尔最终将出售多少 Altera 股份，但任何交易的价值都可能至少数十亿美元。\n英特尔表示，截至9 月 30 日的季度，Altera 营收环比增长 14%，达 4.12 亿美元。\n英特尔首席执行官帕特·基辛格 (Pat Gelsinger) 在上周的财报电话会议上告诉分析师：“我们仍专注于在未来几年内出售 Altera 的股份，以便其上市。为此，我们已经开始与潜在投资者进行讨论，预计将在 2025 年初完成。”\n英特尔发言人拒绝对公司在电话会议上发表的评论发表任何评论。Silver Lake 和贝恩的代表拒绝发表评论，而 Francisco Partners 也没有立即回应置评请求。\n此次交易预计将为英特尔提供急需的现金支持，因为该公司正在探索各种选择，通过出售那些其曾巨额利润无法再支持的业务来削减总体成本。\n英特尔在其最新季度报告中公布了乐观的营收预测，但由于这家曾经的芯片制造之王错过了人工智能热潮，目前正努力扭亏为盈，其股价今年迄今仍下跌 50% 以上。\n总部位于加利福尼亚州圣何塞的 Altera 公司生产一种可编程芯片，可以随时用于各种应用，从处理上传到网站的视频到军事和电信设备。\n在被英特尔收购之前，Altera 的许多芯片都是由台湾半导体制造股份有限公司生产的。\n收购完成后，英特尔计划将 Altera 的芯片生产转移到自己的工厂。专家表示，这一转移发生在英特尔开始将制造领先地位拱手让给台积电的时候。\n","date":"2024-11-07","externalUrl":null,"permalink":"/hardware/three-companies-bid-for-altera/","section":"Hardwares","summary":"\u003cp\u003e最新消息消息显示，收购公司 Silver Lake 和贝恩资本是可能\u003ca href=\"https://www.kad8.com/hardware/three-companies-bid-for-altera/\" target=\"_blank\"\u003e竞购 Altera\u003c/a\u003e 少数股权的潜在竞购者之一。Altera 是英特尔的控股公司之一，该公司于 2015 年以近 170 亿美元的价格收购了该公司。\u003c/p\u003e\n\u003cp\u003e消息人士称，英特尔已采取措施将 Altera 分拆为一家独立公司，并于最近几周启动了出售该部门股权的程序。消息人士还称，谈判尚处于早期阶段，英特尔准备在未来几周内接受潜在买家的初步出价。\u003c/p\u003e\n\u003cp\u003e据一位消息人士称，私募股权公司 Francisco Partners 也对收购 Altera 股份表现出了兴趣，并且有可能成为竞标者之一。\u003c/p\u003e","title":"三家公司，竞购Altera","type":"hardware"},{"content":"","date":"2024-11-05","externalUrl":null,"permalink":"/tags/log/","section":"Tags","summary":"","title":"Log","type":"tags"},{"content":"Linux系统中的日志文件是一个非常重要的资源，可以提供关于系统运行状态、应用程序运行情况以及安全等方面的信息。为了方便用户查看日志文件，Linux系统提供了一些命令和工具。本文我们将介绍一些常用的命令和工具以及它们的使用示例。\ntail命令 # tail命令用于查看文件的末尾内容，通常用于实时跟踪正在添加到文件中的内容。要查看一个日志文件的末尾内容，可以使用以下命令：\ntail -f location_of_log_file 其中，location_of_log_file是日志文件的路径。使用-f选项可以跟踪文件末尾的内容，即持续显示被新添加到文件中的内容。要停止跟踪日志文件，可以使用Ctrl + c快捷键。\ngrep命令 # grep命令用于搜索和显示文件中包含特定字符串的行。可以将tail和grep命令结合起来使用，以便在跟踪日志文件时搜索特定的术语。例如，假设要搜索一个名为error.log的日志文件中包含关键字ERROR的行，可以使用以下命令：\ntail -f error.log | grep ERROR 使用管道符|将tail和grep命令连接起来，可以在跟踪日志文件时搜索特定的字符串并显示检索结果。\n如果想要显示检索结果相关的前后几行信息，可以使用-C选项。例如，要显示包含检索结果的前后三行内容，可以使用以下命令：\ntail -f error.log | grep -C3 ERROR vim编辑器 # vim是一款文本编辑器，可以用于编辑日志文件。要打开一个日志文件并搜索特定的字符串，可以使用以下命令：\nvim +/keyword location_of_log_file 其中，+表示打开文件后直接跳转到末尾，/keyword表示搜索特定的字符串，location_of_log_file是日志文件的路径。\nless分页器 # less是一款分页器，可以用于随意浏览文件。它不会一次性加载整个文件，而是按需加载，这使得查看大文件时更加流畅。要使用less查看一个日志文件，可以使用以下命令：\nless location_of_log_file 可以使用向上和向下箭头键浏览文件内容，还可以使用/键搜索特定的字符串。在less中按下q键可以退出。\ncat命令 # cat命令用于显示文件的全部内容。可以结合grep命令来搜索特定关键字的日志。例如，假设要查看一个名为access.log的日志文件中包含关键字666的所有行，可以使用以下命令：\ncat -n access.log | grep \u0026#34;666\u0026#34; 上述示例中，cat -n access.log用于显示access.log文件的内容，并在每行前面添加行号；grep ‘666’用于搜索包含关键字666的行。\n总结一下，Linux系统提供了多种查看日志文件的命令和工具，每个都有其独特的用途和优点。我们可以根据需要选择合适的命令或工具来查看和分析日志文件，以便更好地了解系统运行状态和排除故障等。\n","date":"2024-11-05","externalUrl":null,"permalink":"/software/commands-to-easily-view-linux-log-files/","section":"Softwares","summary":"\u003cp\u003e\u003ca href=\"https://www.gaitpu.com/os/linux/how-to-select-the-three-big-linux-distribution\" target=\"_blank\"\u003eLinux系统\u003c/a\u003e中的日志文件是一个非常重要的资源，可以提供关于系统运行状态、应用程序运行情况以及安全等方面的信息。为了方便用户查看日志文件，Linux系统提供了一些命令和工具。本文我们将介绍一些常用的命令和工具以及它们的使用示例。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003etail命令 \n    \u003cdiv id=\"tail%E5%91%BD%E4%BB%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#tail%E5%91%BD%E4%BB%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003etail命令用于查看文件的末尾内容，通常用于实时跟踪正在添加到文件中的内容。要查看一个日志文件的末尾内容，可以使用以下命令：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etail -f location_of_log_file\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e其中，\u003ccode\u003elocation_of_log_file\u003c/code\u003e是日志文件的路径。使用\u003ccode\u003e-f\u003c/code\u003e选项可以跟踪文件末尾的内容，即持续显示被新添加到文件中的内容。要停止跟踪日志文件，可以使用\u003ccode\u003eCtrl + c\u003c/code\u003e快捷键。\u003c/p\u003e","title":"轻松查看Linux日志文件的命令","type":"software"},{"content":"Intel深陷危机，着急的不光有自己，还有将其视之为掌上明珠的美国政府，已经在悄悄研究各种援助方案，有些看起来相当的异想天开。\n据悉，《芯片与科学法案》(CHIPS Act)的主要倡导者，美国参议员马克·华纳(Mark Warner)等国会议员，以及负责监督法案补贴落实的美国商务部高级官员，都已经坐在一起讨论Intel的出路，而这还不包括根据《芯片法案》将要提供给Intel的多达85亿美元。\n其中一种选择，就是让Intel的芯片设计业务与AMD或者Mavell等竞争对手合并，并接受美国政府的监督与支持。\n但是即便Intel愿意，正在劲头上的AMD也未必，而且就算双方都愿意，欧盟、中国的反垄断审查也不可能过去。\n关于高通收购Intel的话题，近期炒得非常热，但是并无实质性进展。\n最初曝料是9月下旬，有媒体称高通已经向Intel发出了收购要约，并进行了接洽，但被高通否认。\n10月中旬，知情人士称高通可能会等到11月中旬美国大选之后，再决定是否接洽Intel。\n甚至还有说法称三星、苹果都对Intel感兴趣，不能更离谱……\n另外，Intel晶圆厂拆分独立也是一种方向，但这是Intel最大的资本之一，不会轻易放弃，而且就算拆分也很难找到愿意接手的资本。\n不过，美国政府的这些讨论只是非常初步的，也可以算作是一个备用计划。\n毕竟，Intel虽然最近亏损严重，但也在积极自救，并乐观地预计财务状况到第四季度会有很大改善。\n尽管如此，这足以彰显Intel对于美国的重要性，绝对是美国高科技的标杆。\n尽管AMD、NVIDIA也都是美国高科技的代表，而且一片欣欣向荣，但是他们都没有半导体制造业，Intel则是唯一既能设计，还能制造的。\nIntel发言人自己都说：“Intel是唯一能够同时设计、制造尖端芯片的美国企业，在保证美国半导体全球竞争优势中扮演着关键角色。”\n万一Intel倒下了，美国芯片制造就只能完全依赖台积电、三星，但他们在美国看来都是非常危险的。\n虽然三星一直在美国有工厂，台积电也积极赴美建厂，但规模都太小了。\n另外，Intel还是美国的顶级出口商，2023年出口额超过400亿美元，难以替代。\n无论如何，对于大型企业而言，起起伏伏是正常的，AMD推土机时代也差点破产，希望Intel能早日东山再起，至少，更好的竞争对消费者更有利。\n当然，对于眼下的Intel来说，首要的就是抓紧精简人员，提高运营效率。\nIntel将缩减以色列研发团队的规模，预计裁员数百人，这也是Intel整体调整、全球裁员上万人计划的一部分。\nIntel在以色列有三个研发中心，各有所长，其中，大大有名的海法(Haifa)团队负责CPU处理器、AI硬件和软件，曾经立下赫赫战功的Banias、Yonah/Merom、Nehalem等等都是这里出炉的。\n其中，Banias就是Intel迅驰平台的顶梁柱，Yonah/Merom则淘汰了高功耗的奔腾4而让Intel重回正规，Nehalem则是的压倒AMD的早期酷睿的一部分。\n另外，佩塔提克瓦(Petah Tikva)团队主要是通信与AI方案；耶路撒冷(Jerusalem)团队则是通信、软件、网络安全领域，雅库姆(Yakum)也有一部分研发人员。\n在以色列，Intel还有两座晶圆厂。\n目前，Intel在以色列一共有大约1.17万名员工，其中研发约7800人、制造约3900人。\nIntel本次裁员主要针对研发，基本不涉及制造，但具体细节暂时不详。\n有趣的是，Intel在以色列裁员的同时，NVIDIA则招募了不少人，今年就有至少40名Intel以色列员工投奔NVIDIA。\n截至今年年中，NVIDIA在以色列有大约4000人。\n","date":"2024-11-05","externalUrl":null,"permalink":"/hardware/us-government-considers-merger-of-intel-design-unit-with-amd/","section":"Hardwares","summary":"\u003cp\u003eIntel深陷危机，着急的不光有自己，还有将其视之为掌上明珠的美国政府，已经在悄悄研究各种援助方案，有些看起来相当的异想天开。\u003c/p\u003e\n\u003cp\u003e据悉，《芯片与科学法案》(CHIPS Act)的主要倡导者，美国参议员马克·华纳(Mark Warner)等国会议员，以及负责监督法案补贴落实的美国商务部高级官员，都已经坐在一起讨论Intel的出路，而这还不包括根据《芯片法案》将要提供给Intel的多达85亿美元。\u003c/p\u003e\n\u003cp\u003e其中一种选择，就是让Intel的芯片设计业务与AMD或者Mavell等竞争对手合并，并接受美国政府的监督与支持。\u003c/p\u003e\n\u003cp\u003e但是即便Intel愿意，正在劲头上的AMD也未必，而且就算双方都愿意，欧盟、中国的反垄断审查也不可能过去。\u003c/p\u003e\n\u003cp\u003e关于\u003ca href=\"https://www.kad8.com/hardware/arm-holdings-to-cancel-qualcomm-chip-design-license/\" target=\"_blank\"\u003e高通\u003c/a\u003e收购Intel的话题，近期炒得非常热，但是并无实质性进展。\u003c/p\u003e\n\u003cp\u003e最初曝料是9月下旬，有媒体称高通已经向Intel发出了收购要约，并进行了接洽，但被高通否认。\u003c/p\u003e\n\u003cp\u003e10月中旬，知情人士称高通可能会等到11月中旬美国大选之后，再决定是否接洽Intel。\u003c/p\u003e\n\u003cp\u003e甚至还有说法称三星、苹果都对Intel感兴趣，不能更离谱……\u003c/p\u003e\n\u003cp\u003e另外，Intel晶圆厂拆分独立也是一种方向，但这是Intel最大的资本之一，不会轻易放弃，而且就算拆分也很难找到愿意接手的资本。\u003c/p\u003e\n\u003cp\u003e不过，美国政府的这些讨论只是非常初步的，也可以算作是一个备用计划。\u003c/p\u003e\n\u003cp\u003e毕竟，Intel虽然最近亏损严重，但也在积极自救，并乐观地预计财务状况到第四季度会有很大改善。\u003c/p\u003e\n\u003cp\u003e尽管如此，这足以彰显Intel对于美国的重要性，绝对是美国高科技的标杆。\u003c/p\u003e\n\u003cp\u003e尽管AMD、NVIDIA也都是美国高科技的代表，而且一片欣欣向荣，但是他们都没有半导体制造业，Intel则是唯一既能设计，还能制造的。\u003c/p\u003e\n\u003cp\u003eIntel发言人自己都说：“Intel是唯一能够同时设计、制造尖端芯片的美国企业，在保证美国半导体全球竞争优势中扮演着关键角色。”\u003c/p\u003e\n\u003cp\u003e万一Intel倒下了，美国芯片制造就只能完全依赖台积电、三星，但他们在美国看来都是非常危险的。\u003c/p\u003e\n\u003cp\u003e虽然三星一直在美国有工厂，台积电也积极赴美建厂，但规模都太小了。\u003c/p\u003e\n\u003cp\u003e另外，Intel还是美国的顶级出口商，2023年出口额超过400亿美元，难以替代。\u003c/p\u003e\n\u003cp\u003e无论如何，对于大型企业而言，起起伏伏是正常的，AMD推土机时代也差点破产，希望Intel能早日东山再起，至少，更好的竞争对消费者更有利。\u003c/p\u003e","title":"美国政府考虑Intel设计部门与AMD合并","type":"hardware"},{"content":"","date":"2024-11-04","externalUrl":null,"permalink":"/tags/dl/","section":"Tags","summary":"","title":"DL","type":"tags"},{"content":"本文介绍了人工智能生态相关技术 - 用于加速构建 AI 核心算力的 GPU 硬件技术。\n毫无疑问，你可能已经听说过 CUDA，并且知道它与 NVIDIA GPU 有关。但你可能对 CUDA 的确切含义和用途还不甚了解。究竟，CUDA 是什么呢？它只是一个与 GPU 进行对话的库吗？如果是，它是一个 C++ 库，还是可以通过 Python 等高级语言进行调用？或者，CUDA 是为 GPU 编写代码的编译器？它是否是让操作系统与 GPU 进行通信的驱动程序？\u0026hellip;\nCUDA 是什么 # 从本质上来讲，CUDA（Compute Unified Device Architecture） 是由 NVIDIA 开发的一种并行计算平台和编程模型，使开发者能够使用 C、C++、Python 等高层次的编程语言，直接编写程序在 NVIDIA 的 GPU 上执行。CUDA 的核心并不仅仅是一个库，而是一个完整的生态系统，包括开发工具、编译器、驱动程序等，专门设计用于让 GPU 加速各种类型的计算任务，特别是那些涉及 大规模并行处理 的任务。\n首先，CUDA 不是一个传统的库。虽然我们可以将它理解为一个为 GPU 编写程序的工具集，但它功能不仅限于此。CUDA 实际上提供了一种开发环境，其中包括了库（如cuBLAS、cuDNN）、编译器（nvcc）、以及与系统底层硬件交互的 驱动程序。这些组件一起工作，使得开发者可以编写代码，专门利用 GPU 的强大并行计算能力进行任务加速。\n那么，CUDA 是 GPU 的编译器吗？\n严格意义上来说，CUDA 包含了一个 编译器（nvcc），将我们用 CUDA C/C++ 或 CUDA Fortran 编写的代码编译为能够在 GPU 上运行的机器代码。因此，我们可以认为 CUDA 提供了一种工具链，允许开发者将并行计算的程序逻辑高效地映射到 GPU 的硬件资源上。\nCUDA 是让操作系统与 GPU 对话的驱动程序吗？\n谨慎角度而言，不完全是。CUDA 本身并不是驱动程序，而是构建在 NVIDIA GPU驱动程序（如 NVIDIA 的显卡驱动）之上的。驱动程序负责与硬件设备进行通信，而 CUDA 则提供了一种抽象层，让开发者可以通过高层语言编写并行程序，并让这些程序通过驱动程序在 GPU 上执行。因此，虽然 CUDA 依赖于 NVIDIA 的驱动程序，但它不是一个替代品。\n深度学习在 AI 生态中的价值与地位 # 在深度学习出现之前，AI 的发展主要依赖“规则驱动”的系统，如专家系统和基于逻辑推理的算法，这些系统的表现严重依赖于专家手工编写的规则和预定义的知识库。随着数据量的爆发性增长，传统的基于规则的系统在面对复杂、动态、多样的数据时表现出明显的局限性。\n然而，随着深度学习，尤其是 卷积神经网络（CNN）、递归神经网络（RNN） 和 生成对抗网络（GAN） 等新型神经网络结构的出现，使得机器学习模型在多个领域的性能得到了革命性提升。特别是在 图像识别、语音识别、自然语言处理 等感知领域，深度学习的表现远远超过了传统的机器学习算法。\n众所周知，AI 的一个核心目标是让机器具备“智能”，即感知、理解和处理复杂信息的能力。在传统算法的框架下，计算机难以应对大量未标记、复杂非结构化的数据。然而，深度学习的层次化特征提取和自动学习能力，让机器可以逐步接近人类的感知和理解能力，特别是在 图像识别、语音处理、文本生成 等任务中表现出卓越的效果。\n例如，深度学习的卷积神经网络（CNN） 通过层级学习图像中的局部特征，能够自动识别物体、边缘和纹理，从而使得计算机视觉技术在医疗影像分析、自动驾驶等领域的应用成为可能。与此同时，递归神经网络（RNN）和 Transformer 等网络结构在自然语言处理中的成功应用，使得机器翻译、文本摘要生成、对话系统等技术有了质的飞跃。\n同时，深度学习的发展与大数据和高性能计算技术的进步密切相关。深度学习模型，特别是那些具有数亿甚至数十亿参数的模型（如 GPT-4、BERT 等），依赖于大规模数据集的训练和强大的计算资源。这种模式虽然对计算资源的要求极高，但通过 云计算平台 和 专用硬件（如GPU、TPU） 的支持，深度学习模型的训练速度得到了显著提升，并使得这些模型具备了 可扩展性 和 规模化应用 的潜力。\n在商业应用中，深度学习模型推动了从 研发到生产的落地速度。例如，科技巨头利用深度学习开发了推荐系统（如亚马逊、Netflix 的推荐算法），实现了针对用户行为的个性化推送，大大提升了用户体验和商业效益。\n此外，深度学习不仅在感知领域取得了巨大进展，还催生了“生成式 AI” 的兴起。通过生成对抗网络（GAN）和变分自编码器（VAE） 等深度学习技术，AI 系统可以生成全新的图像、视频、音乐甚至文本内容。这在艺术创作、游戏设计、虚拟现实 等创意领域，带来了巨大的变革。\n作为现代 AI 生态系统中的核心基石。几乎所有的前沿 AI 应用，包括自动驾驶、自然语言处理、图像处理、推荐系统以及机器人技术，都依赖于深度学习算法及其衍生模型。深度学习模型不仅解决了许多传统AI方法难以解决的问题，还通过其强大的学习能力和广泛的应用场景推动了 AI 技术的持续进步。\n最后，深度学习还通过其庞大的开源社区和平台生态（如 TensorFlow、PyTorch 等），促进了全球 AI 开发者的协作和技术创新。通过这些平台，研究者和开发者可以快速搭建和优化深度学习模型，加速了从概念验证到实际应用的落地速度。\nCUDA 如何加速深度学习 # 作为并行计算平台和编程模型，CUDA 使得开发者能够在 NVIDIA GPU 上执行通用计算任务。与传统的 CPU 相比，GPU（图形处理单元）擅长处理大规模并行计算任务，而深度学习中的大部分计算任务正是这种高度并行化的任务，例如矩阵乘法、卷积操作等。CUDA 提供了一种使开发者能够利用 GPU 强大计算能力的接口和开发工具。\n基于并行计算架构特性和通用 GPU 编程模型，CUDA 能够在以下层面对深度学习进行作用，具体：\n加速前向传播和反向传播 在深度学习中，前向传播涉及从输入数据中计算各层神经网络的输出，反向传播则涉及通过梯度下降算法更新模型的权重。前向和反向传播都需要执行大量的矩阵运算，而这些运算非常适合在 GPU 上通过 CUDA 并行化处理。\n对于大型神经网络，如卷积神经网络（CNN）和 Transformer 网络，CUDA 能够显著加速前向传播中的卷积运算和矩阵乘法，以及反向传播中的梯度计算。使用 CUDA 进行训练的深度学习模型，可以将训练时间从几天缩短到几个小时，极大地提升了开发效率和模型迭代速度。\n加速大规模数据的处理 深度学习通常依赖大规模的数据集进行训练，如 ImageNet 数据集。这些数据集的规模往往非常庞大，训练一个深度学习模型需要处理数百万甚至上亿的样本。CUDA 提供了高效的 数据并行计算 能力，使得每个 GPU 核心可以同时处理多个样本，从而极大地加快了模型的训练速度。\n尤其在处理图像、视频等大规模数据时，CUDA 提供了显著的加速效果。例如，在卷积操作中，GPU 能够并行处理不同的图像块，而这种并行化的计算方式使得每个 GPU 核心能够同时处理多个数据通道，大幅提高了处理效率。\n加速大模型的训练 现代深度学习模型如 GPT-4、BERT 等具有数亿甚至数十亿参数，训练这些大规模模型的计算复杂度极高。CUDA 所提供的张量核心（Tensor Core）和混合精度训练（FP16/FP32）功能，使得在训练这些大模型时能够显著减少计算时间，同时降低内存开销。\n混合精度训练通过在计算中使用更小的浮点数（如 FP16），不仅加速了模型的计算速度，还能减少内存带宽占用，从而使得同样的硬件可以处理更大的模型或更大的批量大小。这一技术已经被 NVIDIA Apex 工具集成，广泛用于深度学习模型的加速训练。\nCUDA 在深度学习应用中的表现 # 通常而言，CUDA 在深度学习应用场景目前主要集中在如下几个核心方面，具体可参考：\n计算机视觉中的应用 在计算机视觉领域，深度学习广泛应用于图像分类、目标检测、图像分割等任务。CUDA 通过加速卷积操作和其他矩阵运算，使得 CNN 模型在处理大规模图像数据时能够以更高的速度完成训练和推理。\n例如，使用 CUDA 加速的卷积神经网络可以在几分钟内完成数百万张图片的训练，这在没有 GPU 加速的情况下可能需要数天时间。此外，在图像处理应用中，CUDA 能够实时处理视频流中的每一帧图像，为 自动驾驶 和 视频监控 系统提供了高速实时的视觉感知能力。\n自然语言处理中的应用 自然语言处理（NLP）领域中的任务，如机器翻译、文本生成和语义分析，通常涉及到对大规模文本数据的处理。深度学习模型，如 LSTM 和 Transformer，依赖于大量矩阵乘法运算和注意力机制。CUDA 加速了这些运算，使得像 BERT 和 GPT 这样的预训练语言模型可以在短时间内处理海量数据。\nCUDA 还极大地提高了 NLP 任务中的推理速度。在实际应用中，如对话系统和智能客服，使用 GPU 加速的模型可以实时处理用户请求并生成相应的回复，大大提高了响应速度和服务质量。\n强化学习和机器人控制中的应用 在强化学习和机器人控制领域，深度学习模型需要实时处理环境反馈，并在复杂的多任务环境中进行决策。CUDA 加速了这些深度学习模型的训练过程，使得智能体可以在模拟环境中更快地学习到有效的策略。\n例如，使用 CUDA 加速的深度 Q 网络（DQN），强化学习系统能够对数百个甚至数千个状态-动作对进行迭代加速，显著提高了 Q 值的更新速度，使智能体能够更快地学习到有效的策略。\n综上所述，深度学习解决方案对计算资源的需求极为巨大，特别是在模型训练和推理过程中，往往涉及到大量的矩阵运算和并行计算。传统的 CPU 在处理这种计算密集型任务时，表现出较为明显的瓶颈。相反，支持 CUDA 的 GPU 通过其强大的并行处理能力，能够在短时间内高效地执行深度学习任务。没有 GPU 技术的支持，许多复杂的深度学习模型训练不仅需要消耗更高的计算成本，而且训练时间也会大幅延长，甚至可能需要数周甚至数月，这将极大限制创新和应用的推进。\nGPU 的引入，特别是与 CUDA 紧密结合，使得神经网络的训练和推理速度得到了显著提升。由于 CUDA 提供了灵活且高效的编程接口，深度学习的许多常用框架都依赖于其计算能力来加速复杂的神经网络计算任务。这些框架包括 Caffe2、Keras、MXNet、PyTorch 和 Torch 等，它们广泛应用于图像识别、自然语言处理、自动驾驶等多个领域。\n此外，深度学习模型的复杂性正不断增加，模型的参数量从数百万到数十亿不等，特别是在处理如 Transformer 和 GPT 等大型模型时，GPU 的加速能力变得尤为关键。通过利用 CUDA 的并行计算能力，开发者能够有效缩短模型训练的周期，并在短时间内进行多次迭代和优化。这种计算能力的提升，不仅降低了深度学习的训练成本，还为更大规模的模型实验和快速部署铺平了道路，推动了 AI 技术的持续突破与创新。\nReference ：\n[1] https://www.turing.com/kb/understanding-nvidia-cuda [2] https://kernel-operations.io/keops/autodiff_gpus/what_is_a_gpu.html ","date":"2024-11-04","externalUrl":null,"permalink":"/ai/why-cuda-is-crucial-for-deep-learning/","section":"Ais","summary":"\u003cp\u003e本文介绍了人工智能生态相关技术 - 用于加速构建 AI 核心算力的 GPU 硬件技术。\u003c/p\u003e\n\u003cp\u003e毫无疑问，你可能已经听说过 CUDA，并且知道它与 NVIDIA GPU 有关。但你可能对 CUDA 的确切含义和用途还不甚了解。究竟，\u003ca href=\"https://www.kad8.com/ai/why-cuda-is-crucial-for-deep-learning/\" target=\"_blank\"\u003eCUDA\u003c/a\u003e 是什么呢？它只是一个与 GPU 进行对话的库吗？如果是，它是一个 C++ 库，还是可以通过 Python 等高级语言进行调用？或者，CUDA 是为 GPU 编写代码的编译器？它是否是让操作系统与 GPU 进行通信的驱动程序？\u0026hellip;\u003c/p\u003e","title":"为什么 CUDA 对深度学习至关重要","type":"ai"},{"content":"","date":"2024-11-04","externalUrl":null,"permalink":"/tags/wechat-linux/","section":"Tags","summary":"","title":"Wechat Linux","type":"tags"},{"content":"本次微信Linux 4.0公测版全面重构，不仅在架构上实现了突破，更在功能上完成对Windows与Mac版本的全面对齐。这意味着，无论用户使用哪个平台，都能获得丰富且一致的应用体验。文末附有下载地址\n下载安装包之后，使用命令进行安装。\nsudo apt install -y ./wechat-beta_4.0.0.21_amd64.deb 支持自动登录与代理设置 # 新版微信引入自动登录功能，在用户使用一段时间后即可激活此功能。同时，支持登录时设置代理，为有特殊网络需求的用户提供更多选择。\n聊天界面，支持小程序 # 语音，视频，表情，动态表情，地理位置等。\n语音通话 # 视频通话 # 动态表情，地址位置 # 图片查看，编辑 # 图片文字识别，翻译 # 朋友圈互动更便捷 # 支持浏览、刷新朋友圈，并能在朋友圈中进行点赞和评论；\nPC端小程序 # 看一看，搜一搜，视频号等功能 # 除了深度系统的应用商店可以下载，找了一下其他地方下载地址。\n优麒麟提供的下载地址：https://archive2.kylinos.cn/DEB/KYLIN_DEB/pool/main/deb/wechat/ 64位版本：https://archive2.kylinos.cn/DEB/KYLIN_DEB/pool/main/deb/wechat/wechat-beta_4.0.0.21_amd64.deb Arm版本：https://archive2.kylinos.cn/DEB/KYLIN_DEB/pool/main/deb/wechat/wechat-beta_4.0.0.21_arm64.deb 龙芯版本：https://archive2.kylinos.cn/DEB/KYLIN_DEB/pool/main/deb/wechat/wechat-beta_4.0.0.21_loongarch64.deb ","date":"2024-11-04","externalUrl":null,"permalink":"/software/wechat-linux-4.0-public-beta-version-launched/","section":"Softwares","summary":"\u003cp\u003e本次微信\u003ca href=\"https://www.kad8.com/software/wechat-linux-4.0-public-beta-version-launched/\" target=\"_blank\"\u003eLinux 4.0\u003c/a\u003e公测版全面重构，不仅在架构上实现了突破，更在功能上完成对Windows与Mac版本的全面对齐。这意味着，无论用户使用哪个平台，都能获得丰富且一致的应用体验。文末附有下载地址\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./wechat-linux-4.0-1.webp\" alt=\"Wechat Linux 4.0\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e下载安装包之后，使用命令进行安装。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo apt install -y ./wechat-beta_4.0.0.21_amd64.deb\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\n\u003ch2 class=\"relative group\"\u003e支持自动登录与代理设置 \n    \u003cdiv id=\"%E6%94%AF%E6%8C%81%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%E4%B8%8E%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%94%AF%E6%8C%81%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%E4%B8%8E%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e新版微信引入自动登录功能，在用户使用一段时间后即可激活此功能。同时，支持登录时设置代理，为有特殊网络需求的用户提供更多选择。\u003c/p\u003e","title":"微信Linux4.0发布，功能与Windows，Mac同步","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/openbmc/","section":"Tags","summary":"","title":"OpenBMC","type":"tags"},{"content":"10年前，四位当时还名不见经传的程序员在一次黑客松上敲出了OpenBMC的第一行代码，由此也改写了整个固件领域的发展史……\n几年后，2018年3月，OpenBMC正式成为Linux Foundation项目，其创始成员包括Meta（原Facebook）、谷歌、IBM、英特尔、微软等几家行业内的科技巨头。时至今日，OpenBMC已经成为业界广受欢迎的开源项目之一，不少互联网、金融、通信、服务器、芯片等科技企业也纷纷加入OpenBMC大家庭，推出相关的固件解决方案，并进一步加速应用落地。\n日前，我们也有幸采访到了英特尔技术经理汤超燕，听听她对OpenBMC发展的判断和展望。\n殊途同归，让固件应用更简单、更高效 # 其实说到OpenBMC的发展，我们看看这个组织的早起发起者，包括硬件巨头、软件巨头和互联网大厂，可以说是妥妥的应用驱动。在汤超燕看，OpenBMC发起的初衷就是改变传统BMC应用的窘态，具体说来就是随着互联网应用的逐步展开，传统BMC无论在功能还是在技术上的发展都显得滞后，由此也让巨头们不得不身体力行的进行调整和优化。在这个过程中，包括英特尔、微软、IBM、谷歌、Meta都意识到固件创新的重要性，因此大家才携手打造了OpenBMC组织，也是希望群策群力，实现新应用、开创新业务。\n这有点像智能手机取代传统手机。虽然曾几何时，所谓的“塞班智能机”也能安装通讯软件、游戏等等应用，但是这些应用都是出厂适配的，用户无法自行修改，而当时用户已经对手机通讯之外的功能有所期待，于是才有了以苹果为代表的智能手机横空出世，短短几年时间就实现了用户体验的革命，开创了智能手机如今的局面。从这个角度来说，OpenBMC也扮演了“智能手机”的角色，甚至整个行业也将面临OpenBMC的全新重组，从底层应用上带来新的变革。\n作为平台公司，英特尔在这其中扮演了关键的角色，甚至提供了从硬件到软件的多维解决方案。“随着大规模数据中心的部署，从运维角度对于精细化管理、层次化管理提出了更高的要求，英特尔在新一代芯片的设计中，也对传统PCH设计进行了转化，将部分功能整合到了BMC当中。这样通过OpenBMC开源，可以方便客户的后续应用，利好客户”，在谈到英特尔在OpenBMC中扮演角色的时候，汤超燕介绍说。\n作为业界巨头，其实英特尔一直对OpenBMC有着不小的贡献。每一代英特尔处理器平台的升级对于BMC固件适配来说都是不小的变革，而这些变革都朝着更便捷、更优化的方向来发展。从最初创立OpenBMC到今天，英特尔对于组织的贡献一直排在前列，每一代产品都会经历一年甚至更长时间的测试，以保证在性能、可靠性、稳定性等多方面的品质。按照汤超燕的话说，英特尔对于客户非常重视，每一代产品的交付都要保证固件就绪的最佳状态。\n英特尔PFR固件保护，让OpenBMC从此更安全 # 正所谓“一千个人眼中就有一千个哈姆雷特”，对于不同行业的客户来说，对于应用的需求也不同，但这也恰恰是OpenBMC的价值所在。针对不同的应用场景，英特尔也会为客户提供接口实现功能上的定制化需求，这样可以通过代码或者软件的微调更适配于客户业务。同时，英特尔也提供了PFR固件保护功能（Platform Firmware Resilience），为保护企业服务器固件提供了一种全新的方法，可全面防止对服务器所有固件的攻击。\n“这个功能是平台的安全性功能，它会验证整个平台上不同的组件是否安全，并实时进行反馈”，汤超燕介绍说。所谓“固件保护”，就是对平台上的其他各种固件进行授权（必要时还能将这些固件恢复至正常状态）。在运行过程中，英特尔 PFR 技术会对关键总线进行主动过滤，避免对关键部件，如 SPI Flash、电源固件、热交换背板固件和数字电压调节器固件的损坏性攻击。\n如此一来，首先增强了固件的安全性，通过多层保护机制对固件安全继续检测和管理，可以最大限度保证系统安全性，防止被恶意篡改或替换。同时，PFR固件保护功能也具备了快速的攻击检测和恢复能力，可以在攻击的第一时间触发相应并进行自动恢复，最大限度减少攻击对业务的影响和停机时间。此外，对于提升平台的可靠性和稳定性、支持供应链安全等方面，PFR固件保护功能也至关重要，可以保障客户底层固件与数据安全，杜绝安全隐患。\n为此，英特尔也提供了全球化的团队支持。据汤超燕介绍，OpenBMC开发本身就需要庞大的团队，而英特尔在这个领域深耕多年，如今在美国、印度、波兰等多地都有布局。不同地域的团队协同开发合作，日常也保持了充分的沟通和交流，每个部门都有各自承担的任务。\n除了安全性的优化之外，如何有效降低服务器能耗也是OpenBMC固件优化的重点。从传统BMC到OpenBMC，其实服务器节能会变得更精准、更低碳。比如，英特尔在节点管理中就提供了能耗管理，并可以根据不同部件的进行精细化运维。\n“我们可以对整个平台做能耗管理、对CPU做能耗管理、对内存做能耗管理或者对不同的卡做能效管理。同时，我们也在不断引入创新项目，比如运用AI算法优化服务器每个组件上的能耗管理，再比如用AI算法优化风扇转速等等，这都是我们目前研究的方向”，汤超燕表示。\n一直以来，英特尔给人的第一感觉就是处理器，但事实上英特尔更多扮演了平台化的角色。尤其是近些年，英特尔提出了“五大超级技术力量”的理念，即计算、连接、基础设施、人工智能、传感和感知。其实从OpenBMC的投入上我们也可以看出，这不仅仅是硬件层面的方便，更多需要融合软件、AI、生态等多个维度，而英特尔也需要扮演行业引领者的角色，为更多生态伙伴提供平台化、系统化的支持，这样才能加速整个产业的创新与进步。\n推动OpenBMC的持续发展，是英特尔的现在，更是未来。\n","date":"2024-11-03","externalUrl":null,"permalink":"/software/intel-promot-openbmc-technology-innovation/","section":"Softwares","summary":"\u003cp\u003e10年前，四位当时还名不见经传的程序员在一次黑客松上敲出了OpenBMC的第一行代码，由此也改写了整个固件领域的发展史……\u003c/p\u003e\n\u003cp\u003e几年后，2018年3月，OpenBMC正式成为Linux Foundation项目，其创始成员包括Meta（原Facebook）、谷歌、IBM、英特尔、微软等几家行业内的科技巨头。时至今日，OpenBMC已经成为业界广受欢迎的开源项目之一，不少互联网、金融、通信、服务器、芯片等科技企业也纷纷加入OpenBMC大家庭，推出相关的固件解决方案，并进一步加速应用落地。\u003c/p\u003e\n\u003cp\u003e日前，我们也有幸采访到了英特尔技术经理汤超燕，听听她对OpenBMC发展的判断和展望。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e殊途同归，让固件应用更简单、更高效 \n    \u003cdiv id=\"%E6%AE%8A%E9%80%94%E5%90%8C%E5%BD%92%E8%AE%A9%E5%9B%BA%E4%BB%B6%E5%BA%94%E7%94%A8%E6%9B%B4%E7%AE%80%E5%8D%95%E6%9B%B4%E9%AB%98%E6%95%88\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%AE%8A%E9%80%94%E5%90%8C%E5%BD%92%E8%AE%A9%E5%9B%BA%E4%BB%B6%E5%BA%94%E7%94%A8%E6%9B%B4%E7%AE%80%E5%8D%95%E6%9B%B4%E9%AB%98%E6%95%88\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e其实说到OpenBMC的发展，我们看看这个组织的早起发起者，包括硬件巨头、软件巨头和互联网大厂，可以说是妥妥的应用驱动。在汤超燕看，OpenBMC发起的初衷就是改变传统BMC应用的窘态，具体说来就是随着互联网应用的逐步展开，传统BMC无论在功能还是在技术上的发展都显得滞后，由此也让巨头们不得不身体力行的进行调整和优化。在这个过程中，包括英特尔、微软、IBM、谷歌、Meta都意识到固件创新的重要性，因此大家才携手打造了OpenBMC组织，也是希望群策群力，实现新应用、开创新业务。\u003c/p\u003e","title":"英特尔：持续推动OpenBMC技术创新的先行者","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/colossus/","section":"Tags","summary":"","title":"Colossus","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/xai/","section":"Tags","summary":"","title":"XAI","type":"tags"},{"content":"近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的数据中心内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。\nColossus的4U液冷服务器，强调为液冷而设计\nColossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？\n最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成AI服务器。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。\n因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。\nColossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。\nSupermicro这台4U液冷服务器是完全面向液冷设计的服务器，而不是风冷改造的，这样可以提供更好的液冷散热。此外，这款服务器有更高的可维护性，服务器的组件都安装在托盘上，可以在不移出机架的情况下对服务器进行维护。\n服务器后面板配有四个冗余电源，安装有三相供电系统，还能看到400GbE以太网网线，以及一个1U机架大小的歧管，配合底部的带有冗余水泵的CDU（冷却分配单元），为整个液冷系统提供支持。\nColossus的存储部分，SSD闪存大面积部署\nColossus的存储部分也用了Supermicro的存储设备，设备中配备了大量2.5英寸的NVMe存储槽。这让我想起了最近一则消息，有外媒传出，特斯拉要向SK海力士（Solidigm）采购大量企业级SSD的新闻。\n随着AI集群规模的扩大，存储系统逐渐从基于磁盘的存储转向闪存存储，因为闪存不仅能显著节省电力，还能提供更高的性能和密度，尽管每PB成本更高，但从整体拥有成本（TCO）来看，在这种规模的集群中，闪存更具优势。\nColossus的网络部分，用以太网替代了InfiniBand\n多数超算都在使用InfiniBand等技术，而xAI团队选择了英伟达的Spectrum-X以太网方案，不仅获得了超强的可扩展性，部署和维护成本也更低了。在高带宽、低延迟场景中表现更好，搭配智能流量管理功能，提供了高效的数据传输。\n具体而言，网络部分采用了Spectrum SN5600交换机提供高达800Gb/s的端口，每个GPU配备400GbE的BlueField-3 SuperNIC专用网卡，提供GPU间的RDMA连接。另有400Gb的网卡给CPU用，算下来，每台服务器的以太网带宽总计3.6 Tbps。\nxAI为GPU、CPU和存储各自建立了独立的网络，这样可以确保GPU和CPU之间的通信需求得到优化，GPU网络专注于高速的RDMA数据传输，而CPU网络则支持其他管理和计算任务，从而提高整个系统的性能和效率。\nPatrick在文中表示，不要小瞧400GbE的速度，这个带宽甚至超过了2021年初顶级Intel 至强服务器处理器的所有PCIe通道总带宽。而现在，每台服务器就配备了9条这样的连接速度。\n英伟达提到，在训练Grok这种超大型模型时，整个系统都没有出现任何因流量冲突，而造成的应用延迟增加或数据包丢失的情况。Spectrum-X的拥塞控制功能，能将系统数据吞吐量保持在95%，而传统以太网在发生冲突时，只能提供60%的数据吞吐量。\n在Colossus超级计算机外部，可以看到大量Tesla Megapack电池。由于计算集群在启动和停止时存在毫秒级的电力波动，电网或马斯克的柴油发电机难以应对，因此采用了Tesla Megapack作为电网与超算之间的能量缓冲装置，确保供电稳定。\n外文原文地址: Inside the 100K GPU xAI Colossus Cluster that Supermicro Helped Build for Elon Musk\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/","section":"Ais","summary":"\u003cp\u003e近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的\u003ca href=\"https://www.gaitpu.com/category/data-center/server\" target=\"_blank\"\u003e数据中心\u003c/a\u003e内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eColossus的4U液冷服务器，强调为液冷而设计\u003c/b\u003e\u003c/p\u003e\n\u003cp\u003eColossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./mgx-hgx-dgx.webp\" alt=\"MGX HGX DGX\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI服务器\u003c/a\u003e。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。\u003c/p\u003e\n\u003cp\u003e因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。\u003c/p\u003e\n\u003cp\u003eColossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./xAI-Colossus-Data-Center-Supermicro-Liquid-Cooled-Nodes-Low-Angle.jpg\" alt=\"XAI Colossus Data Center Supermicro Liquid Cooled Nodes Low Angle\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"拥有10万块英伟达H100的数据中心长什么样","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":"Git是一种分布式版本控制系统，它的强大和灵活性使其在开发人员中广受欢迎。掌握Git的基本概念和常用命令对于提高开发效率和协作能力是非常有帮助的。本文将介绍Git的基础知识，包括常用命令、分支管理、远程仓库操作等，帮助您从新手成长为Git专家。\nGit基础命令 # git init: 初始化一个新的Git仓库。在目录下执行该命令，将当前目录转化为一个Git仓库 git add: 将文件添加到Git的暂存区，准备提交。例如，git add . 将所有文件添加到暂存区 git commit: 提交暂存区中的文件到Git仓库，并添加提交信息。例如，git commit -m \u0026ldquo;Initial commit\u0026rdquo; git status: 查看Git仓库的状态，显示新增、修改和删除的文件 git diff: 比较文件在Git仓库和本地工作区的差异 git show: 显示指定提交的详细信息 git log: 查看提交历史记录 Git分支管理 # git branch: 创建、切换和删除分支 git branch new_branch 创建一个新分支 git checkout new_branch 切换到新分支 git branch -d branch_name 删除指定分支 git checkout: 切换到指定的分支或恢复工作区文件 git checkout new_branch 切换到新分支 git checkout . 恢复工作区文件 git merge: 将指定分支的修改合并到当前分支 git merge new_branch 将new_branch分支的修改合并到当前分支 Git远程仓库操作 # git remote: 管理远程仓库地址 git remote add origin https://github.com/user/repo.git 添加远程仓库地址 git pull: 从远程仓库拉取最新的代码并合并到当前分支\ngit push: 将本地提交推送到远程仓库\ngit push origin master 将当前分支的修改推送到远程仓库的master分支 Git高级操作 # git stash: 保存当前工作区的修改，恢复到最近一次提交的状态。 例如，在需要切换到其他任务时，可以使用该命令保存当前修改，完成任务后再通过 git stash pop 恢复修改。\ngit revert: 撤销指定提交。 通过 git revert commit_id 可以撤销指定提交并生成新的提交。\ngit reset: 重置HEAD指针。 通过 git reset --hard commit_id 可以将HEAD指针重置为指定提交，但会丢失重置点之后的提交历史。\ngit cherry-pick: 选择性地应用提交。 通过 git cherry-pick commit_id 可以将指定提交应用到当前分支。\n总之，Git具有丰富的功能和灵活的用法，这些命令可以帮助我们完成从基础到高级的Git操作。但是，Git的强大不仅限于此，还有更多的高级功能和概念值得深入探讨。通过不断学习和实践，我们将能够更好地利用Git来提高开发效率和协作能力。\n","date":"2024-11-03","externalUrl":null,"permalink":"/software/the-most-commonly-used-git-commands/","section":"Softwares","summary":"\u003cp\u003e\u003ca href=\"https://www.kad8.com/software/gitui-terminal-ui-for-git/\" target=\"_blank\"\u003eGit\u003c/a\u003e是一种分布式版本控制系统，它的强大和灵活性使其在开发人员中广受欢迎。掌握Git的基本概念和常用命令对于提高开发效率和协作能力是非常有帮助的。本文将介绍Git的基础知识，包括常用命令、分支管理、远程仓库操作等，帮助您从新手成长为Git专家。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eGit基础命令 \n    \u003cdiv id=\"git%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#git%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003egit init: 初始化一个新的Git仓库。在目录下执行该命令，将当前目录转化为一个Git仓库\u003c/li\u003e\n\u003cli\u003egit add: 将文件添加到Git的暂存区，准备提交。例如，git add . 将所有文件添加到暂存区\u003c/li\u003e\n\u003cli\u003egit commit: 提交暂存区中的文件到Git仓库，并添加提交信息。例如，git commit -m \u0026ldquo;Initial commit\u0026rdquo;\u003c/li\u003e\n\u003cli\u003egit status: 查看Git仓库的状态，显示新增、修改和删除的文件\u003c/li\u003e\n\u003cli\u003egit diff: 比较文件在Git仓库和本地工作区的差异\u003c/li\u003e\n\u003cli\u003egit show: 显示指定提交的详细信息\u003c/li\u003e\n\u003cli\u003egit log: 查看提交历史记录\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./git-tutorials-How-Git-branches-work.webp\" alt=\"Git Tutorial How Git Branches\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"Git 最常用的几个操作命令","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/dgx-b200/","section":"Tags","summary":"","title":"DGX B200","type":"tags"},{"content":"OpenAI 将通过最新的 DGX B200 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。\nDGX B200 # DGX B200的电源要求 # 每个DGX B200系统有6个电源模块，其中至少5个模块需要运行才能让系统正常工作。 如果有1个电源模块故障，系统仍能继续运行。但如果有2个或更多的模块故障，系统就无法运行。这和是否有额外的备用电源无关。 DGX B200电源和散热规划 # 电路部署方式： # 每个机架使用两条电路，每条电路需要能够处理机架一半的峰值用电量，并且要考虑断路器的安全裕量。\n额外散热设备： # 一些像 rear door heat exchangers 和 in-row coolers这样的额外散热设备通常不适合DGX B200系统。\nDGX 超节点 # 每个48U/52U机架放置两个风冷的DGX B200 高密度部署的情况下，52U的机架可以放4个DGX B200\n机间互联采用IB网络\nIB结构决定了机架间电缆距离的要求\nDGX 超节点最多可以有127个DGX B200，每32个是一个单元。\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/specific-system-spec-about-dgx-b200/","section":"Ais","summary":"\u003cp\u003eOpenAI 将通过最新的 \u003ca href=\"https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/\" target=\"_blank\"\u003eDGX B200\u003c/a\u003e 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eDGX B200 \n    \u003cdiv id=\"dgx-b200\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#dgx-b200\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./DGX-B200-1.webp\" alt=\"DGX B200\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"OpenAI获得的DGX B200的具体信息","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/benchmark/","section":"Tags","summary":"","title":"Benchmark","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/m4-pro/","section":"Tags","summary":"","title":"M4 Pro","type":"tags"},{"content":"近日，苹果新推出的 M4 Max 芯片在 Geekbench 上的测试结果曝光。不出所料，苹果巩固了其在性能领域的领先地位，成为 Geekbench 上最快的芯片。即使在多核性能方面，M4 Max 也让英特尔和 AMD 的最新产品相形见绌，而这仅仅是其强大性能的一部分。\nApple M4 Max\n测试环境采用了全新的 16 英寸 MacBook Pro，让 M4 Max 得以充分发挥实力。根据基准测试数据，M4 Max 在 Geekbench 6 中的单核得分为 4,060 分，多核得分为 26,675 分。与去年的 M3 Max 相比，单核性能提升了约 30%，多核性能提升了 27%，这也说明苹果在芯片性能上的迭代诚意非常足。\n在与 x86 架构的对比中，AMD 和英特尔的芯片明显处于劣势。M4 Max 即使在多核性能上也轻松领先，同时功耗却仅为对手的一小部分。具体来说，M4 Max 的单核性能比英特尔的 Core Ultra 9 285K 高出约 19%，多核性能高出 16%；相比 AMD 的 Ryzen 9 9950X，单核性能高出 18%，多核性能高出 25%。\nApple M4 Max\n作为苹果的旗舰级 SoC，M4 Max 主要面向数据科学家、3D 艺术家和其他专业人士。顶级配置包含 16 个 CPU 核心（12 个性能核心和 4 个高效核心）和 40 个 GPU 核心，以及高达 128GB 的统一内存，CPU 和 GPU 均可直接访问。此外，苹果还为新款 MacBook Pro 系列配备了对 Thunderbolt 5 的支持，传输速度高达 120 Gb/s。\n苹果全新的 M4 系列芯片，是对英特尔、AMD 和高通最近推出的 AI PC 产品的有力回应。尽管性能表现令人瞩目，但价格依然十分高昂——但是好东西的价格从来就不便宜，配备完整功能的 M4 Max 机型（16核）售价高达30000以上。在这个价位上，内容创作者和注重生产力的用户可能会考虑配备独立显卡的笔记本电脑。\n需要注意的是，Geekbench 并不是评估芯片性能的最佳基准测试工具。因此，M4 Max 在 Cinebench 或 HandBrake 等其他测试中的表现将更具参考价值，以判断其是否真正超越竞争对手。搭载 M4 Max 的 MacBook Pro 2024 将于 11 月 8 日开始交付，届时我们将更全面地了解 M4 Max 的实际性能。\n","date":"2024-11-03","externalUrl":null,"permalink":"/hardware/apple-m4-pro-benchmark-shows-it-outperforms-the-m3-max/","section":"Hardwares","summary":"\u003cp\u003e近日，苹果新推出的 M4 Max 芯片在 Geekbench 上的测试结果曝光。不出所料，苹果巩固了其在性能领域的领先地位，成为 Geekbench 上最快的芯片。即使在多核性能方面，M4 Max 也让英特尔和 AMD 的最新产品相形见绌，而这仅仅是其强大性能的一部分。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"./apple-m4-pro-1.webp\"\u003eApple M4 Max\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e测试环境采用了全新的 16 英寸 MacBook Pro，让 M4 Max 得以充分发挥实力。根据基准测试数据，M4 Max 在 Geekbench 6 中的单核得分为 4,060 分，多核得分为 26,675 分。与去年的 M3 Max 相比，单核性能提升了约 30%，多核性能提升了 27%，这也说明苹果在芯片性能上的迭代诚意非常足。\u003c/p\u003e","title":"苹果M4 Max登顶Geekbench，击败Intel和AMD","type":"hardware"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/dow/","section":"Tags","summary":"","title":"DOW","type":"tags"},{"content":"据CNBC报道，英伟达将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。\n英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。\n与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。\n回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。\n而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。\n注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。\n道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。\n道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/nvidia-to-join-the-dow-jones-industrial-average/","section":"Ais","summary":"\u003cp\u003e据CNBC报道，\u003ca href=\"https://www.gaitpu.com/data-center/server/difference-between-nvlink-version-and-pcie-version-for-nvidia-ai-server\" target=\"_blank\"\u003e英伟达\u003c/a\u003e将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。\u003c/p\u003e\n\u003cp\u003e英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。\u003c/p\u003e\n\u003cp\u003e与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。\u003c/p\u003e\n\u003cp\u003e回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。\u003c/p\u003e\n\u003cp\u003e而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。\u003c/p\u003e\n\u003cp\u003e注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。\u003c/p\u003e\n\u003cp\u003e道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。\u003c/p\u003e\n\u003cp\u003e道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。\u003c/p\u003e","title":"英伟达替代英特尔，成为道指成份股","type":"ai"},{"content":" LVS概念 # LVS（Linux Virtual Server）是一个基于Linux操作系统的虚拟服务器技术，用于实现负载均衡和高可用性。LVS通过将客户端的请求分发到多台后端服务器上，从而提高整体服务的处理能力和可靠性。LVS主要有两个组件：IPVS（IP Virtual Server）和LVS-NAT、LVS-DR、LVS-TUN三种工作模式。\nLVS的优势 # 高性能：LVS工作在内核层，性能高效，能够处理大量并发请求。 高可用性：通过配置Keepalived等工具，LVS可以实现高可用性，确保服务的持续运行。 灵活性强：支持多种负载均衡算法和工作模式，适应不同的应用场景。 LVS架构 # LVS的整体架构主要包括负载均衡器（Load Balancer）、后端服务器（Real Server）和客户端三部分。客户端的请求首先到达负载均衡器，然后由负载均衡器根据一定的调度算法将请求转发到后端服务器进行处理，处理结果再返回给客户端。\nLVS的工作模式 # LVS支持三种主要的工作模式：\nLVS-NAT模式：通过修改请求报文的目标IP地址实现负载均衡。 LVS-DR模式：通过操纵封装新的MAC地址实现负载均衡。 LVS-TUN模式：在原请求IP报文之外新加一个IP首部实现负载均衡。 LVS实战案例 # LVS-DR模式实战案例\n环境准备： # 负载均衡器（Director）：CentOS 7 真实服务器（Real Server）：两台 CentOS 7 VIP：192.168.1.100 配置 LVS 负载均衡器： # 首先，确保 LVS 和 ipvsadm 已安装：\nyum install ipvsadm -y modprobe ip_vs 设置 LVS 负载均衡规则： # ipvsadm -A -t 192.168.1.100:80 -s rr ipvsadm -a -t 192.168.1.100:80 -r 192.168.1.101:80 -g ipvsadm -a -t 192.168.1.100:80 -r 192.168.1.102:80 -g 解释：\n-A -t 192.168.1.100:80：添加一个 VIP 地址监听 80 端口的服务。 -s rr：使用轮询调度算法。 -a -r 192.168.1.101:80 -g：将真实服务器 192.168.1.101 加入到 VIP 服务中，并使用 DR 模式（ -g 表示 DR 模式）。 -a -r 192.168.1.102:80 -g：同样将 192.168.1.102 加入服务。 配置真实服务器： # 为了使 LVS DR 模式生效，我们需要在真实服务器上进行一些特殊的配置。\n配置 lo 接口的 VIP，但不要让它对外 ARP 应答：\nifconfig lo:0 192.168.1.100 netmask 255.255.255.255 up route add -host 192.168.1.100 dev lo:0 禁止真实服务器对 VIP 发送 ARP 响应：编辑 /etc/sysctl.conf 文件，添加以下内容：\nnet.ipv4.conf.lo.arp_ignore = 1 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_ignore = 1 net.ipv4.conf.all.arp_announce = 2 然后执行 sysctl -p 使配置生效。\n启动 web 服务（如 Nginx 或 Apache）监听所有 IP：\nyum install nginx -y systemctl start nginx 测试： # 在客户端访问 http://192.168.1.100，请求会被 LVS 分发到后端的真实服务器上。通过多次刷新页面，您可以看到请求在两台真实服务器之间轮流分发。\n查看 LVS 状态： # 可以使用以下命令查看 LVS 的负载均衡状态：\nipvsadm -L -n 输出将显示 LVS 的规则以及每台真实服务器的连接数。\n","date":"2024-11-03","externalUrl":null,"permalink":"/software/introduction-to-linux-lvs/","section":"Softwares","summary":"\u003ch2 class=\"relative group\"\u003eLVS概念 \n    \u003cdiv id=\"lvs%E6%A6%82%E5%BF%B5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#lvs%E6%A6%82%E5%BF%B5\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eLVS\u003c/code\u003e（Linux Virtual Server）是一个基于\u003ca href=\"https://www.gaitpu.com/category/os/linux\" target=\"_blank\"\u003eLinux操作系统\u003c/a\u003e的虚拟服务器技术，用于实现负载均衡和高可用性。LVS通过将客户端的请求分发到多台后端服务器上，从而提高整体服务的处理能力和可靠性。LVS主要有两个组件：IPVS（IP Virtual Server）和LVS-NAT、LVS-DR、LVS-TUN三种工作模式。\u003c/p\u003e","title":"Linux LVS简介","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/pipe/","section":"Tags","summary":"","title":"Pipe","type":"tags"},{"content":"","date":"2024-11-02","externalUrl":null,"permalink":"/tags/3d-cache/","section":"Tags","summary":"","title":"3D Cache","type":"tags"},{"content":"AMD早就说Ryzen 9000X3D系列会带来真正的第二代3D缓存技术，那么到底有什么革命性的变化呢？根据最新曝料，至少其中之一就是，3D缓存的位置变了！\n锐龙5000X3D、锐龙7000X3D系列的3D缓存都在CCD模块之上，同时在旁边还有填充模块，保持二者大小面积一致。\n锐龙9000X3D则将3D缓存放在了CCD模块之下，当然肯定也少不了填充模块支撑。\n这么做的好处就是可以让包含CPU核心、发热量更高的CCD模块贴着IHS散热顶盖，散热效果更好，自然可以跑到更高的频率。\n比如首发的锐龙7 9800X3D，默认频率为4.7-5.2GHz，相比于锐龙7 7800X3D分别高了500MHz、200MHz，基准频率也远高于锐龙9000系列标准版。\n同时，AMD应该是基本解决了X3D系列的超频限制，可以超到接近全核5.7GHz。\n另外，锐龙7 9800X3D的专业跑分首次出现，搭档ROG CROSSHAIR X870E HERO主板、32GB DDR5-6000内存、RTX 4090显卡，PugetBench DaVinci测试得分10487、Premiere得分14201。\n作为对比，锐龙7 7800X3D在最接近的配置下，Premiere得分为13005，锐龙7 9700X只是13349。\n再说说AMD新一代的Zen5架构移动版APU，整个家族包含三大成员：\nStrix Point已发布，就是锐龙AI 9/7 300系列，定位高端； Strix Halo定位旗舰级，将命名为锐龙AI Max 300系列，拥有史上最强GPU； Krackan定位主流和低端，预计命名为锐龙AI 7/5 300系列。 Krackan虽然规格不高，但同样拥有三大新架构，最多8个Zen5+Zen5c CPU核心、8个RDNA3.5 GPU核心，对付Intel的酷睿Ultra 200V系列不成问题。\n现在我们获悉了Krackan的一款样品，编号为“AMD Eng Sample 100-000000713-21_N”，看样子像是PRO商用版本的锐龙AI 7 300。\n有趣的是，它定位不高，但是搭配了32GB大容量的LPDDR5X-8000高频内存，要知道Strix Point系列最高才LPDDR5X-7500。\n更高的内存频率，无疑可以更充分地释放GPU的性能。\n按理说，Intel、AMD似乎一直水火不相容，但是恐怕谁都没想到，Intel CEO帕特·基辛格、AMD CEO苏姿丰肩并肩站在了一起，联合宣布成立x86生态系统顾问小组，共同捍卫x86架构的江湖地位。\nIntel官方近日更是撰文，表明了基辛格的态度，强调了x86在AI PC时代的核心地位与意义。\nAI正在“飞入寻常百姓家”，成为随时随地可用的生产力和创意工具，让我们的日常生活变得更加美好。\n基辛格表示，得益于AI所带来的机遇，作为数十年来计算技术基础的x86架构，正在迎来一个定制、扩大和拓展的时期。\n基辛格认为，每家公司都将成为AI公司，每台设备都将成为AI设备，特别是每个人打开AI PC，便能受益于AI技术的神奇力量。\nAI PC让人们在使用AI时，不再受到时间、地点的限制，不必将个人数据分享到云端，网络连接也不再必需，正如当年Intel迅驰平台推动Wi-Fi在公共场所的普及。\n根据市调机构IDC的预测，AI PC将在2025年占据一半的市场份额，而到2030年，这一比例将达到100％。\n目前，单单是Intel就已出货了超过2000万台AI设备，生态系统方面已获得100多家ISV软件厂商的支持，出现了300多项AI应用、500多个AI模型。\n基辛格表示，AI PC时代需要定义核心架构，x86架构正是AI PC时代的关键，一如它是数据中心、边缘和网络解决方案的核心一样。\nx86生态系统顾问小组的成立，正是为了让x86架构在未来变得更加灵活、开放，进一步提升其成本效益，其目标是进一步推动x86生态系统的蓬勃发展，以更强大的定制化能力、兼容性和可扩展性满足客户的需求。\n在产品层面，Intel在与OEM厂商密切合作，推出了以酷睿Ultra系列处理器为核心的AI PC，拥有出色的性能和电池续航。\nIntel还将于明年推出基于Intel 18A(等效于1.8nm)制程节点的Panther Lake处理器，目前样片已经出厂、上电运行并顺利启动操作系统。\n","date":"2024-11-02","externalUrl":null,"permalink":"/hardware/amd-ryzen-9000x-3d-cache-has-changed/","section":"Hardwares","summary":"\u003cp\u003eAMD早就说\u003ca href=\"https://www.kad8.com/hardware/amd-ryzen-7-9800x3d-benchmark-leaked/\" target=\"_blank\"\u003eRyzen 9000X3D\u003c/a\u003e系列会带来真正的第二代3D缓存技术，那么到底有什么革命性的变化呢？根据最新曝料，至少其中之一就是，3D缓存的位置变了！\u003c/p\u003e\n\u003cp\u003e锐龙5000X3D、锐龙7000X3D系列的3D缓存都在CCD模块之上，同时在旁边还有填充模块，保持二者大小面积一致。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-Ryzen-9000X-3D-Cache-1.webp\" alt=\"AMD Ryzen 9000X\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e锐龙9000X3D则将3D缓存放在了CCD模块之下，当然肯定也少不了填充模块支撑。\u003c/p\u003e\n\u003cp\u003e这么做的好处就是可以让包含CPU核心、发热量更高的CCD模块贴着IHS散热顶盖，散热效果更好，自然可以跑到更高的频率。\u003c/p\u003e\n\u003cp\u003e比如首发的锐龙7 9800X3D，默认频率为4.7-5.2GHz，相比于锐龙7 7800X3D分别高了500MHz、200MHz，基准频率也远高于锐龙9000系列标准版。\u003c/p\u003e\n\u003cp\u003e同时，AMD应该是基本解决了X3D系列的超频限制，可以超到接近全核5.7GHz。\u003c/p\u003e\n\u003cp\u003e另外，锐龙7 9800X3D的专业跑分首次出现，搭档ROG CROSSHAIR X870E HERO主板、32GB DDR5-6000内存、RTX 4090显卡，PugetBench DaVinci测试得分10487、Premiere得分14201。\u003c/p\u003e","title":"AMD锐龙9000X3D缓存变了","type":"hardware"},{"content":"","date":"2024-11-02","externalUrl":null,"permalink":"/tags/ryzen/","section":"Tags","summary":"","title":"Ryzen","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/chiplet/","section":"Tags","summary":"","title":"Chiplet","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/gpu/","section":"Tags","summary":"","title":"GPU","type":"tags"},{"content":"Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。\n本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。\n据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。\n通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。\n此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。\n这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。\n其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。\n而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。\n事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。\n在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。\n这种思路可以提高设计和封装灵活性，使不同类型的芯片块可以分别进行优化和制造，然后再通过先进封装技术集成在一起，以实现更高的性能和效率。\n未来，无论是CPU、还是GPU，芯粒都是大势所趋。\n当然， Intel这份专利何时才能落地，目前尚未可知。期待Intel未来能带来好消息。\n不过如今想玩爽游戏，除了好显卡，也离不开好处理，比如AMD X3D这种逆天的存在。\nAMD即将推出的锐龙7 9800X3D处理器，完整规格已在Geizhals上泄露。\n锐龙7 9800X3D拥有8核心16线程，基础频率达到4.7GHz，最大加速频率为5.2GHz，相较于上一代7800X3D的4.2GHz基础频率和5.05GHz最大加速频率有了明显提升。\n该处理器的热设计功耗（TDP）为120W，与7800X3D相同，这意味着用户可能无需升级现有的散热方案。\n锐龙7 9800X3D的缓存配置保持不变，总计104MB缓存，包括8MB二级缓存、32MB内置三级缓存和64MB堆叠三级缓存。\n内存支持方面，该处理器升级至DDR5-5600，最大支持192GB内存，在使用两个DIMM时会降至DDR5-3600水平。\n与Ryzen 5000X3D和7000X3D不同，9800X3D的倍频解锁，为极限超频玩家提供了创造新世界记录的空间。\n值得注意的是，该处理器最高工作温度也从89摄氏度提高到了95摄氏度，与Ryzen 9000非X3D系列相似。\nAMD已经宣布，新一代锐龙9000X3D系列将于11月7日正式上市，届时锐龙7 9800X3D将正式亮相。\n","date":"2024-11-01","externalUrl":null,"permalink":"/ai/intel-chiplet-gpu-design-patents/","section":"Ais","summary":"\u003cp\u003eIntel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。\u003c/p\u003e\n\u003cp\u003e本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Intel-patents-chiplet-gpu-design-1.webp\" alt=\"Intel Patents Chiplet GPU design\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。\u003c/p\u003e\n\u003cp\u003e通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。\u003c/p\u003e\n\u003cp\u003e此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。\u003c/p\u003e\n\u003cp\u003e这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。\u003c/p\u003e\n\u003cp\u003e其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。\u003c/p\u003e\n\u003cp\u003e而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。\u003c/p\u003e\n\u003cp\u003e事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。\u003c/p\u003e\n\u003cp\u003e在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。\u003c/p\u003e","title":"英特尔获得 Chiplet GPU 设计专利","type":"ai"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/csodimm/","section":"Tags","summary":"","title":"CSODIMM","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/cudimm/","section":"Tags","summary":"","title":"CUDIMM","type":"tags"},{"content":"宜鼎国际（Innodisk）宣布推出业界容量最大的DDR5 6400内存模块，具备单条64GB的超大容量。\n该系列内存提供8GB至64GB的容量选项，以及CUDIMM、CSODIMM、ECC CUDIMM、ECC CSODIMM与RDIMM等多重规格。\n宜鼎DDR5 6400内存相比前代产品，速度提升14%，容量翻倍，可应用于自动驾驶、智慧医疗、安防监控等高精密影像识别场景。\n业界最高的单条64GB存储容量，可满足LLM等对内存容量需求较高的应用领域。\n该系列内存还在模块上增设独特CKD元件，针对时脉信号进行驱动与缓冲，有效减少干扰或噪声，确保高频传输下的信号完整性，降低在智慧医疗、自动驾驶等需要极高精准度的应用场景中的错误风险。\n此外，宜鼎DDR5 6400全系列产品搭载TVS二极管，传导因电压异常所产生的过电流，并将其释放到地面，防止静电、电压波动等突发状况损害模块元件。\n针对服务器应用推出的RDIMM规格，配备eFuse（电子熔断器），当电压超过额定值时，eFuse将自动中断电路，防止元件损坏。\n铠侠宣布量产业界首款采用四层单元技术的QLC UFS 4.0闪存。相比于传统的TLC UFS有着更高的位密度。\n在性能方面，512GB容量的QLC UFS 4.0闪存充分发挥了UFS 4.0接口的高速潜力，实现了惊人的4200MB/s顺序读取速度和3200MB/s的顺序写入速度。\n技术层面，铠侠巧妙地将先进的BiCS FLASH 3D NAND闪存与高效的主控芯片集成于JEDEC标准封装之内，不仅支持M-PHY 5.0和UniPro 2.0的最新规范，还确保了每通道高达23.2 Gb/s（或每设备46.4 Gbps）的理论接口速度，同时保持了与UFS 3.1标准的向下兼容性。\n此外，QLC UFS 4.0闪存还引入了多项前沿特性，如HS-LSS（高速链路启动序列），该特性相比传统方法能显著缩短链路启动时间，提升效率约70%。\n通过采用高级RPMB技术，实现了对安全数据的快速读写访问。\n扩展启动器ID（Ext-IID）功能的加入，旨在与UFS 4.0主控的多循环队列（MCQ）协同工作，共同提升随机性能。\n","date":"2024-11-01","externalUrl":null,"permalink":"/hardware/innodisk-unveils-ddr5-6400-64gb-cudimm-and-csodimm-memory-modules/","section":"Hardwares","summary":"\u003cp\u003e宜鼎国际（Innodisk）宣布推出业界容量最大的DDR5 6400内存模块，具备单条64GB的超大容量。\u003c/p\u003e\n\u003cp\u003e该系列内存提供8GB至64GB的容量选项，以及\u003ccode\u003eCUDIMM\u003c/code\u003e、\u003ccode\u003eCSODIMM\u003c/code\u003e、\u003ccode\u003eECC CUDIMM\u003c/code\u003e、\u003ccode\u003eECC CSODIMM\u003c/code\u003e与\u003ccode\u003eRDIMM\u003c/code\u003e等多重规格。\u003c/p\u003e\n\u003cp\u003e宜鼎DDR5 6400内存相比前代产品，速度提升14%，容量翻倍，可应用于自动驾驶、智慧医疗、安防监控等高精密影像识别场景。\u003c/p\u003e\n\u003cp\u003e业界最高的单条64GB存储容量，可满足\u003ccode\u003eLLM\u003c/code\u003e等对内存容量需求较高的应用领域。\u003c/p\u003e\n\u003cp\u003e该系列内存还在模块上增设独特CKD元件，针对时脉信号进行驱动与缓冲，有效减少干扰或噪声，确保高频传输下的信号完整性，降低在智慧医疗、自动驾驶等需要极高精准度的应用场景中的错误风险。\u003c/p\u003e\n\u003cp\u003e此外，宜鼎DDR5 6400全系列产品搭载TVS二极管，传导因电压异常所产生的过电流，并将其释放到地面，防止静电、电压波动等突发状况损害模块元件。\u003c/p\u003e\n\u003cp\u003e针对服务器应用推出的RDIMM规格，配备eFuse（电子熔断器），当电压超过额定值时，eFuse将自动中断电路，防止元件损坏。\u003c/p\u003e\n\u003cp\u003e铠侠宣布量产业界首款采用四层单元技术的QLC UFS 4.0闪存。相比于传统的TLC UFS有着更高的位密度。\u003c/p\u003e\n\u003cp\u003e在性能方面，512GB容量的\u003ccode\u003eQLC UFS 4.0\u003c/code\u003e闪存充分发挥了UFS 4.0接口的高速潜力，实现了惊人的4200MB/s顺序读取速度和3200MB/s的顺序写入速度。\u003c/p\u003e","title":"Innodisk 推出 DDR5 6400 64GB CUDIMM 和 CSODIMM 内存模块","type":"hardware"},{"content":"今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (UALink ) 联盟正式成立，并向社区发出成员邀请。\n资料显示，Ultra Accelerator Link(UALink) 是一种用于加速器到加速器通信的开放行业标准化互连。\nUALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 AI 加速器（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。\n新闻稿指出，联盟公司代表着广泛的行业专业知识，包括云服务提供商、系统 OEM、加速器开发商、交换机开发商和 IP 提供商。目前正在开发用于数据中心 AI 连接的更多使用模型。\nUALink 联盟总裁 Willie Nelson 表示：“UALink 标准定义了数据中心内扩展 AI 系统的高速、低延迟通信。我们鼓励有兴趣的公司以贡献者成员的身份加入，以支持我们的使命：为 AI 工作负载建立开放且高性能的加速器互连。”\n一个早在五月就发起的协议 # 其实早在今年五月，AMD、博通、思科、谷歌、惠普企业、英特尔、Meta 和微软就携手成立了超级加速器链接 (UALink：Ultra Accelerator Link)小组，旨在推动数据中心 AI 连接。\n这个初始小组名为“超级加速器链路”(UALink)，将定义和建立一项开放的行业标准，使 AI 加速器能够更有效地通信。通过创建基于开放标准的互连，UALink 将使系统 OEM、IT 专业人员和系统集成商能够为其 AI 连接数据中心创建一条更轻松的集成、更大的灵活性和可扩展性的途径。\n发起人集团公司在基于开放标准、效率和强大的生态系统支持创建大规模 AI 和 HPC 解决方案方面拥有丰富的经验。\n据他们所说，随着对 AI 计算的需求不断增长，拥有一个强大、低延迟且高效的扩展网络至关重要，该网络可轻松将计算资源添加到单个实例中。为扩展功能创建开放的行业标准规范将有助于为 AI 工作负载建立一个开放的高性能环境，从而提供尽可能高的性能。\nUALink 和行业规范对于标准化下一代 AI 数据中心和实现的 AI 和机器学习、HPC 和云应用程序接口至关重要。该小组将制定一项规范，定义 AI 计算舱中加速器和交换机之间扩展通信的高速、低延迟互连。\n根据最初报道，UAlink1.0 规范将允许在 AI 计算Pod内连接多达 1024 个加速器，并允许在舱内连接到加速器（例如 GPU）的内存之间进行直接加载和存储。按照最初规划，UALink 1.0 规范预计将于 2024 年第三季度推出，并提供给加入 Ultra Accelerator Link (UALink) 联盟的公司。\n但根据最新的报道，UALink 1.0 规范依然还将为 AI pod 内最多 1024 个加速器实现高达每通道 200Gbps 的扩展连接。而且该规范将于今年向贡献者成员提供，并于 2025 年第一季度提供一般审查。\n不过，按照UALink 联盟主席 Kurtis Bowman 所说，UALink 1.0 规范要到2025 年第一季度发布，在他们看来，这是一个重要的里程碑，因为它将建立一个开放的行业标准，使 AI 加速器和交换机能够更有效地通信、扩展内存访问以满足大型 AI 模型要求，并展示行业协作的好处。\n探索GPU连接的新方法 # GPU 是当前的市场热点，它们可轻松完成矩阵数学运算。它最初设计用于在计算机显示器上快速绘制点，后来被 HPC 从业者发现在大量使用时非常有用。随着 GenAI 的出现，这些小型矩阵专家的需求量巨大，以至于我们称之为 GPU Squeeze。\n著名且占主导地位的市场领导者 Nvidia 已经为 GPU 技术开辟了道路。对于 HPC、GenAI 和大量其他应用程序，连接 GPU 提供了一种解决更大问题并提高应用程序性能的方法。\n据外媒HPC报道，具体而言，连接GPU有三种基本方法：\nPCI 总线：标准服务器通常可以在 PCI 总线上支持 4-8 个 GPU。通过使用GigaIO FabreX 内存结构等技术，可以将这个数字增加到 32 个。CXL 也显示出希望，但是 Nvidia 的支持很少。对于许多应用程序来说，这些可组合的 GPU 域代表了下面提到的 GPU 到 GPU 扩展方法的替代方案。\n服务器到服务器互连：以太网或 InfiniBand 可以连接包含 GPU 的服务器。这种连接级别通常称为横向扩展，其中较快的多 GPU 域通过较慢的网络连接以形成大型计算网络。自从比特开始在机器之间移动以来，以太网一直是计算机网络的主力。最近，通过引入超级以太网联盟，该规范已被推动以提供高性能。事实上，英特尔已经在以太网上插上了互连旗帜，因为英特尔 Gaudi -2 AI 处理器在芯片上拥有 24 个 100 千兆以太网连接。\n值得一提的是，Nvidia 没有加入超级以太网联盟，因为他们在 2019 年 3 月收购 Mellanox 后，基本上独占了高性能 InfiniBand 互连市场。超级以太网联盟旨在成为其他所有人的“InfiniBand”。此外，英特尔也曾经高举 InfiniBand 大旗。\nGPU 到 GPU 互连：认识到快速且可扩展的 GPU 连接的需求，Nvidia 创建了 NVLink，这是一种 GPU 到 GPU 的连接，目前可在 GPU 之间以每秒 1.8 TB 的速度传输数据。此外，还有一个 NVLink 机架级交换机，能够在无阻塞计算结构中支持多达 576 个完全连接的 GPU。通过 NVLink 连接的 GPU 称为“pod”，表示它们有自己的数据和计算域。 对于其他人来说，除了用于连接 MI300A APU 的 AMD Infinity Fabric 之外，没有其他选择。与 InfiniBand/以太网的情况类似，需要某种“超级”竞争对手联盟来填补非 Nvidia 的“pod 空缺”。而这正是发生的事情。\n于是，UALink横空出世。\n能给英伟达带来压力吗？ # 如很多分析人士所说，创建 UALink 的举措反映了业界对高性能计算中可扩展、开放架构需求的日益认识。随着人工智能和数据密集型应用的发展，对此类技术的需求可能会增加，这使得 UALink 成为下一代计算工具的关键组件。\n通过提供 NVIDIA NVLink 和 NVSwitch 的可靠和开放替代方案，UALink 旨在打破 NVIDIA 在 GPU 互连市场的主导地位。这一点尤为重要，因为人工智能工作负载和模型不断增长，需要更具可扩展性和更高效的互连解决方案。\n毫无疑问，UALink 的推出给 NVIDIA 带来了压力，这将迫使他们继续创新和改进自己的技术。为了保持竞争优势，NVIDIA 需要提高 NVLink 和 NVLink Switch 的性能、可扩展性和成本效益，从而有可能加快行业创新的步伐。\n同时，UALink 的开源性质鼓励采用协作方式进行开发。摆脱专有系统可以促进创新，并允许快速采用和改进技术。\n分析人士指出，UALink 的潜力不仅仅是提供 NVLink 的替代方案。它旨在创建一个生态系统，无论公司规模大小，公司都可以为先进的互连技术做出贡献并从中受益。对于超大规模企业和大型数据中心而言，采用 UALink 可能意味着显着的成本节约、硬件部署的更大灵活性以及增强的性能。\n与此同时，UALink 还是一个技术公司联盟的重大举措，旨在限制 AI 加速器的专有互连，促进开放、竞争和创新。它对市场的影响可能是巨大的，为 AI 和基于加速器的系统营造一个更具活力和成本效益的生态系统。很难在这项使命中找到负面作用。\n虽然牌面上说给英伟达带来了竞争。\n但是，我们也必须认识到，NVIDIA 的 NVLink 为 UALink 设定了一个高标准和具有挑战性的目标，需要实现和超越。如今，其多代产品已投入生产，提供稳定的高性能解决方案，NVLink 不太可能停滞不前，预计将继续发展以满足预期的未来系统要求。UALink 不仅需要实现其解决方案的稳定性和支持供应商之间的互操作性，还需要超越 NVLink 目前所处的位置。\n此外，虽然建立稳定、高性能、可互操作的物理互连（可从多家供应商处获得并支持）是保持竞争力的必要条件，但这还不够。NVIDIA 的 CUDA 软件开发环境也是一个难以克服的巨大障碍。用户不愿意将他们的应用程序代码移植到新硬件上，只为实现相同的性能和功能；他们宁愿将投资集中在解决方案上，为客户提供新的功能、能力和价值。\n尽管存在上述挑战，UALink 仍朝着正确的方向前进。该组织由来自先进技术计算生态系统（系统、交换机、云、超大规模器、加速器、I/O、组件设计）的领先供应商组成，他们在合作定义新标准并将其推向市场方面有着良好的记录。\n同时，与 UEC 结盟和合作也是一个明智之举，因为生态系统采用的范围越广，成功的可能性就越大。虽然这超出了 UALink 的范围，但与更高级别的软件工作建立联系并提供支持，以帮助用户从 CUDA 移植到标准加速器软件环境，将进一步提高 UALink 实现广泛采用目标的可能性。\n为了支持 UALink 的努力，超级以太网联盟 (UEC) 主席 J Metz 博士在五月的小组成立新闻稿中直言：“在很短的时间内，技术行业已经接受了人工智能和 HPC 发现的挑战。在寻求提高效率和性能时，将 GPU 等加速器互连需要整体视角。在 UEC，我们相信 UALink 解决 pod 集群问题的扩展方法与我们自己的扩展协议相得益彰，我们期待在未来共同合作创建一个开放、生态系统友好、全行业的解决方案，以满足这两种需求。”\n针对这个协议，英伟达CEO黄仁勋在早前曾直言不会太在意。他同时强调，目前NVLink已推出到第五代，而UALink还只是个提案，至少数年内都不会威胁到NVLink。当UALink第一代推出时，NVLink可能已到第七、八代了；甚至针对未来NVIDIA网络技术改进，内部也有许多不错的想法，不排除将有更进一步创新。\n但，有竞争力总是好事。\n","date":"2024-11-01","externalUrl":null,"permalink":"/ai/nine-giants-established-the-ualink-alliance/","section":"Ais","summary":"\u003cp\u003e今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (\u003ccode\u003eUALink\u003c/code\u003e ) 联盟正式成立，并向社区发出成员邀请。\u003c/p\u003e\n\u003cp\u003e资料显示，\u003ccode\u003eUltra Accelerator Link(UALink)\u003c/code\u003e 是一种用于加速器到加速器通信的开放行业标准化互连。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./UALink-1.webp\" alt=\"UALink\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eUALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 \u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI 加速器\u003c/a\u003e（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。\u003c/p\u003e","title":"九大巨头，正式成立UALink联盟","type":"ai"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/macbook-air/","section":"Tags","summary":"","title":"MacBook Air","type":"tags"},{"content":"前天，苹果官方网站悄然上架了全新的M4系列MacBook Pro，以及升级后的MacBook Air机型，为用户带来性能和配置的双重提升。新款MacBook Pro提供14英寸和16英寸两种尺寸选择，起售价为12999元。14英寸版本可选配M4、M4 Pro和M4 Max三种芯片，标配16GB内存；16英寸版本则提供M4 Pro和M4 Max两种芯片，标配24GB内存。\n值得注意的是，M4 Max芯片首次在MacBook Pro中亮相，成为M4系列中性能最强的PC芯片。M4 Max拥有14核中央处理器、32核图形处理器和16核神经网络引擎，支持Apple智能功能。苹果官方表示，这款芯片重新定义了专业级笔记本电脑的性能极限。\n凭借M4 Max的强大性能，用户可以轻松完成过去需要高配台式电脑才能处理的任务，例如与拥有数千亿参数的大语言模型进行交互。对于制作精细的视觉特效、3D动画和电影配乐等高强度的创意工作，M4 Max也能游刃有余。与上一代M3 Max相比，M4 Max在Redshift渲染性能上提升了64.9倍，表现极为出色。\n在配置方面，14英寸MacBook Pro采用14.2英寸Liquid视网膜XDR显示屏，提供深空黑色和银色两种配色，内置72.4瓦时锂聚合物电池。16英寸版本则配备16.2英寸Liquid视网膜XDR显示屏，内置100瓦时锂聚合物电池。两款机型均配备1200万像素摄像头，支持1080P视频拍摄，并搭载高保真六扬声器系统。\n接口方面，新款MacBook Pro搭载了雷雳5接口，数据传输速度最高可达120Gb/s，方便用户连接高速外设、驱动高分辨率显示器，或直接读取SDXC卡的数据。新品将于11月8日正式上市发售。\n此外，苹果还宣布，搭载M2和M3芯片的MacBook Air机型现已标配16GB内存，起售价分别仍为7999元和8999元，价格未发生变化。目前，苹果官网提供13英寸M2 MacBook Air、13英寸M3 MacBook Air和15英寸M3 MacBook Air三种选择，固态硬盘容量为256GB起步。\n苹果此举的目的是为了更好地支持Apple智能功能。根据分析师郭明錤的说法，Apple Intelligence采用端侧3B LLM技术，经过压缩后，需要预留约0.7-1.5GB的DRAM来运行。因此，提升内存容量有助于提高设备的整体性能和用户体验。\n截至目前，苹果新款MacBook Pro、Mac mini、iMac等设备全部以16GB内存起步，老款MacBook Air也淘汰了8GB内存版本。这标志着苹果正式结束了Mac设备的8GB内存时代，为用户带来更强大的性能和更高的工作效率。\n此次苹果对Mac系列产品的全面升级，不仅在硬件配置上进行了大幅提升，也体现了苹果对用户需求的重视和对未来技术发展的前瞻性。新款MacBook Pro和升级后的MacBook Air，将为用户带来更出色的使用体验。\n","date":"2024-11-01","externalUrl":null,"permalink":"/hardware/macbook-air-now-starts-with-16gb-ram/","section":"Hardwares","summary":"\u003cp\u003e前天，苹果官方网站悄然上架了全新的M4系列\u003ccode\u003eMacBook Pro\u003c/code\u003e，以及升级后的\u003ccode\u003eMacBook Air\u003c/code\u003e机型，为用户带来性能和配置的双重提升。新款MacBook Pro提供14英寸和16英寸两种尺寸选择，起售价为12999元。14英寸版本可选配M4、M4 Pro和M4 Max三种芯片，标配16GB内存；16英寸版本则提供M4 Pro和M4 Max两种芯片，标配24GB内存。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MacBook-Pro-Air-1.webp\" alt=\"MacBook Pro and MacBook Air\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e值得注意的是，M4 Max芯片首次在MacBook Pro中亮相，成为M4系列中性能最强的PC芯片。M4 Max拥有14核中央处理器、32核图形处理器和16核神经网络引擎，支持Apple智能功能。苹果官方表示，这款芯片重新定义了专业级笔记本电脑的性能极限。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MacBook-Pro-Air-2.webp\" alt=\"MacBook Pro and MacBook Air\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"苹果新款MacBook标配16GB","type":"hardware"},{"content":"","date":"2024-10-28","externalUrl":null,"permalink":"/tags/docker-compose/","section":"Tags","summary":"","title":"Docker-Compose","type":"tags"},{"content":"最近在使用docker的过程中，发现CPU和内存经常占满，导致其它服务都不能正常使用。下面本文就探讨一下如何使用docker-compose限制内存和cpu。本文以docker-compose.yml中version 3.x为例。\n内存和CPU限制 # yml文件添加 service.deploy内容如下：\ndeploy: resources: limits: cpus: \u0026#34;2.00\u0026#34; memory: 5G reservations: memory: 200M 注意：reservations中不支持cpus，仅支持内存。\n以ldap为例：\nversion: \u0026#39;3.7\u0026#39; services: openldap: image: 10.10.239.54/public/openldap:1.3.0 container_name: openldap environment: - N9E_NID=22 ports: - \u0026#34;389:389\u0026#34; - \u0026#34;636:636\u0026#34; deploy: resources: limits: cpus: \u0026#34;2.00\u0026#34; memory: 5G reservations: memory: 200M volumes: - ./ldap:/var/lib/ldap - ./slapd.d:/etc/ldap/slapd.d restart: always 启动容器 # 限制指令为deploy.resources.limits这部分，注意节点位置，上面这部分限制的含义是：openldap服务的CPU使用被限制在最多200%的CPU能力，内存使用被限制在最多5GB。同时，这个服务至少需要200MB的内存。\n我们启动的时候命令需要发生一些变化，否则不会生效：\n#原本的启动命令为 docker-compse up -d # 需要添加一个参数--compatibility表示以兼容模式来运行 docker-compose --compatibility up -d 这里的关键在于添加\u0026ndash;compatibility参数以兼容模式来运行，否则限制不会生效。\n验证 # 通过上述方法限制容器CPU和内存后，可以使用命令：docker stats查看容器资源使用情况.\n总结 # docker-compose.yml限制内存需要添加deploy.resources.limits节点 docker-compose命令启动的时候需要添加\u0026ndash;compatibility参数以兼容模式来运行，否则限制不会生效 以上就是Docker Compose中限制容器的CPU和内存使用的全部内容。\n","date":"2024-10-28","externalUrl":null,"permalink":"/software/limit-memory-and-cpu-using-docker-compose/","section":"Softwares","summary":"\u003cp\u003e最近在使用\u003ca href=\"https://www.kad8.com/software/linux-docker-port-mapping/\" target=\"_blank\"\u003edocker\u003c/a\u003e的过程中，发现CPU和内存经常占满，导致其它服务都不能正常使用。下面本文就探讨一下如何使用docker-compose限制内存和cpu。本文以docker-compose.yml中version 3.x为例。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e内存和CPU限制 \n    \u003cdiv id=\"%E5%86%85%E5%AD%98%E5%92%8Ccpu%E9%99%90%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%86%85%E5%AD%98%E5%92%8Ccpu%E9%99%90%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eyml文件添加 service.deploy内容如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mark\" data-lang=\"mark\"\u003edeploy:\n      resources:\n         limits:\n            cpus: \u0026#34;2.00\u0026#34;\n            memory: 5G\n         reservations:\n            memory: 200M\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e注意：reservations中不支持cpus，仅支持内存。\u003c/p\u003e","title":"使用docker-compose限制内存和cpu","type":"software"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/hbm/","section":"Tags","summary":"","title":"HBM","type":"tags"},{"content":"像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： 人工智能(AI) ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”\n三星电子已经成功地将其高带宽内存(HBM)设备与英伟达的 H100 GPU 等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。\n事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。\nSK海力士的HBM优势 # SK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。\n因此，这些存储设备被广泛用于高性能计算系统上的生成式AI设备，这并不奇怪。例如，SK海力士的HBM3芯片销售额在2023年同比增长了5倍以上。《数字时报》的一篇报道称，英伟达已经向SK海力士和美光支付了5.4亿至7.7亿美元的预付款，以确保为其GPU产品提供HBM存储芯片。\nSK海力士计划在批量生产新一代HBM3E的同时，开发下一代HBM4存储芯片。据韩国媒体报道，英伟达计划将其H200和B100 GPU分别与6个和8个HBM3E模块配对。与HBM3相比，HBM3E显著提高了速度，每秒可以处理高达1.15TB的数据。\n三星电子将HBM3E称为AI内存产品，并声称在该领域处于技术领先地位。虽然三星和美光都已经准备好了他们的HBM3E设备，并且正在英伟达等AI巨头的认证过程中，但SK海力士似乎比其内存竞争对手领先一步。以SK海力士目前正在开发的HBM4为例，预计将于2025年面市。\n特别值得注意的是，HBM4能够直接将内存堆栈到处理器上，完全消除了中间层。目前，HBM堆栈在CPU或GPU旁边集成了8、12或16个存储设备，这些存储设备通过接口连接到这些处理器。将内存直接集成到处理器上将改变芯片的设计和制造方式。\n一家AI存储公司 # 行业分析师还认为，SK海力士是以AI为中心的内存升级周期的主要受益者，因为它是一家纯粹的内存公司，与其主要竞争对手三星不同。值得注意的是，三星也在大力投资AI研发，以加强其内存产品。\nAI确实需要大量内存，拥有前两大内存供应商的韩国渴望成为AI强国也就不足为奇了。就SK海力士而言，它已经证明了自己在AI服务器设计和设备上的重要性。\n在美国拉斯维加斯举行的国际消费电子展(CES 2024)上，三星电子CEO在谈到内存在生成式AI中的关键作用时，誓言要在三年内将公司市值翻一番。这就是为什么它现在寻求成为一家全面的AI内存提供商，同时寻求通过高价值的HBM产品实现快速周转。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/","section":"Ais","summary":"\u003cp\u003e像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： \u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003e人工智能\u003c/a\u003e(AI)  ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”\u003c/p\u003e\n\u003cp\u003e三星电子已经成功地将其\u003ca href=\"https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/\" target=\"_blank\"\u003e高带宽内存(HBM)\u003c/a\u003e设备与英伟达的 H100 GPU  等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-AI-1.png\" alt=\"HBM in AI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eSK海力士的HBM优势 \n    \u003cdiv id=\"sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eSK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。\u003c/p\u003e","title":"HBM内存芯片: AI革命的无名英雄","type":"ai"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/ddr5/","section":"Tags","summary":"","title":"DDR5","type":"tags"},{"content":"在AI服务器需求剧增的情况下，HBM正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，DDR5预计将上涨15%至20%。\nHBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。\n从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。\n从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端AI应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。\n由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。\n展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/","section":"Ais","summary":"\u003cp\u003e在AI服务器需求剧增的情况下，\u003ca href=\"https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/\" target=\"_blank\"\u003eHBM\u003c/a\u003e正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，\u003ca href=\"https://www.gaitpu.com/data-center/storage/ddr4-vs-ddr5-ram-all-the-design-challenges-advantages\" target=\"_blank\"\u003eDDR5\u003c/a\u003e预计将上涨15%至20%。\u003c/p\u003e\n\u003cp\u003eHBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。\u003c/p\u003e\n\u003cp\u003e从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-DDR-1.png\" alt=\"HBM DDR\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI\u003c/a\u003e应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。\u003c/p\u003e\n\u003cp\u003e由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-DDR-2.png\" alt=\"HBM DDR\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。\u003c/p\u003e","title":"爆炸性的HBM需求预计推动DDR5价格上涨20%","type":"ai"},{"content":"10月24日消息，Google宣布推出名为SynthID Text的开源水印工具，旨在帮助开发人员识别人工智能生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。\nSynthID Text的工作能力 # Google DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。\n这一过程不会对文本的质量和生成速度产生影响，在一次用户反馈实验中，用户对Google的Gemini大型语言模型生成的2000万条文本的反馈显示，带有水印的文本与未带水印的文本在质量上没有明显差异。\n但是SynthID Text在某些方面仍存在局限性，对于较短的文本、事实性回答以及从其他语言翻译过来的内容，该工具的检测可靠性会下降。\nGoogle承认了这些局限，但其更强调该工具的整体优势。因为SynthID Text的开源特性使它可以被广泛地应用和改进，从而提高整个行业的标准。开发者和研究人员现在可以利用这一工具来确保人工智能文本生成系统在高效的基础上更加的透明和负责。Google DeepMind的副总裁表示，他们希望其他人工智能模型开发者能够应用这一技术，并将其集成到自己的系统中。\n开发水印工具的必要性 # 随着人工智能生成内容需求的增长，对人工智能生成内容检测方法的需求也在增加。中国等国家已经开始强制要求对人工智能生成的内容进行水印标记，美国加利福尼亚州也在考虑类似的法规。\n据预测，到2026年人工智能生成的内容可能会占据在线文本的90%，这将为打击虚假信息和欺诈带来新的挑战。Google这一工具的发布响应了全球范围内对于人工智能生成内容检测方法需求增长的迫切性。\n随着人工智能生成内容的增多，确保其应用的透明度和责任性变得尤为重要。Google的这一行动可能是推动人工智能水印技术成为行业标准的重要一步，为防止互联网充斥着人工智能生成的垃圾信息提供了一种可能的解决方案。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/","section":"Ais","summary":"\u003cp\u003e10月24日消息，\u003ccode\u003eGoogle\u003c/code\u003e宣布推出名为\u003ccode\u003eSynthID Text\u003c/code\u003e的开源水印工具，旨在帮助开发人员识别\u003ca href=\"https://www.kad8.com/ai/\" target=\"_blank\"\u003e人工智能\u003c/a\u003e生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Google-Synthid-text.webp\" alt=\"Google SynthID Text\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eSynthID Text的工作能力 \n    \u003cdiv id=\"synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGoogle DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。\u003c/p\u003e","title":"Google发布开源AI文本水印工具","type":"ai"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/synthid/","section":"Tags","summary":"","title":"Synthid","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/watermarking/","section":"Tags","summary":"","title":"Watermarking","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/bios/","section":"Tags","summary":"","title":"BIOS","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/bmc/","section":"Tags","summary":"","title":"BMC","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/peci/","section":"Tags","summary":"","title":"PECI","type":"tags"},{"content":"PECI是用于监测CPU及芯片组温度的一线总线(one-wire bus)，全称是Platform Environment Control Interface。它最主要的应用是监测CPU温度，最新版本的PECI接口还包括一些其他的功能。\nIntel Processor的温控机制 # 在CPU中，通常每个CPU核心都有一个数字温度传感器。在PC平台下，处理器可以通过MSR(Mode specific registers)获得处理器自身的温度、调节风扇转速，从而实现温度控制。在服务器平台下，温度控制通常是由BMC来做的，业务CPU本身没有办法控制服务器里的风扇转速。BMC直接或间接通过PECI总线获取到CPU的核心温度，再根据所读到的温度值来调整风扇的转速。\nMSR方式读取CPU温度读取到的是即时温度，PECI方式读取到的是256ms时间窗内的平均温度。MSR方式是需要CPU处理C0状态才能读取。PECI方式在C0~C6均可以使用。\n图表1 PECI接中的连接方式 Intel Pentium M 开始在处理器中引入DTS（数字温度传感器）。温度传感器通常是每个CPU核心一个。\n图表2 Intel温控组件 TM1 # 为了保护CPU不会在过热时被烧坏，从Pentium4开始，处理器中又加入了一个温度监示器Thermal Monitor 1，简称TM1。TM1会监示数字温度传感器的读数，当读数高于阈值Tjmax时，TM1会调节处理器时钟的占空比，以降低功耗，降低温度。这里所谓的调节时钟占空比与传统意义上的时钟占空比不同，这里调节的是时钟信号的开闭时间比例，比如说，它会在某一段时间内，37.5%的时间打开CPU时钟，让CPU工作，另62.5%的时间关闭CPU时钟，让CPU停止工作以降低功耗和温度。\nFigure 1 TM1调整CPU时钟占空比 TM2 # TM2是Pentium M引入的，它提供了另一种降低CPU温度的办法。在CPU某个核心的温度超过Tjmax时，它会尝试降低时钟频率和供电电压来降低功耗和温度。TM1和TM2是两个单独的机制，或以分别启用和禁用。Intel推荐两个机制同时使用。它们的启用和禁用是通过BIOS设置IA32_MISC_ENABLE这个模式寄存器的第3、13位来实现的。BIOS打开这两个机制后，OS和用户程序不可关闭。\n温度阈值 # Tjmax是我们所知的第一个阈值，当CPU上任意一个核心的温度达到这个阈值时，CPU会产生一个PROCHOT#信号（processor hot）。该信号可触发TM1和TM2。处理器时会通过调节时钟占空比、降低时钟频率和供电电压的方式来降低功耗和温度。产生PROCHOT#信号的同时，温度监示器还会产生一个中断给CPU，其中断向量号通过LAPIC和LVT来设置。模式寄存器IA32_THERM_INTERRUPT有两个位用于高温中断使能（温度超过Tjmax时产生中断）和低温中断使能（温度回到低于Tjmax的范围时产生中断）。\nPROCHOT#通过CPU的一个引脚拉出，并且可以连接在外设上，由外设来发生这个信号。比如说一个系统中有另一个设备的温度超过阈值，它可以拉低使能这个信号，从而使CPU也一起降温，从而降低机箱内的温度，制造一个更好的散热环境。\n如果TM1和TM2启动后温度没能降低下来，并且继续升高到可能造成CPU物理损坏的温度时，核心会触发THERMTRIP#信号，并且关闭CPU电源。\nCPU硬件实现的温度控制机制是用于CPU自我保存的温控机制，当这些机制不足以降温时，CPU会断电，从而造成系统突然掉电，造成数据损失。因而一般要求BMC在要以一定的周期读取CPU核心温度，根据温度调整风扇转速，并且当温度超过Tjmax-10时，让风扇全速转动。\n相关MSR # IA32_THERM_INTERRUPT # IA32_THERM_INTERRUPT寄存的地址为0x19B。BIOS通过IA32_THERM_INTERRUPT模式寄存器使能温度相关的中断，其各字段定义如下：\n表格 1 IA32_THERM_INTERRUPT 0x19B\n位 描述 0 High temperature interrupt enable 1 Low temperature interrupt enable 2 PROCHOT# interrupt enable 3 FORCEPR# interrupt enable 4 Critical Temperature interrupt enable 7:5 reserved 14:8 Threshold 1 value 15 Threshold 1 int enable 22:16 Threshold 2 value 23 Threshold 2 int enable 63:24 reserved 在一个实际系统读到的该寄存器的值为：\nsudo modprobe msr sudo rdmsr –p 0 0x19B 3 IA32_TEMPERATURE_TARGET # IA32_TEMPERATURE_TARGET模式寄存器的地址为0x1A2。该模式寄存器是只读的。\n表格 2 IA32_TEMPERATURE_TARGET模式寄存器\n位 描述 23:16 温度目标，单为是摄氏度，当达到这个温度时触发TM1和TM2，产生PROCHOT#信号。 在一个实际系统读到的该寄存器的值为：\nsudo modprobe msr sudo rdmsr –p 0 0x1A2 0x5B08 0x5B=91摄氏度\n嵌入汇编方式读取MSR：\n__asm____volatile__(“movl $0x1A2, %%ecx\\n\\trdmsr\\n\\t”) PECI接口 # BMC获取CPU核心温度有两种途径：\n通过PECI总线直接从CPU上获取温度数据 通过IPMI协议从南桥上的ME上获取CPU核心温度 在第二种情况下，ME需要通过PECI接口从CPU上获取温度。由于PECI的一线总线是intel的私有总线协议，很多BMC厂商并没有办法集成支持PECI接口协议的硬件，因而途径2是获取CPU核心温度的主流途径。\nPECI规范 # PECI是一个私有的协议，不得到Intel授权无从得知协议的细节。PECI规范到现在有三个主要版本：1.1、2.0和3.0。PECI 1.1支持最简单的温度监示，PECI2.0则支持更多的如读取MSR等特性，PECI 3.0进一步支持PCIe总线配置空间的读取。\n表格 3 PECI 1.1和2.0比较\n版本 1.1 2.0 特性 温度监示 温度监示 Ping() Ping() GetTemp() GetTemp() GetDib() GetDib() 访问CPU内存 BIST Memory throttling相关 下图是PECI 3.0支持的命令列表：\n表格 4 PECI 3.0支持的命令列表\n现代服务器系统中，BMC通常不直接使用PECI接口，而是通过南桥上的ManagementEngine来间接使用PECI接口。Management Engine是南桥上的一个嵌入式微控制器，它可以通过南桥上的PECI主控器访问CPU上的PECI从设备。同时，ME还实现了一些IPMI命令，可以让BMC通过SMLink间接使用这个PECI主控制器。这样的系统架构如下图所示：\n图表 5 南桥做PECI Proxy 所有的IPMI命令可以参考《IntelIntelligent Power Node Manager 2.0 External Interface Specification》的2.9节： IPMI OEMPECI Proxy Commands。\n","date":"2024-10-27","externalUrl":null,"permalink":"/software/introduction-to-peci-interface-in-server/","section":"Softwares","summary":"\u003cp\u003e\u003ccode\u003ePECI\u003c/code\u003e是用于监测\u003ccode\u003eCPU\u003c/code\u003e及\u003ccode\u003e芯片组\u003c/code\u003e温度的一线总线(one-wire bus)，全称是\u003ccode\u003ePlatform Environment Control Interface\u003c/code\u003e。它最主要的应用是监测CPU温度，最新版本的PECI接口还包括一些其他的功能。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eIntel Processor的温控机制 \n    \u003cdiv id=\"intel-processor%E7%9A%84%E6%B8%A9%E6%8E%A7%E6%9C%BA%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#intel-processor%E7%9A%84%E6%B8%A9%E6%8E%A7%E6%9C%BA%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在CPU中，通常每个CPU核心都有一个数字温度传感器。在PC平台下，处理器可以通过\u003ccode\u003eMSR\u003c/code\u003e(Mode specific registers)获得处理器自身的温度、调节风扇转速，从而实现温度控制。在\u003ccode\u003e服务器\u003c/code\u003e平台下，温度控制通常是由\u003ccode\u003eBMC\u003c/code\u003e来做的，业务CPU本身没有办法控制服务器里的风扇转速。\u003ca href=\"https://www.kad8.com/software/intel-promot-openbmc-technology-innovation/\" target=\"_blank\"\u003eBMC\u003c/a\u003e直接或间接通过PECI总线获取到CPU的核心温度，再根据所读到的温度值来调整风扇的转速。\u003c/p\u003e","title":"服务器下的PECI接口简介","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"Infrastructure","type":"tags"},{"content":" AI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。\n概述 # AI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。\n然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。\n云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。\n要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。\nAI对基础设施的新要求 # AI基础设施对于传统IT团队而言是一片全新的疆域。团队可能在GPU等加速硬件、异构系统架构方面经验不足。尽管团队在数据存储和管理上有深厚积累，但对AI的工作原理和应用场景却可能知之甚少。AI环境通常处理来自多个异构数据源的信息，这些数据需要经过数据工程师的精心整理，才能用于模型训练。这些数据可能来自关系型数据库、文件系统、甚至外部数据源，且格式不统一、存储位置分散。数据的规模庞大，进一步增加了处理的复杂性。\n图1. AI典型数据流 数据科学团队负责数据的质量和可用性，但IT部门需要提供坚实的技术基础。数据科学团队要求数据能够即时获取，这对存储系统的性能提出了极高的要求。IT团队在选择存储系统时，需要充分考虑数据访问的I/O特性，并优化与GPU或加速器的互联。此外，数据复制、保护和数据库访问等数据服务也是IT基础设施需要提供的关键功能。\n目前，AI开发主要集中在公有云平台上。企业通常会选择已有的基础模型，并利用私有数据进行微调，以创建定制化的AI模型。生成式AI中的检索增强生成（RAG）就是一个典型的例子。RAG通过引入新的、定制化的数据，提升了大型语言模型的准确性、时效性和相关性。\n由于公有云在AI开发中占据主导地位，数据科学团队对云端存储系统的性能、可用性和保护机制的重视程度往往不够。因此，IT部门需要深入了解业务需求，评估各种存储解决方案，并向数据科学团队清晰地传达本地部署的优势。在私有环境中，IT部门需要考虑数据的存储位置、访问方式、以及数据保护和安全合规性等方面的问题。\n随着AI应用的不断深入，企业开始将AI工作负载从公有云迁移到本地数据中心，或者采用混合云部署模式。一方面，公有云的高昂成本在规模化部署时会成为企业的负担；另一方面，数据安全、隐私保护以及对资源的掌控需求也在推动企业向本地化迁移。此外，新型的基础设施和存储即服务（SaaS）解决方案的出现，\nAI本地化存储的特性 # 用于训练AI模型的数据来源广泛，包括结构化和非结构化数据。这些数据通常存储在数据湖或数据湖仓中，以满足AI/ML项目对大规模、高性能存储的需求。数据工程师创建的训练数据集是AI模型训练的基石。数据科学团队对存储系统的性能要求极高，包括大容量、高带宽和低延迟。\n图2. AI/ML和BI数据平台 随着AI的发展，对存储系统的需求也日益多样化。全闪存存储凭借其性能一致性，成为AI存储的首选。AI环境在不同发展阶段对存储系统的需求也不同：\n初始/成熟阶段：需要兼具高性能文件存储和对象存储。 生产级：需要大规模容量的文件和对象存储，同时保持高性能。 IT基础设施团队和AI平台架构师对存储系统都有各自的关注点。对于存储系统，除了传统的性能、可靠性、安全性和可扩展性之外，还应考虑以下特性：\n性能：AI工作负载对性能的可预测性和一致性要求极高。全闪存存储能提供低延迟和高带宽，是理想选择。 可靠性与数据保护：存储系统应具备容错能力，防止数据丢失。 安全性：采用最佳实践保护数据安全。 K8s原生支持：考虑到Kubernetes在AI/ML领域的广泛应用，存储系统应与K8s无缝集成。 加速MLOps：数据科学家应能自助访问存储、向量数据库和ML服务，加速模型开发。 可扩展性：存储系统应能线性扩展，以满足不断增长的数据需求。 简单性：易于配置和管理，减少运维负担。 成本效益：存储成本应与容量成正比，且不影响性能。 能效：存储系统应节能，以降低总体拥有成本。 总结 # AI的迅猛发展给传统的IT基础设施带来了前所未有的挑战，尤其是数据存储与管理方面。这些挑战不仅新颖，而且与以往的IT问题存在显著差异。例如，AI平台架构师可能对IT环境中的操作流程和关键数据存储的特性并不熟悉，他们的经验往往集中在公共云环境。鉴于此，组织在部署和发展AI环境时，必须做出关键的IT决策。\n其中，选择合适的存储类型是至关重要的。一个理想的数据存储平台应具备以下特点：\n加速AI落地：从早期部署到成熟的AI生产环境，该平台能够显著缩短AI项目的交付周期。 全方位性能：在性能、效率、可靠性、数据保护、扩展性和易用性等方面提供均衡且一致的解决方案，满足不同使用场景和成本要求。 高级功能：支持快速部署、简化操作、无需复杂培训、最大化效率，并提供多维性能和多协议访问等高级特性。 容器化友好：与主流容器编排框架（如Kubernetes）无缝集成，简化有状态应用程序的管理。 显著缩短模型开发周期：能够帮助企业快速搭建一个能够训练和部署私有数据的AI环境，从而加速AI项目的落地。 高置信度：系统的稳定性和可靠性能够最大程度地减少存储基础设施部署的时间，降低项目风险。 ","date":"2024-10-26","externalUrl":null,"permalink":"/ai/setting-direction-for-enterprise-ai-infrastructure/","section":"Ais","summary":"\u003cblockquote\u003e\n\u003cp\u003eAI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e概述 \n    \u003cdiv id=\"%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eAI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。\u003c/p\u003e\n\u003cp\u003e然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。\u003c/p\u003e\n\u003cp\u003e云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。\u003c/p\u003e\n\u003cp\u003e要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。\u003c/p\u003e","title":"如何构建高效可靠的AI基础设施","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/sc8480xpsc8480xp/","section":"Tags","summary":"","title":"SC8480XPSC8480XP","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/snapdragon-x2/","section":"Tags","summary":"","title":"Snapdragon X2","type":"tags"},{"content":"高通公司近日开始测试其用于 PC 的下一代基于 ARM 架构的 Snapdragon X2 CPU，内部型号为 SC8480XP，代号为“Project Glymur”。据悉，这款芯片已在今年7月和8月进行了测试。\n几个月前，高通推出了 Snapdragon X 系列，宣称具备强大的 CPU 和 GPU 组合，可以为用户带来可靠的 AI PC 体验，因此受到了业内广泛关注。但是尽管宣传力度很大，初期的评测和性能结果并不完全令人满意。单核性能、IPC 数据以及效率和电池寿命被视为亮点，但在多核和图形性能方面表现平平。本来很多人憧憬的ARM版本windows挑战苹果电脑的格局并不存在。\n当前一代的 Snapdragon X SoC 内部型号为“SC8380XP”，代号为“Hamoa”。如前所述，正在测试的下一代 SoC SC8480XP，代号为“Glymur”或“Project Glymur”。测试使用的开发板配备了各种 NAND 和内存组件，类似于早期评估平台（RVP 或 EVP），用于在最终规格确定前测试样品。这意味着高通仍处于新 SoC 测试的早期阶段。\n此前的戴尔 XPS 泄露信息显示，高通正在开发至少两个基于 Oryon CPU 架构的下一代变体，计划用于基于 Snapdragon X 的 AI PC。这包括计划于2025年中期推出的 Snapdragon X V2，以及预计于2027年第四季度推出的后续产品 Snapdragon V3。尽管这些时间表是初步的，但由于信息来源于高通的重要合作伙伴戴尔，可以推测这些计划具有较高的可信度。\n与此同时，科技媒体还报道称，高通正在准备一款新的 Snapdragon X Plus 系列入门级变体，标签为“X1P-24-100”。预计这款芯片将保留8核设计，但在时钟频率或 GPU 性能方面可能有所降低，以满足入门级市场的需求。\n在 x86 厂商如 AMD 和英特尔推出 Ryzen AI 300“Strix”和 Core Ultra 200V“Lunar Lake”等强大产品的背景下，这些产品具备改进的 NPU、强大的 CPU 核心和卓越的集成 GPU，提供了市场上领先的性能。高通显然意识到竞争的激烈，正在加紧完善其 Snapdragon X 系列产品线。\n高通想把自己在手机SoC的领先经验带入到PC领域，目前看并不容易，一方面x86领域的对手实力很强，迭代迅速，另一方面苹果阵营的软硬件生态也固若金汤。目前看初代的产品连搅局的能力都不具备，前期大量的宣传如同石头丢进河里，泛起一阵涟漪后就消失不见。当然，我们还是期待高通能够积极推进下一代 Snapdragon X2 CPU 的开发和测试，能够给市场带来更多样的格局。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/qualcomm-begins-testing-next-generation-snapdragon-x2-cpu/","section":"Hardwares","summary":"\u003cp\u003e高通公司近日开始测试其用于 PC 的下一代基于 ARM 架构的 Snapdragon X2 CPU，内部型号为 SC8480XP，代号为“Project Glymur”。据悉，这款芯片已在今年7月和8月进行了测试。\u003c/p\u003e\n\u003cp\u003e几个月前，高通推出了 \u003ccode\u003eSnapdragon X\u003c/code\u003e 系列，宣称具备强大的 \u003ccode\u003eCPU\u003c/code\u003e 和 \u003ccode\u003eGPU\u003c/code\u003e 组合，可以为用户带来可靠的 \u003ccode\u003eAI PC\u003c/code\u003e 体验，因此受到了业内广泛关注。但是尽管宣传力度很大，初期的评测和性能结果并不完全令人满意。单核性能、IPC 数据以及效率和电池寿命被视为亮点，但在多核和图形性能方面表现平平。本来很多人憧憬的ARM版本windows挑战苹果电脑的格局并不存在。\u003c/p\u003e","title":"高通着手测试下一代Snapdragon X2 CPU","type":"hardware"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/edk2/","section":"Tags","summary":"","title":"EDK2","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/ide/","section":"Tags","summary":"","title":"IDE","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/sata/","section":"Tags","summary":"","title":"SATA","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/uefi/","section":"Tags","summary":"","title":"UEFI","type":"tags"},{"content":"笔者研究了一下磁盘相关的 Protocol，本文描述了uEFI下如何获取磁盘信息。\n简介 # 与本次探究相关的主要有三个 Protocol：EFI_BLOCK_IO_PROTOCOL、EFI_DISK_IO_PROTOCOL 以及 EFI_DISK_INFO_PROTOCOL 。前两个是在 UEFI SPEC 定义的，最后一个则是在 PI SPEC。\nBlockIo 与 DiskIo # BlockIo 与 DiskIo 两个Protocol 均是用于访问存储设备的协议，只是它们可以进行操作的级别不同。前者能以 块 的级别对存储设备进行操作，而后者则提供更加底层的能力，它可以以 字节 为单位对设备进行访问。\nDiskInfo # 这两个Protocol 的主要目的是提供一种标准化的方式来获取磁盘设备的信息。这些信息可能包括磁盘的类型、制造商、序列号、固件版本等。\n实例 # 描述 # 写一个程序，枚举出所有物理磁盘，并打印磁盘的型号，SN 以及容量大小。\n思路 # 使用 BlockIo 获取所有块设备的实例，然后再使用 DiskIo 进行筛选，得到所有的物理磁盘。接着将物理磁盘的实例传给 DiskInfo，通过 Identify 函数可获取 Identify Data，再根据磁盘的接口类型对数据进行解析，便能打印型号等信息。\n代码 # /** * @file DiskInfo.c * * @version 0.2 * @date 2024-09-09 * * @copyright Copyright (c) 2015 - 2024 * */ #include \u0026lt;Uefi.h\u0026gt; #include \u0026lt;Library/PcdLib.h\u0026gt; #include \u0026lt;Library/UefiLib.h\u0026gt; #include \u0026lt;Library/UefiApplicationEntryPoint.h\u0026gt; #include \u0026lt;Library/UefiBootServicesTableLib.h\u0026gt; #include \u0026lt;Library/MemoryAllocationLib.h\u0026gt; #include \u0026lt;Protocol/BlockIo.h\u0026gt; #include \u0026lt;Protocol/DiskIo.h\u0026gt; #include \u0026lt;Protocol/DiskInfo.h\u0026gt; #include \u0026lt;Library/BaseMemoryLib.h\u0026gt; #include \u0026lt;Library/PrintLib.h\u0026gt; #include \u0026lt;Protocol/IdeControllerInit.h\u0026gt; VOID HexDump (UINT8 *Buffer, UINT8 RowNum) { UINT8 Cols; UINT8 Rows; for (Rows = 0; Rows \u0026lt; RowNum; Rows ++) { for (Cols = 0; Cols \u0026lt; 16; Cols ++) { Print (L\u0026#34;%2X \u0026#34;, Buffer[Cols+Rows*16]); } Print (L\u0026#34; \u0026#34;); for (Cols = 0; Cols \u0026lt; 16; Cols ++) { if ((Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;9\u0026#39;) || (Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;z\u0026#39;) || (Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;Z\u0026#39;)) Print (L\u0026#34;%c\u0026#34;, Buffer[Cols+Rows*16]); else Print (L\u0026#34;.\u0026#34;); } Print (L\u0026#34;\\n\\r\u0026#34;); } Print (L\u0026#34;\\n\\r\u0026#34;); } /** Eliminate the extra spaces in the Str to one space. @param Str Input string info. **/ VOID BmEliminateExtraSpaces ( IN CHAR16 *Str ) { UINTN Index; UINTN ActualIndex; for (Index = 0, ActualIndex = 0; Str[Index] != L\u0026#39;\\0\u0026#39;; Index++) { if ((Str[Index] != L\u0026#39; \u0026#39;) || ((ActualIndex \u0026gt; 0) \u0026amp;\u0026amp; (Str[ActualIndex - 1] != L\u0026#39; \u0026#39;))) { Str[ActualIndex++] = Str[Index]; } } Str[ActualIndex] = L\u0026#39;\\0\u0026#39;; } EFI_STATUS EFIAPI GetDiskIdentifyData (EFI_HANDLE Handle) { EFI_STATUS Status; EFI_DISK_INFO_PROTOCOL *DiskInfo; EFI_ATAPI_IDENTIFY_DATA IdentifyData; UINT32 IdentifyDataSize; CHAR16 *ModelName; CHAR16 *SerialNo; CONST UINTN ModelNameLength = 40; CONST UINTN SerialNoLength = 20; UINTN Index; Status = gBS-\u0026gt;HandleProtocol(Handle, \u0026amp;gEfiDiskInfoProtocolGuid, (VOID**)\u0026amp;DiskInfo); if (EFI_ERROR(Status)) { return Status; } // // AHCI or IDE // if (CompareGuid (\u0026amp;DiskInfo-\u0026gt;Interface, \u0026amp;gEfiDiskInfoAhciInterfaceGuid) || CompareGuid (\u0026amp;DiskInfo-\u0026gt;Interface, \u0026amp;gEfiDiskInfoIdeInterfaceGuid)) { IdentifyDataSize = sizeof (EFI_ATAPI_IDENTIFY_DATA); Status = DiskInfo-\u0026gt;Identify(DiskInfo, \u0026amp;IdentifyData, \u0026amp;IdentifyDataSize); if (!EFI_ERROR (Status)) { ModelName = AllocatePool(sizeof(CHAR16) * ModelNameLength); SerialNo = AllocatePool(sizeof(CHAR16) * SerialNoLength); // According to the ATA specification, the model name and serial number fields // in the identify data are stored as an array of 16-bit words. // Each word is stored in little-endian format, meaning the least significant byte comes first. for (Index = 0; Index + 1 \u0026lt; ModelNameLength; Index += 2) { ModelName[Index] = (CHAR16) IdentifyData.ModelName[Index + 1]; ModelName[Index + 1] = (CHAR16) IdentifyData.ModelName[Index]; } for (Index = 0; Index + 1 \u0026lt; SerialNoLength; Index += 2) { SerialNo[Index] = (CHAR16) IdentifyData.SerialNo[Index + 1]; SerialNo[Index + 1] = (CHAR16) IdentifyData.SerialNo[Index]; } BmEliminateExtraSpaces(ModelName); BmEliminateExtraSpaces(SerialNo); HexDump((UINT8 *)\u0026amp;IdentifyData, 16); Print (L\u0026#34;Model Name: %s\\n\\r\u0026#34;, ModelName); Print (L\u0026#34;Serial No : %s\\n\\r\u0026#34;, SerialNo); Print (L\u0026#34;Disk type: %g\\n\\r\u0026#34;, DiskInfo-\u0026gt;Interface); } else { return Status; } } return EFI_SUCCESS; } /** The user Entry Point for Application. The user code starts with this function as the real entry point for the application. @param[in] ImageHandle The firmware allocated handle for the EFI image. @param[in] SystemTable A pointer to the EFI System Table. @retval EFI_SUCCESS The entry point is executed successfully. @retval other Some error occurs when executing this entry point. **/ EFI_STATUS EFIAPI UefiMain ( IN EFI_HANDLE ImageHandle, IN EFI_SYSTEM_TABLE *SystemTable ) { EFI_STATUS Status; UINTN HandleCount = 0; EFI_HANDLE *HandleBuffer = NULL; UINTN Index; EFI_BLOCK_IO_PROTOCOL *BlockIo; EFI_DISK_IO_PROTOCOL *DiskIo; Status = gBS-\u0026gt;LocateHandleBuffer( ByProtocol, \u0026amp;gEfiBlockIoProtocolGuid, NULL, \u0026amp;HandleCount, \u0026amp;HandleBuffer ); if (EFI_ERROR(Status)) { Print(L\u0026#34;Failed to locate block I/O handles: %r\\n\u0026#34;, Status); return Status; } for (Index = 0; Index \u0026lt; HandleCount; Index++) { Status = gBS-\u0026gt;HandleProtocol( HandleBuffer[Index], \u0026amp;gEfiBlockIoProtocolGuid, (VOID**)\u0026amp;BlockIo ); if (EFI_ERROR(Status) || BlockIo == NULL || BlockIo-\u0026gt;Media == NULL) { continue; } Status = gBS-\u0026gt;HandleProtocol( HandleBuffer[Index], \u0026amp;gEfiDiskIoProtocolGuid, (VOID**)\u0026amp;DiskIo ); if (!EFI_ERROR(Status) \u0026amp;\u0026amp; DiskIo != NULL \u0026amp;\u0026amp; !BlockIo-\u0026gt;Media-\u0026gt;RemovableMedia) { if (BlockIo-\u0026gt;Media-\u0026gt;LogicalPartition == FALSE \u0026amp;\u0026amp; BlockIo-\u0026gt;Media-\u0026gt;BlockSize \u0026gt; 0 \u0026amp;\u0026amp; BlockIo-\u0026gt;Media-\u0026gt;LastBlock \u0026gt; 0) { GetDiskIdentifyData(HandleBuffer[Index]); Print (L\u0026#34;Size : %d MB\\n\\r\u0026#34;, (BlockIo-\u0026gt;Media-\u0026gt;LastBlock + 1) * BlockIo-\u0026gt;Media-\u0026gt;BlockSize / (1024 * 1024)); Print(L\u0026#34;\\n\\r\u0026#34;); } } } if (HandleBuffer != NULL) { gBS-\u0026gt;FreePool(HandleBuffer); } return EFI_SUCCESS; } 上面代码参考了 MdeModulePkg\\Library\\UefiBootManagerLib\\BmBootDescription.c ，其中 BmGetDescriptionFromDiskInfo 函数的实现，需要注意的是，EDK2 默认的代码中只对 IDE / AHCI 两种有解析的定义，对于 NVME、SD 之类的还没有，所以只写了这一部分。\n代码中有个解析算法也值得说一下：\n// According to the ATA specification, the model name and serial number fields // in the identify data are stored as an array of 16-bit words. // Each word is stored in little-endian format, meaning the least significant byte comes first. for (Index = 0; Index + 1 \u0026lt; ModelNameLength; Index += 2) { ModelName[Index] = (CHAR16) IdentifyData.ModelName[Index + 1]; ModelName[Index + 1] = (CHAR16) IdentifyData.ModelName[Index]; } for (Index = 0; Index + 1 \u0026lt; SerialNoLength; Index += 2) { SerialNo[Index] = (CHAR16) IdentifyData.SerialNo[Index + 1]; SerialNo[Index + 1] = (CHAR16) IdentifyData.SerialNo[Index]; } 在ATA规范中，型号名称和序列号等字段存储为16位的数组。每个16位字以小端格式存储，这意味着最低有效字节（LSB）先存储，然后是最高有效字节（MSB）。\n","date":"2024-10-26","externalUrl":null,"permalink":"/software/how-to-get-disk-information-for-uefi/","section":"Softwares","summary":"\u003cp\u003e笔者研究了一下磁盘相关的 Protocol，本文描述了uEFI下如何获取磁盘信息。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e简介 \n    \u003cdiv id=\"%E7%AE%80%E4%BB%8B\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%80%E4%BB%8B\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e与本次探究相关的主要有三个 Protocol：\u003ccode\u003eEFI_BLOCK_IO_PROTOCOL\u003c/code\u003e、\u003ccode\u003eEFI_DISK_IO_PROTOCOL\u003c/code\u003e 以及 \u003ccode\u003eEFI_DISK_INFO_PROTOCOL\u003c/code\u003e 。前两个是在 UEFI SPEC 定义的，最后一个则是在 PI SPEC。\u003c/p\u003e","title":"UEFI 获取磁盘信息","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/csv/","section":"Tags","summary":"","title":"CSV","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"今天咱们聊聊如何用Python高效地处理CSV文件。无论你是数据分析新手还是资深开发者，这些技巧都能让你的工作更加得心应手。\n使用csv模块读取CSV文件 # Python自带的csv模块是处理CSV文件的利器。先来看看基本用法：\nimport csv with open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.reader(file) for row in reader: print(row) 这段代码会逐行读取data.csv中的数据并打印出来。\n读取带标题的CSV文件 # 如果CSV文件有标题行，可以使用DictReader类，这样每一行都会被转换成字典：\nwith open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.DictReader(file) for row in reader: print(row[\u0026#39;Name\u0026#39;]) 写入CSV文件 # csv.writer可以帮助你轻松写入数据：\nwith open(\u0026#39;output.csv\u0026#39;, mode=\u0026#39;w\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: writer = csv.writer(file) writer.writerow([\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;]) writer.writerow([\u0026#39;Alice\u0026#39;, 30]) 使用pandas库读写CSV # pandas是数据科学领域的大佬，用它读写CSV超级简单：\nimport pandas as pd df = pd.read_csv(\u0026#39;data.csv\u0026#39;) df.to_csv(\u0026#39;output.csv\u0026#39;, index=False) 处理大文件 # 对于大文件，逐行处理是个好办法，避免内存溢出：\nchunksize = 10 ** 6 for chunk in pd.read_csv(\u0026#39;large_data.csv\u0026#39;, chunksize=chunksize): # 处理每一块数据 CSV编码问题 # 处理非英文字符时，确保正确设置文件编码：\nwith open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: # ... 快速访问特定列 # pandas可以快速获取CSV中的特定列：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, usecols=[\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;]) 跳过CSV文件的前几行 # 有时候我们需要跳过CSV文件的前几行：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, skiprows=range(1, 10)) 修改CSV文件的分隔符 # 不是所有CSV文件都用逗号分隔，有时你需要自定义分隔符：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, sep=\u0026#39;;\u0026#39;) 处理缺失值 # pandas可以帮你优雅地处理缺失值：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;).fillna(0) 数据类型转换 # 确保数据以正确的类型加载：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, dtype={\u0026#39;Age\u0026#39;: int}) 选择性读取行 # 你可以根据条件筛选CSV中的行：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;) filtered_df = df[df[\u0026#39;Age\u0026#39;] \u0026gt; 25] 利用itertools处理CSV # itertools模块提供了高效的迭代工具：\nfrom itertools import islice with open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.reader(file) header = next(reader) # 读取标题行 for row in islice(reader, 10): # 只读取接下来的10行 print(row) 使用多线程或进程加速处理 # 处理大量数据时，单线程可能效率低下。利用多线程或多进程可以显著提升处理速度，尤其是在读取和写入大型CSV文件时。\nimport concurrent.futures import pandas as pd def process_chunk(chunk): # 对每块数据执行处理逻辑 return chunk.describe() # 读取CSV文件，分割成多个小块 chunks = pd.read_csv(\u0026#39;large_data.csv\u0026#39;, chunksize=1000) # 使用多线程处理每一块数据 with concurrent.futures.ThreadPoolExecutor() as executor: results = list(executor.map(process_chunk, chunks)) # 合并处理结果 final_result = pd.concat(results) 高级技巧总结与注意事项 # 性能优化：对于大型数据集，优先考虑数据预处理和数据类型管理，避免不必要的内存负担。 异常处理：在读取或写入CSV文件时，加入异常处理机制，确保程序的健壮性和可靠性。 数据验证：在数据处理过程中，进行必要的数据验证，如检查数据完整性、格式一致性等，避免错误数据导致的后续分析问题。 代码复用：将常用的数据处理逻辑封装成函数或类，提高代码的复用性和维护性。 实战案例深入分析 # 让我们回到销售数据的实战案例，进一步分析如何识别销售趋势和预测未来销量。\nimport pandas as pd from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split # 读取CSV文件 sales_df = pd.read_csv(\u0026#39;sales.csv\u0026#39;) # 数据预处理 sales_df[\u0026#39;Date\u0026#39;] = pd.to_datetime(sales_df[\u0026#39;Date\u0026#39;]) sales_df[\u0026#39;Month\u0026#39;] = sales_df[\u0026#39;Date\u0026#39;].dt.month # 构建模型输入和输出 X = sales_df[[\u0026#39;Month\u0026#39;]] y = sales_df[\u0026#39;Quantity\u0026#39;] # 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 训练线性回归模型 model = LinearRegression() model.fit(X_train, y_train) # 预测未来销量 future_months = pd.DataFrame({\u0026#39;Month\u0026#39;: range(1, 13)}) predictions = model.predict(future_months) # 输出预测结果 future_months[\u0026#39;Predicted Sales\u0026#39;] = predictions print(future_months) 通过构建线性回归模型，我们可以预测未来的销售趋势，为业务决策提供有力支持。\n结语 # 掌握了这些技巧，你已经能够在Python中熟练地处理CSV文件了。无论是简单的数据读写，还是复杂的分析任务，这些技能都将助你一臂之力。\n","date":"2024-10-26","externalUrl":null,"permalink":"/software/14-efficient-techniques-to-process-csv-files-by-python/","section":"Softwares","summary":"\u003cp\u003e今天咱们聊聊如何用Python高效地处理CSV文件。无论你是数据分析新手还是资深开发者，这些技巧都能让你的工作更加得心应手。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e使用csv模块读取CSV文件 \n    \u003cdiv id=\"%E4%BD%BF%E7%94%A8csv%E6%A8%A1%E5%9D%97%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BD%BF%E7%94%A8csv%E6%A8%A1%E5%9D%97%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003ePython自带的csv模块是处理CSV文件的利器。先来看看基本用法：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecsv\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;data.csv\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;r\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enewline\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eencoding\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003efile\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ereader\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecsv\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ereader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efile\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003erow\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003ereader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这段代码会逐行读取data.csv中的数据并打印出来。\u003c/p\u003e","title":"Python处理CSV文件的14个高效技巧","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/genai/","section":"Tags","summary":"","title":"GenAI","type":"tags"},{"content":"现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。\n如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。\n本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。\n数据湖 # 企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。\n这些数据湖必须支持流处理工作负载，具备高效的加密和纠删码能力，能够将元数据与对象原子性地存储，并支持Lambda计算等技术。由于这些现代对象存储是云原生的，它们能与其他云原生技术栈（从防火墙到可观测性再到用户和访问管理）无缝集成。\n基于OTF的数据仓库 # 对象存储同样是基于OTF的数据仓库的底层存储方案。虽然用对象存储构建数据仓库听起来有些反常，但这种方式代表了新一代数据仓库。Netflix、Uber和Databricks制定的OTF规范使得在数据仓库中使用对象存储变得简单可行。\n这些OTF包括Apache Iceberg、Apache Hudi和Delta Lake，是因为市场上缺乏能够满足创建者数据需求的产品而开发的。它们的核心功能（尽管实现方式不同）是定义一个可以构建在对象存储之上的数据仓库。对象存储提供了其他存储方案无法比拟的可扩展容量和高性能的结合。\n作为现代规范，它们具备传统数据仓库所不具备的高级功能，如分区演进、模式演进和零拷贝分支。\n能够在MinIO之上运行基于OTF的数据仓库的是Dremio和Starburst。\nDremio Sonar（数据仓库处理引擎） Dremio Arctic（数据仓库目录） 开放数据湖仓 | Starburst（目录和处理引擎） 机器学习运维（MLOps） # MLOps之于机器学习，犹如DevOps之于传统软件开发。两者都是一套旨在提升工程团队（开发或机器学习团队）与IT运维团队之间协作的实践和原则。其目标是通过自动化来简化开发生命周期，涵盖从规划、开发到部署和运维的各个阶段。其中一个主要优势是实现持续改进。\nMLOps的技术和功能在不断演进。选择一个有大厂支持的工具至关重要，以确保工具能持续开发和改进，并提供长期支持。这些工具底层都使用MinIO来存储模型生命周期中的各种工件。\nMLRun（Iguazio，现已被麦肯锡公司收购） MLflow（Databricks） Kubeflow（Google） 机器学习框架 # 机器学习框架是用于创建模型和编写训练代码的库（通常是Python库）。这些库功能丰富，提供多种损失函数、优化器、数据转换工具和神经网络的预构建层。其中最重要的功能之一是张量（Tensor）。张量是可以被移至GPU上的多维数组，在模型训练过程中具有自动微分功能。\n当前最流行的两个机器学习框架是PyTorch（来自Meta）和TensorFlow（来自Google）。\nPyTorch TensorFlow 分布式训练 # 分布式模型训练是指在多个计算设备或节点上同时训练机器学习模型的过程。这种方法能够加速训练过程，尤其在使用大型数据集训练复杂模型时效果显著。\n在分布式模型训练中，数据集被分割为更小的子集，每个子集由不同的节点并行处理。这些节点可以是集群中的独立机器、独立进程或Kubernetes集群中的独立Pod，并可能具备GPU访问权限。每个节点独立处理其子集数据，并相应地更新模型参数。以下五个库屏蔽了分布式训练的大部分复杂性。虽然可以在本地运行这些库，但要显著减少训练时间，仍需要一个集群。\nDeepSpeed（来自Microsoft） Horovod（来自Uber） Ray（来自Anyscale） Spark PyTorch Distributor（来自Databricks） Spark TensorFlow Distributor（来自Databricks） 模型中心 # 虽然模型中心并非严格属于现代数据湖参考架构的一部分，但由于其对快速启动生成式AI至关重要，仍将其纳入其中。Hugging Face已成为大型语言模型的首选平台。它托管了一个模型中心，工程师可以在此下载预训练模型并分享自己创建的模型。Hugging Face还开发了Transformers和Datasets库，这些库与大型语言模型（LLM）以及用于训练和微调它们的数据协同工作。\n当然，还有其他模型中心。所有主要的云供应商都提供了上传和分享模型的途径，但Hugging Face凭借其丰富的模型和库，已成为该领域的领导者。\nHugging Face 应用框架 # 应用框架帮助将LLM集成到应用程序中。使用LLM与使用标准API有所不同，需要进行大量工作将用户请求转换为LLM可以理解和处理的内容。例如，如果你构建一个聊天应用程序，并希望使用检索增强生成（RAG），你需要将请求标记化，将标记转换为向量，集成向量数据库（如下所述），创建提示，然后调用你的LLM。生成式AI的应用框架允许你将这些操作串联在一起。\n当前最广泛使用的应用框架是LangChain。它可以与其他技术集成，如Hugging Face的Transformer库和Unstructured的文档处理库。它功能丰富，使用起来可能有些复杂，因此对于那些需求不复杂并希望使用比LangChain更简单工具的用户，下面列出了一些替代方案。\nLangChain AgentGPT Auto-GPT BabyAGI Flowise GradientJ LlamaIndex Langdock TensorFlow（Keras API） 文档处理 # 大多数组织并没有一个统一的、包含清晰准确文档的存储中心，而是将文档散落在各个团队的门户中，且格式多样。在为生成式AI准备数据时，首要任务是建立一条管道，筛选出已获批用于生成式AI的文档，并将它们导入向量数据库。对于大型跨国企业而言，这通常是最具挑战性的环节。\n文档管道应将文档转化为文本，将长文本分割成更小的片段，并利用嵌入模型对这些片段进行处理，从而获得它们的向量表示，以便存储在向量数据库中。一些开源库可以处理多种常见的文档格式，并能与LangChain无缝结合，构建完整的文档处理流程。\nUnstructured Open-Parse 向量数据库 # 向量数据库支持语义搜索。理解其工作原理需要大量的数学背景，较为复杂。然而，语义搜索在概念上很容易理解。假设你想找到所有讨论“artificial intelligence”相关内容的文档。要在传统数据库中实现这一点，你需要搜索“artificial intelligence”的每一个可能的缩写、同义词和相关术语。你的查询可能会像这样：\nSELECT snippet FROM MyCorpusTable WHERE (text like \u0026#39;%artificial intelligence%\u0026#39; OR text like \u0026#39;%ai%\u0026#39; OR text like \u0026#39;%machine learning%\u0026#39; OR text like \u0026#39;%ml%\u0026#39; OR ... and on and on ... 这种手动的相似性搜索既繁琐又容易出错，而且搜索本身也非常缓慢。向量数据库可以接收类似下面的请求，运行查询更快且更准确。如果你希望使用检索增强生成，快速而准确地运行语义查询至关重要。\n{ Get { MyCorpusTable(nearText: {concepts: [\u0026#34;artificial intelligence\u0026#34;]}) {snippet} } } 以下列出了四个流行的向量数据库。\nMilvus Pgvector Pinecone Weaviate 数据探索与可视化 # 拥有能够处理数据并以不同方式可视化的工具始终是明智之选。以下列出的Python库，正是提供了这样的能力。它们不仅适用于传统的AI，在生成式AI中同样大有用武之地。比如，在情感分析中，通过可视化工具，我们可以直观地检查数据集的分布，确保各个情感类别的样本均衡。\nPandas Matplotlib Seaborn Streamlit 结论 # 以上是现代数据湖参考架构中的十项关键能力，以及对应的具体供应商产品和库。\n以下是这些工具的汇总表。\n数据湖： MinIO、AWS、GCP、Azure 基于OTF的数据仓库： Dremio Dremio Sonar Dremio Arctic Starburst Open Data Lakehouse | Starburst 机器学习框架： PyTorch TensorFlow 机器学习运维（MLOps）： MLRun（麦肯锡公司） MLflow（Databricks） Kubeflow（Google） 分布式训练： DeepSpeed（Microsoft） Horovod（Uber） Ray（Anyscale） Spark PyTorch Distributor（Databricks） Spark TensorFlow Distributor（Databricks） 模型中心： Hugging Face 应用框架： LangChain AgentGPT Auto-GPT BabyAGI Flowise GradientJ LlamaIndex Langdock TensorFlow（Keras API） 文档处理： Unstructured Open-Parse 向量数据库： Milvus Pgvector Pinecone Weaviate 数据探索与可视化： Pandas Matplotlib Seaborn Streamlit ","date":"2024-10-26","externalUrl":null,"permalink":"/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/","section":"Ais","summary":"\u003cp\u003e现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。\u003c/p\u003e\n\u003cp\u003e如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。\u003c/p\u003e\n\u003cp\u003e本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./GenAI-Tech-Stack.jpg\" alt=\"GenAI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e数据湖 \n    \u003cdiv id=\"%E6%95%B0%E6%8D%AE%E6%B9%96\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%95%B0%E6%8D%AE%E6%B9%96\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。\u003c/p\u003e","title":"生成式AI技术栈架构师指南","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/h100/","section":"Tags","summary":"","title":"H100","type":"tags"},{"content":"据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。\n云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。\n这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。\n并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。\n无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。\n如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。 而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。\n","date":"2024-10-26","externalUrl":null,"permalink":"/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/","section":"Ais","summary":"\u003cp\u003e据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。\u003c/p\u003e\n\u003cp\u003e云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Google-Engineer-GenAI-GPU.webp\" alt=\"Google GenAI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。\u003c/p\u003e\n\u003cp\u003e并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。\u003c/p\u003e\n\u003cp\u003e无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。\u003c/p\u003e\n\u003cp\u003e如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。\n而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。\u003c/p\u003e","title":"数据中心GPU的寿命最多只有3年","type":"ai"},{"content":"作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。\n我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。\n这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。\n引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。\nMeta的大规模AI集群 # Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。\n虽然我们在构建AI基础设施方面有着悠久的历史，但我们在2022年首次分享了我们的AI研究超级集群（ AI Research SuperCluster，简称RSC）的细节，该集群拥有16,000个NVIDIA A100 GPU。RSC通过帮助我们建立第一代先进的AI模型，加速了开放AI研究。它在Llama和Llama 2的开发中发挥了重要作用，并将继续发挥重要作用，以及用于计算机视觉、自然语言处理、语音识别、图像生成甚至编码等应用的先进AI模型。\n揭开面纱 # 我们新的AI集群建立在RSC的成功和经验教训之上。我们专注于构建端到端的人工智能系统，主要强调研究人员和开发人员的经验和生产力。这些集群中的高性能网络结构的效率，一些关键的存储决策，结合每个集群中的24,576个NVIDIA Tensor Core H100 GPU，允许两个集群版本支持比RSC支持更大更复杂的模型，并为GenAI产品开发和AI研究的进步铺平道路。\n网络 # 在Meta，我们每天处理数以万亿计的AI模型。大规模交付这些服务需要高度先进和灵活的基础设施。定制设计我们自己的硬件、软件和网络结构，使我们能够优化AI研究人员的端到端体验，同时确保我们的数据中心高效运行。\n考虑到这一点，我们基于带有Wedge400和Minipack2 OCP机架交换机的Arista 7800构建了一个基于融合以太网（RoCE）网络结构解决方案的远程直接内存访问（RDMA）集群。另一个集群采用NVIDIA Quantum2 InfiniBand结构。这两种解决方案都将400 Gbps的端点互连起来。有了这两个，我们能够评估这些不同类型的互连在大规模训练中的适用性和可扩展性，为我们提供更多的见解，这将有助于我们在未来如何设计和构建规模更大的集群。通过仔细设计网络、软件和模型架构，我们已经成功地将RoCE和InfiniBand集群用于大型GenAI工作负载（包括在RoCE集群上正在进行的Llama 3培训），没有任何网络瓶颈。\n计算 # 这两个集群都是使用Grand Teton构建的，这是我们内部设计的开放GPU硬件平台，我们已经为开放计算项目（OCP）做出了贡献。Grand Teton基于多代AI系统，将电源、控制、计算和结构接口集成到单个机箱中，以获得更好的整体性能、信号完整性和热性能。它以简化的设计提供了快速的可扩展性和灵活性，使其能够快速部署到数据中心中，并且易于维护和扩展。结合其他内部创新，如我们的 Open Rack电源和Rack架构，Grand Teton允许我们以一种专门为Meta当前和未来应用程序构建的方式构建新的集群。\n从2015年的Big Sur平台开始，我们已经公开设计了我们的GPU硬件平台。\n存储 # 存储在AI训练中扮演着重要的角色，但却是最少被提及的方面之一。随着时间的推移，GenAI训练工作变得越来越多，需要大量的图像、视频和文本数据，因此对数据存储的需求迅速增长。然而，将所有数据存储放入高性能且节能的需求并没有消失，这使得问题变得更加有趣。\n我们的存储部署通过本地的Linux Filesystem in Userspace (FUSE) API解决了AI集群的数据和检查点需求，该API由Meta的“构造”分布式存储解决方案版本支持，该解决方案针对Flash进行了优化。该解决方案使数千个GPU能够以同步方式保存和加载检查点（对任何存储解决方案来说都是一个挑战），同时还提供数据加载所需的灵活且高吞吐量的exabyte级存储。\n我们还与Hammerspace合作，共同开发并行网络文件系统（NFS）部署，以满足该AI集群的开发人员经验要求。Hammerspace的优点之一是，工程师可以使用数千个GPU对作业进行交互式调试，因为环境中的所有节点都可以立即访问代码更改。当组合在一起时，我们的构造分布式存储解决方案和Hammerspace的组合可以在不影响规模的情况下实现快速迭代速度。\nGenAI集群中的存储部署，包括构造和hammerspace支持，都基于YV3 Sierra Point服务器平台，并升级了最新的高容量E1.S SSD。除了更高的SSD容量之外，还定制了每个机架的服务器，以实现每个服务器的吞吐量、机架数量和功耗之间的适当平衡。利用OCP服务器作为乐高积木，我们的存储层能够灵活地扩展到该集群以及未来更大的AI集群需求，同时对日常基础设施维护操作具有容错能力。\n性能 # 我们在构建大规模AI集群时的原则之一是最大化性能和易用性，而不牺牲其中一个。这是创建一流AI模型的重要原则。\n当我们不断挑战AI系统的极限时，我们测试自己扩展设计能力的最佳方式就是简单地构建一个系统，对其进行优化，并进行实际测试（虽然模拟器可以提供帮助，但它们也只能做到这一点）。在这个设计过程中，我们比较了小型集群和大型集群的性能，以了解瓶颈在哪里。下面图表显示了AllGather的总体性能（按0-100的标准带宽表示）。\n与优化后的小集群性能相比，我们在大型集群上的开箱性能最初很差，而且不一致。为了解决这个问题，我们对内部作业调度器在网络拓扑感知的情况下调度作业的方式进行了一些更改——这带来了延迟方面的好处，并最大限度地减少了流向网络上层的流量。我们还结合NVIDIA集体通信库（NCCL）的变化优化了网络路由策略，以实现最佳的网络利用率。这有助于推动大型集群实现与小型集群一样的出色性能。\n除了针对内部基础设施的软件变更之外，我们还与编写训练框架和模型的团队密切合作，以适应不断发展的基础设施。例如，NVIDIA H100 GPU开启了利用8位浮点（FP8）等新数据类型进行训练的可能性。充分利用更大的集群需要在额外的并行化技术和新的存储解决方案上进行投资，从而提供在数千个队列中高度优化检查点以在数百毫秒内运行的机会。\n我们也认识到可调试性是大规模训练中的主要挑战之一。在大规模的情况下，识别一个阻碍整个训练工作的GPU变得非常困难。我们正在构建诸如设计调试或分布式集体记录器之类的工具，以公开分布式训练的细节，用更快更容易的方式识别出问题。\n最后，我们将继续发展PyTorch，这是为AI工作负载提供动力的基础AI框架，使其为数万甚至数百，数千个GPU训练做好准备。我们已经确定了进程组初始化的多个瓶颈，并将启动时间从有时几小时减少到几分钟。\n致力于开放AI创新 # Meta将继续致力于AI软硬件的开放式创新。我们相信，开源硬件和软件将永远是帮助行业大规模解决问题的宝贵工具。\n今天，我们作为OCP的创始成员继续支持开放硬件创新，在那里我们为OCP社区提供Grand Teton和开放机架等设计。我们还将继续成为PyTorch的最大和主要贡献者，PyTorch是推动行业发展的AI软件框架。\n我们还将继续致力于AI研究领域的开放式创新。我们已经启动了开放创新AI研究社区，这是一个学术研究人员的合作项目，旨在加深我们对如何负责任地开发和分享AI技术的理解——特别是LLM。\n对Meta来说，开放的AI方法并不新鲜。我们还启动了AI联盟，这是一个由AI行业的领先组织组成的团体，致力于在一个开放的社区内加速AI领域的创新。我们的AI工作建立在开放科学和交叉合作的理念之上。一个开放的生态系统为AI的发展带来了透明度、审查和信任，并让每个人都能从中受益。\nMeta AI基础设施的未来 # 当我们展望未来时，我们认识到昨天或今天行之有效的方法可能不足以满足明天的需要。这就是为什么我们不断评估和改进基础设施的各个方面，从物理和虚拟层到软件层等等。我们的目标是创建灵活可靠的系统，以支持快速发展的新模型和研究。\n","date":"2024-10-26","externalUrl":null,"permalink":"/ai/building-metas-genai-infrastructure/","section":"Ais","summary":"\u003cp\u003e作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。\u003c/p\u003e\n\u003cp\u003e我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。\u003c/p\u003e\n\u003cp\u003e这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。\u003c/p\u003e\n\u003cp\u003e引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eMeta的大规模AI集群 \n    \u003cdiv id=\"meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eMeta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。\u003c/p\u003e","title":"Meta的AI大模型基础设施","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/epyc/","section":"Tags","summary":"","title":"Epyc","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/granite-rapids/","section":"Tags","summary":"","title":"Granite Rapids","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/turin/","section":"Tags","summary":"","title":"Turin","type":"tags"},{"content":"2017 年，AMD 推出代号为 Naples 的第一代 Epyc 处理器后不久，英特尔就打趣说，其竞争对手为了保持相关性，已经沦落到只能将一堆台式机芯片粘在一起的地步。\n不幸的是，对于英特尔来说，这句评论已经过时了，短短几年后，这家 x86 巨头就开始自己寻找粘合剂了。\n英特尔的Xeon 6处理器于今年开始分阶段推出，这是其第三代多芯片 Xeon 处理器，也是其首款采用与AMD自己的异构芯片架构类似的数据中心芯片。\n虽然英特尔最终认识到了AMD小芯片战略的明智之处，但其方法却截然不同。\n突破标线限制 # 快速回顾一下为什么这么多 CPU 设计正在远离单片架构，这主要归结为两个因素：掩模版限制和产量。\n一般而言，在工艺技术没有重大改进的情况下，更多内核必然意味着更多硅片。然而，芯片实际尺寸存在实际限制 - 我们称之为光罩极限 - 大约为 800 平方毫米。一旦达到极限，继续扩展计算的唯一方法就是使用更多芯片。\n我们现在看到许多产品（不仅仅是 CPU）都采用了这种技术，它们将两个大型芯片塞进一个封装中。Gaudi 3、Nvidia的Blackwell和英特尔的Emerald Rapids Xeons 只是其中几个例子。\n多芯片的问题在于，它们之间的桥梁往往是带宽方面的瓶颈，并且有可能引入额外的延迟。这通常不像将工作负载分散到多个插槽那么糟糕，但这也是一些芯片设计师倾向于使用较少数量的较大芯片来扩展计算的原因之一。\n然而，制造更大的芯片确实成本高昂，因为芯片越大，缺陷率就越高。这使得使用大量较小的芯片成为一个有吸引力的提议，并解释了为什么AMD的设计使用了如此多的芯片——最新的Epycs芯片多达 17 个。\n了解了这些基础知识后，让我们深入探讨一下英特尔和AMD最新Xeons和Epyc处理器的不同设计理念。\nAMD的做法 # 我们将从AMD的第五代Epyc Turin处理器开始。具体来说，我们正在研究该芯片的 128 核 Zen 5 版本，它具有 16 个4nm核心复合芯片 (CCD)，这些芯片围绕着基于台积电 6nm 工艺技术制造的单个 I/O 芯片 (IOD)。\nAMD 最新的Epycs配备多达 16 个计算芯片 如果这听起来很熟悉，那是因为 AMD 在其第二代 Epyc 处理器上使用了相同的基本公式。作为参考，第一代Epyc缺乏独特的 I/O 芯片。\n正如我们前面提到的，使用大量较小的计算芯片意味着 AMD 可以获得更高的产量，但这也意味着他们可以在 Ryzen 和 Epyc 处理器之间共享硅片。\n此外，使用八核或十六核 CCD（每个 CCD 具有 32 MB 的 L3 缓存），AMD 在按缓存和内存比例扩展核心数量时可以获得额外的灵活性。\n例如，如果您想要一个具有 16 个内核的 Epyc（由于许可限制，这是 HPC 工作负载的常见 SKU），最明显的实现方法是使用两个八核 CCD，两个 CCD 之间有 64 MB 的 L3 缓存。但是，您也可以使用 16 个 CCD，每个 CCD 只有一个内核处于活动状态，但板载缓存为 512 MB。这听起来可能很疯狂，但这两种芯片确实存在。\nAMD 的第五代Epycs遵循熟悉的模式，即16个计算芯片围绕一个中央 I/O 芯片 另一方面，I/O 芯片负责除计算之外的几乎所有功能，包括内存、安全性、PCIe、CXL 和其他 I/O（如 SATA），并且还充当芯片 CCD 与其他插槽之间通信的骨干。\n将内存控制器放置在I/O芯片上确实有一些优点和缺点。从好的方面来说，这意味着内存带宽在很大程度上独立于核心数量而扩展。缺点是某些工作负载的内存和缓存访问延迟可能会更高。我们强调“可能”，因为这种事情高度依赖于工作负载。\n英特尔Xeon的chiplet 之旅 # 谈到英特尔，这家芯片制造商对多芯片硅片的处理方式与 AMD 有很大不同。虽然现代 Xeon 处理器采用具有不同计算和 I/O 芯片的异构架构，但情况并非总是如此。\n英特尔首款多芯片 Xeon 处理器，代号为Sapphire Rapids，采用一块单片、中等核心数芯片或四块极端核心数芯片，每块芯片都有自己的内存控制器和板载 I/O。Emerald Rapids采用了类似的模式，但为芯片核心数较高的 SKU 选择了两块更大的芯片。\n正如您在 Sapphire 和 Emerald Rapids 之间看到的，英特尔从四个中型芯片转换为一对近乎网状的有限芯片 所有这一切都随着 Xeon 6 的推出而发生了改变，英特尔将I /O、UPI 链接和加速器移至基于英特尔 7 工艺节点制造的一对芯片上，这对芯片位于基于英特尔 3 制造的中心的一到三个计算芯片之间。\n出于稍后会讲到的原因，我们将主要关注英特尔更主流的 Granite Rapids Xeon 6 处理器，而不是其多核 Sierra Forest 部件。\n看看英特尔的计算芯片，我们就能发现它与 AMD 的第一个重大区别。每个计算模块至少有 43 个板载核心，可根据 SKU 开启或关闭融合。这意味着英特尔实现 128 个核心所需的芯片数量比 AMD 少得多，但由于面积较大，因此成品率可能会更低。\n根据 SKU，Granite Rapids 使用夹在一对 I/O 芯片之间的一到三个计算芯片 除了增加内核之外，英特尔还选择将这些芯片的内存控制器放在计算芯片上，每个芯片支持 4 个通道。理论上，这应该可以降低访问延迟，但这也意味着，如果你想要所有 12 个内存通道，就需要填充所有 3 个芯片。\n对于我们上个月看过的 6900P 系列部件，你不必担心这一点，因为每个 SKU 都配有三个计算芯片。然而，这意味着 72 核版本只利用了封装中一小部分硅片。同样，我们之前讨论过的 16 核 HPC 中心 Epyc 也是如此。\n另一方面，英特尔将于明年初推出的 6700P 系列部件将配备一个或两个计算芯片，具体取决于所需的内存带宽和核心数量，这意味着内存通道在高端将限制为 8 个，在板载单个计算芯片的配置中可能只有 4 个。我们目前还不清楚 HCC 和 LCC 芯片上的内存配置，因此英特尔有可能增强了这些部件上的内存控制器。\n与 AMD 的 Epyc 一样，英特尔的 Xeon 现在采用带有计算和 I/O 芯片的异构芯片架构 英特尔的 I/O 芯片也相当薄，并包含 PCIe、CXL 和 UPI 链路组合，用于与存储、外围设备和其他插槽进行通信。除此之外，我们还发现了许多用于直接流 (DSA)、内存分析 (IAA)、加密/解密 (QAT) 和负载平衡的加速器。\n我们得知，在 I/O 芯片上放置加速器的部分原因是为了让它们更靠近进出芯片的数据。\n我们接下来要去哪里？ # 从表面上看，英特尔的下一代多核处理器代号为 Clearwater Forest，预计将于明年上半年推出，其型号与 Granite Rapids 类似，具有两个 I/O 模块和三个计算模块。\n它可能看起来像缩小版的 Granite Rapids，但显然那只是隐藏着更多芯片的结构硅 然而，外表是会骗人的。据我们了解，这三个计算芯片实际上只是隐藏着许多较小计算芯片的结构硅片，而这些较小的计算芯片本身位于有源硅片中介层之上。\n根据英特尔今年早些时候展示的效果图，Clearwater Forest 每个封装最多可使用 12 个计算芯片。使用硅中介层绝不是新鲜事，它提供了许多好处，包括芯片间带宽更高、延迟比有机基板中通常看到的更低。这与英特尔核心数最高的 Sierra Forest 部件上的一对 144 核计算芯片大不相同。\n如果英特尔今年早些时候发布的渲染图有任何可参考之处，那么 Clearwater Forest 隐藏的芯片数量要比 Granite Rapids 多得多 当然，讨论 Clearwater 森林将使用的技术的效果图并不意味着明年到达时我们将会得到完全相同的技术。\n也许更大的问题是 AMD 下一步将把其小芯片架构带向何方。看看 AMD 的 128 核 Turin 处理器，封装上没有太多空间容纳更多硅片，但 House of Zen 仍有一些选择。\n首先，AMD 可以选择更大的封装，为额外的芯片腾出空间。或者，该芯片制造商也可以将更多内核封装到更小的芯片上。然而，我们怀疑 AMD 的第六代 Epycs 最终可能看起来更像其 Instinct MI300 系列加速器。\nMI300A 将 24 个 Zen 4 核心、6 个 CDNA 3 GPU 芯片和 128GB HBM3 内存整合到一个封装中，旨在满足 HPC 工作负载的需求 您可能还记得，与 MI300X GPU 一起推出的还有一款 APU，它将芯片的两个 CDNA3 模块换成了三个 CCD，中间有 24 个 Zen 4 核心。这些计算模块堆叠在四个 I/O 芯片上，并连接到一组八个 HBM3 模块。\n现在，这只是猜测，但不难想象 AMD 会做类似的事情，将所有内存和 GPU 芯片换成额外的 CCD。这样的设计可能也会受益于更高的带宽和更低的芯片间通信延迟。\n这是否真的会实现，只有时间才能证明。我们预计AMD的第6 代Epycs 将于 2026 年底上市。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/different-approach-for-intel-and-amd-to-gluing-together-cpus/","section":"Hardwares","summary":"\u003cp\u003e2017 年，AMD 推出代号为 Naples 的第一代 Epyc 处理器后不久，英特尔就打趣说，其竞争对手为了保持相关性，已经沦落到只能将一堆台式机芯片粘在一起的地步。\u003c/p\u003e\n\u003cp\u003e不幸的是，对于英特尔来说，这句评论已经过时了，短短几年后，这家 x86 巨头就开始自己寻找粘合剂了。\u003c/p\u003e\n\u003cp\u003e英特尔的Xeon 6处理器于今年开始分阶段推出，这是其第三代多芯片 Xeon 处理器，也是其首款采用与AMD自己的异构芯片架构类似的数据中心芯片。\u003c/p\u003e\n\u003cp\u003e虽然英特尔最终认识到了AMD小芯片战略的明智之处，但其方法却截然不同。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e突破标线限制 \n    \u003cdiv id=\"%E7%AA%81%E7%A0%B4%E6%A0%87%E7%BA%BF%E9%99%90%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AA%81%E7%A0%B4%E6%A0%87%E7%BA%BF%E9%99%90%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e快速回顾一下为什么这么多 CPU 设计正在远离单片架构，这主要归结为两个因素：掩模版限制和产量。\u003c/p\u003e","title":"英特尔和AMD封装CPU的不同做法","type":"hardware"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/5600t/","section":"Tags","summary":"","title":"5600T","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/5600xt/","section":"Tags","summary":"","title":"5600XT","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/am4/","section":"Tags","summary":"","title":"AM4","type":"tags"},{"content":"AMD在发布全新Ryzen 9000系列处理器几周后，再次推出了两款价格实惠的AM4 CPU——Ryzen 5 5600T和Ryzen 5 5600XT。这两款芯片现已在美亚上架，Ryzen 5 5600T售价为186.58美元，Ryzen 5 5600XT截至本文撰写时售价为192.08美元。这个定价使它们成为AMD最实惠的处理器之一。\n新发布的Ryzen 5 5600T和5600XT依然采用6核12线程设计，与将要被取代的Ryzen 5 5600和5600X类似。不过Ryzen 5 5600T的基础频率提高到了3.7 GHz，比Ryzen 5 5600高出200 MHz；Ryzen 5 5600XT的基础频率达到3.8 GHz，比Ryzen 5 5600X高出100 MHz。除此之外，它们的TDP仍为65瓦，L3缓存也保持在32MB。\n以下是部分Ryzen处理器的规格对比：\n虽然这些处理器不是定位顶级游戏性能的X3D芯片，但对于想要组装台式机且需要控制预算的用户来说，它们还是不错的选择。如果您正在搭建新电脑，此次发布为您提供了三代Ryzen处理器可供选择。\n此次发布使AM4成为市场上使用时间最长的插槽之一，自2016年推出以来，已历经八年多。尽管AM5已经问世，AMD仍在继续为AM4平台推出新处理器。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/amd-launch-2-am4-cpu-5600t-and-5600xt/","section":"Hardwares","summary":"\u003cp\u003eAMD在发布全新Ryzen 9000系列处理器几周后，再次推出了两款价格实惠的AM4 CPU——Ryzen 5 5600T和Ryzen 5 5600XT。这两款芯片现已在美亚上架，Ryzen 5 5600T售价为186.58美元，Ryzen 5 5600XT截至本文撰写时售价为192.08美元。这个定价使它们成为AMD最实惠的处理器之一。\u003c/p\u003e\n\u003cp\u003e新发布的Ryzen 5 5600T和5600XT依然采用6核12线程设计，与将要被取代的Ryzen 5 5600和5600X类似。不过Ryzen 5 5600T的基础频率提高到了3.7 GHz，比Ryzen 5 5600高出200 MHz；Ryzen 5 5600XT的基础频率达到3.8 GHz，比Ryzen 5 5600X高出100 MHz。除此之外，它们的TDP仍为65瓦，L3缓存也保持在32MB。\u003c/p\u003e","title":"AMD推出两款AM4 CPU：5600T和5600XT","type":"hardware"},{"content":"HBM是传统内存类型的重大飞跃。更高的内存带宽和容量、更低的功耗和快速的传输速率等关键特性使HBM区别于它的前辈。了解这些特征对于了解这项尖端技术至关重要。\n通过这个终极指南，读者可以了解HBM的发展，它在各个行业中的重要应用，与传统DRAM相比提供的优势，以及计算世界中内存配置的未来。欢迎来到HBM知识之门。\nHBM市场规模在2022年价值28亿美元。HBM市场行业预计将从2023年的35.3亿美元增长到2032年的225.73亿美元，在预测期内（2024 - 2032年）的复合年增长率（CAGR）为26.10%。\nHBM主要特性 # HBM已经彻底改变了高性能计算系统管理数据流的方式。与传统内存解决方案相比，其最显著的特性之一是带宽显著增加。HBM通过使用TSV和微凸点连接的堆叠DRAM芯片来实现这一目标。这种创新的设计允许更短的数据路径，从而提高数据速度和能效。\n将多个存储芯片集成到一个封装中，不仅可以提高电源效率，还可以减少内存在PCB上的面积。通过利用宽接口架构，HBM有助于提高传输速率和降低功耗。与努力平衡性能和功率预算的传统内存系统不同，HBM提供了针对高性能计算、图形卡和机器学习应用程序的功率效率和性能需求量身定制的内存解决方案。\n内存带宽 # HBM技术的核心在于其一流的存储带宽。内存带宽指的是在内存和处理器之间快速移动大量数据的能力。HBM利用更宽的内存总线，通过独立通道同时访问数据，大大提高了每个周期传输的数据量。这种特性有利于需要高速数据处理的应用程序，如高级图形渲染或复杂的科学计算。\n功耗 # HBM的高效架构使其在功耗方面脱颖而出。传统的DRAM需要更高的功率来长距离驱动信号，而HBM的垂直堆叠IC和更短的连接路径显著降低了传输每比特所需的能量。这意味着更高的功率效率，这对于控制功率预算至关重要，特别是在高性能计算环境和半导体工程中的先进节点中经常出现的密集封装中。\n内存容量 # HBM专注于垂直堆叠和硅中间体的使用，与传统的平面内存解决方案相比，HBM可以在单个封装中实现更大的内存容量。通过将多个DRAM芯片堆叠在一起，HBM不仅节省了空间，而且还提供了更多的空间可以根据需要扩展内存容量，同时不会受到PCB设计人员所面临的典型面积限制。HBM的这一特性使它成为在有限的功率和空间范围内需要大内存容量系统的一个有吸引力的存储设备。\n传输速率 # HBM拥有惊人的传输速率，这是依赖数据快速传输系统的关键考虑因素。HBM的设计允许使用宽接口总线，这样可以使传输速率大大超过传统内存。利用HBM的传输速率，系统可以从更快的加载时间、更流畅的数据处理和整体性能提升中受益，使其适用于涉及高数据吞吐量的任务，例如视频处理和神经网络训练。\nHBM技术的发展 # 内存技术的发展一直在不懈地追求多个方面的平衡：容量、速度、功率效率和面积。在这段旅程的每个关键时刻，创新都解决了前几代的局限性。这种演变推动了HBM的出现，HBM是一个技术飞跃，重塑了内存解决方案的性能格局。\n传统内存解决方案 # 在传统内存解决领域，系统通常依赖于DDR SDRAM，其后续迭代(DDR2、DDR3、DDR4)在性能和功率效率方面提供了渐进式的进步。然而，这些传统存储器采用并行总线接口，随着带宽和容量需求的增加，面临着信号完整性和布线拥挤等挑战。此外，更宽的内存总线需要更多的物理空间和功耗，这反过来又影响了系统设计和热管理。\nHBM介绍 # HBM的引入代表了一个重大的范式转变。HBM通过实现堆叠存储器架构重新定义了数据传输，多个DRAM芯片堆叠在一起，通过TSV互连，实现超高速信号传输。这种3D封装技术显著拓宽了数据接口，而不增加面积，允许与处理单元直接相邻的高速通信。通过这一创新，HBM消除了困扰传统平面内存设计的限制，提供了更大的带宽并降低了功耗。\nHBM进展 # 随着HBM技术的进步，每次迭代都带来了令人敬畏的进步。例如，HBM2将每个引脚的带宽提高了一倍，并提高了密度。此后，HBM2E进一步扩展了容量和速度。这些进步使得HBM对于最新的图形密集型任务和AI及机器学习等新兴领域至关重要，这些领域需要快速和强大的存储能力。HBM无缝集成到硅中间体中，与半导体工程中的先进节点一起提高计算能力，同时坚守严格的功率预算。\n下表总结了HBM的进化里程碑：\n随着不断的进步，HBM继续推动技术的发展，为下一代计算应用提供前所未有的性能。\nHBM应用 # HBM已经成为一种变革性的存储器解决方案，在速度、效率和容量等关键节点交叉的一系列领域中找到了应用。它能够以令人印象深刻的速度处理大量数据，同时又节能，这使它成为各种计算范例的理想选择。我们将探讨它在高性能计算、图形、人工智能和数据中心应用程序中的重要作用，说明它的独特属性如何满足快速数据处理和传输的不断增长的需求。\n高性能计算 # 高性能计算（HPC）涵盖了广泛的系统，这些系统提供了强大的计算能力，可以完成复杂的任务，如科学模拟、气候建模和先进材料研究。HPC系统需要能够与其强大的处理能力保持同步的内存，而HBM巧妙地满足了这一需求。\n性能驱动：HBM的堆叠配置提供并行工作的多个通道，最大限度地提高数据吞吐量。 节能：尽管HBM具有高速数据传输速率，但HBM仍保持较低的功耗，这在高性能计算环境中至关重要，因为高性能计算环境中功耗是一个关键的问题。 密度：通过提高每个芯片的密度，HBM允许HPC系统在不影响物理空间的情况下管理更广泛的数据集。 图形应用程序 # HBM和图形应用程序之间的相关性特别强，因为对内存带宽的需求随着图形分辨率和复杂性的提高而增强。\n高分辨率和帧率：具有HBM的GPU可以以更高的帧率渲染高分辨率图像和视频，这是现代游戏、虚拟现实和专业可视化所必需的。 平滑的性能：高带宽可以实现稳定的数据流，这样即使在高图形负载下也可以实现平滑的性能。 紧凑的外形因素：HBM的小占地面积允许紧凑和高效的图形卡设计，这是时尚消费电子设备的一个重要特点。 AI # AI和ML模型通常需要较大的内存带宽才能有效地训练大型数据集。HBM提供了支持AI应用程序的密集工作负载所需的功能。\n快速数据访问：快速访问内存对于AI和ML算法的迭代过程至关重要，而HBM以其优越的传输速率保证了这一点。 并行处理支持：HBM促进了复杂AI计算所需的并行处理能力。 高效扩展：随着AI模型在规模和复杂性上的增长，HBM的可扩展性确保内存不会成为开发的瓶颈。 数据中心的应用程序 # 数据中心是数字经济的支柱，支持云计算、内容交付和企业服务。HBM可以在优化数据中心操作方面发挥不可或缺的作用。\n用于虚拟化的带宽：当运行多个虚拟机或容器时，数据中心可以从增加的带宽中受益，因为它允许并发处理更多数据而不会延迟。 节能：HBM的能效为数据中心节省了大量成本，而数据中心的功耗是一项重要的运营支出。 低延迟：HBM的低延迟特性缩短了响应时间，有助于更快地提供服务并改善用户体验。 总之，HBM的广泛应用强调了其作为推动未来复杂计算任务的核心技术的重要性。随着每一代HBM的出现，潜在的应用程序不断扩展，有望满足对更快、更高效和更密集的内存解决方案的不断需求。\nHBM的优点 # HBM已经成为存储器技术的重要创新，主要是因为它比传统的DRAM解决方案具有明显的优势。通过解决传统内存面临的一些关键限制，例如数据传输速率瓶颈和能源效率低下，HBM已成为要求高速数据处理和最小延迟的应用程序的基石。让我们深入研究使HBM与众不同的具体优势，重点介绍增加的内存带宽、改进的电源效率、高内存容量和更快的传输速率。\n增加内存带宽 # 高带宽内存的定义特征是其扩展的内存带宽能力。与传统存储设备在繁重的工作负载下挣扎不同，HBM采用了通过堆叠多个DRAM芯片构建的宽接口，并使用硅通孔进行互连。这种方法可以使大量的独立通道同时运行，从而大大增加了可用的总内存带宽。实际上，这意味着对大量数据的快速处理，这是许多当代应用程序（从高性能计算到最新显卡）的关键因素。\n高内存容量 # 除了带宽和功率效率，HBM还拥有紧凑的物理外形因素内的高内存容量。DRAM芯片与HBM的垂直堆叠导致内存解决方案提供更高的密度，从而在单个封装中提供更大的容量。这种配置适用于空间有限但需要大量内存的系统，例如工作站笔记本电脑和小型设备中的紧凑高性能GPU。\n更快的传输速率 # 最后，HBM提供了极快的传输速率——这是其架构设计的直接结果。由于多个存储库在配备高速TSV的宽接口上协同工作，数据传输的速度比传统存储解决方案要快得多。这种改进的传输性能确保了数据密集型操作，特别是在像机器学习这样的领域，速度是一个成败因素。\n总之，高带宽存储器代表了一种突破性的存储器类型，它解决了各种类型存储器面临的关键挑战。它的架构是精心定制的，以提供符合当代高级计算需求的高性能内存解决方案。由于这些固有的优势，HBM作为新兴技术和高端计算平台寻求向未来飞跃的重要组成部分脱颖而出。\nHBM配置 # HBM以其高速、大容量和高能效而闻名，能够满足现代高性能计算环境的需求。HBM的独特配置使其能够提供数倍于传统存储器的带宽。HBM背后的独创性在于其创新的布局，它有各种配置，以最大限度地提高性能和最大限度地减少空间使用。这些HBM配置包括3D堆叠存储器设计和先进的5D多模封装系统。\n5D多模封装系统 # 5D多模封装系统是封装技术的顶峰，旨在实现无与伦比的性能。作为3D堆叠的进化，这些系统增加了额外的集成维度，将多层3D堆叠芯片组合在一起，形成一个非常强大和高效的存储解决方案。“5D”指的是三个空间维度加上两个额外的集成维度，包括互连和封装级组装。这种方法精心协调每个芯片的操作，实现更快的传输速率和更低的功耗，同时保持在硬件板上的小面积。\n3D堆叠DRAM # 当谈到HBM时，3D堆叠DRAM是一项关键技术。它通过TSV连接将多层DRAM芯片堆叠在一起。这些TSV穿过硅片，使堆叠的不同层之间实现垂直电连接。这种3D堆叠不仅节省了空间，而且有助于闪电般的数据传输速率和增强的带宽，实现高性能计算场景中的实时数据处理。\n3D堆叠内存架构 # 3D堆叠存储器架构代表了存储器设计的飞跃，将多层IC组合到单个封装中。通过堆叠内存芯片，HBM有效地减少了信号距离，并且与2D配置相比，在延迟和能效方面有了巨大的改进。这些架构采用微凸点和TSV来实现密集的芯片间连接，从而简化了存储单元之间的通信路径。这种紧凑的安排显著提高了每个芯片的可用带宽，使HBM成为带宽密集型应用程序的最佳内存解决方案。\n高带宽内存与传统DRAM解决方案 # 目前，HBM已经成为存储技术领域的领跑者，特别是与传统的DRAM解决方案相比。这种形式的存储技术在设计时考虑到了当代高性能计算、图形渲染和先进机器学习算法的强烈要求，这些要求不仅需要更高的速度，还需要更大的带宽和能源效率。HBM通过创新的设计配置（如3D堆叠和先进的封装技术）实现了这些目标，将其与传统DRAM的传统平面布局区分开来。\n内存带宽比较 # 与传统DRAM相比，HBM最突出的优点之一是它提供了大量的带宽。HBM具有宽接口存储器总线和并行工作的多个独立通道，极大地增强了数据传输能力。为了说明这一点，典型的HBM配置可以提供大约256 GB/s或更高的带宽，这是传统DRAM提供的带宽的几倍，传统DRAM可能在32 GB/s左右徘徊。这种明显的差异允许更快的数据处理，在带宽饥渴的场景中被证明是必不可少的。\n功耗对比 # 与传统DRAM相比，功耗效率是HBM的另一个亮点。HBM的分层设计意味着数据传输距离更短，内存工作电压更低，从而降低了总体功耗。虽然传统DRAM的功耗可能是一个限制因素，特别是在功率敏感型应用中，但HBM的架构可以在更低的功耗预算下保持高性能。具体的节能效果可能会有所不同，但是与传统方法相比，HBM通常可以显著降低每千兆字节的功耗。\n内存容量比较 # 在内存容量方面，HBM通过其堆叠能力引入了一种范式转变，允许芯片的垂直集成，并在相同甚至更小的占地面积内实现更密集的内存配置。因此，HBM可以实现更高的密度，从而在单个堆栈内实现更高的内存容量，而无需增加内存设备的物理大小。\n传输速率比较 # 传输速率，或从内存中读取或写入数据的速度，对整个系统性能至关重要。HBM由于其3D堆叠架构和高速TSV的短数据路径提供了卓越的传输速率。传统DRAM的传输速率可能达到8到14 Gbps，而HBM的传输速率可以远远超过100 Gbps。这允许更有效地处理数据密集型任务，推动计算机图形学、科学计算和实时分析的进步。\n","date":"2024-10-24","externalUrl":null,"permalink":"/hardware/high-bandwidth-memory-hbm-ultimate-guide/","section":"Hardwares","summary":"\u003cp\u003eHBM是传统内存类型的重大飞跃。更高的内存带宽和容量、更低的功耗和快速的传输速率等关键特性使HBM区别于它的前辈。了解这些特征对于了解这项尖端技术至关重要。\u003c/p\u003e\n\u003cp\u003e通过这个终极指南，读者可以了解HBM的发展，它在各个行业中的重要应用，与传统DRAM相比提供的优势，以及计算世界中内存配置的未来。欢迎来到HBM知识之门。\u003c/p\u003e\n\u003cp\u003eHBM市场规模在2022年价值28亿美元。HBM市场行业预计将从2023年的35.3亿美元增长到2032年的225.73亿美元，在预测期内（2024 - 2032年）的复合年增长率（CAGR）为26.10%。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eHBM主要特性 \n    \u003cdiv id=\"hbm%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#hbm%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eHBM已经彻底改变了高性能计算系统管理数据流的方式。与传统内存解决方案相比，其最显著的特性之一是带宽显著增加。HBM通过使用TSV和微凸点连接的堆叠DRAM芯片来实现这一目标。这种创新的设计允许更短的数据路径，从而提高数据速度和能效。\u003c/p\u003e","title":"HBM终极指南","type":"hardware"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/computing-power/","section":"Tags","summary":"","title":"Computing Power","type":"tags"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/flops/","section":"Tags","summary":"","title":"FLOPS","type":"tags"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/tops/","section":"Tags","summary":"","title":"TOPS","type":"tags"},{"content":"算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：\n算力的计算方式 # FLOPS # FLOPS（Floating Point Operations Per Second）来衡量算力通常以每秒钟可以执行的浮点运算次数。常见的FLOPS的计算算力单位根据数量级还有不同的表达，具体如下：\nKFLOPS-kilo Floating Point Operations Per Second（千次浮点运算每秒） MFLOPS-Mega Floating Point Operations Per Second（百万次浮点运算每秒） GFLOPS-Giga Floating Point Operations Per Second（十亿次浮点运算每秒） TFLOPS-Tera Floating Point Operations Per Second（万亿次浮点运算每秒） PFLOPS-Peta Floating Point Operations Per Second（千万亿次浮点运算每秒） FLOPS的计算方式：计算机的算力取决于处理器的性能、核心数量、频率以及并行计算能力等因素。一般来说，可以通过以下公式来计算处理器的FLOPS数值：算力 = 处理器核心数量 x 每个核心的频率 x 每个时钟周期的指令数量 x 每个指令的执行\n例如，如果一台处理器有4个核心，每个核心的频率为3.5 GHz，每个时钟周期执行4条指令，每条指令的执行时间为0.5纳秒，则该处理器的算力为：算力 = 4核 x 3.5 GHz x 4 x (0.5 ns) = 56 GFLOPS\nTOPS # TOPS（Tera Operations Per Second）是指每秒进行的万亿次运算，是衡量人工智能（AI）处理器性能的重要指标，也是评估处理器在深度学习和神经网络推理任务中的计算能力的重要指标。\n计算TOPS的基本原理是根据处理器的时钟频率、每个时钟周期执行的指令数量以及每个指令的计算量来计算。一般来说，可以使用以下公式来计算处理器的TOPS：TOPS = 处理器时钟频率 x 每个时钟周期的指令数量 x 每个指令的计算量\n其中，处理器时钟频率表示处理器的工作频率，每个时钟周期的指令数量表示每个时钟周期处理器执行的指令数量，每个指令的计算量表示每个指令的浮点运算量。\n某些情况下我们也是通过TOPS/W来评价处理器算力的一个性能指标，表达的含义是在1W功耗的情况下处理器可以执行多少亿万次操作。\nMIPS # MIPS（Million Instructions Per Second）是指每秒钟能够执行的指令数，单位为百万条指令每秒（Million Instructions Per Second）。\n计算MIPS的方法如下：\n首先，确定在一个特定时间段内处理器执行的总指令数（例如1秒内）。 将总指令数除以1,000,000（即1百万），得到每秒钟能够执行的指令数，即MIPS值。 举例说明：\n假设一个处理器在1秒钟内执行了总共500,000条指令，那么它的MIPS值为：\nMIPS = 500,000 / 1,000,000 = 0.5 MIPS这表示该处理器每秒钟能够执行0.5百万条指令。通过计算MIPS值，可以评估处理器的指令执行速度和性能表现，但是对于特定的应用场景和任务可能不是最准确的性能指标。\nDMIPS # DMIPS（Dhrystone Million Instructions Per Second）是指每秒钟能够执行的Dhrystone基准测试指令数，单位为百万条指令每秒。Dhrystone是一种通用的CPU性能测试工具，DMIPS是基于Dhrystone测试结果计算得出的性能指标。DMIPS更适用于衡量通用处理器在特定测试条件下的性能，可以提供更具体的性能评估结果。\n计算DMIPS的方法如下：\n首先，进行Dhrystone基准测试，得到处理器在测试条件下执行的总指令数（例如1秒内）。 将总指令数除以1,000,000（即1百万），得到每秒钟能够执行的Dhrystone基准测试指令数，即DMIPS值。 举例说明：\n假设一个处理器在进行Dhrystone基准测试时，在1秒钟内执行了总共800,000条指令，那么它的DMIPS值为：\nDMIPS = 800,000 / 1,000,000 = 0.8 DM\n这表示该处理器在Dhrystone基准测试条件下，每秒钟能够执行0.8百万条指令。通过计算DMIPS值，可以评估处理器在特定测试条件下的性能现。\nHash/ # \u0026ldquo;hash/s\u0026quot;通常用来衡量计算机或网络设备的哈希计算速度，特别是在加密货币挖矿等领域常被使用。基本原理是通过计算机执行哈希函数并输出哈希值的速度来衡量设备的计算能力。\n哈希函数是一种将任意长度的输入数据（消息）转换为固定长度的输出数据（哈希值）的函数。在加密货币挖矿中，通常会使用哈希函数来寻找符合特定条件的哈希值，这需要大量的计算。\n计算\u0026quot;hash/s\u0026quot;的算力通常是通过以下步骤进行估算：\n选择哈希函数：确定要使用的哈希函数，如SHA-256（比特币挖矿中常用的哈希函数）。 执行哈希计算：在设备上执行哈希函数，将输入数据进行哈希运算，得到哈希值。 计算速度：记录设备在单位时间内执行哈希计算的次数，即\u0026quot;hash/s\u0026rdquo;。 例如，如果一个计算机在1秒内执行了100,000次SHA-256哈希计算，那么它的哈希计算速度就是100,000 hash/s。这个速度可以用来衡量设备的计算能力，特别是在加密货币挖矿等需要\n总结 # ","date":"2024-10-24","externalUrl":null,"permalink":"/ai/computer-computing-power-unit-introduction/","section":"Ais","summary":"\u003cp\u003e算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e算力的计算方式 \n    \u003cdiv id=\"%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Computing-Power-1.png\" alt=\"Computer Computing Power\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"计算机算力单位简介","type":"ai"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/blackwell/","section":"Tags","summary":"","title":"Blackwell","type":"tags"},{"content":"最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。\n微软 # 微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。\n看上去右边三分之二的区域用于冷却。\n谷歌 # 谷歌也是通过社交网络X发布的图片，谷歌表示这是在实验室中正在进行的定制GB200 NVL机架，更多信息将在10月30日的举行的谷歌云应用开发和基础设施峰会展示。\n谷歌没有披露采用了什么样的网络，可能不是Infiniband网络。\n相比微软的机架方案，这个只占有两个机架的空间。\nMeta # 在上周的2024 年开放计算项目 (OCP) 峰会上，Meta展示了基于NVIDIA Blackwell 平台全机架解决方案Catalina。其重点关注模块化和灵活性，旨在支持最新的 NVIDIA GB200 Grace Blackwell Superchip，确保满足现代 AI 基础设施日益增长的需求。\n这款机架能够支持高达140kW的功率。完整的解决方案采用液冷，由支持计算托盘、交换机托盘、Orv3 HPR、Wedge 400结构交换机、管理交换机、电池备用单元和机架管理控制器的电源架组成。\n下面是Catalina的正面图和后视图，我们可以看到，这个机架解决方案只用了一个机架空间。\n","date":"2024-10-24","externalUrl":null,"permalink":"/ai/several-rack-solutions-for-nvidia-blackwell-platform/","section":"Ais","summary":"\u003cp\u003e最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e微软 \n    \u003cdiv id=\"%E5%BE%AE%E8%BD%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BE%AE%E8%BD%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。\u003c/p\u003e","title":"Nvidia Blackwell的几款机架服务器解决方案","type":"ai"},{"content":"据彭博社报道，Arm已正式向高通发出通知，将取消双方之间的架构许可协议。这一决定正值两家公司之间的法律纠纷愈演愈烈之际，引发了业界的广泛关注。\n报道称，Arm已向高通发出了60天的强制通知，取消允许高通基于Arm拥有的标准设计并制造自己的芯片的许可协议。\n高通每年销售的处理器数量高达数亿片，其技术被广泛应用于大多数安卓智能手机中。一旦该终止生效，高通可能不得不停止销售占其总收入约390亿美元重要份额的产品，否则将面临巨额的赔偿风险。\n双方关系的恶化可追溯到2021年高通宣布的14亿美元收购芯片设计公司Nuvia的交易。2022年8月，Arm在特拉华州提起诉讼，指控高通在未进行新许可谈判的情况下，利用从Nuvia收购的技术进行开发，这违反了双方的授权协议，并要求赔偿。\n对于Arm的这一举措，高通发言人通过电子邮件声明表示：“这是Arm的一贯伎俩，其不断发出毫无根据的威胁，试图强迫长期合作伙伴，干扰我们性能领先的CPU，并提高专利费率，而不顾我们根据架构许可所享有的权利。随着12月审判的临近，Arm的行为似乎是在试图破坏法律程序。其终止诉讼的要求完全没有根据。我们相信，高通根据与Arm的协议所享有的权利将得到肯定。Arm的反竞争行为是不能容忍的。”\n然而，Arm方面拒绝对此报道发表评论。\n这场法律战定于12月在特拉华州联邦法院开庭。如果Arm在诉讼中胜诉，可能会迫使高通及其约20家合作伙伴（包括微软）停止出货新笔记本电脑。此外，这也将使高通近年来最大的战略收购之一——对Nuvia的收购功亏一篑。\n尽管两家公司在公开场合争斗激烈，但一些投资者和分析师仍相信，他们有可能在审判前达成和解。毕竟，这两家公司相互依赖，且都面临着巨大的收入和利润压力。未来，这场法律战的结果将如何影响整个半导体行业，仍值得我们密切关注。\n","date":"2024-10-24","externalUrl":null,"permalink":"/hardware/arm-holdings-to-cancel-qualcomm-chip-design-license/","section":"Hardwares","summary":"\u003cp\u003e据彭博社报道，Arm已正式向高通发出通知，将取消双方之间的架构许可协议。这一决定正值两家公司之间的法律纠纷愈演愈烈之际，引发了业界的广泛关注。\u003c/p\u003e\n\u003cp\u003e报道称，Arm已向高通发出了60天的强制通知，取消允许高通基于Arm拥有的标准设计并制造自己的芯片的许可协议。\u003c/p\u003e\n\u003cp\u003e高通每年销售的处理器数量高达数亿片，其技术被广泛应用于大多数安卓智能手机中。一旦该终止生效，高通可能不得不停止销售占其总收入约390亿美元重要份额的产品，否则将面临巨额的赔偿风险。\u003c/p\u003e\n\u003cp\u003e双方关系的恶化可追溯到2021年高通宣布的14亿美元收购芯片设计公司Nuvia的交易。2022年8月，Arm在特拉华州提起诉讼，指控高通在未进行新许可谈判的情况下，利用从Nuvia收购的技术进行开发，这违反了双方的授权协议，并要求赔偿。\u003c/p\u003e\n\u003cp\u003e对于Arm的这一举措，高通发言人通过电子邮件声明表示：“这是Arm的一贯伎俩，其不断发出毫无根据的威胁，试图强迫长期合作伙伴，干扰我们性能领先的CPU，并提高专利费率，而不顾我们根据架构许可所享有的权利。随着12月审判的临近，Arm的行为似乎是在试图破坏法律程序。其终止诉讼的要求完全没有根据。我们相信，高通根据与Arm的协议所享有的权利将得到肯定。Arm的反竞争行为是不能容忍的。”\u003c/p\u003e\n\u003cp\u003e然而，Arm方面拒绝对此报道发表评论。\u003c/p\u003e\n\u003cp\u003e这场法律战定于12月在特拉华州联邦法院开庭。如果Arm在诉讼中胜诉，可能会迫使高通及其约20家合作伙伴（包括微软）停止出货新笔记本电脑。此外，这也将使高通近年来最大的战略收购之一——对Nuvia的收购功亏一篑。\u003c/p\u003e\n\u003cp\u003e尽管两家公司在公开场合争斗激烈，但一些投资者和分析师仍相信，他们有可能在审判前达成和解。毕竟，这两家公司相互依赖，且都面临着巨大的收入和利润压力。未来，这场法律战的结果将如何影响整个半导体行业，仍值得我们密切关注。\u003c/p\u003e","title":"Arm将取消高通架构许可协议","type":"hardware"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/qualcomm/","section":"Tags","summary":"","title":"Qualcomm","type":"tags"},{"content":"在Linux中，竖线（|，也称为管道符）是一个非常强大的工具，尤其在命令行操作中。它允许将一个命令的输出传递给另一个命令作为输入，从而实现将多个命令组合成一个流式的操作。本文将通过一些例子，展示竖线的作用和实际应用，带你更好地理解如何利用它提升工作效率。\n管道的基本概念 # Linux中的管道是一种将一个命令的标准输出（stdout）连接到另一个命令的标准输入（stdin）的方式。通俗点说，就是把第一个命令的“结果”直接交给第二个命令处理，而不是中途保存到文件。\n例如，使用管道可以将文件内容通过cat命令输出，并通过grep命令进行筛选：\ncat file.txt | grep \u0026#34;keyword\u0026#34; 这里，cat file.txt将文件内容显示出来，而竖线将内容交给grep，它会搜索包含“keyword”的行。这种方式避免了多次存储临时文件，让命令更加简洁流畅。\n统计特定日志出现的次数 # 在服务器维护过程中，我们经常需要分析日志文件，看看某个错误信息出现了多少次。假设我们有一个日志文件error.log，我们想统计其中包含\u0026quot;ERROR\u0026quot;的行数。\ncat error.log | grep \u0026#34;ERROR\u0026#34; | wc -l cat error.log：显示日志文件的内容。 grep \u0026quot;ERROR\u0026quot;：从日志中筛选出包含\u0026quot;ERROR\u0026quot;的行。 wc -l：统计行数，即\u0026quot;ERROR\u0026quot;出现的次数。 这个命令通过三步操作轻松实现了日志分析，非常实用。\n显示当前目录中文件最多的前三个扩展名 # 在开发中，我们可能会遇到一个目录里有大量不同类型的文件，想要统计其中哪个文件类型最多。通过管道组合命令，我们可以快速得出结果：\nls -l | awk \u0026#39;{print $NF}\u0026#39; | rev | cut -d. -f1 | rev | sort | uniq -c | sort -nr | head -n 3 ls -l：列出当前目录的文件。 awk '{print $NF}'：提取文件名。 rev | cut -d. -f1 | rev：通过cut和rev组合，获取文件的扩展名。 sort：对扩展名排序。 uniq -c：统计每个扩展名出现的次数。 sort -nr：按出现次数排序，次数多的排在前面。 head -n 3：取前3个扩展名。 通过管道的组合，一行命令完成了一个较为复杂的统计分析任务。\n查看端口占用情况并杀掉对应进程 # 服务器上有时候需要检查某个端口是否被占用并结束对应的进程。例如，我们需要查看80端口的占用情况并终止相应的进程：\nsudo netstat -tuln | grep \u0026#39;:80\u0026#39; | awk \u0026#39;{print $7}\u0026#39; | cut -d/ -f1 | xargs sudo kill -9 netstat -tuln：显示所有监听的TCP/UDP端口。 grep ':80'：筛选出80端口的相关信息。 awk '{print $7}'：提取出对应的进程ID（PID）。 cut -d/ -f1：进一步提取出纯数字的PID。 xargs sudo kill -9：通过xargs将PID传递给kill -9命令，终止该进程。 这个命令可以快速解决端口占用问题。\n将命令输出保存到文件并统计行数 # 有时，我们不仅想查看某个命令的输出，还想将其保存到文件中并进一步处理。比如，我们可以将一个ps命令的输出保存到文件，然后统计文件中的行数：\nps aux | tee output.txt | wc -l ps aux：列出当前系统的所有进程。 tee output.txt：将输出同时保存到文件output.txt中，并继续传递给下一个命令。 wc -l：统计行数，显示当前运行的进程数。 tee命令在这里的作用是让输出同时保存到文件和传递给管道的下一个命令，实现了一石二鸟的效果。\n管道符|在Linux中极大地增强了命令行的灵活性，它使得多个命令可以串联在一起工作，避免了使用临时文件或重复操作。在实际开发、运维过程中，通过巧妙地使用管道，能极大提高工作效率。例如日志分析、数据统计、进程管理等常见任务，都可以通过组合简单的命令行工具快速完成。\n管道的魅力在于它的简单性与可组合性——每个命令只需专注于自己的输入和输出，管道则负责将这些命令连接起来，形成强大的操作链。每个人都可以根据自己的需求和场景，创建独特的管道组合，让Linux的命令行变成真正的“魔法棒”。\n","date":"2024-10-23","externalUrl":null,"permalink":"/software/introduction-to-linux-pipe/","section":"Softwares","summary":"\u003cp\u003e在Linux中，竖线（\u003ccode\u003e|\u003c/code\u003e，也称为管道符）是一个非常强大的工具，尤其在命令行操作中。它允许将一个命令的输出传递给另一个命令作为输入，从而实现将多个命令组合成一个流式的操作。本文将通过一些例子，展示竖线的作用和实际应用，带你更好地理解如何利用它提升工作效率。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e管道的基本概念 \n    \u003cdiv id=\"%E7%AE%A1%E9%81%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%A1%E9%81%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux中的管道是一种将一个命令的标准输出（stdout）连接到另一个命令的标准输入（stdin）的方式。通俗点说，就是把第一个命令的“结果”直接交给第二个命令处理，而不是中途保存到文件。\u003c/p\u003e\n\u003cp\u003e例如，使用管道可以将文件内容通过\u003ccode\u003ecat\u003c/code\u003e命令输出，并通过\u003ccode\u003egrep\u003c/code\u003e命令进行筛选：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat file.txt \u003cspan class=\"p\"\u003e|\u003c/span\u003e grep \u003cspan class=\"s2\"\u003e\u0026#34;keyword\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这里，\u003ccode\u003ecat file.txt\u003c/code\u003e将文件内容显示出来，而竖线将内容交给\u003ccode\u003egrep\u003c/code\u003e，它会搜索包含“keyword”的行。这种方式避免了多次存储临时文件，让命令更加简洁流畅。\u003c/p\u003e","title":"Linux 管道Pipe简介","type":"software"},{"content":"","date":"2024-10-23","externalUrl":null,"permalink":"/tags/router/","section":"Tags","summary":"","title":"Router","type":"tags"},{"content":" Router是什么 # 路由器（Router）是一个用于连接不同网络的设备，它的主要作用是连接不同网络。路由器通常工作在 OSI 模型的第三层（网络层），负责管理数据包的路径选择和转发。\n主要特性 # IP 转发：Linux 内核支持 IP 包的转发功能，能够将数据包从一个网络接口转发到另一个接口。通过简单的配置可以实现基本的路由器功能。 流量控制和管理：Linux 路由器可以使用 tc（Traffic Control）工具来管理网络带宽，限制流量，进行流量优先级排序，防止网络拥塞。 VPN 支持：Linux 路由器可以通过 OpenVPN、IPsec 等协议实现虚拟专用网（VPN）功能，建立安全的网络隧道，保护数据在公网上传输。 QoS（服务质量）：可以使用 tc 或类似的工具实现 QoS 功能，优先处理特定类型的网络流量，确保关键应用的带宽和延迟需求得到满足。 动态路由协议：Linux 支持动态路由协议，如 OSPF（开放式最短路径优先协议）、BGP（边界网关协议）等。通过使用软件如 Quagga 或 FRRouting（FRR），可以实现复杂的大规模动态路由环境。 DHCP 和 DNS 服务：Linux 路由器可以配置为 DHCP 服务器，自动为内部网络分配 IP 地址。同时，它也可以运行 DNS 服务（如 dnsmasq），提供 DNS 解析和缓存功能。 工作机制 # IP 包的转发： Linux 路由器的核心工作机制是 IP 包的转发功能。启用 IP 转发后，Linux 内核会在接收到数据包时根据路由表决定下一跳。 内核查找路由表，确定数据包的目的地，并根据路由表中的信息将数据包从一个接口转发到下一个网络。 路由表的管理： 路由器使用路由表来决定数据包的转发路径。Linux 系统通过 ip route 命令可以配置和查看路由表。路由表中包含目标网络、下一跳设备和出口接口等信息。 路由表可以通过手动静态配置，也可以通过动态路由协议（如 OSPF 或 BGP）自动更新。 动态路由协议： 动态路由协议（如 OSPF、BGP）可在多台路由器之间动态交换路由信息。通过 FRRouting 等软件实现，Linux 可以参与动态路由网络，自动调整路由表，适应网络变化。 常见应用场景 # Linux 路由器通常应用于网络虚拟化中。如：虚拟专用网络（VPN）网关、流量控制和负载均衡、动态路由器和核心路由器。\n实现步骤 # 路由器的核心功能是转发数据包，因此需要在 Linux 上开启 IP 转发功能。\n临时启用 IP 转发（物理机重启后失效） echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 永久开启 IP 转发（物理机重启后仍然生效） 修改系统配置\nsudo vim /etc/sysctl.conf 将以下内容取消注释或条件\nnet.ipv4.ip_forward = 1 使配置生效\nsudo sysctl -p ","date":"2024-10-23","externalUrl":null,"permalink":"/software/how-to-implement-router-function-on-linux/","section":"Softwares","summary":"\u003ch2 class=\"relative group\"\u003eRouter是什么 \n    \u003cdiv id=\"router%E6%98%AF%E4%BB%80%E4%B9%88\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#router%E6%98%AF%E4%BB%80%E4%B9%88\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e路由器（Router）是一个用于连接不同网络的设备，它的主要作用是连接不同网络。路由器通常工作在 OSI 模型的第三层（网络层），负责管理数据包的路径选择和转发。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e主要特性 \n    \u003cdiv id=\"%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eIP 转发：Linux 内核支持 IP 包的转发功能，能够将数据包从一个网络接口转发到另一个接口。通过简单的配置可以实现基本的路由器功能。\u003c/li\u003e\n\u003cli\u003e流量控制和管理：Linux 路由器可以使用 tc（Traffic Control）工具来管理网络带宽，限制流量，进行流量优先级排序，防止网络拥塞。\u003c/li\u003e\n\u003cli\u003eVPN 支持：Linux 路由器可以通过 OpenVPN、IPsec 等协议实现虚拟专用网（VPN）功能，建立安全的网络隧道，保护数据在公网上传输。\u003c/li\u003e\n\u003cli\u003eQoS（服务质量）：可以使用 tc 或类似的工具实现 QoS 功能，优先处理特定类型的网络流量，确保关键应用的带宽和延迟需求得到满足。\u003c/li\u003e\n\u003cli\u003e动态路由协议：Linux 支持动态路由协议，如 OSPF（开放式最短路径优先协议）、BGP（边界网关协议）等。通过使用软件如 Quagga 或 FRRouting（FRR），可以实现复杂的大规模动态路由环境。\u003c/li\u003e\n\u003cli\u003eDHCP 和 DNS 服务：Linux 路由器可以配置为 DHCP 服务器，自动为内部网络分配 IP 地址。同时，它也可以运行 DNS 服务（如 dnsmasq），提供 DNS 解析和缓存功能。\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e工作机制 \n    \u003cdiv id=\"%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eIP 包的转发：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eLinux 路由器的核心工作机制是 IP 包的转发功能。启用 IP 转发后，Linux 内核会在接收到数据包时根据路由表决定下一跳。\u003c/li\u003e\n\u003cli\u003e内核查找路由表，确定数据包的目的地，并根据路由表中的信息将数据包从一个接口转发到下一个网络。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e路由表的管理：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e路由器使用路由表来决定数据包的转发路径。Linux 系统通过 \u003ccode\u003eip route\u003c/code\u003e 命令可以配置和查看路由表。路由表中包含目标网络、下一跳设备和出口接口等信息。\u003c/li\u003e\n\u003cli\u003e路由表可以通过手动静态配置，也可以通过动态路由协议（如 OSPF 或 BGP）自动更新。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e动态路由协议：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e动态路由协议（如 OSPF、BGP）可在多台路由器之间动态交换路由信息。通过 FRRouting 等软件实现，Linux 可以参与动态路由网络，自动调整路由表，适应网络变化。\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e常见应用场景 \n    \u003cdiv id=\"%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux 路由器通常应用于网络虚拟化中。如：虚拟专用网络（VPN）网关、流量控制和负载均衡、动态路由器和核心路由器。\u003c/p\u003e","title":"如何在 Linux 上实现 Router 功能","type":"software"},{"content":"TFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于局域网中的小文件传输，如嵌入式系统的固件更新。以下是在Linux系统中配置TFTP服务器的详细步骤。\n安装TFTP服务 # 首先，您需要安装TFTP服务器软件。在基于Debian的系统（如Ubuntu）上，您可以使用以下命令安装tftpd-hpa：\nsudo apt-get update sudo apt-get install tftpd-hpa 对于基于RPM的系统（如CentOS），使用以下命令：\nsudo yum install tftp-server 配置TFTP服务器 # 安装完成后，您需要配置TFTP服务器。配置文件通常位于/etc/default/tftpd-hpa。\n编辑配置文件：\nsudo nano /etc/default/tftpd-hpa 在配置文件中，您可以设置以下参数：\nTFTP_USERNAME: 运行TFTP服务的用户，通常是tftp TFTP_DIRECTORY: TFTP服务的根目录，通常是/srv/tftp或/var/lib/tftpboot TFTP_ADDRESS: TFTP服务监听的地址和端口，通常是0.0.0.0:69 TFTP_OPTIONS: TFTP服务的额外选项，如--secure --create 例如：\nTFTP_USERNAME=\u0026#34;tftp\u0026#34; TFTP_DIRECTORY=\u0026#34;/srv/tftp\u0026#34; TFTP_ADDRESS=\u0026#34;0.0.0.0:69\u0026#34; TFTP_OPTIONS=\u0026#34;--secure --create\u0026#34; 创建TFTP根目录 # 创建TFTP服务的根目录，并设置适当的权限：\nsudo mkdir -p /srv/tftp sudo chmod 777 /srv/tftp 重启TFTP服务 # 配置完成后，重启TFTP服务以应用更改：\nsudo systemctl restart tftpd-hpa 测试TFTP服务 # 要测试TFTP服务器，您可以使用TFTP客户端软件。在客户端机器上，使用以下命令连接到TFTP服务器：\ntftp \u0026lt;服务器IP地址\u0026gt; 然后，您可以使用get命令下载文件，或使用put命令上传文件。\n注意事项 # TFTP协议不提供任何身份验证或加密，因此请确保只在受信任的网络内使用 出于安全考虑，您可以在TFTP_OPTIONS中使用--secure选项，以防止目录遍历攻击 如果需要允许客户端上传文件，可以在TFTP_OPTIONS中添加--create选项 通过以上步骤，您可以在Linux系统上成功配置TFTP服务器，以便在局域网中进行简单的文件传输。\n","date":"2024-10-22","externalUrl":null,"permalink":"/software/how-to-configure-tftp-server-in-linux/","section":"Softwares","summary":"\u003cp\u003eTFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于局域网中的小文件传输，如嵌入式系统的固件更新。以下是在Linux系统中配置TFTP服务器的详细步骤。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e安装TFTP服务 \n    \u003cdiv id=\"%E5%AE%89%E8%A3%85tftp%E6%9C%8D%E5%8A%A1\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%AE%89%E8%A3%85tftp%E6%9C%8D%E5%8A%A1\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e首先，您需要安装TFTP服务器软件。在基于Debian的系统（如Ubuntu）上，您可以使用以下命令安装tftpd-hpa：\u003c/p\u003e","title":"Linux下如何配置tftp服务器","type":"software"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/tftp/","section":"Tags","summary":"","title":"Tftp","type":"tags"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/9800x3d/","section":"Tags","summary":"","title":"9800X3D","type":"tags"},{"content":"最新的 AMD Ryzen 7 9800X3D 基准测试泄露显示，这款新游戏 CPU 的时钟速度比其前身 7800X3D 快得多。尽管 AMD 3D V 缓存提供了强大的游戏能力，但后者却因 5GHz 的时钟速度而受到限制。然而，这次泄露显示，新款八核 Ryzen 9000X3D 游戏 CPU 的运行速度超过 5.6GHz。\n从CPU-Z的截图可以看到，该处理器达到了惊人的5643.14MHz。在Cinebench R23的基准测试中，有效时钟频率更是达到了5598.4MHz和5689MHz。这表明，在合适的散热条件下，该处理器有可能突破5.7GHz的频率。\n据报道，Ryzen 7 9800X3D的加速时钟频率将达到5.2GHz，比Ryzen 7 7800X3D高出200MHz。在Cinebench R23多核测试中，该处理器取得了25258分的高分，单核得分为2261分。相比之下，Ryzen 7 7800X3D的多核得分在18000-19000分之间，这意味着9800X3D在时钟频率提升至5.6-5.7GHz时，性能提升了约35%。单核性能也比7800X3D高出至少25%。\n虽然目前尚不清楚这些分数在游戏性能上意味着什么，但令人惊讶的是，Ryzen 7 9800X3D的综合性能甚至可能超过Ryzen 7 9700X。通常情况下，非X3D系列的处理器由于更高的时钟频率，在综合基准测试中表现更佳。然而在这次测试中，9800X3D在单核和多核性能上都表现出色，打破了以往的规律。\n根据最新的价格信息，Ryzen 7 9800X3D的售价预计在450至500美元之间，但在正式发布前价格可能会有所调整。此前的传言显示，该处理器将于11月7日正式上市，距离现在大约还有两周时间。\n总体上，AMD Ryzen 7 9800X3D有望在性能和超频能力上带来显著提升，对于追求高性能的用户来说，这无疑是一个令人期待的选择。\n","date":"2024-10-22","externalUrl":null,"permalink":"/hardware/amd-ryzen-7-9800x3d-benchmark-leaked/","section":"Hardwares","summary":"\u003cp\u003e最新的 AMD Ryzen 7 9800X3D 基准测试泄露显示，这款新游戏 CPU 的时钟速度比其前身 7800X3D 快得多。尽管 AMD 3D V 缓存提供了强大的游戏能力，但后者却因 5GHz 的时钟速度而受到限制。然而，这次泄露显示，新款八核 Ryzen 9000X3D 游戏 CPU 的运行速度超过 5.6GHz。\u003c/p\u003e","title":"AMD 锐龙7 9800X3D 核心参数泄露","type":"hardware"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/ryzen-7/","section":"Tags","summary":"","title":"Ryzen 7","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/cpu/","section":"Tags","summary":"","title":"CPU","type":"tags"},{"content":"GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。\n设计目的与功能 # CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。\nGPU：设计目的是为了快速渲染图像和视频，以及进行大规模的并行计算。它专注于图像处理及大型矩阵运算等方面，并凭借强大的并行处理能力在这些领域展现出巨大的优势。\n处理器结构 # CPU：通常拥有少量的处理核心，但每个核心的性能较高。其架构是基于冯·诺依曼体系结构的，包含控制单元、算术逻辑单元、缓存等部分。这种结构使得CPU适合于顺序计算和复杂的控制任务。\nGPU：拥有大量的处理核心（通常以数百甚至数千计），但每个核心的性能较低。其架构是基于数据流体系结构的，包含许多流处理器和专用硬件单元。这种结构使得GPU适合于并行计算和大规模数据处理。\n适用领域 # CPU：广泛应用于各种需要复杂逻辑运算和数据处理的场景中，如操作系统管理、应用软件运行、武器装备运动控制等。\nGPU：在游戏娱乐、影视制作、科学研究和人工智能等领域发挥着重要作用。例如，在游戏娱乐领域，GPU能够为玩家提供流畅、逼真的3D游戏画面和高质量的音频效果；在人工智能领域，GPU则能够加速神经网络的训练和推理过程，提高人工智能系统的性能和效率。\n功耗与散热 # CPU：由于处理核心较少，功耗和散热相对较低。\nGPU：由于拥有大量的处理核心和高性能特性，通常需要较高的功耗和散热设计。显卡通常需要配备强大的散热系统来保持稳定的性能。\n编程模型与框架 # CPU：编程通常使用标准的编程语言和库，如C++和OpenMP。\nGPU：编程通常使用特定的编程模型，如CUDA和OpenCL。这些编程模型允许开发人员编写并行代码，以便可以在GPU上执行。\n性能与效率 # CPU：在处理顺序计算和控制任务时具有较高的性能和效率。\nGPU：在处理并行计算和大规模数据处理时具有更高的性能和效率。其并行计算能力可以大大提高计算速度，从而加快应用程序的执行速度。\n结语 # 综上所述，GPU和CPU在设计目的、处理器结构、适用领域、功耗与散热、编程模型与框架以及性能与效率等方面都存在显著的区别。它们各自承担着不同的任务并发挥着不可替代的作用，共同协作以确保计算机能够高效地运行各种应用程序和任务。\n","date":"2024-10-21","externalUrl":null,"permalink":"/ai/difference-between-cpu-and-gpu/","section":"Ais","summary":"\u003cp\u003eGPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./cpu-vs-gpu.webp\" alt=\"CPU vs GPU\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e设计目的与功能 \n    \u003cdiv id=\"%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eCPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。\u003c/p\u003e","title":"CPU与GPU的区别","type":"ai"},{"content":"AMD正式发布了面向嵌入式系统的新一代EPYC处理器，即EPYC Embedded 8004系列。该系列采用了AMD密度优化的Zen 4c内核，核心数量从12个到64个不等。\nEPYC Embedded 8004系列支持单路处理器配置，通过六个内存通道可支持高达1.152TB的DDR5内存，热设计功耗（TDP）范围在70W到225W之间。AMD表示，该系列的目的是在紧凑且功耗受限的环境中，为高需求的工作负载提供卓越的性能。其目标应用包括网络系统、路由器、安全设备和工业边缘应用等。\n具体型号和规格如下：\nEPYC Embedded 8534P：基础频率2.3GHz，加速频率3.1GHz，64核心128线程，TDP为200W。 EPYC Embedded 8434P：基础频率2.5GHz，加速频率3.1GHz，48核心96线程，TDP为200W。 EPYC Embedded 8324P：基础频率2.65GHz，加速频率3.0GHz，32核心64线程，TDP为180W。 EPYC Embedded 8224P：基础频率2.55GHz，加速频率3.0GHz，24核心48线程，TDP为180W。 EPYC Embedded 8124P：基础频率2.45GHz，加速频率3.0GHz，16核心32线程，TDP为125W。 EPYC Embedded 8C24P：基础频率2.45GHz，加速频率3.0GHz，12核心24线程，TDP为100W。 EPYC Embedded 8004系列是首款采用AMD Zen 4c内核的EPYC处理器。Zen 4c是一种密度优化且注重性能功耗比的架构，将Zen 4架构缩小到更紧凑的封装，并通过降低时钟频率来提高能效。这使得AMD能够在更小的芯片尺寸中集成更多的核心。\n相比采用常规Zen 4内核的EPYC Embedded 9004系列，8004系列更注重功耗管理。Zen 4c系列的规格相比Zen 4有大幅缩减，例如，旗舰型号EPYC Embedded 8534P拥有3.1GHz的加速频率、64个Zen 4c核心和200W的TDP，而EPYC Embedded 9654P则拥有3.7GHz的加速频率、96个核心和360W的TDP。\n8004系列的核心数量更少、频率更低、总体TDP也更低。这种优化还体现在其他方面：由于Zen 4c的密度优化，L3缓存减少了多达三倍，PCIe通道数量减半（64条对比128条），内存通道数量也从12个减少到6个。值得注意的是，虽然AMD在公告中提到TDP低至70W，但规格中最低的是100W。\nAMD表示，EPYC Embedded 8004系列非常适合那些需要在性能、能效、热管理和平台密度之间取得平衡的客户。由于引入了Zen 4c核心，AMD指出8004系列比9004系列的Zen 4芯片尺寸小了19%，更适合用于更小、更紧凑的设备中。\n","date":"2024-10-21","externalUrl":null,"permalink":"/hardware/amd-releases-new-generation-of-epyc-processors-for-embedded-systems/","section":"Hardwares","summary":"\u003cp\u003eAMD正式发布了面向嵌入式系统的新一代EPYC处理器，即\u003ccode\u003eEPYC Embedded 8004\u003c/code\u003e系列。该系列采用了AMD密度优化的\u003ccode\u003eZen 4c\u003c/code\u003e内核，核心数量从12个到64个不等。\u003c/p\u003e\n\u003cp\u003eEPYC Embedded 8004系列支持单路处理器配置，通过六个内存通道可支持高达1.152TB的DDR5内存，热设计功耗（TDP）范围在70W到225W之间。AMD表示，该系列的目的是在紧凑且功耗受限的环境中，为高需求的工作负载提供卓越的性能。其目标应用包括网络系统、路由器、安全设备和工业边缘应用等。\u003c/p\u003e\n\u003cp\u003e具体型号和规格如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEPYC Embedded 8534P：基础频率2.3GHz，加速频率3.1GHz，64核心128线程，TDP为200W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8434P：基础频率2.5GHz，加速频率3.1GHz，48核心96线程，TDP为200W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8324P：基础频率2.65GHz，加速频率3.0GHz，32核心64线程，TDP为180W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8224P：基础频率2.55GHz，加速频率3.0GHz，24核心48线程，TDP为180W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8124P：基础频率2.45GHz，加速频率3.0GHz，16核心32线程，TDP为125W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8C24P：基础频率2.45GHz，加速频率3.0GHz，12核心24线程，TDP为100W。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEPYC Embedded 8004系列是首款采用AMD Zen 4c内核的EPYC处理器。Zen 4c是一种密度优化且注重性能功耗比的架构，将Zen 4架构缩小到更紧凑的封装，并通过降低时钟频率来提高能效。这使得AMD能够在更小的芯片尺寸中集成更多的核心。\u003c/p\u003e","title":"AMD发布面向嵌入式系统的新一代EPYC处理器","type":"hardware"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/epyc-embedded-8004/","section":"Tags","summary":"","title":"EPYC Embedded 8004","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/zen-4c/","section":"Tags","summary":"","title":"Zen 4c","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/apo/","section":"Tags","summary":"","title":"APO","type":"tags"},{"content":"英特尔近日宣布，其专属应用程序优化软件（APO）现已支持多达26款游戏，包括众多电子竞技类和3A大作。这些游戏在最新的第14代酷睿处理器和Core Ultra 200S系列上将获得更佳的性能优化。\nAPO软件与英特尔动态调优技术（DTT）相结合，可以提升硬件的性能、电池寿命和温度管理。通过实时识别并将资源分配给最需要的应用程序，APO能够为游戏带来更流畅的运行体验。\n新增支持的游戏名单包括：\n《英雄连3》 《反恐精英2》 《赛博朋克2077》 《尘埃5》 《Dota 2》 《梦幻三国2》（中国） 《F1 22》 《最终幻想14：终局之诗》 《Fortnite》 《银河护卫队》 《地铁：离去》 《永劫无间》 《荒野大镖客2》 《裂隙破坏者》 《英雄萨姆4》 《古墓丽影：暗影》 《奇异旅程》（VLK） 《小缇娜的奇幻之地》 《汤姆·克兰西的彩虹六号：围攻》 《全面战争：法老》 《全面战争：三国》 《全面战争：战锤3》 《看门狗：军团》 《坦克世界》 《魔兽世界》 《僵尸世界大战》 其中，《反恐精英2》和《Dota 2》等游戏在Steam平台上拥有数十万的实时在线玩家，是最受欢迎的游戏之一。新增的《赛博朋克2077》、《荒野大镖客2》、《古墓丽影：暗影》等3A大作，将在最新的英特尔硬件上运行得更加顺畅，特别是Core Ultra 200S系列芯片。\n目前，只有第12代、第13代和第14代酷睿处理器可以充分利用英特尔APO，许多用户已成功提升了性能。需要注意的是，APO与Core Ultra 200S（Ultra 7和Ultra 9）以及第14代Core i7和Core i9处理器的兼容性最佳。\n对于移动端处理器，只有Core i7-14700HX和Core i9-14900HX完全支持APO。其他处理器，包括Core Ultra 5、第14代及以后的Core i5，以及所有第12代和第13代处理器，仅提供有限的高级模式支持。\n以下是经过验证的支持英特尔APO的处理器：\n桌面处理器： # Core Ultra 9 处理器 285K Core Ultra 7 处理器 265K Core Ultra 7 处理器 265KF Core i9 处理器 14900KS Core i9 处理器 14900K Core i9 处理器 14900KF Core i7 处理器 14700K Core i7 处理器 14700KF 移动处理器： # Core i9 处理器 14900HX Core i7 处理器 14700HX 英特尔APO的更新将为广大游戏玩家带来更佳的体验，充分发挥最新处理器的性能潜力。可以看出英特尔在优化硬件性能和满足用户需求方面的不懈努力。\n","date":"2024-10-21","externalUrl":null,"permalink":"/software/intel-announces-apo-supports-26-games/","section":"Softwares","summary":"\u003cp\u003e英特尔近日宣布，其专属应用程序优化软件（APO）现已支持多达26款游戏，包括众多电子竞技类和3A大作。这些游戏在最新的第14代酷睿处理器和Core Ultra 200S系列上将获得更佳的性能优化。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eAPO\u003c/code\u003e软件与英特尔动态调优技术（\u003ccode\u003eDTT\u003c/code\u003e）相结合，可以提升硬件的性能、电池寿命和温度管理。通过实时识别并将资源分配给最需要的应用程序，APO能够为游戏带来更流畅的运行体验。\u003c/p\u003e\n\u003cp\u003e新增支持的游戏名单包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e《英雄连3》\u003c/li\u003e\n\u003cli\u003e《反恐精英2》\u003c/li\u003e\n\u003cli\u003e《赛博朋克2077》\u003c/li\u003e\n\u003cli\u003e《尘埃5》\u003c/li\u003e\n\u003cli\u003e《Dota 2》\u003c/li\u003e\n\u003cli\u003e《梦幻三国2》（中国）\u003c/li\u003e\n\u003cli\u003e《F1 22》\u003c/li\u003e\n\u003cli\u003e《最终幻想14：终局之诗》\u003c/li\u003e\n\u003cli\u003e《Fortnite》\u003c/li\u003e\n\u003cli\u003e《银河护卫队》\u003c/li\u003e\n\u003cli\u003e《地铁：离去》\u003c/li\u003e\n\u003cli\u003e《永劫无间》\u003c/li\u003e\n\u003cli\u003e《荒野大镖客2》\u003c/li\u003e\n\u003cli\u003e《裂隙破坏者》\u003c/li\u003e\n\u003cli\u003e《英雄萨姆4》\u003c/li\u003e\n\u003cli\u003e《古墓丽影：暗影》\u003c/li\u003e\n\u003cli\u003e《奇异旅程》（VLK）\u003c/li\u003e\n\u003cli\u003e《小缇娜的奇幻之地》\u003c/li\u003e\n\u003cli\u003e《汤姆·克兰西的彩虹六号：围攻》\u003c/li\u003e\n\u003cli\u003e《全面战争：法老》\u003c/li\u003e\n\u003cli\u003e《全面战争：三国》\u003c/li\u003e\n\u003cli\u003e《全面战争：战锤3》\u003c/li\u003e\n\u003cli\u003e《看门狗：军团》\u003c/li\u003e\n\u003cli\u003e《坦克世界》\u003c/li\u003e\n\u003cli\u003e《魔兽世界》\u003c/li\u003e\n\u003cli\u003e《僵尸世界大战》\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e其中，《反恐精英2》和《Dota 2》等游戏在Steam平台上拥有数十万的实时在线玩家，是最受欢迎的游戏之一。新增的《赛博朋克2077》、《荒野大镖客2》、《古墓丽影：暗影》等3A大作，将在最新的英特尔硬件上运行得更加顺畅，特别是Core Ultra 200S系列芯片。\u003c/p\u003e","title":"英特尔宣布APO支持26款游戏","type":"software"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/xscape/","section":"Tags","summary":"","title":"Xscape","type":"tags"},{"content":"据传言，Nvidia 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 NVLink 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。\n由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。\n无论你是否知道，哥伦比亚大学都是互连和光子学的温床。\nAl Gara 教授和 Norman Christ 教授构建了一台采用 DSP 驱动的超级计算机，该计算机具有专有互连功能，可运行量子色动力学应用程序，并于 1998 年荣获戈登贝尔奖。这项 QCDSP 系统研究为 IBM 的 BlueGene 大规模并行超级计算机奠定了基础，Gara 是该超级计算机的首席架构师。（Gara 转投英特尔，也是其假定继任者——阿贡国家实验室的“Aurora”超级计算机的架构师。）\n哥伦比亚大学有一组完全不同的研究人员致力于硅光子学研究，他们中的许多人联手创建了 Xscape Photonics。该公司联合创始人之一、光波研究实验室负责人 Keren Bergman一直在利用光子学降低系统中数据传输的能量。联合创始人 Alex Gaeta 是这家初创公司的总裁，他最初担任首席执行官，在量子和非线性光子学方面做了基础性工作，即参量放大器和光频梳发生器。联合创始人 Michal Lipson 发明了一些关键的光子学元件，例如微环调制器和纳米锥耦合器。联合创始人 Yoshi Okawachi 是光频梳这一特殊激光器的专家。\n有趣的是，当这些哥伦比亚大学的研究人员决定将他们的光互连理念商业化时，他们选择了 Xscape 的联合创始人之一、并非来自哥伦比亚大学的维韦克·拉古纳坦 (Vivek Raghunathan) 担任首席执行官，因为加埃塔 (Gaeta) 决定减少自己的职责，重返大学教授职位。\nRaghunathan 来自麻省理工学院，在那里获得了材料科学与工程学位，Xscape 的一些同事也曾在此工作过；他在麻省理工学院担任了六年的研究助理，参与了各种硅光子学项目，并于 2013 年加入英特尔，担任亚利桑那州钱德勒代工厂的高级封装研发工程师。Raghunathan 一步步晋升，领导开发了英特尔首款 100 Gb/秒以太网光收发器，并致力于其 GPU 到 HBM 互连。Raghunathan 曾在 Rockley Photonics 担任工程师，然后于 2019 年加入博通，担任“Humbolt”共封装光学器件的负责人，该器件用于 25.6 Tb/秒的 Tomahawk 4 交换机 ASIC 变体，由腾讯和字节跳动在中国部署。Raghunathan 启动了 52.6 Tb/秒 Tomahawk 5 代“Bailly”后续 CPO 项目，但在完成之前离开并加入了 Xscape。\n本周的重磅新闻是，Xscape 在 A 轮风险投资中筹集了 4400 万美元，此前该公司于 2022 年成立后进行了 1300 万美元的种子轮融资。此次融资由 IAG Capital Partners 领投。有趣的是，HyperWorks 计算机辅助工程工具的创造者 Altair 是投资者之一，其创始人之一也是哥伦比亚大学的校友，也是工程学院的董事会成员。思科投资、Fathom Fund、Kyra Ventures、LifeX Ventures、Nvidia 和 Osage University Partners 也参与了投资。\nNvidia 的投资很有意思，因为需要将大量的 GPU 连接在一起，而这家 GPU 巨头在 3 月份宣布使用“Blackwell”B100 GPU 加速器推出的 GB200 NVL72 机架式系统中使用铜基 NVLink-NVSwitch 互连能够做到这一点。通过在 GPU 及其内存之间使用光导管，Nvidia 可以将数据中心真正变成一个巨大的虚拟 GPU。你可以打赌，这正是 Nvidia 想要做的事情，并且早在 2022 年，它就暗示了其带有 CPO 概念设计的 NVSwitch。\n无论人工智能加速器的架构如何，它的问题在于，一旦超出给定设备的边缘，计算元素或内存之间的带宽就会开始逐渐减小，而且速度相当快。\n对于任何加速器来说，都需要使用电信号将 HBM堆叠内存放置在非常靠近计算引擎的位置，这意味着你只能在芯片给定的周长内封装这么多东西。（并且你只能将内存堆叠得这么高才能增加容量，即使这样做，也不会增加带宽。只有更快的内存和更多的内存端口才能增加带宽。而且由于 HBM 价格昂贵且供应不足，我们看到 GPU 加速器路线图做了一些奇怪的事情，以匹配有限的内存容量和带宽，以应对有时性能过强的 GPU。\nRaghunathan 说，归根结底，就是数据从加速器中出来的“逃逸速度”，这也是 Xscape Photonics 这个名字的由来。（不要太拘泥于字面意思。）\n这些是我们经常谈论的数字，但最好将它们全部放在一个地方以显示逐渐减小的情况，当您查看 Nvidia GB200 混合集群时，该逐渐减小大约为 160 倍，每个“Grace”CG100 Arm 服务器 CPU 都有两个“Blackwell”GB100 GPU 加速器。带宽逐渐减小是将其中一个 GPU 与 400 Gb/秒 Quantum 2 InfiniBand 端口进行比较，该端口通常用于让 GPU 与集群中及其自身节点之外的其他 GPU 进行通信。\n那么带宽减少会产生什么影响呢？这意味着数据无法足够快地进出 GPU。这会导致非常昂贵的设备的利用率低。\n对于 AI 训练和推理，Raghunathan 引用了 Alexis Bjorlin 的数据，他曾经负责 Meta Platforms 的基础设施，但现在已转任 Nvidia 的 DGX Cloud 总经理。请看：\nRaghunathan 告诉The Next Platform ：“因此，对于训练来说，随着 GPU 的不断扩展，问题已经从 GPU 设备级性能转变为系统级网络问题。根据工作负载，你最终会花费大量时间在 GPU 之间的通信上。在 Meta 展示的图表中，他们讨论了某些工作负载，其中几乎 60% 的时间都花在了网络上。同样，当你考虑推理时，你会看到最先进的 GPU 在进行 ChatGPT 搜索时利用率在 30% 到 40% 之间。这种低 GPU 利用率是我们的客户想要解决的根本问题，因为他们会继续购买数十亿美元的 GPU。”\n这个数学很简单。利用率为 50% 时，峰值计算的百分比是由有限的 GPU 进出带宽预先决定和限制的，这意味着 GPU 的成本是你认为的两倍，这意味着你浪费了一半的钱。\n现在，公平地说，我们非常怀疑全世界的平均 CPU 利用率是否会高于 50%。但平均 CPU 成本也不会达到 30,000 美元。每年大约 1500 万台服务器的平均成本可能接近 1,000 美元。但这仍然是每年数百亿美元的低效浪费。GPU 的浪费比“损失”的资金多出一个数量级，这就是每个人都感到恐慌的原因。\n“我们真正想在 Xscape Photonics 解决的就是带宽逐渐减少的问题，”Raghunathan 说道，他与我们听到的Ayar Labs、Lightmatter、Eliyan、Celestial AI 、 Ultra Accelerator Link 联盟成员等许多公司的意见一致。“我们如何解决这个问题？我们认为，将所有从 GPU 中逸出的电信号直接转换为同一封装中的光信号，并在我们将 GPU 和内存池连接在一起时最大化利用光信号，这是扩展 GPU 性能最具成本效益和能源效率的方法。”\nXscape 团队想出的诀窍是，使用一种激光器，它可以同时从光纤中驱动多种波长，比如多达 128 种不同的颜色，这意味着带宽可能比驱动四种不同颜色的光互连中使用的激光器高 32 倍。此外，Raghunathan 表示，Xscape 的 ChromX 平台方法将使用更简单的调制方案，如 NRZ，它不会像 PAM-4 等高阶调制方案那样影响延迟，近年来，这种方案已用于提高 InfiniBand 和以太网的带宽。\n或许同样重要的是，ChromX 光子平台是可编程的，因此提供的波长数量与特定 AI 训练或推理工作负载的需求以及加速器与其 HBM 内存之间的连接需求相匹配，所有这些都在交换结构基础设施内完成。可编程激光器将率先问世，其概念如下：\n该图表左侧显示了 CWDM4 收发器用于创建 AI 训练集群互连的激光器所需的四种波长。\n中间是制造 LR4 光纤收发器所需的四种不同波长，这种光纤收发器通常用于当您必须使用光纤链路跨越两个数据中心并同步链接它们时，以便可以在两个数据中心上进行训练，就好像它们是一个更大的数据中心一样。\n右边是一个推理引擎，它有一个交换加速器和 HBM 内存复合体，与 Nvidia 对 NVLink 和 NVSwitch 所做的有很大不同，并且有 16 种不同的波长。\n不同的波长对应于设备之间的预期距离。根据 Raghunathan 的说法，设备之间的训练距离通常为 2 公里或更短，跨数据中心边缘用例预计在 20 公里到 40 公里之间，但有些人说的是 10 公里到 20 公里。推理具有更多波长，设备之间的距离预计在 10 米到 200 米之间，并且需要更多的带宽才能使这些设备高效运行。\n后一点与计算和内存的分解结构架构有关，我们认为这对于训练和推理都有效，这很有趣。让我们来看看：\n这种架构下，HBM 内存不连接到 GPU，而是粘合在一起，这些存储体可能位于机架中物理上不同的架子上，或跨整个机架。GPU（或任何类型的 AI 或 HPC 加速器）都存储在一起，因此它们可以在一致性域中共享缓存中的本地数据，但它们都通过交换机连接，该交换机将加速器池与内存池交叉连接。上述每条管道都是一条光链路，其属性可以由 ChromX 平台编程，使用适当数量的波长和适当的频率来满足带宽和距离（以及延迟）要求。\n“我们的技术几乎打破了成本障碍和规模障碍，并且非常可靠，因为我们只需要一个激光器就可以泵送一块硅片，而且我们可以从单个设备生成多达数百个波长，”Raghunathan 说。“我们提供了一个全新的带宽扩展向量。核心 IP 由哥伦比亚大学独家授权，完全归我们所有。我们的愿景是将封装内通信带宽与封装外通信逃逸带宽相匹配。我们认为，当我们使用多色方法时，我们可以匹配这一点，以便大型数据中心（或多个数据中心）可以像一个大型 GPU 一样运行。”\n目前，Xscape Photonics 并未试图制造支持这种分解式光子结构的网络接口或交换机，而是试图制造其他人想要购买的适合的低功率、多色激光器，以制造这些设备。他们拥有一台激光器，可以实现所有这些频率，而市场上其他人则必须使用多台激光器来实现这一点。他们的想法是将加速器及其内存的互连总功耗降低 10 倍，同时将带宽提高 10 倍，从而将每个带宽的能量降低 100 倍。\n看看谁会采用这款 Xscape 激光以及如何采用它，将会很有趣。\n","date":"2024-10-21","externalUrl":null,"permalink":"/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/","section":"Ais","summary":"\u003cp\u003e据传言，\u003ccode\u003eNvidia\u003c/code\u003e 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 \u003ccode\u003eNVLink\u003c/code\u003e 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。\u003c/p\u003e\n\u003cp\u003e由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。\u003c/p\u003e","title":"英伟达投资光芯片公司，将互联带宽提高10倍","type":"ai"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/pcie-5.0/","section":"Tags","summary":"","title":"PCIe 5.0","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/ssd/","section":"Tags","summary":"","title":"SSD","type":"tags"},{"content":"较旧、速度较慢的 SATA SSD 正在逐渐消失，取而代之的是 NVMe SSD，后者的速度快很多倍，而且不需要任何杂乱的布线，因为它们可以直接插入现代主板上的 M.2 插槽。市场上正开始出现基于更快的 PCIe 5.0 标准的驱动器，它们可以为用户提供超过 14 GB/s 的惊人连续读写速度。\n这里测试了七款 NVMe SSD，包括四款最受欢迎的 PCIe 4.0 选项，以及三款全新的 PCIe 5.0 SSD，它们将存储性能推向了极限。这组 SSD 经过了 Gigabyte Aorus Elite X WiFi 7 主板的测试，该主板顶部有一个 PCIe 5.0 M.2 插槽。\n2024 年最佳工作站 SSD # 三星 990 Pro # 三星是 NAND 闪存领域的全球领导者，在推出性能卓越的 SSD 方面拥有悠久的历史。990 Pro 延续了这一趋势，成为目前性能最佳的 PCIe 4.0 NVMe 驱动器。\n它使用三星设计的 Pascal 控制器，基于 8nm 工艺制造，而不是目前许多其他 SSD 中使用的各种 12nm 控制器。它使用最新的三星设计的 V8 TLC 3D 闪存。这种组合意味着它提供较高的产品规格，具有 7,450 MB/s 的读取速度和 6,900 MB/s 的写入速度，160 万次随机 4K 读取和 150 万次写入 IOPS。此外，如果您需要它，990 Pro 还提供 TCG Opal 硬件加密，这是您在每个 SSD 上都找不到的。\n除此之外，还有三星的 Magician 软件，它无疑是执行低级任务（例如检查驱动器的健康状况或安全擦除驱动器）的最佳软件工具。值得注意的是，三星 990 Pro 在所有容量下的耐久性相对较低；4TB 型号仅为 2,400 TBW。无论是否配备优秀的散热器。\n同时，在性能方面，笔者的测试显示其性能略低于三星的说法，达到 7,140 MB/s 的连续读取速度，IOPS 比广告宣传的低约 10%。但令人惊讶的是，即便如此，990 Pro 仍然比任何 PCIe 4.0 竞争对手都快，IOPS 几乎与 PCIe 5.0 SSD 相匹配。特别是，它在所有测试的 PCIe 4.0 驱动器中获得了最高的 PCMark 10 分数和最低的延迟（36ms）。\n因此，尽管耐久性数据较低，但如果您只追求高性能，而不考虑成本，990 Pro 仍然是我们的 PCIe 4.0 SSD 首选。虽然它肯定不是市场上最实惠的 SSD，但如果您货比三家，仍然应该可以找到一些不错的选择。\nCrucial T705 # 竞争对手高端 Crucial T705 和 Corsair MP700 Pro SE（如下所示）PCIe 5.0 SSD 几乎是相同的 SSD，性能几乎相同，在误差范围内。它们都基于 Phison PS5026-E26 控制器，都使用 Micron TLC NAND，都具有相似的配置，而且都非常昂贵，要价大约是 PCIe 4.0 驱动器的两倍。如果没有散热器，这两款 SSD 也会变得非常热，从而导致性能下降。但稍后会详细介绍。\n尽管本文已经提到了成本和散热方面的考虑，但 T705 在存储性能方面绝对胜出。使用 PCIe 5.0，笔者测量的连续传输速度为 14,088 MB/s 读取和 12,005 MB/s 写入，这大约是 PCIe 4.0 SSD 的两倍。\n但 T705 的领先优势并不仅仅在于这个结果。我们测量了 160 万 IOPS，击败了所有 PCIe 4.0 SSD，并且在 PCMark 10 中笔者记录的延迟仅为 26ms，这是所测试过的所有 SSD 中的最佳结果。\n但是，您需要为这种额外的速度付出高昂的代价。4TB T705 轻松突破了 600 英镑的价格障碍，当 Lexar NM790 等 PCIe 4.0 驱动器的价格不到其一半时，这个价格实在是太高了。PCIe 5.0 目前显然是一项高级功能，专为那些真正的高端工作站保留。\n笔者测试了一款配备 Crucial 提供的集成散热器的 2TB 型号。散热器运行良好，在测试系统中将温度稳定保持在 45°C 左右，不会妨碍设置中的任何其他组件。 T705 的超高速度在很多情况下都非常有用。但对于其他人来说，这可能是一个棘手的选择。如果您想要最快的 SSD 性能，请购买 T705，或者选择仍然足够的 PCIe 4.0，而是将额外的现金投资于直接加快 3D 渲染时间的硬件。\nCorsair MP700 Pro SE # 鉴于 Crucial T705 和 Corsair MP700 Pro SE 非常相似，笔者预计两者的结果会几乎相同，Corsair 提供同样先进的存储性能。\nCorsair 发送了顶级的 4TB MP700 Pro SE 进行评测，代表了当今市场上最高端的消费级 SSD 规格。笔者在 CrystalDiskMark 中测得的读取性能为 14,088 MB/s，写入性能为 11,958 MB/s，IOPS 高达 160 万。29ms 的延迟几乎与 Crucial 的 T705 相同，但略长，而 PCMark 10 和 AS SSD 的总体得分相同，除了百分之几的微小差异。\n笔者收到的用于测试的 SSD 是没有散热器的准系统型号，但在这方面 Corsair 可能比其他任何供应商都走得更远。你可以买到一个带有被动散热器的版本，还有另一个带有自己风扇的版本。这听起来很疯狂，但似乎系统中单个 SSD 的主动冷却现在已经成为现实。值得注意的是，这可能是最高效的 MP700 Pro SE 冷却系统。\n它也是必需的，因为在没有它的情况下进行测试时我们遇到了一些问题。在 AS SSD 测试中，一旦驱动器开始旋转，性能就会减半至 PCIe 4.0 水平以下，而温度会飙升至 85C 以上。需要澄清的是，并非每次测试都是这种情况，或者在不将 MP700 Pro SE 推到极限时也是如此。如果没有散热器，每个 PCIe 5.0 SSD 都可能发生这种情况。一旦测试时在技嘉的 Aorus 主板上应用了隔热罩，问题就消失了。\n但除此之外，MP700 Pro SE 是另一个具有惊人存储性能的绝佳选择。它比 Seagate 的 FireCuda 540 更快，如果您对 PCIe 5.0 存储提供的优势感兴趣，它是 Corsair 和 Crucial 之间的选择。由于这两个驱动器非常相似，因此决定很可能归结为成本。\nLexar NM790 # NM790 是最为有趣的 NVMe SSD 之一。其价格比竞争对手的 PCIe 4.0 SSD 低约 50%，同时具备出色性能，拥有可观的 7400MB/s 读取速度、6500MB/s 写入速度以及高达 100 万 IOPS 的随机 4K 读取速度。这些数值相当出色，几乎与价格高得多的高端 PCIe 4.0 驱动器性能相当。\n由于 NM790 价格便宜得多，在亚马逊上可以以大约 240 英镑的价格购买 4TB 型号，此价格与一些品牌对 2TB 的近期定价相近。这非常划算，尤其考虑到 2024 年 SSD 价格略有上涨。\nNM790 与其他一些 NVMe SSD 有一个主要区别：它没有板载 DRAM 缓存，而是使用 HMB 3.0（主机内存缓冲区）技术，利用工作站系统内存的一小部分来替代板载 DRAM。没有 DRAM 意味着整体功耗更低，在某些系统中具有显著好处。\nNM790 搭载 Maxiotech MAP1602A 控制器，仍使用三级单元（TLC）闪存和小型单级单元（SLC）缓存，而非通过采用速度慢得多的四级单元（QLC）NAND 类型来进一步降低成本。因此，它在大多数测试中表现优异，可与其他可用的 PCIe 4.0 SSD 相媲美。事实上，尽管价格较低，但需仔细观察才能发现真正差异。\n测量的 IOPS 和连续传输速度与三星 990 Pro 等驱动器不相上下，且在所有测试中仍符合 Lexar 的要求。PCMark 10 得分（包括延迟）与竞争对手相当甚至超越竞争对手。仅在 AS SSD 中，NM790 略有下降，在所有测试的 SSD 中得分最低。\n若想用尽可能多的高性能 NVMe SSD 填充主板上的所有 M.2 插槽，NM790 无疑是最经济实惠的方式。\n金士顿 KC3000 # 金士顿是 2021 年最早推出 PCIe 4.0 NVMe SSD 的供应商之一。在没有 PCIe 5.0 产品的情况下，KC3000 仍是其性能最佳的旗舰消费级 NVMe SSD。\n其宣称的性能高达 7000MB/s 的连续读写速度以及 100 万 IOPS。三年后，KC3000 依然是市场上最好的 PCIe 4.0 SSD。在内部构造上，KC3000 由 Phison E18 控制器驱动，配备 1GB DRAM 缓存，并使用 3D TLC NAND 闪存。两侧的 NAND 芯片均覆盖有石墨烯散热器，以使其在使用时保持较低的平均温度。\nKC3000 的额定耐久性为 0.4 DWPD（每日驱动器写入次数），对于 4TB 型号来说为 3200TBW。值得注意的是，这一耐久性远高于其他竞争 NVMe SSD 的通常额定值。它享有五年保修和 2000000 小时 MTBF（平均故障间隔时间）。\n刚推出时，KC3000 是市场上性能最好的 SSD 之一。但如今，它面临着一些激烈的竞争。在我们的测试中，4TB KC3000 完全符合金士顿宣称的 7000MB/s 连续读写速度，这是一个非常好的结果。在我们的 IOPS 测试中，KC3000 超过了宣称的数据，因为我们测量到近 150 万次随机 4K 写入 IOPS，这个数字表明小文件的传输速度很快。同样，KC3000 在 AS SSD 基准测试中也取得了不错的成绩，击败了其他 PCIe 4.0 NVMe SSD。\n然而，这对金士顿来说并非全是好消息。KC3000 在 PCMark 10 中获得了最高的延迟分数，为 45ms，而配备更现代控制器的 SSD 则超过了这一数字。 尽管如此，考虑到 KC3000 现在可以在网上以极其合理的价格买到，并且具有出色的耐用性，它仍然是一个引人注目的选择。\n西部数据 Black SN850X # 西部数据或许是全球最为多元化的存储品牌，在固态硬盘和硬盘领域皆占据领先地位。西部数据旗下还有 SanDisk 品牌，通过对两种存储格式以及 NAS、DAS、云、监控、存储卡等进行投资，对未来进行了押注。\n其一系列精巧的彩色产品名称能够让人一眼辨认出来。不同的颜色代表不同的使用场景，红色、蓝色、绿色和黑色突出显示经过调整的规格，以优先处理特定的存储工作负载。例如，其红色驱动器适用于 NAS 设备，而黑色代表高性能。WD_Black SN850X 是该公司目前销售的最快的消费级 NVMe SSD。\n它由 Kioxia TLC NAND 和西部数据的内部控制器构建而成。附加功能包括简洁的 WD 管理软件仪表板，可显示驱动器运行状况和其他低层级信息。若选择该产品，还有一个特别简洁、厚实的散热器，自然是黑色的。\n额定读取速度为 7300MB/s，写入速度为 6300MB/s，其更高容量型号可达到 120 万 IOPS，所有规格均符合快速存储性能的要求。\n即便如此，其标称的耐用性评级略低，4TB 型号仅为 2400TBW，与三星 990 Pro 相同，但低于金士顿的 KC3000 或 Lexar 的 NM790 的相同容量。\n在我们的测试中，性能数据基本符合预期。6962MB/s 的连续读取性能略低于标称速度。我们测试的 1TB 型号的读取 IOPS 为 800000，容量越高，IOPS 越高。同时，写入性能在两次测试中都表现出色。SN850X 的延迟为 41ms，位于 PCIe 4.0 产品的中间位置，这是一款符合所有要求的 SSD。\n希捷 FireCuda 540 # 2023 年，希捷是首批推出 PCIe 5.0 SSD 的公司之一。基于 Phison PS5026-E26 控制器的 FireCuda 540 超越了 PCIe 4.0，令存储领域为之惊叹。\n然而，到了 2024 年，与较新的 Crucial T705 和 Corsair MP700 Pro SSD 相比，它所提供的性能如今看来略显不足，而后者将 PCIe 5.0 标准推向了更接近极限的水平。 FireCuda 540 的规格与其他 PCIe 5.0 SSD 类似。它有 1TB 和 2TB 两种版本，4TB 型号似乎尚未推出。2TB 型号采用 232 层 Micron NAND 闪存，可提供可观的 2000TBW 耐用性。\nFireCuda 540 的性能不可小觑，总体而言是一款出色的存储设备。在我们的测试中，测得的读取速度为 10077MB/s，写入速度为 10195MB/s，读取 IOPS 为 150 万，延迟为 30 毫秒，其得分全面击败了我们测试过的所有 PCIe 4.0 SSD。\n尽管如此，这些结果确实比我们从 Crucial 和 Corsair 的较新 PCIe 5.0 SSD 测得的速度低了约 40%。鉴于希捷的定价几乎与他们的 1TB 和 2TB 型号相匹配，这使得 FireCuda 540 的性价比降低。如果要花费额外的资金来获得最快的性能存储，那么就需要最好的。\n虽然 FireCuda 540 在各方面都是一款出色的 SSD，但较低的性能使我们无法将其列为首选推荐。希望希捷能推出更新的型号，使其再次成为 SSD 军备竞赛的引领者。 Image 如何为工作站选择最佳 SSD？\nPCIe 5.0 是超高速 SSD 性能的下一步，测试结果表明，它提供了比任何 PCIe 4.0 SSD 都更快的顺序性能、更快的 IOPS 和更低的延迟。毫不夸张地说，为了获得最快的工作站存储性能，您会想要选择 PCIe 5.0 SSD 型号。\n是否应该使用取决于您的预算和个人使用情况。如果钱不是问题，PCIe 5.0 是明智之举。然而，考虑到我们遇到的散热问题和高昂的成本，我们很乐意暂时不在我们的工作站上使用 PCIe 5.0，而是将多余的钱用于 GPU 升级，或更多系统内存和更好的整体渲染时间。\n由于 NVMe 存储速度实在是太快了，我们很难在这里挑选出赢家。即使是价格仅为高端 4TB PCIe 4.0 驱动器三分之一的 Lexar NM790 也表现出色。由于金士顿的 KC3000 提供了顶级耐用性，而三星的 990 Pro 则优于其他 PCIe 4.0 驱动器，因此坚持使用旧标准似乎并不是一个没有吸引力的选择。\n毫不怀疑 PCIe 5.0 是 SSD 的未来，但目前它仍然是尖端的存储技术，在很多方面还未准备好进入主流市场。\n","date":"2024-10-20","externalUrl":null,"permalink":"/hardware/the-best-ssds-for-workstation/","section":"Hardwares","summary":"\u003cp\u003e较旧、速度较慢的 SATA SSD 正在逐渐消失，取而代之的是 NVMe SSD，后者的速度快很多倍，而且不需要任何杂乱的布线，因为它们可以直接插入现代主板上的 M.2 插槽。市场上正开始出现基于更快的 PCIe 5.0 标准的驱动器，它们可以为用户提供超过 14 GB/s 的惊人连续读写速度。\u003c/p\u003e\n\u003cp\u003e这里测试了七款 NVMe SSD，包括四款最受欢迎的 PCIe 4.0 选项，以及三款全新的 PCIe 5.0 SSD，它们将存储性能推向了极限。这组 SSD 经过了 Gigabyte Aorus Elite X WiFi 7 主板的测试，该主板顶部有一个 PCIe 5.0 M.2 插槽。\u003c/p\u003e","title":"适合工作站使用的最佳SSD","type":"hardware"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/ffmpeg/","section":"Tags","summary":"","title":"FFmpeg","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/m3u8/","section":"Tags","summary":"","title":"M3u8","type":"tags"},{"content":"随着互联网技术的飞速发展，越来越多的人选择在线观看视频。无论是直播还是点播，流畅的视频体验离不开背后的技术支持。其中，m3u8文件是一个非常重要的概念。本文将帮助你了解m3u8文件是什么，以及如何使用FFmpeg下载这些视频。\nm3u8文件概述 # m3u8文件是一种文本文件，主要用于支持HLS（HTTP Live Streaming）协议。简单来说，HLS是一种流媒体传输协议，可以让用户在不同的设备上流畅地观看视频。m3u8文件就像一个目录，记录了视频的不同片段在哪里，浏览器或播放器通过读取这个目录来逐步加载视频。\nm3u8文件通常包含以下几个部分：\n文件头：以#EXTM3U开始，表示这是一个m3u8文件 媒体段信息：以#EXTINF开始，后面跟着该媒体段的时长和标题 媒体段URI：指向媒体文件（通常是.ts文件）的路径或URL 文件结尾：以#EXT-X-ENDLIST结束，表示一个完整的m3u8文件 当用户请求观看视频时，播放器首先会读取m3u8文件，然后根据文件中的URL逐个下载视频片段，这样可以实现视频的分段加载，即使网络不稳定也能保证视频的流畅播放。\nm3u8文件的优点：\n支持断点续传：如果网络中断，播放器可以从上次停止的地方继续下载，不会影响观看体验 良好的跨平台兼容性：m3u8文件可以在多种设备和平台上使用，包括手机、电脑和智能电视 适应不同的网络条件：m3u8文件可以根据网络状况动态调整视频质量，确保用户始终获得最佳观看体验 使用FFmpeg下载m3u8视频 # 打开命令行工具（如Windows的CMD/WSL或Mac/Linux的终端），输入以下命令：\nffmpeg -i \u0026#34;m3u8 URL\u0026#34; -c copy output.mp4 -i \u0026quot;m3u8 URL\u0026quot;：指定m3u8文件的URL -c copy：表示直接复制视频和音频流，不进行重新编码，这样可以加快下载速度 output.mp4：指定输出文件的名称和格式 例如，如果你要下载的m3u8文件URL是https://example.com/video.m3u8，命令如下：\nffmpeg -i \u0026#34;https://example.com/video.m3u8\u0026#34; -c copy output.mp4 实战演练 # 首先，你需要找到待下载视频的m3u8链接。这通常可以通过查看网页源代码或使用浏览器的开发者工具（通常可通过按F12键打开）来定位。切换到网络选项卡，在搜索框中输入“.m3u8”过滤出m3u8链接，然后右键点击链接复制URL。\n如果通过上述方式找不到m3u8链接，一般是由于加密了，可以使用浏览器扩展“猫抓”（cat-catch，是github上的开源项目，已经有不少加上广告代码后上架的伪猫抓，请注意自己的数据安全。所有安装地址以github上的为准）。\n打开命令行，输入ffmpeg的下载命令，并粘贴m3u8链接。\n等待ffmpeg下载完成，并保存为mp4文件。\n结语 # m3u8文件在现代流媒体服务中扮演着重要角色，它使得视频可以在不同设备上流畅播放。FFmpeg作为一个强大的开源工具，可以帮助我们轻松下载和处理这些视频。希望本文能够帮助你更好地理解和使用m3u8文件及FFmpeg。\n","date":"2024-10-20","externalUrl":null,"permalink":"/software/download-m3u8-videos-efficiently-with-ffmpeg/","section":"Softwares","summary":"\u003cp\u003e随着互联网技术的飞速发展，越来越多的人选择在线观看视频。无论是直播还是点播，流畅的视频体验离不开背后的技术支持。其中，m3u8文件是一个非常重要的概念。本文将帮助你了解m3u8文件是什么，以及如何使用FFmpeg下载这些视频。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003em3u8文件概述 \n    \u003cdiv id=\"m3u8%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#m3u8%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003em3u8文件是一种文本文件，主要用于支持HLS（HTTP Live Streaming）协议。简单来说，HLS是一种流媒体传输协议，可以让用户在不同的设备上流畅地观看视频。m3u8文件就像一个目录，记录了视频的不同片段在哪里，浏览器或播放器通过读取这个目录来逐步加载视频。\u003c/p\u003e\n\u003cp\u003em3u8文件通常包含以下几个部分：\u003c/p\u003e","title":"用FFmpeg高效下载m3u8视频","type":"software"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/godlike/","section":"Tags","summary":"","title":"GODLIKE","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/msi/","section":"Tags","summary":"","title":"MSI","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/z790/","section":"Tags","summary":"","title":"Z790","type":"tags"},{"content":"MSI近日在其官方YouTube频道进行了超过两小时的直播，正式公布了旗舰级主板MEG Z890 GODLIKE的售价。这款顶级主板在美国市场的售价为1,264美元，欧洲市场的售价则高达1,379.99欧元，成为MSI迄今为止最昂贵的主板产品。\n相比前代产品MEG Z790 GODLIKE的1,200美元定价，新款Z890 GODLIKE的价格进一步提升，打破了之前的记录。在北美市场，Z890 GODLIKE的售价已超过1,250美元，若将官方价格转换为欧盟地区的含税价格，甚至达到1,510美元。MSI的GODLIKE系列一直是其主板产品线中的旗舰，专为追求极致性能的发烧友和超频玩家设计。\nMEG Z890 GODLIKE采用了适用于Intel Arrow Lake CPU的LGA 1851插槽，支持Intel Core Ultra系列处理器（第2代）。主板配备了30相电源VRM和110A SPS，拥有10层PCB设计和服务器级材料，搭配密集的散热器，确保在高负载下仍能保持稳定的性能和被动散热效果。\n主要特点：\n内存支持：主板支持双通道DDR5内存，最高可达DDR5 9200+ MT/s（OC），为用户提供了强大的内存超频潜力。\n动态仪表板III：配备3.99英寸LCD屏幕，可实时监控硬件状态、故障排除、BIOS更新，并提供个性化显示选项，提升整体用户体验。\nM.2 XPANDER-Z SLIDER GEN5：单插槽厚度的M.2扩展卡，具有双高速Gen5 M.2插槽，采用EZ Slide设计，方便SSD的升级和更换。\nThunderbolt 5支持：附带的Thunderbolt 5配件卡拥有双Thunderbolt 5端口，提供高达160Gbps的总带宽和高达27W的快速充电能力。\n超级性能配置：采用26+2+1+1双轨电源系统、110A SPS、OC引擎、双8针CPU电源连接器、Core Boost和Memory Boost等高级配置，由2盎司加厚铜和服务器级材料制成的10层PCB，确保主板的稳定性和性能。\nFrozr Guard散热系统：包含波浪形散热片设计、直触交叉热管、MOSFET底板、9W/mK导热垫、双面M.2 Shield Frozr和Frozr AI软件，确保在低温下实现最佳性能。\nEZ DIY设计：提供EZ Link、EZ PCIe Release、EZ Magnetic M.2 Shield Frozr II、EZ M.2 Clip II和EZ Antenna等功能，方便用户自行安装和升级硬件。\n卓越的连接性：配备双Thunderbolt 4端口、10G LAN和5G LAN，以及全速的Intel Killer Wi-Fi 7解决方案，满足专业和多媒体用途的高要求，提供安全、稳定和高速的网络和数据传输。\n极速游戏体验：支持PCIe 5.0插槽，拥有总共8个M.2接口（带有Lightning Gen 5解决方案），以及带有60W USB供电的前置USB 20G接口，满足高速存储和外设连接需求。\nAudio Boost 5 HD音频系统：采用最新的高级ALC4082音频处理器，结合ESS音频DAC和放大器，提供令人惊叹的音频体验。\n尽管MEG Z890 GODLIKE拥有顶级的规格和功能，但其高昂的价格注定了这款主板并非面向大众市场。它主要吸引那些希望利用Intel Arrow Lake CPU（如Core Ultra 9 285K）打破超频世界纪录的专业超频玩家和硬件发烧友。\n除了这款旗舰主板外，MSI的其他Z890芯片组主板价格都未超过1,000美元。其中，次旗舰型号MEG Z890 ACE售价为689美元，约为Z890 GODLIKE价格的一半，提供了更为实惠的高端选择。\n随着Intel Arrow Lake Core Ultra系列处理器的即将推出，众多主板厂商纷纷发布了Z890芯片组主板。MSI作为一线大厂，提供了涵盖不同价位和需求的多款产品。对于追求极致性能和无与伦比配置的用户而言，MEG Z890 GODLIKE无疑是当前市场上的顶尖之选。\n","date":"2024-10-20","externalUrl":null,"permalink":"/hardware/msi-releases-the-most-expensiv-motherboard-ever/","section":"Hardwares","summary":"\u003cp\u003eMSI近日在其官方YouTube频道进行了超过两小时的直播，正式公布了旗舰级主板MEG Z890 GODLIKE的售价。这款顶级主板在美国市场的售价为1,264美元，欧洲市场的售价则高达1,379.99欧元，成为MSI迄今为止最昂贵的主板产品。\u003c/p\u003e\n\u003cp\u003e相比前代产品MEG Z790 GODLIKE的1,200美元定价，新款Z890 GODLIKE的价格进一步提升，打破了之前的记录。在北美市场，Z890 GODLIKE的售价已超过1,250美元，若将官方价格转换为欧盟地区的含税价格，甚至达到1,510美元。MSI的GODLIKE系列一直是其主板产品线中的旗舰，专为追求极致性能的发烧友和超频玩家设计。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MSI-MEG-Z890-GODLIKE-2.png\" alt=\"MSI Release MEG Z790 GODLIKE\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eMEG Z890 GODLIKE采用了适用于Intel Arrow Lake CPU的LGA 1851插槽，支持Intel Core Ultra系列处理器（第2代）。主板配备了30相电源VRM和110A SPS，拥有10层PCB设计和服务器级材料，搭配密集的散热器，确保在高负载下仍能保持稳定的性能和被动散热效果。\u003c/p\u003e","title":"微星发布了一块史上最昂贵主板","type":"hardware"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/gdb/","section":"Tags","summary":"","title":"GDB","type":"tags"},{"content":"在软件开发的复杂世界里，高效的调试工具是解决问题的关键利器。今天，我们将深入探讨强大的调试工具 —— GDB（GNU Debugger）。GDB 为开发者提供了一种深入程序内部运行机制、查找错误和优化性能的有效途径。让我们一同开启 GDB 的调试之旅，解锁代码中的奥秘。\nGDB调试工具 # GDB（GNU Debugger）是强大的调试工具，在软件开发过程中起着至关重要的作用。它可以帮助开发者快速定位和解决程序中的问题。\nGDB做以下4 件主要的事情来帮助您捕获程序中的bug：\n在程序启动之前指定一些可以影响程序行为的变量或条件 在某个指定的地方或条件下暂停程序 在程序停止时检查已经发生了什么 在程序执行过程中修改程序中的变量或条件，这样就可以体验修复一个 bug 的成果，并继续了解其他 bug 启动 GDB 主要有以下两种方法：\n直接启动 gdb：单独输入此命令启动 GDB，启动后需借助file或者exec-file命令指定要调试的程序 gdb test.out：如果有一个名为test.out的可执行文件，可以直接使用这个命令启动 GDB 并加载该程序进行调试 gdb test.out core：当程序发生错误并生成core文件时，可以使用这个命令启动 GDB，以便对错误进行分析 动态链接：gdb test.out pid，这种方式可以将 GDB 链接到一个正在运行中的进程中去，其中pid就是进程号，可以使用ps aux命令查看对应程序的进程号。 要准备调试的程序，首先需要用gcc的-g参数生成可执行文件。这样才能在可执行文件中加入源代码信息以便调试，但这并不是将源文件嵌入到可执行文件中，所以调试时必须保证 GDB 能找到源文件。例如，编译程序时可以使用gcc -g main.c -o test.out这样的命令来生成带有调试信息的可执行文件。\nGDB调试技巧 # 条件断点 条件断点在调试过程中非常实用。设置条件断点可以利用break if命令，例如(gdb)break 666 if testsize==100123123。条件断点的优势在于可以在特定条件满足时才使程序停止，这对于排查异常情况非常有帮助。比如在一个循环中，当某个变量达到特定值时才中断程序，这样可以更精准地定位问题。\n断点命令 断点命令不仅可以让程序在特定位置停止，还可以编写对到达断点响应的脚本，实现更复杂的调试功能。例如，可以在断点处设置一些打印变量值、检查特定条件等操作，以更好地了解程序的运行状态。\n转储二进制内存 GDB 提供了多种方式查看内存。内置支持的x命令可以查看内存地址中的值，其语法为x/\u0026lt;n/f/u\u0026gt; \u0026lt;addr\u0026gt;，其中n是显示内存的长度，f表示显示的格式，u表示从当前地址往后请求的字节数。例如(gdb) x/16xw 0x7FFFFFFFE0F8可以以十六进制、四字节为单位显示从地址0x7FFFFFFFE0F8开始的 16 个单位的内存内容。此外，也可以使用自定义的hexdump命令来查看内存，更加灵活地控制输出格式。\n行内反汇编 使用disassemble/s命令可以查看与函数源代码对应的指令，这有助于了解程序在 CPU 指令级别上的情况。例如，disas main可以显示main函数对应的汇编代码。通过查看汇编代码，可以更深入地理解程序的执行过程，对于分析性能问题、理解底层实现等非常有帮助。\n反向调试 反向调试是 GDB 的一个强大功能。它可以让程序实现上一步上一步的操作，即反向运行。反向调试在一些情况下非常有用，比如调试过程中不小心多执行了一次命令，或者想再次查看刚刚程序执行的过程。反向调试不适用 IO 操作，并且需要 GDB7.0 以上的版本。相关指令有rc或reverse-continue反向运行程序，直到碰到一个能使程序中断的事件；rs或reverse-step反向运行程序到上一次被执行的源代码行等。通过查看寄存器值等方式，可以深入了解程序在反向运行过程中的状态变化。\nGDB调试方法 # 编译及启动调试 在编译代码时，加上 -g 选项是非常重要的，这可以确保在可执行文件中包含调试信息，以便在使用 GDB 进行调试时能够获取更多的程序内部状态信息。例如，使用 gcc -g main.c -o main.out 这样的命令编译代码，生成的 main.out 可执行文件就可以被 GDB 有效地调试。\n启动调试代码有多种方式。可以直接使用 gdb main.out 来启动调试一个可执行文件，然后在 GDB 环境中使用 run 命令来运行程序。如果程序在启动时需要命令行参数，可以在进入 GDB 后使用 run arg1 arg2... 的方式来提供参数并启动调试。\n另外，还可以调试正在运行的程序。\n首先找到程序的进程号，可以使用 ps aux | grep program_name 或 pidof program_name 来获取进程号。 然后使用 gdb attach pid 或者 gdb -p pid 命令将 GDB 附加到正在运行的程序上进行调试。 调试命令 GDB 有许多强大的调试命令。比如 list 命令可以显示源代码：\nlist 会打印当前行后面的代码 list - 显示当前行前面的代码 list lineNumber 打印出行第 lineNumber 行前后的代码 list FunctionName 打印出行函数 FunctionName 前后的代码 break 命令用于设置断点，可以在指定的行号或函数处设置断点:\nbreak \u0026lt;function\u0026gt; 在进入指定函数时停止运行 break \u0026lt;lineNumber\u0026gt; 在指定代码行打断点 break filename:lineNumber 在指定文件的特定行设置断点 break filename:function 在指定文件的函数入口处设置断点 还可以设置条件断点，如 break... if \u0026lt;condition\u0026gt;，当条件成立时程序停止运行。\nnext 命令执行下一条语句，如果该语句为函数调用，不会进入函数内部执行。\nstep 命令执行下一条语句，如果该语句为函数调用，则进入函数执行其中的第一条语句。\ncontinue 命令继续程序的运行，直到遇到下一个断点。\nprint 和 display 命令用于打印变量 / 表达式的值，print 只输出一次，display 跟踪查看某个变量，每次停下来都显示它的值。可以以不同格式打印变量，如 p /f variable，其中 f 可以是 x（十六进制格式）、d（十进制格式）、u（十六进制格式显示无符号整型）等。\nwatch 命令在程序运行过程中监视变量值的变化，如果有变化，马上停止程序运行，如 watch variable 当变量 variable 有变化时，停止程序运行，还有 rwatch 和 awatch 分别在变量被读取和被读或被写时停止程序运行。\n调试段错误 调试段错误的一种快捷方法是生成 core 文件并使用 GDB 加载分析。首先，可以使用 ulimit -c unlimited 命令将 core 文件生成设置为不限制大小。这样，当程序发生段错误时，会生成 core 文件。\n然后，使用 GDB 加载这个 core 文件进行调试。可以使用 gdb program core 的方式，其中 program 是可执行程序名称，core 是生成的 core 文件。在 GDB 中，可以使用 backtrace 命令查看函数调用栈，找到出错的位置。还可以使用 frame 命令查看特定栈帧的信息，使用 print 命令打印变量的值，以确定问题所在。例如，如果在调试过程中发现某个变量的值为空指针，可能是内存分配失败导致的，可以进一步检查相关的内存分配代码。\nGDB使用其他要点 # 调试参数列表 # GDB 拥有丰富的调试参数，以下是一些常见的命令及其用途：\n启动程序：使用 gdb [可执行文件名] 启动 GDB 并加载要被调试的可执行文件。例如 gdb test.out。还可以使用 gdb file [可执行文件名] 的方式启动，如 gdb file test.out。另外，若要调试正在运行的程序，可以使用 gdb attach [进程号] 或 gdb -p [进程号]。\n设置断点： break [行号]：在指定行设置断点，如 break 10。 break [函数名]：在函数入口处设置断点，如 break main。 break [文件名:行号]：在指定文件的特定行设置断点，如 break test.c:20。 break\u0026hellip; if [条件]：设置条件断点，当条件成立时程序停止运行，如 break 666 if testsize==100123123。 info breakpoints：显示当前程序的断点设置情况。 delete breakpoints [断点号]：删除指定断点，不指定断点号则删除所有断点。 disable [断点号]：暂停指定断点。 enable [断点号]：开启指定断点。 clear [行号]：清除指定行的断点。 单步执行： next（简写为 n）：逐过程调试，执行下一行，当遇到函数调用时，会一次性执行完该函数，不进入函数体内部。 step（简写为 s）：单步调试，执行下一行，当遇到函数调用时，会进入函数体内部。 continue（简写为 c）：继续执行程序，直到下一个断点处或程序结束。 until：当厌倦在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。until+行号：运行至某行，可用于跳出循环。 finish：运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。 call [函数(参数)]：调用程序中可见的函数，并传递参数，如 call gdb_test(55)。 查看信息： info registers：显示所有寄存器的内容，可查看特定寄存器，如 info registers rbp 显示 rbp 寄存器的值，info registers rsp 显示 rsp 寄存器的值。 info stack：显示堆栈信息。 info args：显示当前函数的参数列表。 info locals：显示当前函数的局部变量列表。 info function：查询函数。 info breakpoints：显示当前程序的断点设置情况。 info watchpoints：列出当前所设置的所有观察点。 info line [行号/函数名/文件名:行号/文件名:函数名]：查看源代码在内存中的地址。 查看内存单元值 # 在 GDB 中，可以使用 examine 命令（简写是 x）来查看内存地址中的值。其格式为 x/\u0026lt;n/f/u\u0026gt; \u0026lt;addr\u0026gt;，其中：n是一个正整数，表示显示内存的长度，从当前地址向后显示几个地址的内容。例如 x/16xb 0x7FFFFFFFE0F8 表示以单字节为单位显示从地址 0x7FFFFFFFE0F8 开始的 16 个字节的内容。\nf表示显示的格式，可取如下值：\nx：按十六进制格式显示变量。 d：按十进制格式显示变量。 u：按十进制格式显示无符号整型。 o：按八进制格式显示变量。 t：按二进制格式显示变量。 a：按十六进制格式显示变量。 i：指令地址格式。 c：按字符格式显示变量。 f：按浮点数格式显示变量。 u表示一个地址单元的长度，可用以下字符代替：\nb表示单字节。 h表示双字节。 w表示四字节。 g表示八字节。 查看源程序 # 在 GDB 中，可以使用 list（简写为 l）命令查看源程序，有以下几种方式：\nlist：显示当前行后面的源程序，默认每次显示 10 行，按回车键继续看余下的。 list [行号]：将显示当前文件以 “行号” 为中心的前后 10 行代码，如 list 12。 list [函数名]：将显示 “函数名” 所在函数的源代码。 栈帧相关 # GDB 中有一些与栈帧相关的命令：\ninfo frame：打印当前栈帧的详细信息，包括当前函数、参数和局部变量等。例如：(gdb) info frame会显示诸如 Stack level 0, frame at [地址]: pc = [程序计数器值] in [函数名] ([文件名]:[行号]); saved pc [保存的程序计数器值]等信息。 up和down：在栈帧之间上下移动。up命令将切换到上一个栈帧，而down命令将切换到下一个栈帧。 info locals：显示当前函数的局部变量列表，帮助开发者了解当前栈帧中的局部变量情况。 GDB多线程调试 # GDB 多线程调试基础 # 基本命令介绍 在 GDB 多线程调试中，有许多常用命令。例如设置断点可以使用 (gdb) break function_name，通过这个命令可以在特定的函数处设置断点，当程序执行到该函数时会暂停。删除断点则可以使用 (gdb) delete breakpoints。查看线程信息可以使用 (gdb) info threads，这个命令会列出所有可调试的线程信息，包括 GDB 分配的线程 ID、系统级的线程标识符以及线程的栈信息等。切换线程可以使用 (gdb) thread thread_id，通过指定线程 ID 可以快速切换到对应的线程进行调试。此外，设置监视点可以使用 (gdb) watch variable_name，用于观察某个变量的值是否有变化，一旦变化程序会立即暂停。删除监视点则是 (gdb) delete watchpoints。\n编译多线程程序 在进行多线程调试之前，我们需要先编译多线程程序。通常，我们可以使用 gcc 编译器来编译多线程程序。例如，对于以下多线程程序代码：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define NUM_THREADS 5 void * thread_func(void * thread_id) { long tid = (long)thread_id; printf(\u0026#34;Hello World! It\u0026#39;s me, thread #%ld!\u0026#34;, tid); pthread_exit(NULL); } int main() { pthread_t threads[NUM_THREADS]; int rc; long t; for (t = 0; t \u0026lt; NUM_THREADS; t++) { printf(\u0026#34;In main: creating thread %ld\u0026#34;, t); rc = pthread_create(\u0026amp;threads[t], NULL, thread_func, (void *)t); if (rc) { printf(\u0026#34;ERROR; return code from pthread_create() is %d\u0026#34;, rc); return -1; } } pthread_exit(NULL); } 我们可以将上述代码保存至一个名为 multithread.c 的文件中，并使用以下命令进行编译：$ gcc -g -pthread -o multithread multithread.c。其中，-g 选项用于在可执行文件中加入调试信息，这样在使用 GDB 进行调试时可以获取更多的程序信息；-pthread 选项则用于引入多线程库，确保程序能够正确地使用多线程功能。\n多线程调试案例分析 # 简单多线程程序调试 假设我们有一个如下的简单多线程程序：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void *printNumbers(void *arg) { int i; for (i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;Thread: %d\\n\u0026#34;, i); } return NULL; } int main() { pthread_t thread1, thread2; pthread_create(\u0026amp;thread1, NULL, printNumbers, NULL); pthread_create(\u0026amp;thread2, NULL, printNumbers, NULL); pthread_join(thread1, NULL); pthread_join(thread2, NULL); return 0; } 我们可以使用以下步骤进行 GDB 调试：\n首先，编译程序：$ gcc -g -pthread -o simple_thread simple_thread.c 然后启动 GDB：$ gdb simple_thread 在 main 函数处设置断点：(gdb) break main 运行程序：(gdb) run，程序会停在 main 函数的断点处。 接着，我们可以使用 (gdb) info threads 查看当前的线程信息。可以看到有两个线程正在运行，一个是主线程，一个是其中一个子线程。 使用 (gdb) thread thread_id 切换到子线程，然后进行单步执行操作，如 (gdb) next，可以观察到子线程的执行过程。 复杂多线程程序调试 对于更复杂的多线程程序，比如多个线程之间存在交互和同步问题的程序，调试会更加具有挑战性。\n例如，有一个多线程程序，多个线程同时对一个共享资源进行读写操作，可能会出现竞争条件和数据不一致的问题。\n在这种情况下，我们可以使用 GDB 的以下技巧来处理：\n使用 (gdb) break function_name 在关键的同步函数处设置断点，如互斥锁的加锁和解锁函数。 通过 (gdb) info threads 随时查看线程状态，确定哪个线程正在持有共享资源，哪个线程在等待资源。 使用 (gdb) thread apply all bt 查看所有线程的调用堆栈，以了解每个线程的执行路径和当前状态。 设置条件断点，例如 (gdb) break function_name if condition，当特定条件满足时才触发断点，以便在复杂的交互场景中更精确地定位问题。 例如，假设我们有一个多线程的银行账户管理程序，多个线程同时进行存款和取款操作，我们可以在存款和取款函数处设置断点，并根据账户余额等条件设置条件断点，以便在出现异常情况时能够快速定位问题所在。\n多线程调试技巧 # 线程锁定与并发控制 在 GDB 中，可以使用 set scheduler-locking 命令来控制线程的执行顺序和并发程度。这个命令有三个值，分别是 on、step 和 off。\nset scheduler-locking on：可以用来锁定当前线程，只观察这个线程的运行情况，锁定这个线程时，其他线程处于暂停状态。在当前线程执行 next、step、until、finish、return 命令时，其他线程是不会运行的。需要注意的是，在使用这个选项时要确认当前线程是否是我们期望锁定的线程，如果不是，则可以使用 thread + 线程编号 切换到我们需要的线程，再调用 set scheduler-locking on 锁定。 set scheduler-locking step：也用来锁定当前线程，当且仅当使用 next 或 step 命令做单步调试时会锁定当前线程，如果使用 until、finish、return 等线程内的调试命令（它们不是单步控制命令），则其他线程还是有机会运行的。与 on 选项的值相比，step 选项的值为单步调试提供了更加精细化的控制，因为在某些场景下，我们希望单步调试时其他线程不要对所属的当前线程的变量值造成影响。 set scheduler-locking off：用于释放锁定当前线程。 我们还可以使用 show scheduler-locking 命令来显示线程的 scheduler-locking 状态。\n命令组合与高效调试 一些常用的 GDB 命令组合可以提高多线程调试的效率。例如：\ninfo threads + thread thread_id + bt：先使用 info threads 查看当前进程的所有线程信息，然后使用 thread thread_id 切换到特定线程，再使用 bt 查看该线程的函数调用堆栈，以便分析该线程的执行逻辑。 break function_name + condition + run + next/step：先使用 break function_name if condition 在特定函数处设置条件断点，然后使用 run 运行程序，当条件满足时程序会停在断点处，接着使用 next 或 step 进行单步调试。 thread apply all command：可以让所有被调试线程执行特定的 GDB 命令，例如 thread apply all bt 可以查看所有线程的调用堆栈。 常见问题与解决方案 在多线程调试过程中，可能会遇到以下常见问题：\n线程死锁：如果程序出现死锁，可以使用 GDB 的以下步骤进行分析。\n首先，使用 gdb 启动程序，然后在程序死锁处按 ctrl+c 暂停程序。接着，使用 info threads 查看当前节点上线程状态，使用 thread thread_id 切换线程，使用 bt 查看线程堆栈，并查处死锁位置。多切换几个线程，全面分析死锁的原因。一般来说，首先检查使用频率最高的锁在所有函数出口上是否已解锁。如果是第一轮出现死锁，则可检查锁配对和可能的程序出口上是否进行了开锁。如果多轮运行后出现，且基本确认函数出口均解锁，则需要判断是否是内存越界，可以使用工具 valgrind 进行内存越界诊断。\n无法确定当前调试的线程：可以使用 info threads 命令查看当前可调试的所有线程，每个线程会有一个 GDB 为其分配的 ID，前面有 * 的是当前调试的线程。也可以使用 thread thread_id 切换到特定线程进行确认。\n多线程程序调试效率低下：可以使用前面提到的命令组合和线程锁定功能，有针对性地调试特定线程或在特定条件下进行调试，提高调试效率。同时，可以将程序中的线程数量减少至 1 进行调试，观察是否正确，然后逐步增加线程数量，调试线程的同步是否正确。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/gdb-debugging-multi-threads-case-analysis/","section":"Softwares","summary":"\u003cp\u003e在软件开发的复杂世界里，高效的调试工具是解决问题的关键利器。今天，我们将深入探讨强大的调试工具 —— GDB（GNU Debugger）。GDB 为开发者提供了一种深入程序内部运行机制、查找错误和优化性能的有效途径。让我们一同开启 GDB 的调试之旅，解锁代码中的奥秘。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eGDB调试工具 \n    \u003cdiv id=\"gdb%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#gdb%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGDB（GNU Debugger）是强大的调试工具，在软件开发过程中起着至关重要的作用。它可以帮助开发者快速定位和解决程序中的问题。\u003c/p\u003e","title":"GDB调试多线程案例分析","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/multi-threads/","section":"Tags","summary":"","title":"Multi Threads","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/https/","section":"Tags","summary":"","title":"HTTPS","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/network/","section":"Tags","summary":"","title":"Network","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/series/software/","section":"Series","summary":"","title":"Software","type":"series"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/tcp/","section":"Tags","summary":"","title":"TCP","type":"tags"},{"content":" HTTP # 超文本传输协议 超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII形式给出；而消息内容则具有一个类似MIME的格式。这个简单模型是早期Web成功的有功之臣，因为它使开发和部署非常地直截了当。\nHTTP/3 # HTTP/3 是 HTTP 的下一个主要修订版本。它基于 QUIC 运行，QUIC 是一种专为移动互联网使用量大而设计的新传输协议。它依赖于 UDP 而不是 TCP，从而可以实现更快的网页响应速度。VR 应用需要更多带宽来渲染虚拟场景的复杂细节，并且可能会从迁移到由 QUIC 支持的 HTTP/3 中受益。\nHTTPS # 超文本传输协议安全版 HTTPS（Hypertext Transfer Protocol Secure），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。HTTPS 在HTTP 的基础下加入SSL，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP与 TCP 之间）。这个系统提供了身份验证与加密通讯方法。它被广泛用于万维网上安全敏感的通讯，例如交易支付等方面。\nWebSocket # WebSocket 是独立的、创建在 TCP 上的协议。Websocket 通过HTTP/1.1 协议的101状态码进行握手。为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手”（handshaking）。\nTCP # 传输控制协议 传输控制协议（TCP，Transmission Control Protocol）是为了在不可靠的互联网络上提供可靠的端到端字节流而专门设计的一个传输协议\nUDP # 用户数据报协议 UDP是一种无连接的、不可靠的、基于数据报的传输层通信协议。它追求的是传输速度而非可靠性，适用于对实时性要求较高但对数据完整性要求不高的场景。\nSMTP # 简单邮件传输协议 SMTP是一种用于发送电子邮件的协议，它规定了电子邮件在发送过程中的格式和传输方式。\nFTP # 文件传输协议 文件传输协议（File Transfer Protocol，FTP）是用于在网络上进行文件传输的一套标准协议，它工作在 OSI 模型的第七层，TCP 模型的第四层， 即应用层， 使用 TCP 传输而不是 UDP， 客户在和服务器建立连接前要经过一个“三次握手”的过程， 保证客户与服务器之间的连接是可靠的， 而且是面向连接， 为数据传输提供可靠保证。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/8-popular-network-protocols/","section":"Softwares","summary":"\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./8-Popular-Network-Protocols.gif\" alt=\"8 Popular Network Protocols\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eHTTP \n    \u003cdiv id=\"http\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#http\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cblockquote\u003e超文本传输协议\u003c/blockquote\u003e\n\u003cp\u003e超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII形式给出；而消息内容则具有一个类似MIME的格式。这个简单模型是早期Web成功的有功之臣，因为它使开发和部署非常地直截了当。\u003c/p\u003e","title":"一张图解释 8 种流行网络协议","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/space/","section":"Tags","summary":"","title":"Space","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/windows-11/","section":"Tags","summary":"","title":"Windows 11","type":"tags"},{"content":"是不是经常看到“C盘空间不足”的烦人提示？C盘满了，不仅会影响系统的运行速度，还可能导致更新失败或软件崩溃。其实，只需要几步简单设置，就能大大减少C盘的压力，让你的电脑快起来！下面就分享如何让系统不再占用C盘空间，轻松释放宝贵C盘空间！\n转移用户文件夹到其他分区 # C盘不仅安装系统，许多用户文件（如桌面、文档、下载等）也都默认保存在这里，久而久之占用大量空间。解决办法很简单，直接把这些文件夹挪到D盘或其他分区就好。\n操作步骤： # 在桌面上找到“文档”或“下载”文件夹，右键选择“属性”。\n切换到“位置”选项卡，点击“移动”按钮。\n选择一个其他分区的文件夹（如D盘的某个文件夹），点击“确定”。\n系统会提示是否将已有文件移动到新位置，点击“是”即可。\n这样，今后保存到桌面、文档、下载等地方的文件都会自动放在D盘，再也不用担心C盘空间不够用了！\n改变软件默认安装位置 # 很多软件在安装时，都会默认装到C盘的 Program Files 文件夹，特别是游戏或设计类软件，一装就是好几GB！其实我们可以改变软件的安装路径，让软件装到D盘。\n操作步骤： # 按下 Win + I 打开“设置”。\n点击“系统” -\u0026gt; “存储”，选择“更改新内容的保存位置”。\n在“新应用将保存到”选项中，将C盘改为其他分区，如D盘。\n此后，安装的软件会默认放在D盘，而不是C盘。不过，注意某些软件安装时仍然会让你手动选择安装位置，请记得检查一下！\n将虚拟内存和临时文件转移到其他分区 # Windows为了提高性能，会使用虚拟内存文件以及存储大量的临时文件，它们默认都放在C盘，逐渐占据了不少空间。我们可以轻松将这些文件转移到其他分区。\n转移虚拟内存 # 操作步骤： # 右键点击“此电脑”，选择“属性”。\n在左侧选择“高级系统设置”。\n在“性能”部分点击“设置”，切换到“高级”选项卡，点击“更改”。\n取消“自动管理所有驱动器的分页文件大小”，选择C盘，设置为“无分页文件”，再选择其他分区，设置为“系统管理的大小”。\n点击“确定”并重启电脑。\n转移临时文件 # 操作步骤： # 按下 Win + R 打开“运行”，输入 sysdm.cpl 并回车\n在“高级”选项卡中，点击“环境变量”\n在“用户变量”部分找到 TEMP 和 TMP，分别点击“编辑”\n将它们的路径修改到D盘或其他分区的文件夹，比如 D:\\Temp\n这样，虚拟内存和临时文件都会存储在其他分区，C盘的空间将大大节省。\n关闭休眠功能释放C盘空间 # Windows的休眠功能会在C盘创建一个巨大的文件 hiberfil.sys，有时候这个文件甚至能占用几GB空间。如果你平时很少用休眠功能，可以直接关闭它，释放这块空间。\n操作步骤： # 按下 Win + X，选择“命令提示符（管理员）”。\n在窗口中输入以下命令并按回车：\npowercfg -h off 完成后，休眠功能将被关闭，并且 hiberfil.sys 文件会被删除，立马释放出几个GB的C盘空间。 定期清理系统垃圾文件 # 即使我们做了上述优化，Windows系统在使用过程中仍会产生各种缓存和垃圾文件，定期清理这些文件能让C盘更干净。\n操作步骤： # 打开“此电脑”，右键C盘，选择“属性”。\n点击“磁盘清理”，系统会扫描可清理的文件。\n勾选“临时文件”、“回收站”等选项，点击“确定”进行清理。\n你还可以点击“清理系统文件”，这样能清理到更多的系统缓存和无用文件。\n通过这几步简单设置，C盘不再是系统的唯一战场。转移用户文件、改变软件安装路径、管理虚拟内存和临时文件，再加上定期清理，C盘空间告急的烦恼就能轻松解决。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/free-up-space-on-c-drive-in-windows/","section":"Softwares","summary":"\u003cp\u003e是不是经常看到“C盘空间不足”的烦人提示？C盘满了，不仅会影响系统的运行速度，还可能导致更新失败或软件崩溃。其实，只需要几步简单设置，就能大大减少C盘的压力，让你的电脑快起来！下面就分享如何让系统不再占用C盘空间，轻松释放宝贵C盘空间！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e转移用户文件夹到其他分区 \n    \u003cdiv id=\"%E8%BD%AC%E7%A7%BB%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%E5%85%B6%E4%BB%96%E5%88%86%E5%8C%BA\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%BD%AC%E7%A7%BB%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%E5%85%B6%E4%BB%96%E5%88%86%E5%8C%BA\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eC盘不仅安装系统，许多用户文件（如桌面、文档、下载等）也都默认保存在这里，久而久之占用大量空间。解决办法很简单，直接把这些文件夹挪到D盘或其他分区就好。\u003c/p\u003e\n\n\n\u003ch3 class=\"relative group\"\u003e操作步骤： \n    \u003cdiv id=\"%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e在桌面上找到“文档”或“下载”文件夹，右键选择“属性”。\u003c/p\u003e","title":"如何释放Windows 的C 盘空间","type":"software"},{"content":"本文介绍20个能够大大提升Windows 11操作效率的快捷键，掌握这些快捷键能让你的工作和学习事半功倍！\n启动文件资源管理器 # Windows键 + E 如果你像我一样，经常使用文件资源管理器。使用键盘快捷键，只需按Windows键 + E，就可以在你需要时随时启动一个新的文件资源管理器窗口。\n直接进入任务管理器 # Ctrl + Shift + Esc 你可能知道基本的Ctrl + Alt + Delete快捷键，但如果你用它来打开任务管理器，实际上有一个更好的方法：使用Ctrl + Shift + Esc快捷键。\n打开设置 # Windows键 + I 想要更改操作系统中的设置吗？不必在开始菜单中搜索，实际上有一个你可以使用的键盘快捷键：Windows键 + I，然后，你可以在设置应用中直接搜索你需要的内容。\n查阅剪贴板历史 # Windows键 + V 你知道每次你将图像或文本复制到剪贴板时，Windows都会保存它们的运行历史吗？通常的Ctrl + V快捷键只粘贴你最后复制的项目——但如果你想要粘贴你很久以前复制的东西， 你所要做的只是用Windows键 + V快捷键调出剪贴板历史。如果你以前从未打开过，系统会提示你授予权限以激活该功能。\n剪贴板历史的优点在于，你甚至可以将某些复制的项目固定到面板上，使它们在将来更容易找到。\n在任何地方插入表情符号 # Windows键 + 分号 表情符号已经成为现代通信的一部分——微软知道这一点， 你所要做的只是按Windows键 + 分号快捷键。\n语音输入 # Windows键 + H Windows允许你在几乎任何应用程序中使用语音输入。要调出语音输入界面，只需按Windows键 + H，你会看到一个浮动的窗口（在Windows 11上）或一个栏（在Windows 10上）。\n你可以在窗口/栏的设置菜单中激活自动标点等功能。\n超级用户菜单 # Windows键 + X 当微软在Windows 8中取消了开始菜单时，他们至少还给了超级用户一个面子：隐藏的“超级用户菜单”，可以快速访问各种系统设置。\n在Windows 11，也有超级用户菜单。要打开它，可以使用按Windows键 + X\n锁定你的电脑 # Windows键 + L 为了保护你的电脑免受未经授权的访问——特别是在办公室环境中——你应该在离开时锁定电脑。只需按Windows键 + L快捷键。\n控制声音设置 # Ctrl + Windows键 + V 如果你有多个声音输出设备（例如，扬声器、耳机、无线耳塞）或多个声音输入设备（例如，笔记本麦克风、耳机、外部麦克风），你可能经常在它们之间切换。\n实际上，只需按Ctrl + Windows键 + V 快捷键即可调出声音设置菜单。\n这也可以用来调整系统音量和每个应用的音量（使用滑块），并且是快速进入设置应用的声音部分（通过点击更多音量设置）的一种方式。\n拖拽窗口 # Windows键 +箭头 Snap功能是Windows 11中进行多任务处理的窗口管理工具。你可以轻松地将应用程序窗口“拖拽”到屏幕边缘。\n首先，使用Windows键 + 左箭头和Windows键 + 右箭头将当前聚焦的窗口拖拽到屏幕的左半边或右半边。类似地，使用Windows键 + Alt + 上箭头和Windows键 + Alt + 下箭头将窗口拖拽到屏幕的上方或下方的一半。\n你还可以使用快捷键将窗口移动到屏幕的四个象限。例如，在使用上述快捷键将窗口拖拽到左侧一半后，保持按住Windows键并点击上箭头，将其拖拽到左上象限。\n激活Snap布局 # Windows键 + Z 就像Snap本身已经很有用一样，Windows 11还有一个额外的Snap布局功能，可以更容易地将窗口拖拽到各种配置中。\n要激活Snap布局，使用Windows键 + Z 快捷键。你会看到一个带有编号的弹出窗口——只需按相应的数字键选择该窗口布局。\n你还可以通过将鼠标指针悬停在窗口的最大化按钮上来查看Snap布局。或者，将任何窗口拖拽到屏幕中心顶部的边缘以查看Snap选项。\n在PC游戏中在窗口模式和全屏模式之间切换 # Alt + Enter 许多PC游戏提供窗口模式和全屏模式。如果你想要在这两种模式之间切换，频繁地导航到游戏设置菜单可能会相当麻烦。\n以下是在许多PC游戏中快速在窗口模式和全屏模式之间切换的方法：只需按Alt + Enter，这并不适用于所有游戏，但在许多游戏中都有效。\n在虚拟桌面之间切换 # Windows 11有一个名为任务视图的功能，让你可以创建可以切换的“虚拟桌面”。虚拟桌面就像是“桌面”的单独实例，每个虚拟桌面可以容纳自己的一组运行中的应用窗口。\n任务视图体验有几个键盘快捷键，如Windows键 + Tab，可以轻松创建新的虚拟桌面，删除现有的虚拟桌面，并在它们之间切换。\n但是一旦你创建了一些虚拟桌面，更简单的方法是使用Windows键 + Ctrl + 左箭头和Windows键 + Ctrl + 右箭头 快捷键在它们之间切换。\n在显示器之间移动窗口 # Windows键 + Shift + 箭头 你可以通过按Windows键 + Shift + 左箭头（将当前聚焦的窗口移动到左侧显示器）或Windows键 + Shift + 右箭头（将当前聚焦的窗口移动到右侧显示器）来在显示器之间移动窗口。\n打开经典的文件资源管理器上下文菜单 # 在Windows 11上，文件资源管理器从以前的版本改变了很多，特别是有一个简化的上下文菜单。但有些选项只有在那个经典的、老式的上下文菜单中才能找到。\n你可以实际上使用键盘快捷键立即打开旧的上下文菜单：在文件资源管理器中右键点击时按住Shift键以查看经典上下文菜单。\n快速编辑文本 # 按住Ctrl键可以使大多数键对整个单词而不是单个字符起作用。\n例如，Backspace键删除前一个字符，但Ctrl + Backspace删除前一个单词。另一个例子，左箭头和右箭头键将光标移动一个字符，但Ctrl + 左箭头和Ctrl + 右箭头将光标从单词移动到单词。\n它与Shift键也一起工作。按住Shift键时，你可以随着光标的移动高亮文本——所以，如果你想要快速高亮多个连续的单词，只需按住Ctrl + Shift，然后点击左箭头和右箭头键。（尝试与Home和End键一起按Shift键，就高亮整行文本！）\n重新打开已关闭的浏览器标签页 # Ctrl + Shift + T 所有浏览器——包括Chrome、Firefox、Opera和Edge——都允许你快速重新打开已关闭的标签页。也很容易记住：如果Ctrl + T键盘快捷键创建一个新标签页，那么Ctrl + Shift + T快捷键重新打开最后一个关闭的标签页。\n反向Alt + Tab # Alt + Tab是Windows中最经典的键盘快捷键之一。但是，如果你有很多打开的窗口要循环浏览，有时反向循环可能更有意义。在这种情况下，只需按Shift + Alt + Tab以反向浏览打开窗口的列表。\n当Alt + Tab对话框打开时，你还可以使用箭头键立即跳转到所选缩略图窗口。\n快速重命名文件 # 在文件资源管理器中选择文件后，只需按F2，输入名称，然后按Enter。\n我喜欢使用箭头键在文件之间导航，然后使用F2键快速重命名它们。或者更好的方法是：按下F2并输入文件名后，按Tab键（而不是Enter键），立即开始重命名文件夹中的下一个文件。\n将屏幕截图保存为文件 # 内置的Windows屏幕截图工具已经变得更好了，但有时你可能想要跳过工具，立即保存为图像文件。\n要直接将屏幕截图保存到本地，按Windows键 + Print Screen，屏幕会闪烁，Windows会将屏幕截图保存下来。之后，你可以在图片文件夹中的Screenshots文件夹找到屏幕截图。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/20-very-useful-windows-11-shortcuts/","section":"Softwares","summary":"\u003cp\u003e本文介绍20个能够大大提升Windows 11操作效率的快捷键，掌握这些快捷键能让你的工作和学习事半功倍！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e启动文件资源管理器 \n    \u003cdiv id=\"%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWindows键 + E\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果你像我一样，经常使用文件资源管理器。使用键盘快捷键，只需按\u003ccode\u003eWindows键 + E\u003c/code\u003e，就可以在你需要时随时启动一个新的文件资源管理器窗口。\u003c/p\u003e","title":"20 个非常有用的Windows 11快捷键","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/shortcut/","section":"Tags","summary":"","title":"Shortcut","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/gitui/","section":"Tags","summary":"","title":"GitUI","type":"tags"},{"content":"在软件开发的世界中，版本控制是不可或缺的一部分。Git，作为最流行的版本控制系统之一，已经深入到每个开发者的日常工作中。\n尽管 Git 命令行工具功能强大，但有时候，我们也需要一个更直观、更易用的用户界面来提高效率。\n今天，我们将探索一个名为 gitui 的项目，它旨在为 Git 用户提供一个快速、直观且完全在终端内操作的界面。\ngitui：不仅仅是一个界面 # gitui 是一个用 Rust 语言编写的终端界面程序，专为 Git 设计。它不仅仅是一个简单的图形界面，而是一个全面的工具，旨在提供以下特性：\n快速且直观的键盘控制：gitui 允许用户完全通过键盘操作，无需鼠标，大大提高了操作速度。 基于上下文的帮助系统：用户无需记忆复杂的快捷键，gitui 提供了即时的上下文帮助，让操作变得简单直观。 全面的 Git 功能支持：包括提交、暂存、回滚、分支管理、日志浏览等，几乎涵盖了 Git 的所有核心功能。 性能：不仅仅是快速 # 在大型仓库中，传统的 Git 图形界面可能会变得缓慢甚至无响应。gitui 通过异步 Git API 和优化的内存管理，确保了即使在处理大型项目时也能保持流畅的操作体验。在一次性能测试中，gitui 在解析包含超过 900k 提交的 Linux 仓库时，表现出了卓越的性能。\n安装：简单快捷 # gitui 的安装过程非常简单。用户可以通过 Rust 的包管理工具 cargo 轻松安装。此外，gitui 还提供了预编译的二进制文件，支持 Linux、macOS 和 Windows 系统，使得安装过程更加快捷。\n定制：个性化你的工作流 # gitui 支持用户自定义配置，包括颜色主题和按键绑定。用户可以根据自己的喜好和习惯，调整界面和操作方式，使其更加符合个人的工作流。\n社区与支持 # gitui 是一个开源项目，拥有活跃的社区支持。用户可以通过 GitHub 提交问题、参与讨论或贡献代码。\n结语 # gitui 为 Git 用户提供了一个强大而灵活的工具，它不仅提高了工作效率，还增强了用户体验。无论是新手还是资深开发者，gitui 都能成为你日常工作中的得力助手。如果你还没有尝试过 gitui，现在是时候给它一个机会，体验 Git 的全新世界了。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/gitui-terminal-ui-for-git/","section":"Softwares","summary":"\u003cp\u003e在软件开发的世界中，版本控制是不可或缺的一部分。Git，作为最流行的版本控制系统之一，已经深入到每个开发者的日常工作中。\u003c/p\u003e\n\u003cp\u003e尽管 Git 命令行工具功能强大，但有时候，我们也需要一个更直观、更易用的用户界面来提高效率。\u003c/p\u003e\n\u003cp\u003e今天，我们将探索一个名为 gitui 的项目，它旨在为 Git 用户提供一个快速、直观且完全在终端内操作的界面。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003egitui：不仅仅是一个界面 \n    \u003cdiv id=\"gitui%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E4%B8%80%E4%B8%AA%E7%95%8C%E9%9D%A2\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#gitui%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E4%B8%80%E4%B8%AA%E7%95%8C%E9%9D%A2\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003egitui 是一个用 Rust 语言编写的终端界面程序，专为 Git 设计。它不仅仅是一个简单的图形界面，而是一个全面的工具，旨在提供以下特性：\u003c/p\u003e","title":"GitUI: Git 在终端下的UI","type":"software"},{"content":"","date":"2024-10-18","externalUrl":null,"permalink":"/tags/antivirus/","section":"Tags","summary":"","title":"Antivirus","type":"tags"},{"content":"","date":"2024-10-18","externalUrl":null,"permalink":"/tags/clamav/","section":"Tags","summary":"","title":"ClamAV","type":"tags"},{"content":"虽然 Linux 系统因其安全性和稳健性而被广泛使用，但安装杀毒软件依然是明智的，尤其是在与 Windows 系统共享文件或经常下载未知文件时。\n本文主要介绍如何在 Linux 系统上安装免费的杀毒软件。\n选择合适的免费杀毒软件 # Linux 上流行的免费杀毒软件：\nClamAV：最为知名的开源免费杀毒软件，支持多种 Linux 发行版。它可以扫描病毒、恶意软件以及 Windows 系统上的威胁。 Sophos Antivirus for Linux：虽然是商业软件，但 Sophos 提供了 Linux 版本的免费版，能够检测到多平台的威胁。 Chkrootkit 和 Rkhunter：用于检测系统中的 rootkit 威胁，这些工具可以与其他杀毒软件结合使用，增强系统的安全性。 本文以 ClamAV 为例进行安装和使用的演示，因为它开源且易于配置，适合个人用户和企业环境。\n安装 ClamAV # 首先，更新系统的软件包，并安装 ClamAV。\nUbuntu/Debian 系统：\nsudo apt update sudo apt install clamav clamav-daemon CentOS/RHEL 系统：\n如果使用的是 CentOS 或 RHEL，请执行以下命令：\nsudo yum install epel-release sudo yum install clamav clamav-update Arch Linux 系统：\nArch Linux 用户，执行以下命令：\nsudo pacman -S clamav 更新病毒库 # ClamAV 的病毒库是需要定期更新的，这样它才能识别最新的威胁。安装完 ClamAV 后，首先要更新病毒库。\nsudo freshclam 将下载最新的病毒定义数据库。在大多数系统中，freshclam 会自动更新病毒库，也可以将其添加到定时任务中确保持续更新。\n配置和启动 ClamAV # 为了让 ClamAV 在后台自动扫描文件，我们需要启动 clamav-daemon 服务。\nsudo systemctl start clamav-daemon sudo systemctl enable clamav-daemon 查看运行状态：\nsudo systemctl status clamav-daemon 当我们想要手动扫描时，也可以使用 clamdscan 工具，它会与 clamav-daemon 一起工作，从而减少扫描时间。\n执行手动扫描 # ClamAV 允许你扫描特定目录或文件。以下是一些常用的扫描命令：\n扫描整个系统：\nsudo clamscan -r / 扫描指定目录：\nsudo clamscan -r /path/to/directory -r 参数表示递归扫描文件夹，扫描会包含文件夹内的所有文件。如果希望 ClamAV 在检测到感染文件后自动删除它们，可以使用 `--remove` 参数： sudo clamscan -r --remove /path/to/directory 扫描后的报告输出到文件：\n如果你希望保存扫描结果，可以通过以下命令将报告输出到文件中：\nsudo clamscan -r /path/to/directory \u0026gt; /path/to/report.txt 定时自动扫描 # 可以设置定时任务，让 ClamAV 每天自动扫描指定目录。使用 crontab 进行设置：\nsudo crontab -e 在文件中添加以下内容，设置每天凌晨 2 点自动扫描 /home 目录：\n0 2 * * * /usr/bin/clamscan -r /home --log=/var/log/clamav-scan.log 安全增强（可选） # 还可以结合使用 chkrootkit 或 rkhunter 来检测系统中潜在的 rootkit 威胁：\n安装 Chkrootkit： # sudo apt install chkrootkit sudo chkrootkit 安装 Rkhunter： # sudo apt install rkhunter sudo rkhunter --check 这些工具可以与 ClamAV 配合使用，提供更加全面的安全防护。\n监控与日志 # ClamAV 会在 /var/log/clamav 中生成日志文件，可以通过以下命令查看最近的扫描日志：\ncat /var/log/clamav/clamav.log 根据日志文件中的信息，可以进一步分析潜在的威胁。\n在 Linux 系统上安装杀毒软件，尤其是 ClamAV，是一个简单而有效的安全措施。虽然 Linux 本身相对安全，但额外的防护手段可以减少潜在的安全威胁，特别是在与其他系统共享文件时。通过定期更新病毒库、手动或自动扫描文件、并结合其他安全工具，用户可以确保其系统得到最全面的保护。\n按照本指南，您现在可以在 Linux 系统上有效地安装并运行 ClamAV，确保系统的安全性。\n","date":"2024-10-18","externalUrl":null,"permalink":"/software/installing-free-antivirus-software-on-linux/","section":"Softwares","summary":"\u003cp\u003e虽然 Linux 系统因其安全性和稳健性而被广泛使用，但安装杀毒软件依然是明智的，尤其是在与 Windows 系统共享文件或经常下载未知文件时。\u003c/p\u003e\n\u003cp\u003e本文主要介绍如何在 Linux 系统上安装免费的杀毒软件。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e选择合适的免费杀毒软件 \n    \u003cdiv id=\"%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%85%8D%E8%B4%B9%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%85%8D%E8%B4%B9%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux 上流行的免费杀毒软件：\u003c/p\u003e","title":"在 Linux 系统上安装免费杀毒软件","type":"software"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/gddr/","section":"Tags","summary":"","title":"GDDR","type":"tags"},{"content":" 什么是GDDR内存？ # GDDR代表Graphics Double Data Rate ，是一种专门为显卡设计的内存。GDDR内存与大多数计算机使用的DDR内存相似，但它针对显卡的使用进行了优化。GDDR内存通常比DDR内存带宽更高，这意味着它可以一次传输更多数据。\nGDDR6是GPU的最新内存标准，per-pin数据速率峰值为16Gb/s。GDDR6在包括NVIDIA RTX 6000 Ada和AMD Radeon PRO W7900在内的大多数GPU中使用，仍然用于2024年的GPU。\nNVIDIA还与美光合作开发GDDR6X，这是GDDR6的继任者。我们这样说是因为除了从NRZ到PAM4的编码外，两者之间没有任何硬件变化，并且由于NVIDIA是唯一的用户，JEDEC行业标准化没有认可。DDR6X将per-pin带宽提高到21Gb/s。GDDR7是下一个应该被所有人广泛采用的GDDR标准。\n截至2024年，GDDR6和GDDR6X的最大内存总线为384位。GDDR内存是焊接到GPU芯片周围的PCB上的单个芯片。\n什么是HBM内存？ # HBM代表高带宽内存，是一种专门为GPU开发的新型内存。\nHBM内存旨在提供比GDDR内存更大的内存总线宽度，这意味着它可以一次传输更多数据。单个HBM内存芯片不如单个GDDR6芯片快，但这使得它比GDDR内存更节能，这对移动设备来说是一个重要的考虑因素。\nHBM内存位于GPU封装内并堆叠——例如，HBM有四个DRAM（4-Hi）的堆栈，每个有两个128位通道，总宽度为1024位（4个2个通道128位）。由于HBM内存作为内存芯片模块内置在GPU芯片中，因此错误和空间更少。因此，单个GPU不容易像配备GDDR的GPU那样易于扩展内存配置。\n最新采用最多的HBM内存是NVIDIA H100中的HBM3，具有5120位总线和超过2TB/s的内存带宽。HBM3也存在于竞争对手的AMD Instinct MI300X中，具有8192位总线和超过5.3TB/s的内存带宽。英伟达还在其GH200和H200中引入了新的HBM3e内存，作为第一批使用HBM3e的加速器和处理器，具有更大的内存带宽。这些配备HBM内存的硬件正在快速翻新。H100和MI300X等加速器GPU需要HBM的一个重要原因是多个GPU之间的互连性；为了相互通信，宽总线宽度和快速的数据传输速率对于减少将数据从一个GPU传输到另一个GPU的瓶颈至关重要。\nGDDR与HBM内存 # 那么，哪种类型的内存更适合GPU？答案是，这取决于具体的场景。\n配备GDDR内存的GPU通常是：\n更容易访问，因为它们是主流的GPU类型 更便宜，因为GDDR直接焊接在PCB上，而不是GPU封装上。 大多数主流应用程序不会最大化内存带宽。 但GDDR通常消耗更多的能源，效率不那么高。 配备HBM内存的GPU通常是：\n更不容易获得，更利基 非常昂贵，在H100等旗舰加速器中发现。 仅用于需要最多带宽的HPC和高利基工作负载 高效，并提供更大的总线宽度，以并行化每引脚速率。 大多数应用程序不需要HBM内存。对于利用大量数据的工作负载来说，更高的内存带宽是最重要的。仿真、实时分析、密集的人工智能训练、复杂的人工智能推理等工作负载都可以从使用更多的内存带宽中受益。\n同样重要的是要考虑，如果工作负载相互并行，配备GDDR的最快GPU可以正常工作。NVIDIA RTX 6000 Ada是一款功能强大的旗舰GPU，非常适合中小型人工智能训练、渲染、分析、模拟和数据密集型工作负载，内存带宽为960GB/s。插槽具有多GPU设置的服务器或工作站，工作可以并行化和拆分，以获得更高的性能。\n然而，像NVIDIA H100这样的HBM配备GPU可以显著提高企业部署的生产力（尽管成本很高）。更高的性能和更少的等待可以实现更快的突破。ChatGPT等部署利用H100集群协同工作，在给定时间为数百万用户执行实时推理和生成人工智能功能，处理提示并交付实时输出。\n如果没有快速的高带宽内存和峰值性能，企业部署可能会变得非常缓慢，几乎无法使用。一个很好的例子是ChatGPT的发布月份。ChatGPT和OpenAI可能认为他们有足够的HBM启用的NVIDIA GPU来处理大量并发用户，但不知道他们新的生成式AI聊天机器人将有多受欢迎。他们不得不对并发用户数量设置上限，要求网站访问者在扩展基础设施时对服务保持耐心。然而，从这个角度来看，如果没有使用这些高带宽内存互连的GPU，ChatGPT甚至可能是不可能的。\n结论 # 总之，GDDR内存和HBM内存都有其优点和缺点。GDDR内存更便宜，对于需要高带宽但不需要绝对最高性能的应用程序来说是一个不错的选择。另一方面，HBM内存更昂贵，但提供更高的带宽，是需要高性能的应用程序的不二之选。在这两种类型的内存之间进行选择时，重要的是要考虑场景和成本。\n","date":"2024-10-17","externalUrl":null,"permalink":"/hardware/difference-between-gddr-memory-vs-hbm-memory/","section":"Hardwares","summary":"\u003ch2 class=\"relative group\"\u003e什么是GDDR内存？ \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGDDR代表Graphics Double Data Rate ，是一种专门为显卡设计的内存。GDDR内存与大多数计算机使用的DDR内存相似，但它针对显卡的使用进行了优化。GDDR内存通常比DDR内存带宽更高，这意味着它可以一次传输更多数据。\u003c/p\u003e","title":"GDDR 与 HBM 内存之间的区别","type":"hardware"},{"content":"AMD经常详细介绍已经发布了一段时间的产品。在Hot Chips 2024上，AMD详细介绍了Instinct MI300X。我们知道MI325X很快就会发布。尽管如此，这仍然是NVIDIA GPU之外唯一一个在AI行业每年销售达到数十亿美元的GPU。AMD上周刚刚收购了生产Microsoft Azure MI300X平台的ZT系统公司。\nHot Chips 2024上展示的AMD Instinct MI300X架构 # AMD 的幻灯片看起来很不错，因此让大家阅读它们，并在讲解过程中添加一些色彩。\nMI300A主要应用于惠普的El Capitan等超级计算机。看起来MI300X是今年该系列40多亿美元收入的主要来源。\nAMD有一个有192MB的HBM3，用于计算等应用的multi-chiplet芯片：\n这是AMD CDNA 3结构的演变：\nAMD拥有8-stack HBM3内存阵列，容量达到192GB。\n下面是用于计算的XCD、Infinity Cache、Infinity Fabric和8个HBM封装的框图。\n下面是缓存和内存层次结构。我们不仅可以看到192GB的HBM3，还可以看到256MB的Infinity缓存，8*4MB的L2缓存等。\nMI300X可以作为单个分区运行，也可以在不同的内存和计算分区中运行。\nAMD目前的大平台是8路MI300X OAM平台。\n这是Instinct系统路线图。MI200在OAM板上也看到了，但它为单个GPU。\n以下是AMD对NVIDIA HGX平台的回答。\n每个GPU有7条链路用于直接连接以及主机链路。\nRAS在大规模AI集群中是一件大事。\n这是AMD的服务器。微软/ ZT系统的MI300平台在这里没有提到。令人失望的是，戴尔仍然没有在其AI平台中提供EPYC。同样明显缺失的还有Wiwynn平台。\nAMD谈论ROCm，它正在变得越来越好。\n在某些情况下，AMD可以击败NVIDIA H100。当然，现在人们开始更频繁地部署NVIDIA H200，AMD方面也致力于MI325X。所以两家公司产品性能的对比可以交给时间来检验。\n这是MPT微调，据AMD称和H100性能相当。\n总结 # MI300X是AMD 2023年的设计，现在它将与H100正面交锋，我们预计两者将在不久的将来被更高内存的版本所取代。据了解，该公司今年会推出MI325X，2025年将推出Instinct MI350 288GB GPU。\n尽管如此，AMD凭借数十亿美元的产品线，已经巩固了自己在AI GPU领域仅次于NVIDIA的地位。\n","date":"2024-10-17","externalUrl":null,"permalink":"/hardware/amd-instinct-mi300x-architecture-at-hot-chips-2024/","section":"Hardwares","summary":"\u003cp\u003eAMD经常详细介绍已经发布了一段时间的产品。在Hot Chips 2024上，AMD详细介绍了Instinct MI300X。我们知道MI325X很快就会发布。尽管如此，这仍然是NVIDIA GPU之外唯一一个在AI行业每年销售达到数十亿美元的GPU。AMD上周刚刚收购了生产Microsoft Azure MI300X平台的ZT系统公司。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eHot Chips 2024上展示的AMD Instinct MI300X架构 \n    \u003cdiv id=\"hot-chips-2024%E4%B8%8A%E5%B1%95%E7%A4%BA%E7%9A%84amd-instinct-mi300x%E6%9E%B6%E6%9E%84\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#hot-chips-2024%E4%B8%8A%E5%B1%95%E7%A4%BA%E7%9A%84amd-instinct-mi300x%E6%9E%B6%E6%9E%84\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eAMD 的幻灯片看起来很不错，因此让大家阅读它们，并在讲解过程中添加一些色彩。\u003c/p\u003e","title":"AMD Instinct MI300X 架构亮相 Hot Chips 2024","type":"hardware"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/instinct/","section":"Tags","summary":"","title":"Instinct","type":"tags"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/mi300x/","section":"Tags","summary":"","title":"Mi300X","type":"tags"},{"content":"AMD、Intel之间的服务器与数据中心处理器大战硝烟再起，战况空前！\nIntel正在陆续发布全新设计的第六代至强6系列，AMD则祭出了同样全新的第五代EPYC 9005系列，可谓针尖对麦芒。\n曾经，AMD在服务器与数据中心市场上几近消失；曾经，Intel几乎完全垄断了整个行业。\n七年来，双方进行了一次又一次激烈交锋，AMD无疑气势更盛，无论产品发布节奏还是规格性能提升，都步步为营，一点一点改变了行业格局，第三方机构统计显示市场份额已经达到34％，合作生态也日渐繁荣。\nIntel在对手的强势挑战之下，也是一路马不停蹄，一度因产品延期导致的混乱也终于过去，正在重新起航。\n这一次，双方都是有备而来，都是气势如虹，究竟谁更胜一筹呢？\n架构设计：都是“大小核” 但又截然不同 # 有趣的是，AMD、Intel都将所谓的“大小核”架构设计引入到了数据中心，但具体做法是完全不同的，这也直接导致双方产品的实际表现迥异。\nAMD的做法是“同构大小核”，之前的第四代EPYC率先吃螃蟹，首次划分出了Zen 4、Zen 4c两个版本，分别对应Genoa EPYC 9004系列、Bergamo EPYC 97x4系列两条产品线。\nZen 4、Zen 4c都基于完全相同的底层微架构，拥有完全相同的IPC性能、ISA指令集、技术特性，唯一的不同就是后者三级缓存更少一些，主频更低一些，同样的5nm工艺下核心面积缩小了大约35％之多。\n对于操作系统和应用软件来说，不需要考虑二者的不同，也不需要专门的适配与优化，可一视同仁，只是将它们用在不同的负载和场景而已，其中Zen 4是常规的通用计算，Zen 4c则主攻高密度云计算。\n第五代EPYC延续了这一理念，并进行了全面升级。\n其中，Zen 5部分升级为4nm工艺，CCD模块从12个增至16个，整体从96核心192线程增至128核心256线程(每CCD还是8个)，三级缓存也从384MB增至512MB(每核心还是4MB)。\nZen 5c部分更是升级为3nm工艺，使得核心面积进一步缩小，可以容纳更多核心，CCD模块从8个增至12个，整体从128核心256线程增至192核心384线程(每CCD还是16个)，三级缓存则从256MB增至384MB(每核心还是2MB)。\nAMD暂未公布Zen 5、Zen 5c的具体核心面积，但相信会和上代类似，至少也得差个1/3。\nIntel走的则是“异构大小核”，在至强历史上首次兵分两路，为此放弃了延续五代的“至强可扩展”的名号，改为更简单直接的“至强6”。\n至强6 6000E系列代号Sierra Forest，首次将E核(能效核)引入数据中心，而且只有E核，专门针对高密度运算、可扩展负载。\n至强6 6000P系列代号Granite Rapids，只使用传统的P核(性能核)，主打高性能计算、AI负载场景。\n它们都延续了以往的分离式模块化架构，其中核心计算模块升级为Intel 3制造工艺(可以粗略地认为大致等于3nm)。\n至强6 E系列首发只有一种计算模块，144核心144线程——是的不支持超线程。\n至强6 P系列则有四种计算模块配置：单个小模块16核心32线程、单个大模块48核心96线程、两个大模块96核心192线程、三个大模块128核心256线程(理论上应该是屏蔽了4个核心以保证良品率)。\n至强6两条线的架构设计截然不同，规格、性能自然差异极大，不过还好，二者共享统一的软件开发平台，从而便于部署。\n有趣的是，这是AMD EPYC诞生七年来，Intel第一次在核心数量上追平了AMD，当然只是说完整大核版本，都是128核心。\n在“小核”方面，AMD仍然多出48个，还是高性能架构，还有超线程，还有更多……\n产品布局：128核心大战128核心、384线程大战288线程 # 接下来，我们看看双方第一批新品的产品线布局，也是很有趣，同样走了截然不同的路线。\n上一代EPYC将Zen 4、Zen 4c分成两条不同的子产品线，各有各的代号，命名规则都不一样，客户可以一眼看出区别。\n这一次，EPYC 9005系列将Zen 5、Zen 5c纳入了统一管理，甚至共用一个代号Turin，就在型号命名上都完全混合在一起。\n事实上这一代两种核心对应的内存、PCIe规格都完全一致，不像上代Zen 4c的精简了不少，自然没必要再区分开。\nAMD也希望通过此举消弭Zen 5、Zen 5c之间的鸿沟，简化客户的选择，毕竟它们是同样的架构、性能、指令、功能，不需要差异对待。\n客户根本不用考虑一款产品到底用了Zen 5还是Zen 5c，只需要根据自己的应用需求，选择不同的核心、频率、缓存、功耗等指标组合，即可找到最适合自己的型号。\n非要区分的话，Zen 5的有22款，Zen 5c的有5款。\n8-72个核心的只有Zen 5，144-192核心的只有Zen 5c，96-128核心的两种都有，其中9x55编号的为Zen 5，9x45编号的为Zen 5c。\n另外值得一提的是，AMD首次将最高频率提升到了惊人的5GHz，对比上代的最高值一下子提升了足足600MHz。\n这对于多核心的数据中心处理器来说是非常难得的，而且一次就有两款做到了，分别是16核心的EPYC 9175F、64核心的EPYC 9575F，非常适合对频率非常敏感的应用。\nIntel则是分成了完全不同的两部分，分别冠以P、E的后缀，一眼就能看出谁是大核、谁是小核。\n至强6900P系列都是大核，最高做到了128核心256线程，最少也有72核心144线程。\n至强6700E系列最多144核心144线程，最少则是64核心64线程。\n规格性能：AMD气势如虹 全面碾压 # 对比来看，五代EPYC 9005在纸面规格参数上就远胜于六代至强6，下边逐一对比下：\n核心数： # EPYC 9005 Zen 5最多128核心256线程，与至强6900P持平。\nZen 5c的最多更是192核心384线程，遥遥领先至强6700E 144核心144线程。\n另外，双方都支持最多双路并行，Intel这次也没有四路、八路。\n频率： # EPYC 9005最高达到了空前的5.0GHz，Zen 5c最高也有3.7GHz。\n至强6就差多了，甚至都没迈过4GHz的门槛，6900P最高统一都是3.9GHz，6700E系列更是只有3.2GHz。\n三级缓存： # EPYC 9005 Zen 5、Zen 5c最多分别做到了512MB、384MB，平均每个核心分别4MB、2MB。\n至强6900P最多504MB，只输了一点点；至强6700E则是最多108MB，还不到对手的三分之一，平均每个核心还不到1MB。\nDDR5内存： # EPYC 9005系列全部统一支持12通道DDR5-6000，最低端也没有阉割。\n至强6900P系列也是12通道，频率更高一些DDR5-6400，还支持新型MRDIMM内存，频率高达8800MHz——这几乎是至强6唯一的优势了。\n至强6700E系列只有8个内存通道，而且只有部分型号保留DDR5-6400的频率，还有一部分降级为DDR5-5600。\nPCIe 5.0通道： # EPYC 9005系列都是128条PCIe 5.0通道，和上代相同。\n至强6900P系列只有96条，至强6700E系列进一步减少到88条。\n热设计功耗： # 双方最高都达到了500W，尤其是完整核心都是在128核心的情况下做到的，彼此彼此。\n不过，Zen 5c 192核心时也有500W，至强6700E 144核心时则是330W，平均到每个核心后者更低一些为2.3W，前者是2.6W。\n平台： # EPYC 9005系列延续了上代的SP5封装接口，客户可以无缝升级，而且按照AMD的做法，这一接口还会延续下去，可能要等到支持DDR6内存的时候才会改变。\n至强6系列不但用了新接口，还分为两种，至强6900P系列是LGA7529，至强6700E系列是LGA4710，不仅上代无法升级，大小核之间也无法通用。\n其他： # EPYC 9005系列全部支持AVX-512指令集，这本来是Intel的独门绝技，但异构大小核的设计让它消失了，至强6也没有。\nEPYC 9005系列全部支持多线程，至强6900P也有，至强6700E就没了。\n至强6内置了一系列的AI加速器，可以让某些特定负载大大加速，EPYC 9005系列则没有，不过AMD有更强大的Instinct加速卡，强调二者搭档发挥各自的优势，Intel GPU加速卡则没能做起来。\n当然，纸面得来终觉浅，最终还要看跑分。\nPhoronix网站进行了多型号的全方位测试，Ubuntu系统下跑了多达140个数据中心测试项目，总结如上。\n可以看出，EPYC 9005系列对比至强6呈现一边倒的压倒性优势，可以说是全程吊打。\n旗舰之争中，EPYC 9755面对MRDIMM-8000高频内存加持的至强6980P，双路、单路优势分别高达40.0％、18.4％，如果将后者换成普通的DDR5-6400，领先幅度更是能进一步提升到41.7％、19.3％。\n夸张的是，只需要一颗EPYC 9755，就能干掉两颗搭配DDR5-6400内存的至强6980P！\n同时，192核心的EPYC 9965、5GHz频率的EPYC 9575F，也都超越了至强6980P，后者领先超过20％。\n有趣的是，EPYC的双路并行效率要高得多。\n遗憾的是没有加入至强6700E系列的测试，但不难想象，即便加上也是被欺负的命。\n功耗方面，五代EPYC也有着绝对优势，远远低于至强6。\n无论是192核心的EPYC 9965，还是5GHz频率的EPYC 9575F，实际功耗都没有超过400W的热设计功耗指标。\n即便是128核心旗舰的EPYC 9755，功耗也只有450W左右，远低于500W的热设计功耗。\n至强6980P则正好达到了500W，这就是官方标称的热设计功耗。\n展望未来：只是刚刚开始 都还有杀手锏 # 通过前述种种对比可是看出，EPYC 9005系列在至强6系列面前相当霸道，无论是规格参数、技术，还是实际性能、能效，又或者平台便利性，都实现了全方位的碾压，甚至可以说是吊打，Intel依然毫无还手之力。\n而且，这只是双方新一代平台的开端，各自都还有杀手锏级的后招。\nAMD没有透露具体情况，但显然会有适合极高性能计算的第三代3D缓存版本。\n上一代就做到了768MB 3D缓存，加上原生的384MB合计达1152MB，也是史上第一次超过1GB。\n这一代随着CCD模块数量的增加，3D缓存有望增至1024MB，加上原生的512MB，合计可达1536MB，也就是整整1.5GB！\nIntel方面，明年一季度会发布至强 6900E系列，两个计算模块，最高达288核心288线程，在核心数量上创造新纪录。\n但是因为不支持多线程技术，它的线程数还是稍逊一筹，再考虑到AMD多线程技术的效率，192核心384线程超过它问题不大。\n另外还有至强6700P、6500P、6300P系列，显然核心数不会超过128个。\n按照AMD的说法，EPYC平台已经拥有超过350个OEM平台、超过950个云实例，无论是大规模云厂商还是大型科技/行业企业，都有大量的深度合作伙伴，是实至名归的“超大规模数据中心第一处理器”。\nIntel方面没有明确数据，但凭借长期以来雄厚的积累，以及依然把持住2/3的市场，合作案例肯定更多、更深入。\n仅仅七年，AMD EPYC就吃下了超过1/3的市场，对于一向看重产品和平台品质、看重长期稳定性的服务器与数据中心客户来说，能做到这种程度只能说是一个奇迹。\n更可怕的是，AMD EPYC在产品力上几乎找不到缺点和短板，几乎每一个点都让对手望尘莫及，相信还会拿到更多的市场。\n七年五代产品，AMD将核心数量提升了6倍，性能更是提升了几乎11倍，一路狂奔根本停不下来的架势。\n","date":"2024-10-16","externalUrl":null,"permalink":"/hardware/amd-fifth-gen-epyc-vs-intel-sixth-gen-xeon/","section":"Hardwares","summary":"\u003cp\u003eAMD、Intel之间的服务器与数据中心处理器大战硝烟再起，战况空前！\u003c/p\u003e\n\u003cp\u003eIntel正在陆续发布全新设计的第六代至强6系列，AMD则祭出了同样全新的第五代EPYC 9005系列，可谓针尖对麦芒。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-epyc-vs-intel-xeon-1.png\" alt=\"AMD fifth Gen epyc vs Intel Sixth Gen Xeon\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-epyc-vs-intel-xeon-2.png\" alt=\"AMD fifth Gen epyc vs Intel Sixth Gen Xeon\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"AMD五代EPYC对决Intel六代至强","type":"hardware"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/epyc-9005/","section":"Tags","summary":"","title":"EPYC 9005","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/xeon-6/","section":"Tags","summary":"","title":"Xeon 6","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/zen-5/","section":"Tags","summary":"","title":"Zen 5","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/ecosystem/","section":"Tags","summary":"","title":"Ecosystem","type":"tags"},{"content":"英特尔与AMD一直是业界两大强劲的竞争对手，然而，近日这两家公司却罕见地携手合作，共同宣布成立一个新的x86咨询小组，旨在确保未来x86指令集架构（ISA）的统一和兼容性。这一举措在2024年OCP峰会上正式公布，引起了广泛关注。该小组的成员包括博通、Meta、Oracle、微软、戴尔、HPE、联想、谷歌、红帽等。\nx86指令集架构自诞生以来已有46年历史，已成为个人电脑和数据中心通用计算的最普遍标准。英特尔和AMD作为仅有的两家大批量生产新处理器的主要x86架构授权商，形成了双头垄断的格局。然而，随着x86生态系统在消费者和数据中心市场面临来自Arm和RISC-V的巨大压力，两家公司意识到加强合作、减少定制ISA实现带来的问题至关重要。\n当前消费科技巨头苹果、移动芯片设计商高通以及云计算巨头如AWS、微软和谷歌等都在为PC和云市场设计自己的基于Arm的CPU。此外，另一家移动芯片设计商联发科已公开表示计划为Windows PC推出基于Arm的CPU，并正在与Nvidia合作。这进一步加剧了英特尔和AMD的压力。在过去一年中，这两家公司都推出了自己的高核心密度和高效率处理器。AMD去年推出了其EPYC“Bergamo”芯片，英特尔最近推出了其Xeon 6 E核心芯片。\n在联合声明中，英特尔和AMD表示，该小组将专注于寻找扩展x86生态系统的新方法，实现跨平台兼容性，简化软件开发，并为开发者提供一个平台来识别架构需求和功能。英特尔首席执行官帕特·基辛格表示：“我们正面临x86架构和生态系统几十年来最重大的转变之一，需要达到新的定制化、兼容性和可扩展性水平，以满足当前和未来的客户需求。”\nAMD董事长兼首席执行官苏姿丰在声明中表示：“成立x86生态系统咨询小组将确保x86架构继续发展成为开发人员和客户的首选计算平台。”\n新组织打算对 x86 ISA 的一些新增和修改进行标准化，其中包括几项已经在进行的简化工作。修改和协作领域尚未确定，但有很多明确的候选方案可以进行讨论。\n例如，AMD 有其 Supervisor Entry Extensions，旨在清除 ISA 中的一些旧垃圾，而英特尔有其灵活返回和事件传递 (FRED)代码，其目标类似。英特尔甚至已经开始开发 X86S，这是一种简化的 64 位实现，旨在清除更多遗留垃圾。\n此外x86 ISA 也在不断推进新的功能，在这方面，英特尔和 AMD 之间的合作可能变得更加重要。例如，英特尔最近推出了 AMX，这是一种矩阵数学扩展，可显著提高 AI 推理工作负载的性能。未来肯定会有更新的和尚未预见到的新增功能，特别是关于支持 AI 操作的各种扩展。\n在以动态AI工作负载、定制芯片以及3D封装和系统架构进步为特征的当今环境中，强大且不断扩展的x86生态系统比以往任何时候都更为重要。该顾问小组将团结行业领导者，通过一套更加统一的指令和架构接口来塑造x86的未来，促进开发者的创新。这一举措将增强x86产品的兼容性、可预测性和一致性。\n预期成果包括：\n增强客户在硬件和软件方面的选择和兼容性，加速他们从新功能中获益的能力。 简化架构指南，增强英特尔和AMD的x86产品之间的软件一致性和接口。 使新功能能够更好、更高效地集成到操作系统、框架和应用程序中。 英特尔和AMD虽然是竞争对手，但也有着合作的历史，例如PCIe、ACPI和USB等标准正是整个行业紧密协作的结果。\n总的来说，英特尔与AMD携手成立x86咨询小组是一个重要的里程碑，标志着两家公司在推动x86架构统一和兼容性方面迈出了重要一步。未来，随着更多公司和功能的加入，x86生态系统将更加开放、统一和强大。然而，考虑到现代处理器的设计周期较长，想要咨询小组立马发挥关键作用应该很难，但至少这是一个积极的开始。\n","date":"2024-10-16","externalUrl":null,"permalink":"/hardware/intel-and-amd-launch-x86-ecosystem-advisory-group/","section":"Hardwares","summary":"\u003cp\u003e英特尔与AMD一直是业界两大强劲的竞争对手，然而，近日这两家公司却罕见地携手合作，共同宣布成立一个新的x86咨询小组，旨在确保未来x86指令集架构（ISA）的统一和兼容性。这一举措在2024年OCP峰会上正式公布，引起了广泛关注。该小组的成员包括博通、Meta、Oracle、微软、戴尔、HPE、联想、谷歌、红帽等。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./x86-ecosystem-advisory-group.png\" alt=\"Intel and AMD Launch x86 Ecosystem Advisory Group\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003ex86指令集架构自诞生以来已有46年历史，已成为个人电脑和数据中心通用计算的最普遍标准。英特尔和AMD作为仅有的两家大批量生产新处理器的主要x86架构授权商，形成了双头垄断的格局。然而，随着x86生态系统在消费者和数据中心市场面临来自Arm和RISC-V的巨大压力，两家公司意识到加强合作、减少定制ISA实现带来的问题至关重要。\u003c/p\u003e\n\u003cp\u003e当前消费科技巨头苹果、移动芯片设计商高通以及云计算巨头如AWS、微软和谷歌等都在为PC和云市场设计自己的基于Arm的CPU。此外，另一家移动芯片设计商联发科已公开表示计划为Windows PC推出基于Arm的CPU，并正在与Nvidia合作。这进一步加剧了英特尔和AMD的压力。在过去一年中，这两家公司都推出了自己的高核心密度和高效率处理器。AMD去年推出了其EPYC“Bergamo”芯片，英特尔最近推出了其Xeon 6 E核心芯片。\u003c/p\u003e\n\u003cp\u003e在联合声明中，英特尔和AMD表示，该小组将专注于寻找扩展x86生态系统的新方法，实现跨平台兼容性，简化软件开发，并为开发者提供一个平台来识别架构需求和功能。英特尔首席执行官帕特·基辛格表示：“我们正面临x86架构和生态系统几十年来最重大的转变之一，需要达到新的定制化、兼容性和可扩展性水平，以满足当前和未来的客户需求。”\u003c/p\u003e\n\u003cp\u003eAMD董事长兼首席执行官苏姿丰在声明中表示：“成立x86生态系统咨询小组将确保x86架构继续发展成为开发人员和客户的首选计算平台。”\u003c/p\u003e\n\u003cp\u003e新组织打算对 x86 ISA 的一些新增和修改进行标准化，其中包括几项已经在进行的简化工作。修改和协作领域尚未确定，但有很多明确的候选方案可以进行讨论。\u003c/p\u003e","title":"英特尔 和 AMD 宣布合作，共同成立生态小组","type":"hardware"},{"content":"Intel前脚刚发布至强6 6000系列，AMD就带来了Zen 5/5c架构的五代EPYC 9005系列，彼此针锋相对，后者显然更胜一筹。\nPhoronix提前测试了多颗EPYC 9005的样品，结果自然不出所料，丝毫不对手任何情面。\n测试的新SKU一共三颗，分别是：\nEPYC 9965： Zen 5c顶级旗舰，192核心384线程，384MB三级缓存，2.25-3.7GHz频率，500W热设计功耗。 EPYC 9575F： 最高频率型号之一，Zen 5，64核心128线程，256MB三级缓存，3.3-5.0GHz频率，400W热设计功耗。 EPYC 9755： Zen 5顶级旗舰，128核心256线程，512MB三级缓存，2.7-4.1GHz频率，500W热设计功耗。 至强6980P也是新一代旗舰，P性能核设计，128核心256线程，504MB三级缓存，2.0-3.9GHz频率，500W热设计功耗。\n测试系统是Ubuntu 24.04 LTS，系统内核6.12。测试项目多达140个。\n直接看结果汇总：\n无论双路还是单路，EPYC 9755都是一马当先，优势大到不可思议，面对搭配超高频率MRDIMM 8000MHz内存的至强6980P，优势分别高达40.0％、18.4％，后者换成普通的DDR5-6400，领先幅度还会略微提高到41.7％、19.3％。\n事实上，只需一颗EPYC 9755，就能干掉两颗至强6980P DDR5-6400！\nEPYC 9965、EPYC 9575F同样也是一骑绝尘，全都能将至强6980斩落马下，双路EPYC 9575F对比双路至强6980P(MR-DIMM 8000)，优势仍有22.6％，单路对比也只落后8.4％。\n这从另一方面可以看出，五代EPYC的双路效率非常高，远胜于至强6。\n对比上代产品，128核心EPYC 9755相比于96核心EPYC 9654，都是旗舰，提升幅度高达恐怖的63.1％。\n192核心、Zen 5c架构的EPYC 9965对比128核心、Zen 4c架构的EPYC 9754，提升幅度同样有不可思议的47.6％。\n有趣的是，一颗EPYC 9965就能超过两颗EPYC 9754/9654，领先幅度分别为8.4％、17.7％。\n功耗方面，五代EPYC也有着绝对优势，远远低于至强6。\n无论是192核心的EPYC 9965，还是5GHz频率的EPYC 9575F，实际上都控制在了400W之内，128核心的EPYC 9755也只有450W左右，可以说热设计功耗留足了空间。\n至强6980P则刚好达到了500W。\n可以说，AMD EPYC在性能、功耗、能效等指标上已经处于绝对的统治地位，Intel至强短期内一点办法都没有。\n后续，Intel会推出288核心288线程的顶级型号，不过采用能效核设计，192核心384线程的EPYC 9965领先之目测不会有什么压力。\n","date":"2024-10-15","externalUrl":null,"permalink":"/hardware/amd-zen5-epyc-first-test-result-review/","section":"Hardwares","summary":"\u003cp\u003eIntel前脚刚发布至强6 6000系列，AMD就带来了Zen 5/5c架构的五代EPYC 9005系列，彼此针锋相对，后者显然更胜一筹。\u003c/p\u003e\n\u003cp\u003ePhoronix提前测试了多颗EPYC 9005的样品，结果自然不出所料，丝毫不对手任何情面。\u003c/p\u003e\n\u003cp\u003e测试的新SKU一共三颗，分别是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEPYC 9965：\n\u003cul\u003e\n\u003cli\u003eZen 5c顶级旗舰，192核心384线程，384MB三级缓存，2.25-3.7GHz频率，500W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eEPYC 9575F：\n\u003cul\u003e\n\u003cli\u003e最高频率型号之一，Zen 5，64核心128线程，256MB三级缓存，3.3-5.0GHz频率，400W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eEPYC 9755：\n\u003cul\u003e\n\u003cli\u003eZen 5顶级旗舰，128核心256线程，512MB三级缓存，2.7-4.1GHz频率，500W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-EPYC-9005-SKU-1.png\" alt=\"AMD EPYC 9005 SKU\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"AMD Zen5 EPYC首测","type":"hardware"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/eypc/","section":"Tags","summary":"","title":"EYPC","type":"tags"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/mrdimm/","section":"Tags","summary":"","title":"MRDIMM","type":"tags"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/gaudi-3/","section":"Tags","summary":"","title":"Gaudi 3","type":"tags"},{"content":"早在4月份，Intel就宣布了新一代AI加速器Gaudi 3，现在它终于发布了，详细的规格参数也已出炉，竞争对手直指NVIDIA H100 GPU加速器，当然后者的Blackwell系列也要上量了。\n数据显示，预计到2030年，全球半导体市场规模将达1万亿美元，AI是主要推动力，不过在2023年，只有10％的企业能够成功将其AIGC项目产品化。\nIntel现有的Gaudi 2诞生于2022年5月，并于2023年7月正式引入中国，拥有极高的深度学习性能、效率，以及极高的性价比。\n它采用台积电7nm工艺制造，集成24个可编程的Tenor张量核心(TPC)、48MB SRAM缓存、21个10万兆内部互连以太网接口(ROCEv2 RDMA)、96GB HBM2E高带宽内存(总带宽2.4TB/s)、多媒体引擎等，支持PCIe 4.0 x16，最高功耗800W，可满足大规模语言模型、生成式AI模型的强算力需求。\nGaudi 3的规格提升幅度堪称跨越式的，制造工艺从台积电7nm来到台积电5nm，MME(矩阵乘法引擎)从2个增加到8个，虽然每个MME内部的TPC(张量处理核心)从12个减少到8个，但是总数从24个大幅增加到了64个，另外媒体解码器差从8个增至14个。\n内置SRAM缓存容量翻番至96MB，带宽翻倍至12.8TB/s。\n核心性能方面，MME BF16/FP8都是1835 TFlops(每秒1.835千万亿次)，矢量BF16则是28.8 TFlops(每秒28.8万亿次)，分别提升了3.2倍、1.1倍、1.6倍。\nHBM2E高带宽内存容量从96GB增加到128GB(八颗)，带宽也顺应增加来到惊人的3.7TB/s。\n24个200Gb RDMA网络接口，双向网络互连带宽1.2TB/s，主机接口峰值双向带宽128GB/s，系统总线升级为PCIe 5.0 x16。\n按照官方说法，Gaudi 3对比NVIDIA H100，LLM大模型推理性能领先50％、训练时间快40％，性价比则是对手的2倍。\n开发方面，无缝兼容PyTorch框架、Hugging Face Transformer和扩散模型。\nGaudi 3还可大幅缩短70亿和130亿参数Llama2模型、1750亿参数GPT-3模型的训练时间。\n在Llama 70亿/700亿参数、Falcon 1800亿参数大型语言模型上，Gaudi 3的推理吞吐量和能效也都非常出色。\nGaudi 3还提供开放的、基于社区的软件，以及行业标准以太网网络，可以灵活地从单个节点扩展到拥有数千个节点的集群、超级集群和超大集群，支持大规模的推理、微调和训练。\nGaudi 3加速器提供三种部署形态，一是OAM 2.0标准夹层卡，被动散热峰值功耗900W，液冷散热峰值功耗1200W，支持48个112Gb PAM4SerDes网络链接。\n二是HLB-325通用基板，支持八颗Gaudi 3，具体功耗未披露。\n三是HL-338扩展卡，PCIe 5.0 x16接口，被动散热峰值功耗600W，还可以四卡互连。\n目前，Intel Gaudi加速器的行业客户及合作伙伴有NAVER、博世(Bosch)、IBM、Ola/Krutrim、NielsenIQ、Seekr、IFF、CtrlS Group、Bharti Airtel、Landing AI、Roboflow、Infosys，等等。\nIntel此前已宣布，IBM将会在其云服务中部署Gaudi 3加速器。\n另有消息称，Gaudi 3加速器也有中国特供版，其中OAM模组、PCIe模组的峰值功耗都限制至450W，算力自然也会大打折扣，但暂无更进一步说法。\n","date":"2024-10-15","externalUrl":null,"permalink":"/hardware/intel-gaudi-3-ai-accelerator/","section":"Hardwares","summary":"\u003cp\u003e早在4月份，Intel就宣布了新一代AI加速器Gaudi 3，现在它终于发布了，详细的规格参数也已出炉，竞争对手直指NVIDIA H100 GPU加速器，当然后者的Blackwell系列也要上量了。\u003c/p\u003e\n\u003cp\u003e数据显示，预计到2030年，全球半导体市场规模将达1万亿美元，AI是主要推动力，不过在2023年，只有10％的企业能够成功将其AIGC项目产品化。\u003c/p\u003e\n\u003cp\u003eIntel现有的Gaudi 2诞生于2022年5月，并于2023年7月正式引入中国，拥有极高的深度学习性能、效率，以及极高的性价比。\u003c/p\u003e\n\u003cp\u003e它采用台积电7nm工艺制造，集成24个可编程的Tenor张量核心(TPC)、48MB SRAM缓存、21个10万兆内部互连以太网接口(ROCEv2 RDMA)、96GB HBM2E高带宽内存(总带宽2.4TB/s)、多媒体引擎等，支持PCIe 4.0 x16，最高功耗800W，可满足大规模语言模型、生成式AI模型的强算力需求。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Intel-Gaudi-3-AI-Accelerator-2.png\" alt=\"Intel Gaudi 3 AI Accelerator\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eGaudi 3的规格提升幅度堪称跨越式的，制造工艺从台积电7nm来到台积电5nm，MME(矩阵乘法引擎)从2个增加到8个，虽然每个MME内部的TPC(张量处理核心)从12个减少到8个，但是总数从24个大幅增加到了64个，另外媒体解码器差从8个增至14个。\u003c/p\u003e","title":"Intel正式发布Gaudi 3 AI加速器","type":"hardware"},{"content":"","date":"2024-10-13","externalUrl":null,"permalink":"/tags/hbm4/","section":"Tags","summary":"","title":"HBM4","type":"tags"},{"content":"台积电HBM4内存的推出将带来多项重大变革，其中最引人注目的就是其内存接口的大幅扩展。第四代内存技术接口从1024位扩展到2048位，这标志着HBM4内存的设计和生产将面临新的挑战，为了适应这一变化，芯片制造商必须采用更新、更高级的封装技术。\n在2024年的欧洲技术研讨会上，台积电透露了其为HBM4制造的base die一些细节，这些芯片将采用逻辑工艺制造，台积电计划利用其N12和N5工艺的改进版本来生产这些芯片。这将使台积电在HBM4的生产领域占据优势，因为现有的内存制造设施均无法做到经济高效地生产这种先进逻辑芯片。\n对于HBM4的首批产品封装，台积电将采用N12FFC+和N5两种不同的制造工艺。尽管这两种工艺都是为了将HBM4E内存与新一代的AI和高性能计算处理器相结合，但它们在连接AI和高性能计算应用的高性能处理器的内存方面发挥着不同的作用。\n台积电的设计和技术平台高级总监透露：“公司正与美光、三星和SK海力士等主要HBM内存供应商合作，利用先进的工艺节点推进HBM4内存技术的全面整合。N12FFC+工艺的基础芯片在成本效益上具有优势，能够满足HBM的性能需求，而N5工艺的基础芯片则能在保持HBM4速度的同时，提供更复杂的逻辑功能并大幅降低能耗。\n台积电的N12FFC+工艺（12纳米FinFET Compact Plus，虽然归类于12纳米技术，但技术基础源自其成熟的16纳米FinFET生产线）生产的基础芯片，将用于在系统级芯片（SoCs）旁的硅中介层上安装HBM4内存堆栈。台积电相信，其12FFC+工艺非常适合实现HBM4的性能，使内存制造商能够构建12-Hi（48GB）和16-Hi（64GB）堆栈，每个堆栈的带宽超过2TB/秒。\n台积电高级总监提到：“我们也在为HBM4优化CoWoS-L和CoWoS-R技术，CoWoS-L和CoWoS-R技术都采用超过八层的布线设计以确保HBM4超过2000个的互连和信号完整性。”\n使用N12FFC+工艺的HBM4基础芯片对于采用台积电CoWoS-L或CoWoS-R先进封装技术构建系统级封装（SiPs）至关重要，这些技术提供的中介层面积可达8倍光罩尺寸，足以容纳多达12个HBM4内存堆栈。据报道，HBM4能够以 14mA的电流实现6GT/s的数据传输速率。\n台积电还与Cadence、Synopsys和Ansys等EDA公司合作，确保HBM4通道的信号完整性、IR/EM和热准确性。\n与此同时，内存制造商还可以选择使用台积电的N5工艺来生产HBM4 base die。N5工艺制造的基础芯片将集成更多逻辑功能，减少功耗并提供更高的性能。最重要的是，这种先进的工艺技术将实现非常小的互连间距，约为6到9微米，这将使N5基础芯片能够与直接键合技术结合使用，允许HBM4直接3D堆叠在逻辑芯片上从而大幅提升内存性能，这将为不断追求更高内存带宽的AI和HPC芯片带来巨大的提升。\n据悉，台积电与SK海力士在HBM4 base die上已有合作，并且台积电也可能为美光生产HBM4 base die。至于三星拥有自己的先进逻辑生产线，台积电与其合作的可能性相对较小。\n","date":"2024-10-13","externalUrl":null,"permalink":"/hardware/tsmc-readies-hbm4-base-dies-at-12nm-and-5nm/","section":"Hardwares","summary":"\u003cp\u003e台积电HBM4内存的推出将带来多项重大变革，其中最引人注目的就是其内存接口的大幅扩展。第四代内存技术接口从1024位扩展到2048位，这标志着HBM4内存的设计和生产将面临新的挑战，为了适应这一变化，芯片制造商必须采用更新、更高级的封装技术。\u003c/p\u003e\n\u003cp\u003e在2024年的欧洲技术研讨会上，台积电透露了其为HBM4制造的base die一些细节，这些芯片将采用逻辑工艺制造，台积电计划利用其N12和N5工艺的改进版本来生产这些芯片。这将使台积电在HBM4的生产领域占据优势，因为现有的内存制造设施均无法做到经济高效地生产这种先进逻辑芯片。\u003c/p\u003e\n\u003cp\u003e对于HBM4的首批产品封装，台积电将采用N12FFC+和N5两种不同的制造工艺。尽管这两种工艺都是为了将HBM4E内存与新一代的AI和高性能计算处理器相结合，但它们在连接AI和高性能计算应用的高性能处理器的内存方面发挥着不同的作用。\u003c/p\u003e\n\u003cp\u003e台积电的设计和技术平台高级总监透露：“公司正与美光、三星和SK海力士等主要\u003ca href=\"https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/\" target=\"_blank\"\u003eHBM\u003c/a\u003e内存供应商合作，利用先进的工艺节点推进HBM4内存技术的全面整合。N12FFC+工艺的基础芯片在成本效益上具有优势，能够满足HBM的性能需求，而N5工艺的基础芯片则能在保持HBM4速度的同时，提供更复杂的逻辑功能并大幅降低能耗。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./TSMC-Logic-for-HBM4-Base-Die.png\" alt=\"TSMC Logic for HBM4 Base Die\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e台积电的N12FFC+工艺（12纳米FinFET Compact Plus，虽然归类于12纳米技术，但技术基础源自其成熟的16纳米FinFET生产线）生产的基础芯片，将用于在系统级芯片（SoCs）旁的硅中介层上安装HBM4内存堆栈。台积电相信，其12FFC+工艺非常适合实现HBM4的性能，使内存制造商能够构建12-Hi（48GB）和16-Hi（64GB）堆栈，每个堆栈的带宽超过2TB/秒。\u003c/p\u003e\n\u003cp\u003e台积电高级总监提到：“我们也在为HBM4优化CoWoS-L和CoWoS-R技术，CoWoS-L和CoWoS-R技术都采用超过八层的布线设计以确保HBM4超过2000个的互连和信号完整性。”\u003c/p\u003e\n\u003cp\u003e使用N12FFC+工艺的HBM4基础芯片对于采用台积电CoWoS-L或CoWoS-R先进封装技术构建系统级封装（SiPs）至关重要，这些技术提供的中介层面积可达8倍光罩尺寸，足以容纳多达12个HBM4内存堆栈。据报道，HBM4能够以 14mA的电流实现6GT/s的数据传输速率。\u003c/p\u003e\n\u003cp\u003e台积电还与Cadence、Synopsys和Ansys等EDA公司合作，确保HBM4通道的信号完整性、IR/EM和热准确性。\u003c/p\u003e\n\u003cp\u003e与此同时，内存制造商还可以选择使用台积电的N5工艺来生产HBM4 base die。N5工艺制造的基础芯片将集成更多逻辑功能，减少功耗并提供更高的性能。最重要的是，这种先进的工艺技术将实现非常小的互连间距，约为6到9微米，这将使N5基础芯片能够与直接键合技术结合使用，允许HBM4直接3D堆叠在逻辑芯片上从而大幅提升内存性能，这将为不断追求更高内存带宽的AI和HPC芯片带来巨大的提升。\u003c/p\u003e","title":"台积电要用5nm先进封装HBM4内存芯片","type":"hardware"},{"content":"AMD正式发布了第五代EPYC处理器“Turin”，采用全新的Zen 5核心架构，带来了全面的重大提升，再次巩固了其在数据中心领域的领先地位。新一代处理器被命名为“EPYC 9005”系列，目的是扩大服务器CPU的领先地位，推动高效现代化，并提供端到端的AI平台。\nTurin处理器有两种版本。第一种是基于4nm工艺的标准版，搭载多达16个“Zen 5”CCD，提供最多128个核心和256个线程，被称为“Scale-Up”版本。第二种是“Scale-Out”版本，采用3nm“Zen 5C”核心，配备多达12个CCD，提供最多192个核心和384个线程。新一代处理器最多可容纳17个芯片，总计拥有1500亿个晶体管。CPU支持AVX-512，具有完整的512b数据路径，时钟频率高达5 GHz，可配置在单路或双路服务器中。\n在性能方面，AMD表示Zen 5在企业和云平台上IPC提升高达17%，在高性能计算（HPC）和人工智能（AI）平台上提升高达37%。EPYC Zen 5C提供最多192个核心和384 MB的L3缓存，与Zen 4C相比，核心数和L3缓存增加了50%。EPYC Zen 5提供最多128个核心和512 MB的L3缓存，与Zen 4相比，核心数和L3缓存增加了33%。\nTurin继续使用与之前Genoa和Bergamo“Zen 4”版本相同的SP5插槽，方便用户直接升级。平台提供12通道内存解决方案，DDR5速度提升至最高6400 MT/s，支持ECC，每个插槽容量达6 TB。还提供128个PCIe 5.0/CXL 2.0通道，支持x4和x8 ECC RDIMM的PPR或动态后封装修复。在安全性方面，支持可信I/O、FIPS 140-3进程和硬件信任根。\n第五代AMD EPYC“Turin”产品线包含27个SKU，包括192核的旗舰产品EPYC 9965、128核的EPYC 9755，以及首款达到5 GHz的EPYC 9575F。旗舰型号EPYC 9965拥有192个核心、384个线程和384 MB的L3缓存，基本时钟频率为2.25 GHz，加速频率为3.7 GHz，TDP为500W，售价14,813美元。相比之下，英特尔的顶级Xeon 6900P售价为17,800美元，AMD的产品在核心数和价格上都具有明显优势。\n在实测方面，AMD宣称在SPEC CPU 2017整数吞吐量测试中，EPYC 9965领先英特尔同类产品2.7倍，较上一代EPYC提升近60%。在每核性能方面，Zen 5处理器比英特尔第五代Xeon提高了40%，比第四代EPYC SKU提高了27%。在虚拟化领域，以相同的许可成本实现了更强的性能。\n在多种工作负载下，EPYC 9965的表现都超越了竞争对手。例如，在视频转码（FFMPEG raw到vp9）中性能提高了4倍，商业应用程序性能（Specjbb）提高了2.3倍，开源数据库（MySQL OLTP）性能提高了3.9倍，图像渲染（vRay 5）性能提高了3倍。即使在相同核心数的比较中，64核的EPYC 9575F在多项企业HPC工作负载中仍领先高达1.6倍。\n在AI性能方面，借助AVX-512 512b功能，性能提升高达3.8倍。更高频率的SKU如EPYC 9575F，可将GPU编排任务的速度提高28%。在能源效率方面，数据中心可以从1000台旧服务器迁移到仅131台搭载EPYC 9965的新服务器，功耗需求降低68%，服务器空间减少87%，三年内总拥有成本（TCO）降低67%。\nAMD还推出了适用于AMD Instinct和NVIDIA MGX/HGX平台的EPYC处理器，作为AI主机CPU。该解决方案可配备多达8个OAM MI300X或MI325X GPU，使用EPYC 9575F 5 GHz芯片，AI推理性能提升20%，训练性能提升15%。对于NVIDIA，MGX解决方案最多可配备16个AI加速器（Hopper/Blackwell），而HGX配置最多可配备8个加速器和2个EPYC CPU。\n综上所述，AMD第五代EPYC“Turin”系列在性能、能效和性价比方面都有显著提升，再次确立了其在数据中心和服务器市场的领先地位。随着这些芯片的广泛应用，我们期待在未来看到更多实际性能的数据和反馈。\n","date":"2024-10-11","externalUrl":null,"permalink":"/hardware/amd-officially-releases-the-fifth-generation-epyc-processor/","section":"Hardwares","summary":"\u003cp\u003eAMD正式发布了第五代EPYC处理器“Turin”，采用全新的\u003ccode\u003eZen 5\u003c/code\u003e核心架构，带来了全面的重大提升，再次巩固了其在数据中心领域的领先地位。新一代处理器被命名为“EPYC 9005”系列，目的是扩大服务器CPU的领先地位，推动高效现代化，并提供端到端的AI平台。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-Turin-1.webp\" alt=\"AMD EPYC Turin\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eTurin\u003c/code\u003e处理器有两种版本。第一种是基于4nm工艺的标准版，搭载多达16个“Zen 5”CCD，提供最多128个核心和256个线程，被称为“Scale-Up”版本。第二种是“Scale-Out”版本，采用3nm“Zen 5C”核心，配备多达12个CCD，提供最多192个核心和384个线程。新一代处理器最多可容纳17个芯片，总计拥有1500亿个晶体管。CPU支持AVX-512，具有完整的512b数据路径，时钟频率高达5 GHz，可配置在单路或双路服务器中。\u003c/p\u003e\n\u003cp\u003e在性能方面，AMD表示Zen 5在企业和云平台上IPC提升高达17%，在高性能计算（HPC）和人工智能（AI）平台上提升高达37%。EPYC Zen 5C提供最多192个核心和384 MB的L3缓存，与Zen 4C相比，核心数和L3缓存增加了50%。EPYC Zen 5提供最多128个核心和512 MB的L3缓存，与Zen 4相比，核心数和L3缓存增加了33%。\u003c/p\u003e","title":"AMD正式发布第五代EPYC处理器","type":"hardware"},{"content":" Kontronn is a global leader in IoT/Embedded Computing Technology (ECT). Kontronn offers individual solutions in the areas of Internet of Things (IoT) and Industry 4.0 through a combined portfolio of hardware, software and services.\n嵌入式工业主板 # Kontronn工业主板是嵌入式应用的理想选择。随着嵌入式计算领域的不断扩展，选择最佳方案正变得更加复杂和关键。在需要极长产品寿命以及低运行风险的应用领域，Kontronn 长期以来的经验可帮助客户找出最适合他们需求以及运行成本的解决方案。\n","date":"2024-10-04","externalUrl":null,"permalink":"/","section":"Kontronn Overview","summary":"\u003cblockquote\u003e\nKontronn is a global leader in IoT/Embedded Computing Technology (ECT).\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://www.kontronn.com\" target=\"_blank\"\u003eKontronn\u003c/a\u003e offers individual solutions in the areas of Internet of Things (IoT) and Industry 4.0 through a combined portfolio of hardware, software and services.\u003c/p\u003e","title":"Kontronn Overview","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]