
[{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/ai/","section":"Ais","summary":"","title":"Ais","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/colossus/","section":"Tags","summary":"","title":"Colossus","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/xai/","section":"Tags","summary":"","title":"XAI","type":"tags"},{"content":"近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的数据中心内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。\nColossus的4U液冷服务器，强调为液冷而设计\nColossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？\n最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成AI服务器。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。\n因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。\nColossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。\nSupermicro这台4U液冷服务器是完全面向液冷设计的服务器，而不是风冷改造的，这样可以提供更好的液冷散热。此外，这款服务器有更高的可维护性，服务器的组件都安装在托盘上，可以在不移出机架的情况下对服务器进行维护。\n服务器后面板配有四个冗余电源，安装有三相供电系统，还能看到400GbE以太网网线，以及一个1U机架大小的歧管，配合底部的带有冗余水泵的CDU（冷却分配单元），为整个液冷系统提供支持。\nColossus的存储部分，SSD闪存大面积部署\nColossus的存储部分也用了Supermicro的存储设备，设备中配备了大量2.5英寸的NVMe存储槽。这让我想起了最近一则消息，有外媒传出，特斯拉要向SK海力士（Solidigm）采购大量企业级SSD的新闻。\n随着AI集群规模的扩大，存储系统逐渐从基于磁盘的存储转向闪存存储，因为闪存不仅能显著节省电力，还能提供更高的性能和密度，尽管每PB成本更高，但从整体拥有成本（TCO）来看，在这种规模的集群中，闪存更具优势。\nColossus的网络部分，用以太网替代了InfiniBand\n多数超算都在使用InfiniBand等技术，而xAI团队选择了英伟达的Spectrum-X以太网方案，不仅获得了超强的可扩展性，部署和维护成本也更低了。在高带宽、低延迟场景中表现更好，搭配智能流量管理功能，提供了高效的数据传输。\n具体而言，网络部分采用了Spectrum SN5600交换机提供高达800Gb/s的端口，每个GPU配备400GbE的BlueField-3 SuperNIC专用网卡，提供GPU间的RDMA连接。另有400Gb的网卡给CPU用，算下来，每台服务器的以太网带宽总计3.6 Tbps。\nxAI为GPU、CPU和存储各自建立了独立的网络，这样可以确保GPU和CPU之间的通信需求得到优化，GPU网络专注于高速的RDMA数据传输，而CPU网络则支持其他管理和计算任务，从而提高整个系统的性能和效率。\nPatrick在文中表示，不要小瞧400GbE的速度，这个带宽甚至超过了2021年初顶级Intel 至强服务器处理器的所有PCIe通道总带宽。而现在，每台服务器就配备了9条这样的连接速度。\n英伟达提到，在训练Grok这种超大型模型时，整个系统都没有出现任何因流量冲突，而造成的应用延迟增加或数据包丢失的情况。Spectrum-X的拥塞控制功能，能将系统数据吞吐量保持在95%，而传统以太网在发生冲突时，只能提供60%的数据吞吐量。\n在Colossus超级计算机外部，可以看到大量Tesla Megapack电池。由于计算集群在启动和停止时存在毫秒级的电力波动，电网或马斯克的柴油发电机难以应对，因此采用了Tesla Megapack作为电网与超算之间的能量缓冲装置，确保供电稳定。\n外文原文地址: Inside the 100K GPU xAI Colossus Cluster that Supermicro Helped Build for Elon Musk\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/inside-100000-nvidia-gpu-xai-colossus-cluster/","section":"Ais","summary":"\u003cp\u003e近日，经由马斯克和xAI团队的特别批准，外媒STH的Patrick Kennedy进入到了这个有较多敏感信息的\u003ca href=\"https://www.gaitpu.com/category/data-center/server\" target=\"_blank\"\u003e数据中心\u003c/a\u003e内部，拍了很多照片和视频，一定程度上，满足了很多人对于这种奇观级别的超算的好奇心。\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eColossus的4U液冷服务器，强调为液冷而设计\u003c/b\u003e\u003c/p\u003e\n\u003cp\u003eColossus采用的是来自Supermicro的液冷机架服务器，服务器采用的是英伟达HGX H100平台。这里岔开点话题：经常有朋友问，什么是HGX、什么是DGX还有MGX？有什么区别呢？\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./mgx-hgx-dgx.webp\" alt=\"MGX HGX DGX\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e最常见的，MGX主要面向OEM服务器厂商，服务器厂商用它做成\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI服务器\u003c/a\u003e。HGX常用在超大规模数据中心里，由像Supermicro这样的ODM厂商生产。而DGX是一个集成度最高的方案，开箱即用，看起来金光闪闪，印有NVIDIA Logo的就是。\u003c/p\u003e\n\u003cp\u003e因为Colossus也是超大规模数据中心，所以，就用了HGX，选择的提供商是Supermicro。STH能进入Colossus内部，除了要感谢马斯克，也还得谢谢Supermicro。\u003c/p\u003e\n\u003cp\u003eColossus这里采用的是Supermicro的4U服务器，每台服务器有8块H100，把8台这样的服务器放到一个机架里，单机架就有了64块H100。以8个机架为一组，每组就含有512块H100 GPU，整个Colossus有大概200个机架组。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./xAI-Colossus-Data-Center-Supermicro-Liquid-Cooled-Nodes-Low-Angle.jpg\" alt=\"XAI Colossus Data Center Supermicro Liquid Cooled Nodes Low Angle\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"拥有10万块英伟达H100的数据中心长什么样","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":"Git是一种分布式版本控制系统，它的强大和灵活性使其在开发人员中广受欢迎。掌握Git的基本概念和常用命令对于提高开发效率和协作能力是非常有帮助的。本文将介绍Git的基础知识，包括常用命令、分支管理、远程仓库操作等，帮助您从新手成长为Git专家。\nGit基础命令 # git init: 初始化一个新的Git仓库。在目录下执行该命令，将当前目录转化为一个Git仓库 git add: 将文件添加到Git的暂存区，准备提交。例如，git add . 将所有文件添加到暂存区 git commit: 提交暂存区中的文件到Git仓库，并添加提交信息。例如，git commit -m \u0026ldquo;Initial commit\u0026rdquo; git status: 查看Git仓库的状态，显示新增、修改和删除的文件 git diff: 比较文件在Git仓库和本地工作区的差异 git show: 显示指定提交的详细信息 git log: 查看提交历史记录 Git分支管理 # git branch: 创建、切换和删除分支 git branch new_branch 创建一个新分支 git checkout new_branch 切换到新分支 git branch -d branch_name 删除指定分支 git checkout: 切换到指定的分支或恢复工作区文件 git checkout new_branch 切换到新分支 git checkout . 恢复工作区文件 git merge: 将指定分支的修改合并到当前分支 git merge new_branch 将new_branch分支的修改合并到当前分支 Git远程仓库操作 # git remote: 管理远程仓库地址 git remote add origin https://github.com/user/repo.git 添加远程仓库地址 git pull: 从远程仓库拉取最新的代码并合并到当前分支\ngit push: 将本地提交推送到远程仓库\ngit push origin master 将当前分支的修改推送到远程仓库的master分支 Git高级操作 # git stash: 保存当前工作区的修改，恢复到最近一次提交的状态。 例如，在需要切换到其他任务时，可以使用该命令保存当前修改，完成任务后再通过 git stash pop 恢复修改。\ngit revert: 撤销指定提交。 通过 git revert commit_id 可以撤销指定提交并生成新的提交。\ngit reset: 重置HEAD指针。 通过 git reset --hard commit_id 可以将HEAD指针重置为指定提交，但会丢失重置点之后的提交历史。\ngit cherry-pick: 选择性地应用提交。 通过 git cherry-pick commit_id 可以将指定提交应用到当前分支。\n总之，Git具有丰富的功能和灵活的用法，这些命令可以帮助我们完成从基础到高级的Git操作。但是，Git的强大不仅限于此，还有更多的高级功能和概念值得深入探讨。通过不断学习和实践，我们将能够更好地利用Git来提高开发效率和协作能力。\n","date":"2024-11-03","externalUrl":null,"permalink":"/software/the-most-commonly-used-git-commands/","section":"Softwares","summary":"\u003cp\u003e\u003ca href=\"https://www.kad8.com/software/gitui-terminal-ui-for-git/\" target=\"_blank\"\u003eGit\u003c/a\u003e是一种分布式版本控制系统，它的强大和灵活性使其在开发人员中广受欢迎。掌握Git的基本概念和常用命令对于提高开发效率和协作能力是非常有帮助的。本文将介绍Git的基础知识，包括常用命令、分支管理、远程仓库操作等，帮助您从新手成长为Git专家。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eGit基础命令 \n    \u003cdiv id=\"git%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#git%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003egit init: 初始化一个新的Git仓库。在目录下执行该命令，将当前目录转化为一个Git仓库\u003c/li\u003e\n\u003cli\u003egit add: 将文件添加到Git的暂存区，准备提交。例如，git add . 将所有文件添加到暂存区\u003c/li\u003e\n\u003cli\u003egit commit: 提交暂存区中的文件到Git仓库，并添加提交信息。例如，git commit -m \u0026ldquo;Initial commit\u0026rdquo;\u003c/li\u003e\n\u003cli\u003egit status: 查看Git仓库的状态，显示新增、修改和删除的文件\u003c/li\u003e\n\u003cli\u003egit diff: 比较文件在Git仓库和本地工作区的差异\u003c/li\u003e\n\u003cli\u003egit show: 显示指定提交的详细信息\u003c/li\u003e\n\u003cli\u003egit log: 查看提交历史记录\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./git-tutorials-How-Git-branches-work.webp\" alt=\"Git Tutorial How Git Branches\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"Git 最常用的几个操作命令","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/software/","section":"Softwares","summary":"","title":"Softwares","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/dgx-b200/","section":"Tags","summary":"","title":"DGX B200","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/openai/","section":"Tags","summary":"","title":"OpenAI","type":"tags"},{"content":"OpenAI 将通过最新的 DGX B200 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。\nDGX B200 # DGX B200的电源要求 # 每个DGX B200系统有6个电源模块，其中至少5个模块需要运行才能让系统正常工作。 如果有1个电源模块故障，系统仍能继续运行。但如果有2个或更多的模块故障，系统就无法运行。这和是否有额外的备用电源无关。 DGX B200电源和散热规划 # 电路部署方式： # 每个机架使用两条电路，每条电路需要能够处理机架一半的峰值用电量，并且要考虑断路器的安全裕量。\n额外散热设备： # 一些像 rear door heat exchangers 和 in-row coolers这样的额外散热设备通常不适合DGX B200系统。\nDGX 超节点 # 每个48U/52U机架放置两个风冷的DGX B200 高密度部署的情况下，52U的机架可以放4个DGX B200\n机间互联采用IB网络\nIB结构决定了机架间电缆距离的要求\nDGX 超节点最多可以有127个DGX B200，每32个是一个单元。\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/specific-system-spec-about-dgx-b200/","section":"Ais","summary":"\u003cp\u003eOpenAI 将通过最新的 \u003ca href=\"https://www.kad8.com/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/\" target=\"_blank\"\u003eDGX B200\u003c/a\u003e 平台利用 NVIDIA 的 Blackwell B200 数据中心 GPU 进行 AI 训练，本文将介绍DGX B200的一些规格信息。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eDGX B200 \n    \u003cdiv id=\"dgx-b200\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#dgx-b200\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./DGX-B200-1.webp\" alt=\"DGX B200\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"OpenAI获得的DGX B200的具体信息","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/benchmark/","section":"Tags","summary":"","title":"Benchmark","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/hardware/","section":"Hardwares","summary":"","title":"Hardwares","type":"hardware"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/m4-pro/","section":"Tags","summary":"","title":"M4 Pro","type":"tags"},{"content":"近日，苹果新推出的 M4 Max 芯片在 Geekbench 上的测试结果曝光。不出所料，苹果巩固了其在性能领域的领先地位，成为 Geekbench 上最快的芯片。即使在多核性能方面，M4 Max 也让英特尔和 AMD 的最新产品相形见绌，而这仅仅是其强大性能的一部分。\nApple M4 Max\n测试环境采用了全新的 16 英寸 MacBook Pro，让 M4 Max 得以充分发挥实力。根据基准测试数据，M4 Max 在 Geekbench 6 中的单核得分为 4,060 分，多核得分为 26,675 分。与去年的 M3 Max 相比，单核性能提升了约 30%，多核性能提升了 27%，这也说明苹果在芯片性能上的迭代诚意非常足。\n在与 x86 架构的对比中，AMD 和英特尔的芯片明显处于劣势。M4 Max 即使在多核性能上也轻松领先，同时功耗却仅为对手的一小部分。具体来说，M4 Max 的单核性能比英特尔的 Core Ultra 9 285K 高出约 19%，多核性能高出 16%；相比 AMD 的 Ryzen 9 9950X，单核性能高出 18%，多核性能高出 25%。\nApple M4 Max\n作为苹果的旗舰级 SoC，M4 Max 主要面向数据科学家、3D 艺术家和其他专业人士。顶级配置包含 16 个 CPU 核心（12 个性能核心和 4 个高效核心）和 40 个 GPU 核心，以及高达 128GB 的统一内存，CPU 和 GPU 均可直接访问。此外，苹果还为新款 MacBook Pro 系列配备了对 Thunderbolt 5 的支持，传输速度高达 120 Gb/s。\n苹果全新的 M4 系列芯片，是对英特尔、AMD 和高通最近推出的 AI PC 产品的有力回应。尽管性能表现令人瞩目，但价格依然十分高昂——但是好东西的价格从来就不便宜，配备完整功能的 M4 Max 机型（16核）售价高达30000以上。在这个价位上，内容创作者和注重生产力的用户可能会考虑配备独立显卡的笔记本电脑。\n需要注意的是，Geekbench 并不是评估芯片性能的最佳基准测试工具。因此，M4 Max 在 Cinebench 或 HandBrake 等其他测试中的表现将更具参考价值，以判断其是否真正超越竞争对手。搭载 M4 Max 的 MacBook Pro 2024 将于 11 月 8 日开始交付，届时我们将更全面地了解 M4 Max 的实际性能。\n","date":"2024-11-03","externalUrl":null,"permalink":"/hardware/apple-m4-pro-benchmark-shows-it-outperforms-the-m3-max/","section":"Hardwares","summary":"\u003cp\u003e近日，苹果新推出的 M4 Max 芯片在 Geekbench 上的测试结果曝光。不出所料，苹果巩固了其在性能领域的领先地位，成为 Geekbench 上最快的芯片。即使在多核性能方面，M4 Max 也让英特尔和 AMD 的最新产品相形见绌，而这仅仅是其强大性能的一部分。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"./apple-m4-pro-1.webp\"\u003eApple M4 Max\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e测试环境采用了全新的 16 英寸 MacBook Pro，让 M4 Max 得以充分发挥实力。根据基准测试数据，M4 Max 在 Geekbench 6 中的单核得分为 4,060 分，多核得分为 26,675 分。与去年的 M3 Max 相比，单核性能提升了约 30%，多核性能提升了 27%，这也说明苹果在芯片性能上的迭代诚意非常足。\u003c/p\u003e","title":"苹果M4 Max登顶Geekbench，击败Intel和AMD","type":"hardware"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/dow/","section":"Tags","summary":"","title":"DOW","type":"tags"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/nvidia/","section":"Tags","summary":"","title":"Nvidia","type":"tags"},{"content":"据CNBC报道，英伟达将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。\n英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。\n与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。\n回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。\n而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。\n注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。\n道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。\n道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。\n","date":"2024-11-03","externalUrl":null,"permalink":"/ai/nvidia-to-join-the-dow-jones-industrial-average/","section":"Ais","summary":"\u003cp\u003e据CNBC报道，\u003ca href=\"https://www.gaitpu.com/data-center/server/difference-between-nvlink-version-and-pcie-version-for-nvidia-ai-server\" target=\"_blank\"\u003e英伟达\u003c/a\u003e将于今年11月8日取代英特尔，成为道琼斯工业平均指数的成分股。这一变动反映了人工智能热潮对半导体和科技行业以及整个市场的深远影响。时间距离英特尔陷入财务困境约三个月。\u003c/p\u003e\n\u003cp\u003e英特尔在去年8月公布了灾难性的财务业绩，股价一夜之间暴跌超过30%。其数据中心和代工部门持续亏损，导致2024年第二季度亏损达16亿美元。随后，英特尔宣布大规模裁员，超过15,000名员工受到影响。\u003c/p\u003e\n\u003cp\u003e与之形成鲜明对比的是，英伟达的股价因人工智能的兴起而迅速飙升。在短时间内，英伟达的市值达到3.34万亿美元，成为全球最有价值的公司之一。目前仅次于苹果位于市值第二，但其在如此短时间内取得的惊人增长仍令世人惊叹。\u003c/p\u003e\n\u003cp\u003e回顾2022年11月，英伟达的股价为14.16美元。一年后，股价上涨218%至45.01美元。如今，股价已攀升至135.37美元，在过去12个月中又上涨了201%。这意味着在短短两年内，公司的市值增长了850%以上。\u003c/p\u003e\n\u003cp\u003e而英特尔自1999年起变成为道琼斯工业平均指数的成分股，但由于未能在人工智能领域保持领先，其25年的辉煌即将结束。英伟达作为替代者，将成为继微软、苹果和亚马逊之后，第四家市值超过一万亿美元并进入道琼斯指数的科技公司。值得注意的是，亚马逊也是在今年2月取代零售公司沃尔格林后才被纳入该指数。\u003c/p\u003e\n\u003cp\u003e注：道琼斯工业平均指数（Dow Jones Industrial Average，简称道指）是一个由30家大型美国上市公司组成的股票市场指数。这些公司通常是各自行业的领导者，涵盖了金融、科技、医疗保健、工业和消费品等多个重要领域。\u003c/p\u003e\n\u003cp\u003e道指于1896年由查尔斯·道和爱德华·琼斯创建，是世界上最古老、最知名的股市指数之一。最初，道指主要包含工业公司，但随着经济的发展和行业的多样化，成分股已扩展到更广泛的行业领域。\u003c/p\u003e\n\u003cp\u003e道琼斯工业平均指数被广泛视为衡量美国股市整体表现和经济健康状况的指标。投资者、分析师和媒体经常引用道指的涨跌来评估市场情绪和经济趋势。由于其代表性强，道指的变化常被用作全球金融市场的风向标。\u003c/p\u003e","title":"英伟达替代英特尔，成为道指成份股","type":"ai"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":" LVS概念 # LVS（Linux Virtual Server）是一个基于Linux操作系统的虚拟服务器技术，用于实现负载均衡和高可用性。LVS通过将客户端的请求分发到多台后端服务器上，从而提高整体服务的处理能力和可靠性。LVS主要有两个组件：IPVS（IP Virtual Server）和LVS-NAT、LVS-DR、LVS-TUN三种工作模式。\nLVS的优势 # 高性能：LVS工作在内核层，性能高效，能够处理大量并发请求。 高可用性：通过配置Keepalived等工具，LVS可以实现高可用性，确保服务的持续运行。 灵活性强：支持多种负载均衡算法和工作模式，适应不同的应用场景。 LVS架构 # LVS的整体架构主要包括负载均衡器（Load Balancer）、后端服务器（Real Server）和客户端三部分。客户端的请求首先到达负载均衡器，然后由负载均衡器根据一定的调度算法将请求转发到后端服务器进行处理，处理结果再返回给客户端。\nLVS的工作模式 # LVS支持三种主要的工作模式：\nLVS-NAT模式：通过修改请求报文的目标IP地址实现负载均衡。 LVS-DR模式：通过操纵封装新的MAC地址实现负载均衡。 LVS-TUN模式：在原请求IP报文之外新加一个IP首部实现负载均衡。 LVS实战案例 # LVS-DR模式实战案例\n环境准备： # 负载均衡器（Director）：CentOS 7 真实服务器（Real Server）：两台 CentOS 7 VIP：192.168.1.100 配置 LVS 负载均衡器： # 首先，确保 LVS 和 ipvsadm 已安装：\nyum install ipvsadm -y modprobe ip_vs 设置 LVS 负载均衡规则： # ipvsadm -A -t 192.168.1.100:80 -s rr ipvsadm -a -t 192.168.1.100:80 -r 192.168.1.101:80 -g ipvsadm -a -t 192.168.1.100:80 -r 192.168.1.102:80 -g 解释：\n-A -t 192.168.1.100:80：添加一个 VIP 地址监听 80 端口的服务。 -s rr：使用轮询调度算法。 -a -r 192.168.1.101:80 -g：将真实服务器 192.168.1.101 加入到 VIP 服务中，并使用 DR 模式（ -g 表示 DR 模式）。 -a -r 192.168.1.102:80 -g：同样将 192.168.1.102 加入服务。 配置真实服务器： # 为了使 LVS DR 模式生效，我们需要在真实服务器上进行一些特殊的配置。\n配置 lo 接口的 VIP，但不要让它对外 ARP 应答：\nifconfig lo:0 192.168.1.100 netmask 255.255.255.255 up route add -host 192.168.1.100 dev lo:0 禁止真实服务器对 VIP 发送 ARP 响应：编辑 /etc/sysctl.conf 文件，添加以下内容：\nnet.ipv4.conf.lo.arp_ignore = 1 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_ignore = 1 net.ipv4.conf.all.arp_announce = 2 然后执行 sysctl -p 使配置生效。\n启动 web 服务（如 Nginx 或 Apache）监听所有 IP：\nyum install nginx -y systemctl start nginx 测试： # 在客户端访问 http://192.168.1.100，请求会被 LVS 分发到后端的真实服务器上。通过多次刷新页面，您可以看到请求在两台真实服务器之间轮流分发。\n查看 LVS 状态： # 可以使用以下命令查看 LVS 的负载均衡状态：\nipvsadm -L -n 输出将显示 LVS 的规则以及每台真实服务器的连接数。\n","date":"2024-11-03","externalUrl":null,"permalink":"/software/introduction-to-linux-lvs/","section":"Softwares","summary":"\u003ch2 class=\"relative group\"\u003eLVS概念 \n    \u003cdiv id=\"lvs%E6%A6%82%E5%BF%B5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#lvs%E6%A6%82%E5%BF%B5\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eLVS\u003c/code\u003e（Linux Virtual Server）是一个基于\u003ca href=\"https://www.gaitpu.com/category/os/linux\" target=\"_blank\"\u003eLinux操作系统\u003c/a\u003e的虚拟服务器技术，用于实现负载均衡和高可用性。LVS通过将客户端的请求分发到多台后端服务器上，从而提高整体服务的处理能力和可靠性。LVS主要有两个组件：IPVS（IP Virtual Server）和LVS-NAT、LVS-DR、LVS-TUN三种工作模式。\u003c/p\u003e","title":"Linux LVS简介","type":"software"},{"content":"","date":"2024-11-03","externalUrl":null,"permalink":"/tags/pipe/","section":"Tags","summary":"","title":"Pipe","type":"tags"},{"content":"","date":"2024-11-02","externalUrl":null,"permalink":"/tags/3d-cache/","section":"Tags","summary":"","title":"3D Cache","type":"tags"},{"content":"AMD早就说Ryzen 9000X3D系列会带来真正的第二代3D缓存技术，那么到底有什么革命性的变化呢？根据最新曝料，至少其中之一就是，3D缓存的位置变了！\n锐龙5000X3D、锐龙7000X3D系列的3D缓存都在CCD模块之上，同时在旁边还有填充模块，保持二者大小面积一致。\n锐龙9000X3D则将3D缓存放在了CCD模块之下，当然肯定也少不了填充模块支撑。\n这么做的好处就是可以让包含CPU核心、发热量更高的CCD模块贴着IHS散热顶盖，散热效果更好，自然可以跑到更高的频率。\n比如首发的锐龙7 9800X3D，默认频率为4.7-5.2GHz，相比于锐龙7 7800X3D分别高了500MHz、200MHz，基准频率也远高于锐龙9000系列标准版。\n同时，AMD应该是基本解决了X3D系列的超频限制，可以超到接近全核5.7GHz。\n另外，锐龙7 9800X3D的专业跑分首次出现，搭档ROG CROSSHAIR X870E HERO主板、32GB DDR5-6000内存、RTX 4090显卡，PugetBench DaVinci测试得分10487、Premiere得分14201。\n作为对比，锐龙7 7800X3D在最接近的配置下，Premiere得分为13005，锐龙7 9700X只是13349。\n再说说AMD新一代的Zen5架构移动版APU，整个家族包含三大成员：\nStrix Point已发布，就是锐龙AI 9/7 300系列，定位高端； Strix Halo定位旗舰级，将命名为锐龙AI Max 300系列，拥有史上最强GPU； Krackan定位主流和低端，预计命名为锐龙AI 7/5 300系列。 Krackan虽然规格不高，但同样拥有三大新架构，最多8个Zen5+Zen5c CPU核心、8个RDNA3.5 GPU核心，对付Intel的酷睿Ultra 200V系列不成问题。\n现在我们获悉了Krackan的一款样品，编号为“AMD Eng Sample 100-000000713-21_N”，看样子像是PRO商用版本的锐龙AI 7 300。\n有趣的是，它定位不高，但是搭配了32GB大容量的LPDDR5X-8000高频内存，要知道Strix Point系列最高才LPDDR5X-7500。\n更高的内存频率，无疑可以更充分地释放GPU的性能。\n按理说，Intel、AMD似乎一直水火不相容，但是恐怕谁都没想到，Intel CEO帕特·基辛格、AMD CEO苏姿丰肩并肩站在了一起，联合宣布成立x86生态系统顾问小组，共同捍卫x86架构的江湖地位。\nIntel官方近日更是撰文，表明了基辛格的态度，强调了x86在AI PC时代的核心地位与意义。\nAI正在“飞入寻常百姓家”，成为随时随地可用的生产力和创意工具，让我们的日常生活变得更加美好。\n基辛格表示，得益于AI所带来的机遇，作为数十年来计算技术基础的x86架构，正在迎来一个定制、扩大和拓展的时期。\n基辛格认为，每家公司都将成为AI公司，每台设备都将成为AI设备，特别是每个人打开AI PC，便能受益于AI技术的神奇力量。\nAI PC让人们在使用AI时，不再受到时间、地点的限制，不必将个人数据分享到云端，网络连接也不再必需，正如当年Intel迅驰平台推动Wi-Fi在公共场所的普及。\n根据市调机构IDC的预测，AI PC将在2025年占据一半的市场份额，而到2030年，这一比例将达到100％。\n目前，单单是Intel就已出货了超过2000万台AI设备，生态系统方面已获得100多家ISV软件厂商的支持，出现了300多项AI应用、500多个AI模型。\n基辛格表示，AI PC时代需要定义核心架构，x86架构正是AI PC时代的关键，一如它是数据中心、边缘和网络解决方案的核心一样。\nx86生态系统顾问小组的成立，正是为了让x86架构在未来变得更加灵活、开放，进一步提升其成本效益，其目标是进一步推动x86生态系统的蓬勃发展，以更强大的定制化能力、兼容性和可扩展性满足客户的需求。\n在产品层面，Intel在与OEM厂商密切合作，推出了以酷睿Ultra系列处理器为核心的AI PC，拥有出色的性能和电池续航。\nIntel还将于明年推出基于Intel 18A(等效于1.8nm)制程节点的Panther Lake处理器，目前样片已经出厂、上电运行并顺利启动操作系统。\n","date":"2024-11-02","externalUrl":null,"permalink":"/hardware/amd-ryzen-9000x-3d-cache-has-changed/","section":"Hardwares","summary":"\u003cp\u003eAMD早就说\u003ca href=\"https://www.kad8.com/hardware/amd-ryzen-7-9800x3d-benchmark-leaked/\" target=\"_blank\"\u003eRyzen 9000X3D\u003c/a\u003e系列会带来真正的第二代3D缓存技术，那么到底有什么革命性的变化呢？根据最新曝料，至少其中之一就是，3D缓存的位置变了！\u003c/p\u003e\n\u003cp\u003e锐龙5000X3D、锐龙7000X3D系列的3D缓存都在CCD模块之上，同时在旁边还有填充模块，保持二者大小面积一致。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-Ryzen-9000X-3D-Cache-1.webp\" alt=\"AMD Ryzen 9000X\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e锐龙9000X3D则将3D缓存放在了CCD模块之下，当然肯定也少不了填充模块支撑。\u003c/p\u003e\n\u003cp\u003e这么做的好处就是可以让包含CPU核心、发热量更高的CCD模块贴着IHS散热顶盖，散热效果更好，自然可以跑到更高的频率。\u003c/p\u003e\n\u003cp\u003e比如首发的锐龙7 9800X3D，默认频率为4.7-5.2GHz，相比于锐龙7 7800X3D分别高了500MHz、200MHz，基准频率也远高于锐龙9000系列标准版。\u003c/p\u003e\n\u003cp\u003e同时，AMD应该是基本解决了X3D系列的超频限制，可以超到接近全核5.7GHz。\u003c/p\u003e\n\u003cp\u003e另外，锐龙7 9800X3D的专业跑分首次出现，搭档ROG CROSSHAIR X870E HERO主板、32GB DDR5-6000内存、RTX 4090显卡，PugetBench DaVinci测试得分10487、Premiere得分14201。\u003c/p\u003e","title":"AMD锐龙9000X3D缓存变了","type":"hardware"},{"content":"","date":"2024-11-02","externalUrl":null,"permalink":"/tags/ryzen/","section":"Tags","summary":"","title":"Ryzen","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/chiplet/","section":"Tags","summary":"","title":"Chiplet","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/gpu/","section":"Tags","summary":"","title":"GPU","type":"tags"},{"content":"Intel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。\n本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。\n据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。\n通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。\n此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。\n这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。\n其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。\n而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。\n事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。\n在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。\n这种思路可以提高设计和封装灵活性，使不同类型的芯片块可以分别进行优化和制造，然后再通过先进封装技术集成在一起，以实现更高的性能和效率。\n未来，无论是CPU、还是GPU，芯粒都是大势所趋。\n当然， Intel这份专利何时才能落地，目前尚未可知。期待Intel未来能带来好消息。\n不过如今想玩爽游戏，除了好显卡，也离不开好处理，比如AMD X3D这种逆天的存在。\nAMD即将推出的锐龙7 9800X3D处理器，完整规格已在Geizhals上泄露。\n锐龙7 9800X3D拥有8核心16线程，基础频率达到4.7GHz，最大加速频率为5.2GHz，相较于上一代7800X3D的4.2GHz基础频率和5.05GHz最大加速频率有了明显提升。\n该处理器的热设计功耗（TDP）为120W，与7800X3D相同，这意味着用户可能无需升级现有的散热方案。\n锐龙7 9800X3D的缓存配置保持不变，总计104MB缓存，包括8MB二级缓存、32MB内置三级缓存和64MB堆叠三级缓存。\n内存支持方面，该处理器升级至DDR5-5600，最大支持192GB内存，在使用两个DIMM时会降至DDR5-3600水平。\n与Ryzen 5000X3D和7000X3D不同，9800X3D的倍频解锁，为极限超频玩家提供了创造新世界记录的空间。\n值得注意的是，该处理器最高工作温度也从89摄氏度提高到了95摄氏度，与Ryzen 9000非X3D系列相似。\nAMD已经宣布，新一代锐龙9000X3D系列将于11月7日正式上市，届时锐龙7 9800X3D将正式亮相。\n","date":"2024-11-01","externalUrl":null,"permalink":"/ai/intel-chiplet-gpu-design-patents/","section":"Ais","summary":"\u003cp\u003eIntel首款采用Chiplets（芯粒）设计的桌面处理器Arrow Lake——酷睿Ultra 200S全球首发之后，其第一份“分解式”GPU设计专利也随之曝光。\u003c/p\u003e\n\u003cp\u003e本月早些时候，Intel申请了一份分解式GPU架构的专利，这可能是第一个具有逻辑小芯片的商业GPU架构。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Intel-patents-chiplet-gpu-design-1.webp\" alt=\"Intel Patents Chiplet GPU design\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e据了解，分解式GPU架构将GPU的单芯片设计，改为多个小型专用小芯片，然后使用相关技术互连。\u003c/p\u003e\n\u003cp\u003e通过将GPU划分为小芯片，制造商可以针对特定使用场景（例如计算、图形或AI）微调每个小芯片，从而发挥出最大效能。\u003c/p\u003e\n\u003cp\u003e此外，分解式GPU架构的另一个巨大优势是节能。因为单个小芯片允许电源门控，这意味着当它们不使用时，可以关闭电源以节省能源。\u003c/p\u003e\n\u003cp\u003e这种设计技术还带来了其他一些好处，例如工作负载定制、模块化和灵活性。在GPU设计领域，这种技术被视为未来的基准。\u003c/p\u003e\n\u003cp\u003e其实，AMD早在2022年就在RDNA3 GPU架构第一次引入了chiplet小芯片设计，包括一个GCD图形核心、最多六个MCD显存与缓存核心，但总体思路还是“一个大核心多个小核心”的思路。\u003c/p\u003e\n\u003cp\u003e而Intel这份GPU架构里面的逻辑小芯片，显然每个各自独立，且都有配套显存模块，可以看作是真正意义上的芯粒GPU。\u003c/p\u003e\n\u003cp\u003e事实上，随着摩尔定律逼近极限，5nm以下制程突破面临重重阻碍，Chiplet（芯粒）先进封装技术正是在这样的背景下横空出世。\u003c/p\u003e\n\u003cp\u003e在Chiplet思路下， 芯片被分割成较小的功能块或核心，然后将这些“chiplet芯片粒”以先进封装技术集成在一起以构建性能更强、更复杂化的芯片系统。\u003c/p\u003e","title":"英特尔获得 Chiplet GPU 设计专利","type":"ai"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/csodimm/","section":"Tags","summary":"","title":"CSODIMM","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/cudimm/","section":"Tags","summary":"","title":"CUDIMM","type":"tags"},{"content":"宜鼎国际（Innodisk）宣布推出业界容量最大的DDR5 6400内存模块，具备单条64GB的超大容量。\n该系列内存提供8GB至64GB的容量选项，以及CUDIMM、CSODIMM、ECC CUDIMM、ECC CSODIMM与RDIMM等多重规格。\n宜鼎DDR5 6400内存相比前代产品，速度提升14%，容量翻倍，可应用于自动驾驶、智慧医疗、安防监控等高精密影像识别场景。\n业界最高的单条64GB存储容量，可满足LLM等对内存容量需求较高的应用领域。\n该系列内存还在模块上增设独特CKD元件，针对时脉信号进行驱动与缓冲，有效减少干扰或噪声，确保高频传输下的信号完整性，降低在智慧医疗、自动驾驶等需要极高精准度的应用场景中的错误风险。\n此外，宜鼎DDR5 6400全系列产品搭载TVS二极管，传导因电压异常所产生的过电流，并将其释放到地面，防止静电、电压波动等突发状况损害模块元件。\n针对服务器应用推出的RDIMM规格，配备eFuse（电子熔断器），当电压超过额定值时，eFuse将自动中断电路，防止元件损坏。\n铠侠宣布量产业界首款采用四层单元技术的QLC UFS 4.0闪存。相比于传统的TLC UFS有着更高的位密度。\n在性能方面，512GB容量的QLC UFS 4.0闪存充分发挥了UFS 4.0接口的高速潜力，实现了惊人的4200MB/s顺序读取速度和3200MB/s的顺序写入速度。\n技术层面，铠侠巧妙地将先进的BiCS FLASH 3D NAND闪存与高效的主控芯片集成于JEDEC标准封装之内，不仅支持M-PHY 5.0和UniPro 2.0的最新规范，还确保了每通道高达23.2 Gb/s（或每设备46.4 Gbps）的理论接口速度，同时保持了与UFS 3.1标准的向下兼容性。\n此外，QLC UFS 4.0闪存还引入了多项前沿特性，如HS-LSS（高速链路启动序列），该特性相比传统方法能显著缩短链路启动时间，提升效率约70%。\n通过采用高级RPMB技术，实现了对安全数据的快速读写访问。\n扩展启动器ID（Ext-IID）功能的加入，旨在与UFS 4.0主控的多循环队列（MCQ）协同工作，共同提升随机性能。\n","date":"2024-11-01","externalUrl":null,"permalink":"/hardware/innodisk-unveils-ddr5-6400-64gb-cudimm-and-csodimm-memory-modules/","section":"Hardwares","summary":"\u003cp\u003e宜鼎国际（Innodisk）宣布推出业界容量最大的DDR5 6400内存模块，具备单条64GB的超大容量。\u003c/p\u003e\n\u003cp\u003e该系列内存提供8GB至64GB的容量选项，以及\u003ccode\u003eCUDIMM\u003c/code\u003e、\u003ccode\u003eCSODIMM\u003c/code\u003e、\u003ccode\u003eECC CUDIMM\u003c/code\u003e、\u003ccode\u003eECC CSODIMM\u003c/code\u003e与\u003ccode\u003eRDIMM\u003c/code\u003e等多重规格。\u003c/p\u003e\n\u003cp\u003e宜鼎DDR5 6400内存相比前代产品，速度提升14%，容量翻倍，可应用于自动驾驶、智慧医疗、安防监控等高精密影像识别场景。\u003c/p\u003e\n\u003cp\u003e业界最高的单条64GB存储容量，可满足\u003ccode\u003eLLM\u003c/code\u003e等对内存容量需求较高的应用领域。\u003c/p\u003e\n\u003cp\u003e该系列内存还在模块上增设独特CKD元件，针对时脉信号进行驱动与缓冲，有效减少干扰或噪声，确保高频传输下的信号完整性，降低在智慧医疗、自动驾驶等需要极高精准度的应用场景中的错误风险。\u003c/p\u003e\n\u003cp\u003e此外，宜鼎DDR5 6400全系列产品搭载TVS二极管，传导因电压异常所产生的过电流，并将其释放到地面，防止静电、电压波动等突发状况损害模块元件。\u003c/p\u003e\n\u003cp\u003e针对服务器应用推出的RDIMM规格，配备eFuse（电子熔断器），当电压超过额定值时，eFuse将自动中断电路，防止元件损坏。\u003c/p\u003e\n\u003cp\u003e铠侠宣布量产业界首款采用四层单元技术的QLC UFS 4.0闪存。相比于传统的TLC UFS有着更高的位密度。\u003c/p\u003e\n\u003cp\u003e在性能方面，512GB容量的\u003ccode\u003eQLC UFS 4.0\u003c/code\u003e闪存充分发挥了UFS 4.0接口的高速潜力，实现了惊人的4200MB/s顺序读取速度和3200MB/s的顺序写入速度。\u003c/p\u003e","title":"Innodisk 推出 DDR5 6400 64GB CUDIMM 和 CSODIMM 内存模块","type":"hardware"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/nvlink/","section":"Tags","summary":"","title":"NVLink","type":"tags"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/ualink/","section":"Tags","summary":"","title":"UALink","type":"tags"},{"content":"今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (UALink ) 联盟正式成立，并向社区发出成员邀请。\n资料显示，Ultra Accelerator Link(UALink) 是一种用于加速器到加速器通信的开放行业标准化互连。\nUALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 AI 加速器（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。\n新闻稿指出，联盟公司代表着广泛的行业专业知识，包括云服务提供商、系统 OEM、加速器开发商、交换机开发商和 IP 提供商。目前正在开发用于数据中心 AI 连接的更多使用模型。\nUALink 联盟总裁 Willie Nelson 表示：“UALink 标准定义了数据中心内扩展 AI 系统的高速、低延迟通信。我们鼓励有兴趣的公司以贡献者成员的身份加入，以支持我们的使命：为 AI 工作负载建立开放且高性能的加速器互连。”\n一个早在五月就发起的协议 # 其实早在今年五月，AMD、博通、思科、谷歌、惠普企业、英特尔、Meta 和微软就携手成立了超级加速器链接 (UALink：Ultra Accelerator Link)小组，旨在推动数据中心 AI 连接。\n这个初始小组名为“超级加速器链路”(UALink)，将定义和建立一项开放的行业标准，使 AI 加速器能够更有效地通信。通过创建基于开放标准的互连，UALink 将使系统 OEM、IT 专业人员和系统集成商能够为其 AI 连接数据中心创建一条更轻松的集成、更大的灵活性和可扩展性的途径。\n发起人集团公司在基于开放标准、效率和强大的生态系统支持创建大规模 AI 和 HPC 解决方案方面拥有丰富的经验。\n据他们所说，随着对 AI 计算的需求不断增长，拥有一个强大、低延迟且高效的扩展网络至关重要，该网络可轻松将计算资源添加到单个实例中。为扩展功能创建开放的行业标准规范将有助于为 AI 工作负载建立一个开放的高性能环境，从而提供尽可能高的性能。\nUALink 和行业规范对于标准化下一代 AI 数据中心和实现的 AI 和机器学习、HPC 和云应用程序接口至关重要。该小组将制定一项规范，定义 AI 计算舱中加速器和交换机之间扩展通信的高速、低延迟互连。\n根据最初报道，UAlink1.0 规范将允许在 AI 计算Pod内连接多达 1024 个加速器，并允许在舱内连接到加速器（例如 GPU）的内存之间进行直接加载和存储。按照最初规划，UALink 1.0 规范预计将于 2024 年第三季度推出，并提供给加入 Ultra Accelerator Link (UALink) 联盟的公司。\n但根据最新的报道，UALink 1.0 规范依然还将为 AI pod 内最多 1024 个加速器实现高达每通道 200Gbps 的扩展连接。而且该规范将于今年向贡献者成员提供，并于 2025 年第一季度提供一般审查。\n不过，按照UALink 联盟主席 Kurtis Bowman 所说，UALink 1.0 规范要到2025 年第一季度发布，在他们看来，这是一个重要的里程碑，因为它将建立一个开放的行业标准，使 AI 加速器和交换机能够更有效地通信、扩展内存访问以满足大型 AI 模型要求，并展示行业协作的好处。\n探索GPU连接的新方法 # GPU 是当前的市场热点，它们可轻松完成矩阵数学运算。它最初设计用于在计算机显示器上快速绘制点，后来被 HPC 从业者发现在大量使用时非常有用。随着 GenAI 的出现，这些小型矩阵专家的需求量巨大，以至于我们称之为 GPU Squeeze。\n著名且占主导地位的市场领导者 Nvidia 已经为 GPU 技术开辟了道路。对于 HPC、GenAI 和大量其他应用程序，连接 GPU 提供了一种解决更大问题并提高应用程序性能的方法。\n据外媒HPC报道，具体而言，连接GPU有三种基本方法：\nPCI 总线：标准服务器通常可以在 PCI 总线上支持 4-8 个 GPU。通过使用GigaIO FabreX 内存结构等技术，可以将这个数字增加到 32 个。CXL 也显示出希望，但是 Nvidia 的支持很少。对于许多应用程序来说，这些可组合的 GPU 域代表了下面提到的 GPU 到 GPU 扩展方法的替代方案。\n服务器到服务器互连：以太网或 InfiniBand 可以连接包含 GPU 的服务器。这种连接级别通常称为横向扩展，其中较快的多 GPU 域通过较慢的网络连接以形成大型计算网络。自从比特开始在机器之间移动以来，以太网一直是计算机网络的主力。最近，通过引入超级以太网联盟，该规范已被推动以提供高性能。事实上，英特尔已经在以太网上插上了互连旗帜，因为英特尔 Gaudi -2 AI 处理器在芯片上拥有 24 个 100 千兆以太网连接。\n值得一提的是，Nvidia 没有加入超级以太网联盟，因为他们在 2019 年 3 月收购 Mellanox 后，基本上独占了高性能 InfiniBand 互连市场。超级以太网联盟旨在成为其他所有人的“InfiniBand”。此外，英特尔也曾经高举 InfiniBand 大旗。\nGPU 到 GPU 互连：认识到快速且可扩展的 GPU 连接的需求，Nvidia 创建了 NVLink，这是一种 GPU 到 GPU 的连接，目前可在 GPU 之间以每秒 1.8 TB 的速度传输数据。此外，还有一个 NVLink 机架级交换机，能够在无阻塞计算结构中支持多达 576 个完全连接的 GPU。通过 NVLink 连接的 GPU 称为“pod”，表示它们有自己的数据和计算域。 对于其他人来说，除了用于连接 MI300A APU 的 AMD Infinity Fabric 之外，没有其他选择。与 InfiniBand/以太网的情况类似，需要某种“超级”竞争对手联盟来填补非 Nvidia 的“pod 空缺”。而这正是发生的事情。\n于是，UALink横空出世。\n能给英伟达带来压力吗？ # 如很多分析人士所说，创建 UALink 的举措反映了业界对高性能计算中可扩展、开放架构需求的日益认识。随着人工智能和数据密集型应用的发展，对此类技术的需求可能会增加，这使得 UALink 成为下一代计算工具的关键组件。\n通过提供 NVIDIA NVLink 和 NVSwitch 的可靠和开放替代方案，UALink 旨在打破 NVIDIA 在 GPU 互连市场的主导地位。这一点尤为重要，因为人工智能工作负载和模型不断增长，需要更具可扩展性和更高效的互连解决方案。\n毫无疑问，UALink 的推出给 NVIDIA 带来了压力，这将迫使他们继续创新和改进自己的技术。为了保持竞争优势，NVIDIA 需要提高 NVLink 和 NVLink Switch 的性能、可扩展性和成本效益，从而有可能加快行业创新的步伐。\n同时，UALink 的开源性质鼓励采用协作方式进行开发。摆脱专有系统可以促进创新，并允许快速采用和改进技术。\n分析人士指出，UALink 的潜力不仅仅是提供 NVLink 的替代方案。它旨在创建一个生态系统，无论公司规模大小，公司都可以为先进的互连技术做出贡献并从中受益。对于超大规模企业和大型数据中心而言，采用 UALink 可能意味着显着的成本节约、硬件部署的更大灵活性以及增强的性能。\n与此同时，UALink 还是一个技术公司联盟的重大举措，旨在限制 AI 加速器的专有互连，促进开放、竞争和创新。它对市场的影响可能是巨大的，为 AI 和基于加速器的系统营造一个更具活力和成本效益的生态系统。很难在这项使命中找到负面作用。\n虽然牌面上说给英伟达带来了竞争。\n但是，我们也必须认识到，NVIDIA 的 NVLink 为 UALink 设定了一个高标准和具有挑战性的目标，需要实现和超越。如今，其多代产品已投入生产，提供稳定的高性能解决方案，NVLink 不太可能停滞不前，预计将继续发展以满足预期的未来系统要求。UALink 不仅需要实现其解决方案的稳定性和支持供应商之间的互操作性，还需要超越 NVLink 目前所处的位置。\n此外，虽然建立稳定、高性能、可互操作的物理互连（可从多家供应商处获得并支持）是保持竞争力的必要条件，但这还不够。NVIDIA 的 CUDA 软件开发环境也是一个难以克服的巨大障碍。用户不愿意将他们的应用程序代码移植到新硬件上，只为实现相同的性能和功能；他们宁愿将投资集中在解决方案上，为客户提供新的功能、能力和价值。\n尽管存在上述挑战，UALink 仍朝着正确的方向前进。该组织由来自先进技术计算生态系统（系统、交换机、云、超大规模器、加速器、I/O、组件设计）的领先供应商组成，他们在合作定义新标准并将其推向市场方面有着良好的记录。\n同时，与 UEC 结盟和合作也是一个明智之举，因为生态系统采用的范围越广，成功的可能性就越大。虽然这超出了 UALink 的范围，但与更高级别的软件工作建立联系并提供支持，以帮助用户从 CUDA 移植到标准加速器软件环境，将进一步提高 UALink 实现广泛采用目标的可能性。\n为了支持 UALink 的努力，超级以太网联盟 (UEC) 主席 J Metz 博士在五月的小组成立新闻稿中直言：“在很短的时间内，技术行业已经接受了人工智能和 HPC 发现的挑战。在寻求提高效率和性能时，将 GPU 等加速器互连需要整体视角。在 UEC，我们相信 UALink 解决 pod 集群问题的扩展方法与我们自己的扩展协议相得益彰，我们期待在未来共同合作创建一个开放、生态系统友好、全行业的解决方案，以满足这两种需求。”\n针对这个协议，英伟达CEO黄仁勋在早前曾直言不会太在意。他同时强调，目前NVLink已推出到第五代，而UALink还只是个提案，至少数年内都不会威胁到NVLink。当UALink第一代推出时，NVLink可能已到第七、八代了；甚至针对未来NVIDIA网络技术改进，内部也有许多不错的想法，不排除将有更进一步创新。\n但，有竞争力总是好事。\n","date":"2024-11-01","externalUrl":null,"permalink":"/ai/nine-giants-established-the-ualink-alliance/","section":"Ais","summary":"\u003cp\u003e今天，AMD、亚马逊网络服务 (AWS)、Astera Labs、思科、谷歌、惠普企业 (HPE)、英特尔、Meta 和微软等九大董事会成员联合宣布，由其领导的超级加速器链接 (\u003ccode\u003eUALink\u003c/code\u003e ) 联盟正式成立，并向社区发出成员邀请。\u003c/p\u003e\n\u003cp\u003e资料显示，\u003ccode\u003eUltra Accelerator Link(UALink)\u003c/code\u003e 是一种用于加速器到加速器通信的开放行业标准化互连。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./UALink-1.webp\" alt=\"UALink\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eUALink 联盟则是一个开放的行业标准组织，旨在制定互连技术规范，以促进 \u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI 加速器\u003c/a\u003e（即 GPU）之间的直接加载、存储和原子（atomic）操作。他们的重点是为一个 pod 中的数百个加速器实现低延迟/高带宽结构，并实现具有软件一致性的简单加载和存储语义。UALink 1.0 规范将利用开发和部署了各种加速器和交换机的推广者成员的经验。\u003c/p\u003e","title":"九大巨头，正式成立UALink联盟","type":"ai"},{"content":"","date":"2024-11-01","externalUrl":null,"permalink":"/tags/macbook-air/","section":"Tags","summary":"","title":"MacBook Air","type":"tags"},{"content":"前天，苹果官方网站悄然上架了全新的M4系列MacBook Pro，以及升级后的MacBook Air机型，为用户带来性能和配置的双重提升。新款MacBook Pro提供14英寸和16英寸两种尺寸选择，起售价为12999元。14英寸版本可选配M4、M4 Pro和M4 Max三种芯片，标配16GB内存；16英寸版本则提供M4 Pro和M4 Max两种芯片，标配24GB内存。\n值得注意的是，M4 Max芯片首次在MacBook Pro中亮相，成为M4系列中性能最强的PC芯片。M4 Max拥有14核中央处理器、32核图形处理器和16核神经网络引擎，支持Apple智能功能。苹果官方表示，这款芯片重新定义了专业级笔记本电脑的性能极限。\n凭借M4 Max的强大性能，用户可以轻松完成过去需要高配台式电脑才能处理的任务，例如与拥有数千亿参数的大语言模型进行交互。对于制作精细的视觉特效、3D动画和电影配乐等高强度的创意工作，M4 Max也能游刃有余。与上一代M3 Max相比，M4 Max在Redshift渲染性能上提升了64.9倍，表现极为出色。\n在配置方面，14英寸MacBook Pro采用14.2英寸Liquid视网膜XDR显示屏，提供深空黑色和银色两种配色，内置72.4瓦时锂聚合物电池。16英寸版本则配备16.2英寸Liquid视网膜XDR显示屏，内置100瓦时锂聚合物电池。两款机型均配备1200万像素摄像头，支持1080P视频拍摄，并搭载高保真六扬声器系统。\n接口方面，新款MacBook Pro搭载了雷雳5接口，数据传输速度最高可达120Gb/s，方便用户连接高速外设、驱动高分辨率显示器，或直接读取SDXC卡的数据。新品将于11月8日正式上市发售。\n此外，苹果还宣布，搭载M2和M3芯片的MacBook Air机型现已标配16GB内存，起售价分别仍为7999元和8999元，价格未发生变化。目前，苹果官网提供13英寸M2 MacBook Air、13英寸M3 MacBook Air和15英寸M3 MacBook Air三种选择，固态硬盘容量为256GB起步。\n苹果此举的目的是为了更好地支持Apple智能功能。根据分析师郭明錤的说法，Apple Intelligence采用端侧3B LLM技术，经过压缩后，需要预留约0.7-1.5GB的DRAM来运行。因此，提升内存容量有助于提高设备的整体性能和用户体验。\n截至目前，苹果新款MacBook Pro、Mac mini、iMac等设备全部以16GB内存起步，老款MacBook Air也淘汰了8GB内存版本。这标志着苹果正式结束了Mac设备的8GB内存时代，为用户带来更强大的性能和更高的工作效率。\n此次苹果对Mac系列产品的全面升级，不仅在硬件配置上进行了大幅提升，也体现了苹果对用户需求的重视和对未来技术发展的前瞻性。新款MacBook Pro和升级后的MacBook Air，将为用户带来更出色的使用体验。\n","date":"2024-11-01","externalUrl":null,"permalink":"/hardware/macbook-air-now-starts-with-16gb-ram/","section":"Hardwares","summary":"\u003cp\u003e前天，苹果官方网站悄然上架了全新的M4系列\u003ccode\u003eMacBook Pro\u003c/code\u003e，以及升级后的\u003ccode\u003eMacBook Air\u003c/code\u003e机型，为用户带来性能和配置的双重提升。新款MacBook Pro提供14英寸和16英寸两种尺寸选择，起售价为12999元。14英寸版本可选配M4、M4 Pro和M4 Max三种芯片，标配16GB内存；16英寸版本则提供M4 Pro和M4 Max两种芯片，标配24GB内存。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MacBook-Pro-Air-1.webp\" alt=\"MacBook Pro and MacBook Air\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e值得注意的是，M4 Max芯片首次在MacBook Pro中亮相，成为M4系列中性能最强的PC芯片。M4 Max拥有14核中央处理器、32核图形处理器和16核神经网络引擎，支持Apple智能功能。苹果官方表示，这款芯片重新定义了专业级笔记本电脑的性能极限。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MacBook-Pro-Air-2.webp\" alt=\"MacBook Pro and MacBook Air\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"苹果新款MacBook标配16GB","type":"hardware"},{"content":"","date":"2024-10-28","externalUrl":null,"permalink":"/tags/docker-compose/","section":"Tags","summary":"","title":"Docker-Compose","type":"tags"},{"content":"最近在使用docker的过程中，发现CPU和内存经常占满，导致其它服务都不能正常使用。下面本文就探讨一下如何使用docker-compose限制内存和cpu。本文以docker-compose.yml中version 3.x为例。\n内存和CPU限制 # yml文件添加 service.deploy内容如下：\ndeploy: resources: limits: cpus: \u0026#34;2.00\u0026#34; memory: 5G reservations: memory: 200M 注意：reservations中不支持cpus，仅支持内存。\n以ldap为例：\nversion: \u0026#39;3.7\u0026#39; services: openldap: image: 10.10.239.54/public/openldap:1.3.0 container_name: openldap environment: - N9E_NID=22 ports: - \u0026#34;389:389\u0026#34; - \u0026#34;636:636\u0026#34; deploy: resources: limits: cpus: \u0026#34;2.00\u0026#34; memory: 5G reservations: memory: 200M volumes: - ./ldap:/var/lib/ldap - ./slapd.d:/etc/ldap/slapd.d restart: always 启动容器 # 限制指令为deploy.resources.limits这部分，注意节点位置，上面这部分限制的含义是：openldap服务的CPU使用被限制在最多200%的CPU能力，内存使用被限制在最多5GB。同时，这个服务至少需要200MB的内存。\n我们启动的时候命令需要发生一些变化，否则不会生效：\n#原本的启动命令为 docker-compse up -d # 需要添加一个参数--compatibility表示以兼容模式来运行 docker-compose --compatibility up -d 这里的关键在于添加\u0026ndash;compatibility参数以兼容模式来运行，否则限制不会生效。\n验证 # 通过上述方法限制容器CPU和内存后，可以使用命令：docker stats查看容器资源使用情况.\n总结 # docker-compose.yml限制内存需要添加deploy.resources.limits节点 docker-compose命令启动的时候需要添加\u0026ndash;compatibility参数以兼容模式来运行，否则限制不会生效 以上就是Docker Compose中限制容器的CPU和内存使用的全部内容。\n","date":"2024-10-28","externalUrl":null,"permalink":"/software/limit-memory-and-cpu-using-docker-compose/","section":"Softwares","summary":"\u003cp\u003e最近在使用docker的过程中，发现CPU和内存经常占满，导致其它服务都不能正常使用。下面本文就探讨一下如何使用docker-compose限制内存和cpu。本文以docker-compose.yml中version 3.x为例。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e内存和CPU限制 \n    \u003cdiv id=\"%E5%86%85%E5%AD%98%E5%92%8Ccpu%E9%99%90%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%86%85%E5%AD%98%E5%92%8Ccpu%E9%99%90%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eyml文件添加 service.deploy内容如下：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mark\" data-lang=\"mark\"\u003edeploy:\n      resources:\n         limits:\n            cpus: \u0026#34;2.00\u0026#34;\n            memory: 5G\n         reservations:\n            memory: 200M\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e注意：reservations中不支持cpus，仅支持内存。\u003c/p\u003e","title":"使用docker-compose限制内存和cpu","type":"software"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/hbm/","section":"Tags","summary":"","title":"HBM","type":"tags"},{"content":"像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： 人工智能(AI) ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”\n三星电子已经成功地将其高带宽内存(HBM)设备与英伟达的 H100 GPU 等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。\n事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。\nSK海力士的HBM优势 # SK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。\n因此，这些存储设备被广泛用于高性能计算系统上的生成式AI设备，这并不奇怪。例如，SK海力士的HBM3芯片销售额在2023年同比增长了5倍以上。《数字时报》的一篇报道称，英伟达已经向SK海力士和美光支付了5.4亿至7.7亿美元的预付款，以确保为其GPU产品提供HBM存储芯片。\nSK海力士计划在批量生产新一代HBM3E的同时，开发下一代HBM4存储芯片。据韩国媒体报道，英伟达计划将其H200和B100 GPU分别与6个和8个HBM3E模块配对。与HBM3相比，HBM3E显著提高了速度，每秒可以处理高达1.15TB的数据。\n三星电子将HBM3E称为AI内存产品，并声称在该领域处于技术领先地位。虽然三星和美光都已经准备好了他们的HBM3E设备，并且正在英伟达等AI巨头的认证过程中，但SK海力士似乎比其内存竞争对手领先一步。以SK海力士目前正在开发的HBM4为例，预计将于2025年面市。\n特别值得注意的是，HBM4能够直接将内存堆栈到处理器上，完全消除了中间层。目前，HBM堆栈在CPU或GPU旁边集成了8、12或16个存储设备，这些存储设备通过接口连接到这些处理器。将内存直接集成到处理器上将改变芯片的设计和制造方式。\n一家AI存储公司 # 行业分析师还认为，SK海力士是以AI为中心的内存升级周期的主要受益者，因为它是一家纯粹的内存公司，与其主要竞争对手三星不同。值得注意的是，三星也在大力投资AI研发，以加强其内存产品。\nAI确实需要大量内存，拥有前两大内存供应商的韩国渴望成为AI强国也就不足为奇了。就SK海力士而言，它已经证明了自己在AI服务器设计和设备上的重要性。\n在美国拉斯维加斯举行的国际消费电子展(CES 2024)上，三星电子CEO在谈到内存在生成式AI中的关键作用时，誓言要在三年内将公司市值翻一番。这就是为什么它现在寻求成为一家全面的AI内存提供商，同时寻求通过高价值的HBM产品实现快速周转。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/hbm-memory-chips-the-unsung-hero-of-the-ai-revolution/","section":"Ais","summary":"\u003cp\u003e像DRAM这样长期受周期性趋势影响的存储芯片，现在正瞄准一个更稳定的市场： \u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003e人工智能\u003c/a\u003e(AI)  ，如全球第二大存储芯片供应商SK海力士。三星电子CFO Kim Woo-hyun表示:“三星将通过引领变革和提供定制化解决方案，成长为全面的人工智能存储器供应商。”\u003c/p\u003e\n\u003cp\u003e三星电子已经成功地将其\u003ca href=\"https://www.kad8.com/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/\" target=\"_blank\"\u003e高带宽内存(HBM)\u003c/a\u003e设备与英伟达的 H100 GPU  等配对，用于处理生成式AI中的大量数据。像ChatGPT这样的大型语言模型(LLM)越来越需要高性能内存芯片，以使生成式AI模型能够存储过去对话的细节和用户偏好，从而生成类似人类的响应。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-AI-1.png\" alt=\"HBM in AI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e事实上，AI公司都在抱怨无法获得足够的存储芯片。OpenAI CEO Sam Altman最近访问了韩国，在那里会见了世界最大的存储芯片供应商SK海力士和三星的高管，其次是美国的美光公司。OpenAI的ChatGPT技术在刺激对运行AI应用程序的处理器和内存芯片的需求方面至关重要。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eSK海力士的HBM优势 \n    \u003cdiv id=\"sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#sk%E6%B5%B7%E5%8A%9B%E5%A3%AB%E7%9A%84hbm%E4%BC%98%E5%8A%BF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eSK海力士在人工智能领域的幸运突破是在2015年推出首款HBM设备，超越三星，并在为游戏卡等高速计算应用提供GPU服务方面取得了巨大的领先优势。HBM垂直互连多个DRAM芯片，与早期的DRAM产品相比，显著提高了数据处理速度。\u003c/p\u003e","title":"HBM内存芯片: AI革命的无名英雄","type":"ai"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/ddr5/","section":"Tags","summary":"","title":"DDR5","type":"tags"},{"content":"在AI服务器需求剧增的情况下，HBM正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，DDR5预计将上涨15%至20%。\nHBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。\n从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。\n从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端AI应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。\n由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。\n展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/explosive-hbm-demand-fueling-20-increase-in-ddr5-pricing/","section":"Ais","summary":"\u003cp\u003e在AI服务器需求剧增的情况下，\u003ca href=\"https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/\" target=\"_blank\"\u003eHBM\u003c/a\u003e正在快速增长。美光和SK海力士正式表示，2024年和2025年的HBM供应已经售罄。据TrendForce分析师预计，明年HBM内存的价格将上涨5%至10%。此外，其他类型的DRAM价格也可能上涨，由于内存制造商将优先考虑HBM生产，\u003ca href=\"https://www.gaitpu.com/data-center/storage/ddr4-vs-ddr5-ram-all-the-design-challenges-advantages\" target=\"_blank\"\u003eDDR5\u003c/a\u003e预计将上涨15%至20%。\u003c/p\u003e\n\u003cp\u003eHBM比标准的DRAM要贵得多，大约是DDR5的5倍。与DRAM相比，HBM的性能和容量优势证明了更高的成本是合理的。与传统的DDR芯片和模块相比，构建HBM内存设备和堆栈也要困难得多。内存制造商不得不将更多的产能投入到HBM，减少了其他类型内存的产能，这自然会推高DRAM的价格。\u003c/p\u003e\n\u003cp\u003e从2023年第四季度开始，DRAM价格连续三个季度实现两位数的百分比增长。仅在4月份，所有类别的服务器DRAM价格就上涨了9%至19%。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-DDR-1.png\" alt=\"HBM DDR\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e从市场份额的角度来看，HBM在总DRAM位容量中的份额将迅速增加。预计这一比例将从2023年的2%增长到2024年的5%，最终在2025年底超过10%。这种扩展反映了尖端\u003ca href=\"https://www.gaitpu.com\" target=\"_blank\"\u003eAI\u003c/a\u003e应用对内存子系统不断升级的需求。因此，HBM对整个DRAM市场的贡献预计将大幅增长，到2025年可能占市场价值的30%以上。\u003c/p\u003e\n\u003cp\u003e由于整体DRAM容量有限，关于2025年HBM定价的讨论始于2024年第二季度。这一限制导致最初的价格上涨了5%到10%。这些调整反映了市场对AI需求持续强劲的预期，尽管目前HBM3e的TSV的良率仅在40%至60%之间。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./HBM-DDR-2.png\" alt=\"HBM DDR\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e展望未来，主要的AI解决方案提供商将专注于提高HBM的性能和容量，特别是采用HBM3E和增加12-Hi堆栈产品的使用。TrendForce预测显示，到2024年，HBM的需求增长率将接近200%，预计到2025年将翻一番。\u003c/p\u003e","title":"爆炸性的HBM需求预计推动DDR5价格上涨20%","type":"ai"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/google/","section":"Tags","summary":"","title":"Google","type":"tags"},{"content":"10月24日消息，Google宣布推出名为SynthID Text的开源水印工具，旨在帮助开发人员识别人工智能生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。\nSynthID Text的工作能力 # Google DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。\n这一过程不会对文本的质量和生成速度产生影响，在一次用户反馈实验中，用户对Google的Gemini大型语言模型生成的2000万条文本的反馈显示，带有水印的文本与未带水印的文本在质量上没有明显差异。\n但是SynthID Text在某些方面仍存在局限性，对于较短的文本、事实性回答以及从其他语言翻译过来的内容，该工具的检测可靠性会下降。\nGoogle承认了这些局限，但其更强调该工具的整体优势。因为SynthID Text的开源特性使它可以被广泛地应用和改进，从而提高整个行业的标准。开发者和研究人员现在可以利用这一工具来确保人工智能文本生成系统在高效的基础上更加的透明和负责。Google DeepMind的副总裁表示，他们希望其他人工智能模型开发者能够应用这一技术，并将其集成到自己的系统中。\n开发水印工具的必要性 # 随着人工智能生成内容需求的增长，对人工智能生成内容检测方法的需求也在增加。中国等国家已经开始强制要求对人工智能生成的内容进行水印标记，美国加利福尼亚州也在考虑类似的法规。\n据预测，到2026年人工智能生成的内容可能会占据在线文本的90%，这将为打击虚假信息和欺诈带来新的挑战。Google这一工具的发布响应了全球范围内对于人工智能生成内容检测方法需求增长的迫切性。\n随着人工智能生成内容的增多，确保其应用的透明度和责任性变得尤为重要。Google的这一行动可能是推动人工智能水印技术成为行业标准的重要一步，为防止互联网充斥着人工智能生成的垃圾信息提供了一种可能的解决方案。\n","date":"2024-10-27","externalUrl":null,"permalink":"/ai/google-releases-synthid-text-for-watermarking-ai-generated-content/","section":"Ais","summary":"\u003cp\u003e10月24日消息，\u003ccode\u003eGoogle\u003c/code\u003e宣布推出名为\u003ccode\u003eSynthID Text\u003c/code\u003e的开源水印工具，旨在帮助开发人员识别\u003ca href=\"https://www.kad8.com/ai/\" target=\"_blank\"\u003e人工智能\u003c/a\u003e生成的内容，提高人工智能编写文本的透明度。这项开源技术目前可在Hugging Face和Google Responsible GenAI Toolkit等平台上免费使用。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Google-Synthid-text.webp\" alt=\"Google SynthID Text\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eSynthID Text的工作能力 \n    \u003cdiv id=\"synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#synthid-text%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%83%BD%E5%8A%9B\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGoogle DeepMind的研究人员详细描述了SynthID Text文本水印的工作原理，该技术通过改变人工智能模型生成文本时选用词汇的概率分布，以一种秘密但可检测的方式标记文本。\u003c/p\u003e","title":"Google发布开源AI文本水印工具","type":"ai"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/synthid/","section":"Tags","summary":"","title":"Synthid","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/watermarking/","section":"Tags","summary":"","title":"Watermarking","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/bios/","section":"Tags","summary":"","title":"BIOS","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/bmc/","section":"Tags","summary":"","title":"BMC","type":"tags"},{"content":"","date":"2024-10-27","externalUrl":null,"permalink":"/tags/peci/","section":"Tags","summary":"","title":"PECI","type":"tags"},{"content":"PECI是用于监测CPU及芯片组温度的一线总线(one-wire bus)，全称是Platform Environment Control Interface。它最主要的应用是监测CPU温度，最新版本的PECI接口还包括一些其他的功能。\nIntel Processor的温控机制 # 在CPU中，通常每个CPU核心都有一个数字温度传感器。在PC平台下，处理器可以通过MSR(Mode specific registers)获得处理器自身的温度、调节风扇转速，从而实现温度控制。在服务器平台下，温度控制通常是由BMC来做的，业务CPU本身没有办法控制服务器里的风扇转速。BMC直接或间接通过PECI总线获取到CPU的核心温度，再根据所读到的温度值来调整风扇的转速。\nMSR方式读取CPU温度读取到的是即时温度，PECI方式读取到的是256ms时间窗内的平均温度。MSR方式是需要CPU处理C0状态才能读取。PECI方式在C0~C6均可以使用。\n图表1 PECI接中的连接方式 Intel Pentium M 开始在处理器中引入DTS（数字温度传感器）。温度传感器通常是每个CPU核心一个。\n图表2 Intel温控组件 TM1 # 为了保护CPU不会在过热时被烧坏，从Pentium4开始，处理器中又加入了一个温度监示器Thermal Monitor 1，简称TM1。TM1会监示数字温度传感器的读数，当读数高于阈值Tjmax时，TM1会调节处理器时钟的占空比，以降低功耗，降低温度。这里所谓的调节时钟占空比与传统意义上的时钟占空比不同，这里调节的是时钟信号的开闭时间比例，比如说，它会在某一段时间内，37.5%的时间打开CPU时钟，让CPU工作，另62.5%的时间关闭CPU时钟，让CPU停止工作以降低功耗和温度。\nFigure 1 TM1调整CPU时钟占空比 TM2 # TM2是Pentium M引入的，它提供了另一种降低CPU温度的办法。在CPU某个核心的温度超过Tjmax时，它会尝试降低时钟频率和供电电压来降低功耗和温度。TM1和TM2是两个单独的机制，或以分别启用和禁用。Intel推荐两个机制同时使用。它们的启用和禁用是通过BIOS设置IA32_MISC_ENABLE这个模式寄存器的第3、13位来实现的。BIOS打开这两个机制后，OS和用户程序不可关闭。\n温度阈值 # Tjmax是我们所知的第一个阈值，当CPU上任意一个核心的温度达到这个阈值时，CPU会产生一个PROCHOT#信号（processor hot）。该信号可触发TM1和TM2。处理器时会通过调节时钟占空比、降低时钟频率和供电电压的方式来降低功耗和温度。产生PROCHOT#信号的同时，温度监示器还会产生一个中断给CPU，其中断向量号通过LAPIC和LVT来设置。模式寄存器IA32_THERM_INTERRUPT有两个位用于高温中断使能（温度超过Tjmax时产生中断）和低温中断使能（温度回到低于Tjmax的范围时产生中断）。\nPROCHOT#通过CPU的一个引脚拉出，并且可以连接在外设上，由外设来发生这个信号。比如说一个系统中有另一个设备的温度超过阈值，它可以拉低使能这个信号，从而使CPU也一起降温，从而降低机箱内的温度，制造一个更好的散热环境。\n如果TM1和TM2启动后温度没能降低下来，并且继续升高到可能造成CPU物理损坏的温度时，核心会触发THERMTRIP#信号，并且关闭CPU电源。\nCPU硬件实现的温度控制机制是用于CPU自我保存的温控机制，当这些机制不足以降温时，CPU会断电，从而造成系统突然掉电，造成数据损失。因而一般要求BMC在要以一定的周期读取CPU核心温度，根据温度调整风扇转速，并且当温度超过Tjmax-10时，让风扇全速转动。\n相关MSR # IA32_THERM_INTERRUPT # IA32_THERM_INTERRUPT寄存的地址为0x19B。BIOS通过IA32_THERM_INTERRUPT模式寄存器使能温度相关的中断，其各字段定义如下：\n表格 1 IA32_THERM_INTERRUPT 0x19B\n位 描述 0 High temperature interrupt enable 1 Low temperature interrupt enable 2 PROCHOT# interrupt enable 3 FORCEPR# interrupt enable 4 Critical Temperature interrupt enable 7:5 reserved 14:8 Threshold 1 value 15 Threshold 1 int enable 22:16 Threshold 2 value 23 Threshold 2 int enable 63:24 reserved 在一个实际系统读到的该寄存器的值为：\nsudo modprobe msr sudo rdmsr –p 0 0x19B 3 IA32_TEMPERATURE_TARGET # IA32_TEMPERATURE_TARGET模式寄存器的地址为0x1A2。该模式寄存器是只读的。\n表格 2 IA32_TEMPERATURE_TARGET模式寄存器\n位 描述 23:16 温度目标，单为是摄氏度，当达到这个温度时触发TM1和TM2，产生PROCHOT#信号。 在一个实际系统读到的该寄存器的值为：\nsudo modprobe msr sudo rdmsr –p 0 0x1A2 0x5B08 0x5B=91摄氏度\n嵌入汇编方式读取MSR：\n__asm____volatile__(“movl $0x1A2, %%ecx\\n\\trdmsr\\n\\t”) PECI接口 # BMC获取CPU核心温度有两种途径：\n通过PECI总线直接从CPU上获取温度数据 通过IPMI协议从南桥上的ME上获取CPU核心温度 在第二种情况下，ME需要通过PECI接口从CPU上获取温度。由于PECI的一线总线是intel的私有总线协议，很多BMC厂商并没有办法集成支持PECI接口协议的硬件，因而途径2是获取CPU核心温度的主流途径。\nPECI规范 # PECI是一个私有的协议，不得到Intel授权无从得知协议的细节。PECI规范到现在有三个主要版本：1.1、2.0和3.0。PECI 1.1支持最简单的温度监示，PECI2.0则支持更多的如读取MSR等特性，PECI 3.0进一步支持PCIe总线配置空间的读取。\n表格 3 PECI 1.1和2.0比较\n版本 1.1 2.0 特性 温度监示 温度监示 Ping() Ping() GetTemp() GetTemp() GetDib() GetDib() 访问CPU内存 BIST Memory throttling相关 下图是PECI 3.0支持的命令列表：\n表格 4 PECI 3.0支持的命令列表\n现代服务器系统中，BMC通常不直接使用PECI接口，而是通过南桥上的ManagementEngine来间接使用PECI接口。Management Engine是南桥上的一个嵌入式微控制器，它可以通过南桥上的PECI主控器访问CPU上的PECI从设备。同时，ME还实现了一些IPMI命令，可以让BMC通过SMLink间接使用这个PECI主控制器。这样的系统架构如下图所示：\n图表 5 南桥做PECI Proxy 所有的IPMI命令可以参考《IntelIntelligent Power Node Manager 2.0 External Interface Specification》的2.9节： IPMI OEMPECI Proxy Commands。\n","date":"2024-10-27","externalUrl":null,"permalink":"/software/introduction-to-peci-interface-in-server/","section":"Softwares","summary":"\u003cp\u003e\u003ccode\u003ePECI\u003c/code\u003e是用于监测\u003ccode\u003eCPU\u003c/code\u003e及\u003ccode\u003e芯片组\u003c/code\u003e温度的一线总线(one-wire bus)，全称是\u003ccode\u003ePlatform Environment Control Interface\u003c/code\u003e。它最主要的应用是监测CPU温度，最新版本的PECI接口还包括一些其他的功能。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eIntel Processor的温控机制 \n    \u003cdiv id=\"intel-processor%E7%9A%84%E6%B8%A9%E6%8E%A7%E6%9C%BA%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#intel-processor%E7%9A%84%E6%B8%A9%E6%8E%A7%E6%9C%BA%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在CPU中，通常每个CPU核心都有一个数字温度传感器。在PC平台下，处理器可以通过\u003ccode\u003eMSR\u003c/code\u003e(Mode specific registers)获得处理器自身的温度、调节风扇转速，从而实现温度控制。在\u003ccode\u003e服务器\u003c/code\u003e平台下，温度控制通常是由\u003ccode\u003eBMC\u003c/code\u003e来做的，业务CPU本身没有办法控制服务器里的风扇转速。BMC直接或间接通过PECI总线获取到CPU的核心温度，再根据所读到的温度值来调整风扇的转速。\u003c/p\u003e","title":"服务器下的PECI接口简介","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"Infrastructure","type":"tags"},{"content":" AI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。\n概述 # AI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。\n然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。\n云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。\n要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。\nAI对基础设施的新要求 # AI基础设施对于传统IT团队而言是一片全新的疆域。团队可能在GPU等加速硬件、异构系统架构方面经验不足。尽管团队在数据存储和管理上有深厚积累，但对AI的工作原理和应用场景却可能知之甚少。AI环境通常处理来自多个异构数据源的信息，这些数据需要经过数据工程师的精心整理，才能用于模型训练。这些数据可能来自关系型数据库、文件系统、甚至外部数据源，且格式不统一、存储位置分散。数据的规模庞大，进一步增加了处理的复杂性。\n图1. AI典型数据流 数据科学团队负责数据的质量和可用性，但IT部门需要提供坚实的技术基础。数据科学团队要求数据能够即时获取，这对存储系统的性能提出了极高的要求。IT团队在选择存储系统时，需要充分考虑数据访问的I/O特性，并优化与GPU或加速器的互联。此外，数据复制、保护和数据库访问等数据服务也是IT基础设施需要提供的关键功能。\n目前，AI开发主要集中在公有云平台上。企业通常会选择已有的基础模型，并利用私有数据进行微调，以创建定制化的AI模型。生成式AI中的检索增强生成（RAG）就是一个典型的例子。RAG通过引入新的、定制化的数据，提升了大型语言模型的准确性、时效性和相关性。\n由于公有云在AI开发中占据主导地位，数据科学团队对云端存储系统的性能、可用性和保护机制的重视程度往往不够。因此，IT部门需要深入了解业务需求，评估各种存储解决方案，并向数据科学团队清晰地传达本地部署的优势。在私有环境中，IT部门需要考虑数据的存储位置、访问方式、以及数据保护和安全合规性等方面的问题。\n随着AI应用的不断深入，企业开始将AI工作负载从公有云迁移到本地数据中心，或者采用混合云部署模式。一方面，公有云的高昂成本在规模化部署时会成为企业的负担；另一方面，数据安全、隐私保护以及对资源的掌控需求也在推动企业向本地化迁移。此外，新型的基础设施和存储即服务（SaaS）解决方案的出现，\nAI本地化存储的特性 # 用于训练AI模型的数据来源广泛，包括结构化和非结构化数据。这些数据通常存储在数据湖或数据湖仓中，以满足AI/ML项目对大规模、高性能存储的需求。数据工程师创建的训练数据集是AI模型训练的基石。数据科学团队对存储系统的性能要求极高，包括大容量、高带宽和低延迟。\n图2. AI/ML和BI数据平台 随着AI的发展，对存储系统的需求也日益多样化。全闪存存储凭借其性能一致性，成为AI存储的首选。AI环境在不同发展阶段对存储系统的需求也不同：\n初始/成熟阶段：需要兼具高性能文件存储和对象存储。 生产级：需要大规模容量的文件和对象存储，同时保持高性能。 IT基础设施团队和AI平台架构师对存储系统都有各自的关注点。对于存储系统，除了传统的性能、可靠性、安全性和可扩展性之外，还应考虑以下特性：\n性能：AI工作负载对性能的可预测性和一致性要求极高。全闪存存储能提供低延迟和高带宽，是理想选择。 可靠性与数据保护：存储系统应具备容错能力，防止数据丢失。 安全性：采用最佳实践保护数据安全。 K8s原生支持：考虑到Kubernetes在AI/ML领域的广泛应用，存储系统应与K8s无缝集成。 加速MLOps：数据科学家应能自助访问存储、向量数据库和ML服务，加速模型开发。 可扩展性：存储系统应能线性扩展，以满足不断增长的数据需求。 简单性：易于配置和管理，减少运维负担。 成本效益：存储成本应与容量成正比，且不影响性能。 能效：存储系统应节能，以降低总体拥有成本。 总结 # AI的迅猛发展给传统的IT基础设施带来了前所未有的挑战，尤其是数据存储与管理方面。这些挑战不仅新颖，而且与以往的IT问题存在显著差异。例如，AI平台架构师可能对IT环境中的操作流程和关键数据存储的特性并不熟悉，他们的经验往往集中在公共云环境。鉴于此，组织在部署和发展AI环境时，必须做出关键的IT决策。\n其中，选择合适的存储类型是至关重要的。一个理想的数据存储平台应具备以下特点：\n加速AI落地：从早期部署到成熟的AI生产环境，该平台能够显著缩短AI项目的交付周期。 全方位性能：在性能、效率、可靠性、数据保护、扩展性和易用性等方面提供均衡且一致的解决方案，满足不同使用场景和成本要求。 高级功能：支持快速部署、简化操作、无需复杂培训、最大化效率，并提供多维性能和多协议访问等高级特性。 容器化友好：与主流容器编排框架（如Kubernetes）无缝集成，简化有状态应用程序的管理。 显著缩短模型开发周期：能够帮助企业快速搭建一个能够训练和部署私有数据的AI环境，从而加速AI项目的落地。 高置信度：系统的稳定性和可靠性能够最大程度地减少存储基础设施部署的时间，降低项目风险。 ","date":"2024-10-26","externalUrl":null,"permalink":"/ai/setting-direction-for-enterprise-ai-infrastructure/","section":"Ais","summary":"\u003cblockquote\u003e\n\u003cp\u003eAI的快速发展对数据存储提出了前所未有的挑战，要求海量数据和高性能存储。企业需构建高效、可靠的存储基础设施，如全闪存存储、数据湖等，以满足AI的需求。同时，还需应对数据安全、隐私保护和成本控制等问题。IT团队在有限资源下必须平衡性能、扩展性、安全性和简便性。选择适合业务特点的存储解决方案对加速AI项目落地和提高数据管理效率至关重要，这也是企业应对AI时代的核心任务之一。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e概述 \n    \u003cdiv id=\"%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eAI正以前所未有的速度渗透各行各业，其潜力已毋庸置疑。众多组织将其视为提升竞争力的关键，纷纷加大对AI的投入。\u003c/p\u003e\n\u003cp\u003e然而，AI的价值实现并非一蹴而就。组织需要仔细评估资源需求，尤其是如何有效管理信息资产。随着AI应用的深入，企业面临着将宝贵数据高效引入AI模型的挑战。如何平衡数据访问与安全，如何满足AI环境的独特需求，成为组织IT团队亟待解决的问题。\u003c/p\u003e\n\u003cp\u003e云端AI开发的便捷性与企业对数据主权的重视形成了鲜明对比。企业IT部门必须为AI团队提供本地开发环境，这无疑增加了IT部门的工作复杂性。如何在有限的资源下，为AI团队构建高效、可靠的基础设施，成为IT部门面临的新课题。\u003c/p\u003e\n\u003cp\u003e要满足不断增长的AI需求，选择合适的技术至关重要。除了强大的计算资源和AI工具，高效、可扩展的存储解决方案更是重中之重。这不仅能加速模型训练，降低成本，还能显著提升数据科学家的工作效率。IT部门作为AI基础设施的提供者，必须深入理解AI团队的需求，并提供最优解决方案。\u003c/p\u003e","title":"如何构建高效可靠的AI基础设施","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/sc8480xpsc8480xp/","section":"Tags","summary":"","title":"SC8480XPSC8480XP","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/snapdragon-x2/","section":"Tags","summary":"","title":"Snapdragon X2","type":"tags"},{"content":"高通公司近日开始测试其用于 PC 的下一代基于 ARM 架构的 Snapdragon X2 CPU，内部型号为 SC8480XP，代号为“Project Glymur”。据悉，这款芯片已在今年7月和8月进行了测试。\n几个月前，高通推出了 Snapdragon X 系列，宣称具备强大的 CPU 和 GPU 组合，可以为用户带来可靠的 AI PC 体验，因此受到了业内广泛关注。但是尽管宣传力度很大，初期的评测和性能结果并不完全令人满意。单核性能、IPC 数据以及效率和电池寿命被视为亮点，但在多核和图形性能方面表现平平。本来很多人憧憬的ARM版本windows挑战苹果电脑的格局并不存在。\n当前一代的 Snapdragon X SoC 内部型号为“SC8380XP”，代号为“Hamoa”。如前所述，正在测试的下一代 SoC SC8480XP，代号为“Glymur”或“Project Glymur”。测试使用的开发板配备了各种 NAND 和内存组件，类似于早期评估平台（RVP 或 EVP），用于在最终规格确定前测试样品。这意味着高通仍处于新 SoC 测试的早期阶段。\n此前的戴尔 XPS 泄露信息显示，高通正在开发至少两个基于 Oryon CPU 架构的下一代变体，计划用于基于 Snapdragon X 的 AI PC。这包括计划于2025年中期推出的 Snapdragon X V2，以及预计于2027年第四季度推出的后续产品 Snapdragon V3。尽管这些时间表是初步的，但由于信息来源于高通的重要合作伙伴戴尔，可以推测这些计划具有较高的可信度。\n与此同时，科技媒体还报道称，高通正在准备一款新的 Snapdragon X Plus 系列入门级变体，标签为“X1P-24-100”。预计这款芯片将保留8核设计，但在时钟频率或 GPU 性能方面可能有所降低，以满足入门级市场的需求。\n在 x86 厂商如 AMD 和英特尔推出 Ryzen AI 300“Strix”和 Core Ultra 200V“Lunar Lake”等强大产品的背景下，这些产品具备改进的 NPU、强大的 CPU 核心和卓越的集成 GPU，提供了市场上领先的性能。高通显然意识到竞争的激烈，正在加紧完善其 Snapdragon X 系列产品线。\n高通想把自己在手机SoC的领先经验带入到PC领域，目前看并不容易，一方面x86领域的对手实力很强，迭代迅速，另一方面苹果阵营的软硬件生态也固若金汤。目前看初代的产品连搅局的能力都不具备，前期大量的宣传如同石头丢进河里，泛起一阵涟漪后就消失不见。当然，我们还是期待高通能够积极推进下一代 Snapdragon X2 CPU 的开发和测试，能够给市场带来更多样的格局。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/qualcomm-begins-testing-next-generation-snapdragon-x2-cpu/","section":"Hardwares","summary":"\u003cp\u003e高通公司近日开始测试其用于 PC 的下一代基于 ARM 架构的 Snapdragon X2 CPU，内部型号为 SC8480XP，代号为“Project Glymur”。据悉，这款芯片已在今年7月和8月进行了测试。\u003c/p\u003e\n\u003cp\u003e几个月前，高通推出了 \u003ccode\u003eSnapdragon X\u003c/code\u003e 系列，宣称具备强大的 \u003ccode\u003eCPU\u003c/code\u003e 和 \u003ccode\u003eGPU\u003c/code\u003e 组合，可以为用户带来可靠的 \u003ccode\u003eAI PC\u003c/code\u003e 体验，因此受到了业内广泛关注。但是尽管宣传力度很大，初期的评测和性能结果并不完全令人满意。单核性能、IPC 数据以及效率和电池寿命被视为亮点，但在多核和图形性能方面表现平平。本来很多人憧憬的ARM版本windows挑战苹果电脑的格局并不存在。\u003c/p\u003e","title":"高通着手测试下一代Snapdragon X2 CPU","type":"hardware"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/edk2/","section":"Tags","summary":"","title":"EDK2","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/ide/","section":"Tags","summary":"","title":"IDE","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/sata/","section":"Tags","summary":"","title":"SATA","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/uefi/","section":"Tags","summary":"","title":"UEFI","type":"tags"},{"content":"笔者研究了一下磁盘相关的 Protocol，本文描述了uEFI下如何获取磁盘信息。\n简介 # 与本次探究相关的主要有三个 Protocol：EFI_BLOCK_IO_PROTOCOL、EFI_DISK_IO_PROTOCOL 以及 EFI_DISK_INFO_PROTOCOL 。前两个是在 UEFI SPEC 定义的，最后一个则是在 PI SPEC。\nBlockIo 与 DiskIo # BlockIo 与 DiskIo 两个Protocol 均是用于访问存储设备的协议，只是它们可以进行操作的级别不同。前者能以 块 的级别对存储设备进行操作，而后者则提供更加底层的能力，它可以以 字节 为单位对设备进行访问。\nDiskInfo # 这两个Protocol 的主要目的是提供一种标准化的方式来获取磁盘设备的信息。这些信息可能包括磁盘的类型、制造商、序列号、固件版本等。\n实例 # 描述 # 写一个程序，枚举出所有物理磁盘，并打印磁盘的型号，SN 以及容量大小。\n思路 # 使用 BlockIo 获取所有块设备的实例，然后再使用 DiskIo 进行筛选，得到所有的物理磁盘。接着将物理磁盘的实例传给 DiskInfo，通过 Identify 函数可获取 Identify Data，再根据磁盘的接口类型对数据进行解析，便能打印型号等信息。\n代码 # /** * @file DiskInfo.c * * @version 0.2 * @date 2024-09-09 * * @copyright Copyright (c) 2015 - 2024 * */ #include \u0026lt;Uefi.h\u0026gt; #include \u0026lt;Library/PcdLib.h\u0026gt; #include \u0026lt;Library/UefiLib.h\u0026gt; #include \u0026lt;Library/UefiApplicationEntryPoint.h\u0026gt; #include \u0026lt;Library/UefiBootServicesTableLib.h\u0026gt; #include \u0026lt;Library/MemoryAllocationLib.h\u0026gt; #include \u0026lt;Protocol/BlockIo.h\u0026gt; #include \u0026lt;Protocol/DiskIo.h\u0026gt; #include \u0026lt;Protocol/DiskInfo.h\u0026gt; #include \u0026lt;Library/BaseMemoryLib.h\u0026gt; #include \u0026lt;Library/PrintLib.h\u0026gt; #include \u0026lt;Protocol/IdeControllerInit.h\u0026gt; VOID HexDump (UINT8 *Buffer, UINT8 RowNum) { UINT8 Cols; UINT8 Rows; for (Rows = 0; Rows \u0026lt; RowNum; Rows ++) { for (Cols = 0; Cols \u0026lt; 16; Cols ++) { Print (L\u0026#34;%2X \u0026#34;, Buffer[Cols+Rows*16]); } Print (L\u0026#34; \u0026#34;); for (Cols = 0; Cols \u0026lt; 16; Cols ++) { if ((Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;9\u0026#39;) || (Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;z\u0026#39;) || (Buffer[Cols+Rows*16] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; Buffer[Cols+Rows*16] \u0026lt;= \u0026#39;Z\u0026#39;)) Print (L\u0026#34;%c\u0026#34;, Buffer[Cols+Rows*16]); else Print (L\u0026#34;.\u0026#34;); } Print (L\u0026#34;\\n\\r\u0026#34;); } Print (L\u0026#34;\\n\\r\u0026#34;); } /** Eliminate the extra spaces in the Str to one space. @param Str Input string info. **/ VOID BmEliminateExtraSpaces ( IN CHAR16 *Str ) { UINTN Index; UINTN ActualIndex; for (Index = 0, ActualIndex = 0; Str[Index] != L\u0026#39;\\0\u0026#39;; Index++) { if ((Str[Index] != L\u0026#39; \u0026#39;) || ((ActualIndex \u0026gt; 0) \u0026amp;\u0026amp; (Str[ActualIndex - 1] != L\u0026#39; \u0026#39;))) { Str[ActualIndex++] = Str[Index]; } } Str[ActualIndex] = L\u0026#39;\\0\u0026#39;; } EFI_STATUS EFIAPI GetDiskIdentifyData (EFI_HANDLE Handle) { EFI_STATUS Status; EFI_DISK_INFO_PROTOCOL *DiskInfo; EFI_ATAPI_IDENTIFY_DATA IdentifyData; UINT32 IdentifyDataSize; CHAR16 *ModelName; CHAR16 *SerialNo; CONST UINTN ModelNameLength = 40; CONST UINTN SerialNoLength = 20; UINTN Index; Status = gBS-\u0026gt;HandleProtocol(Handle, \u0026amp;gEfiDiskInfoProtocolGuid, (VOID**)\u0026amp;DiskInfo); if (EFI_ERROR(Status)) { return Status; } // // AHCI or IDE // if (CompareGuid (\u0026amp;DiskInfo-\u0026gt;Interface, \u0026amp;gEfiDiskInfoAhciInterfaceGuid) || CompareGuid (\u0026amp;DiskInfo-\u0026gt;Interface, \u0026amp;gEfiDiskInfoIdeInterfaceGuid)) { IdentifyDataSize = sizeof (EFI_ATAPI_IDENTIFY_DATA); Status = DiskInfo-\u0026gt;Identify(DiskInfo, \u0026amp;IdentifyData, \u0026amp;IdentifyDataSize); if (!EFI_ERROR (Status)) { ModelName = AllocatePool(sizeof(CHAR16) * ModelNameLength); SerialNo = AllocatePool(sizeof(CHAR16) * SerialNoLength); // According to the ATA specification, the model name and serial number fields // in the identify data are stored as an array of 16-bit words. // Each word is stored in little-endian format, meaning the least significant byte comes first. for (Index = 0; Index + 1 \u0026lt; ModelNameLength; Index += 2) { ModelName[Index] = (CHAR16) IdentifyData.ModelName[Index + 1]; ModelName[Index + 1] = (CHAR16) IdentifyData.ModelName[Index]; } for (Index = 0; Index + 1 \u0026lt; SerialNoLength; Index += 2) { SerialNo[Index] = (CHAR16) IdentifyData.SerialNo[Index + 1]; SerialNo[Index + 1] = (CHAR16) IdentifyData.SerialNo[Index]; } BmEliminateExtraSpaces(ModelName); BmEliminateExtraSpaces(SerialNo); HexDump((UINT8 *)\u0026amp;IdentifyData, 16); Print (L\u0026#34;Model Name: %s\\n\\r\u0026#34;, ModelName); Print (L\u0026#34;Serial No : %s\\n\\r\u0026#34;, SerialNo); Print (L\u0026#34;Disk type: %g\\n\\r\u0026#34;, DiskInfo-\u0026gt;Interface); } else { return Status; } } return EFI_SUCCESS; } /** The user Entry Point for Application. The user code starts with this function as the real entry point for the application. @param[in] ImageHandle The firmware allocated handle for the EFI image. @param[in] SystemTable A pointer to the EFI System Table. @retval EFI_SUCCESS The entry point is executed successfully. @retval other Some error occurs when executing this entry point. **/ EFI_STATUS EFIAPI UefiMain ( IN EFI_HANDLE ImageHandle, IN EFI_SYSTEM_TABLE *SystemTable ) { EFI_STATUS Status; UINTN HandleCount = 0; EFI_HANDLE *HandleBuffer = NULL; UINTN Index; EFI_BLOCK_IO_PROTOCOL *BlockIo; EFI_DISK_IO_PROTOCOL *DiskIo; Status = gBS-\u0026gt;LocateHandleBuffer( ByProtocol, \u0026amp;gEfiBlockIoProtocolGuid, NULL, \u0026amp;HandleCount, \u0026amp;HandleBuffer ); if (EFI_ERROR(Status)) { Print(L\u0026#34;Failed to locate block I/O handles: %r\\n\u0026#34;, Status); return Status; } for (Index = 0; Index \u0026lt; HandleCount; Index++) { Status = gBS-\u0026gt;HandleProtocol( HandleBuffer[Index], \u0026amp;gEfiBlockIoProtocolGuid, (VOID**)\u0026amp;BlockIo ); if (EFI_ERROR(Status) || BlockIo == NULL || BlockIo-\u0026gt;Media == NULL) { continue; } Status = gBS-\u0026gt;HandleProtocol( HandleBuffer[Index], \u0026amp;gEfiDiskIoProtocolGuid, (VOID**)\u0026amp;DiskIo ); if (!EFI_ERROR(Status) \u0026amp;\u0026amp; DiskIo != NULL \u0026amp;\u0026amp; !BlockIo-\u0026gt;Media-\u0026gt;RemovableMedia) { if (BlockIo-\u0026gt;Media-\u0026gt;LogicalPartition == FALSE \u0026amp;\u0026amp; BlockIo-\u0026gt;Media-\u0026gt;BlockSize \u0026gt; 0 \u0026amp;\u0026amp; BlockIo-\u0026gt;Media-\u0026gt;LastBlock \u0026gt; 0) { GetDiskIdentifyData(HandleBuffer[Index]); Print (L\u0026#34;Size : %d MB\\n\\r\u0026#34;, (BlockIo-\u0026gt;Media-\u0026gt;LastBlock + 1) * BlockIo-\u0026gt;Media-\u0026gt;BlockSize / (1024 * 1024)); Print(L\u0026#34;\\n\\r\u0026#34;); } } } if (HandleBuffer != NULL) { gBS-\u0026gt;FreePool(HandleBuffer); } return EFI_SUCCESS; } 上面代码参考了 MdeModulePkg\\Library\\UefiBootManagerLib\\BmBootDescription.c ，其中 BmGetDescriptionFromDiskInfo 函数的实现，需要注意的是，EDK2 默认的代码中只对 IDE / AHCI 两种有解析的定义，对于 NVME、SD 之类的还没有，所以只写了这一部分。\n代码中有个解析算法也值得说一下：\n// According to the ATA specification, the model name and serial number fields // in the identify data are stored as an array of 16-bit words. // Each word is stored in little-endian format, meaning the least significant byte comes first. for (Index = 0; Index + 1 \u0026lt; ModelNameLength; Index += 2) { ModelName[Index] = (CHAR16) IdentifyData.ModelName[Index + 1]; ModelName[Index + 1] = (CHAR16) IdentifyData.ModelName[Index]; } for (Index = 0; Index + 1 \u0026lt; SerialNoLength; Index += 2) { SerialNo[Index] = (CHAR16) IdentifyData.SerialNo[Index + 1]; SerialNo[Index + 1] = (CHAR16) IdentifyData.SerialNo[Index]; } 在ATA规范中，型号名称和序列号等字段存储为16位的数组。每个16位字以小端格式存储，这意味着最低有效字节（LSB）先存储，然后是最高有效字节（MSB）。\n","date":"2024-10-26","externalUrl":null,"permalink":"/software/how-to-get-disk-information-for-uefi/","section":"Softwares","summary":"\u003cp\u003e笔者研究了一下磁盘相关的 Protocol，本文描述了uEFI下如何获取磁盘信息。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e简介 \n    \u003cdiv id=\"%E7%AE%80%E4%BB%8B\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%80%E4%BB%8B\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e与本次探究相关的主要有三个 Protocol：\u003ccode\u003eEFI_BLOCK_IO_PROTOCOL\u003c/code\u003e、\u003ccode\u003eEFI_DISK_IO_PROTOCOL\u003c/code\u003e 以及 \u003ccode\u003eEFI_DISK_INFO_PROTOCOL\u003c/code\u003e 。前两个是在 UEFI SPEC 定义的，最后一个则是在 PI SPEC。\u003c/p\u003e","title":"UEFI 获取磁盘信息","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/csv/","section":"Tags","summary":"","title":"CSV","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"今天咱们聊聊如何用Python高效地处理CSV文件。无论你是数据分析新手还是资深开发者，这些技巧都能让你的工作更加得心应手。\n使用csv模块读取CSV文件 # Python自带的csv模块是处理CSV文件的利器。先来看看基本用法：\nimport csv with open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.reader(file) for row in reader: print(row) 这段代码会逐行读取data.csv中的数据并打印出来。\n读取带标题的CSV文件 # 如果CSV文件有标题行，可以使用DictReader类，这样每一行都会被转换成字典：\nwith open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.DictReader(file) for row in reader: print(row[\u0026#39;Name\u0026#39;]) 写入CSV文件 # csv.writer可以帮助你轻松写入数据：\nwith open(\u0026#39;output.csv\u0026#39;, mode=\u0026#39;w\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: writer = csv.writer(file) writer.writerow([\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;]) writer.writerow([\u0026#39;Alice\u0026#39;, 30]) 使用pandas库读写CSV # pandas是数据科学领域的大佬，用它读写CSV超级简单：\nimport pandas as pd df = pd.read_csv(\u0026#39;data.csv\u0026#39;) df.to_csv(\u0026#39;output.csv\u0026#39;, index=False) 处理大文件 # 对于大文件，逐行处理是个好办法，避免内存溢出：\nchunksize = 10 ** 6 for chunk in pd.read_csv(\u0026#39;large_data.csv\u0026#39;, chunksize=chunksize): # 处理每一块数据 CSV编码问题 # 处理非英文字符时，确保正确设置文件编码：\nwith open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: # ... 快速访问特定列 # pandas可以快速获取CSV中的特定列：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, usecols=[\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;]) 跳过CSV文件的前几行 # 有时候我们需要跳过CSV文件的前几行：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, skiprows=range(1, 10)) 修改CSV文件的分隔符 # 不是所有CSV文件都用逗号分隔，有时你需要自定义分隔符：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, sep=\u0026#39;;\u0026#39;) 处理缺失值 # pandas可以帮你优雅地处理缺失值：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;).fillna(0) 数据类型转换 # 确保数据以正确的类型加载：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;, dtype={\u0026#39;Age\u0026#39;: int}) 选择性读取行 # 你可以根据条件筛选CSV中的行：\ndf = pd.read_csv(\u0026#39;data.csv\u0026#39;) filtered_df = df[df[\u0026#39;Age\u0026#39;] \u0026gt; 25] 利用itertools处理CSV # itertools模块提供了高效的迭代工具：\nfrom itertools import islice with open(\u0026#39;data.csv\u0026#39;, mode=\u0026#39;r\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: reader = csv.reader(file) header = next(reader) # 读取标题行 for row in islice(reader, 10): # 只读取接下来的10行 print(row) 使用多线程或进程加速处理 # 处理大量数据时，单线程可能效率低下。利用多线程或多进程可以显著提升处理速度，尤其是在读取和写入大型CSV文件时。\nimport concurrent.futures import pandas as pd def process_chunk(chunk): # 对每块数据执行处理逻辑 return chunk.describe() # 读取CSV文件，分割成多个小块 chunks = pd.read_csv(\u0026#39;large_data.csv\u0026#39;, chunksize=1000) # 使用多线程处理每一块数据 with concurrent.futures.ThreadPoolExecutor() as executor: results = list(executor.map(process_chunk, chunks)) # 合并处理结果 final_result = pd.concat(results) 高级技巧总结与注意事项 # 性能优化：对于大型数据集，优先考虑数据预处理和数据类型管理，避免不必要的内存负担。 异常处理：在读取或写入CSV文件时，加入异常处理机制，确保程序的健壮性和可靠性。 数据验证：在数据处理过程中，进行必要的数据验证，如检查数据完整性、格式一致性等，避免错误数据导致的后续分析问题。 代码复用：将常用的数据处理逻辑封装成函数或类，提高代码的复用性和维护性。 实战案例深入分析 # 让我们回到销售数据的实战案例，进一步分析如何识别销售趋势和预测未来销量。\nimport pandas as pd from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split # 读取CSV文件 sales_df = pd.read_csv(\u0026#39;sales.csv\u0026#39;) # 数据预处理 sales_df[\u0026#39;Date\u0026#39;] = pd.to_datetime(sales_df[\u0026#39;Date\u0026#39;]) sales_df[\u0026#39;Month\u0026#39;] = sales_df[\u0026#39;Date\u0026#39;].dt.month # 构建模型输入和输出 X = sales_df[[\u0026#39;Month\u0026#39;]] y = sales_df[\u0026#39;Quantity\u0026#39;] # 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 训练线性回归模型 model = LinearRegression() model.fit(X_train, y_train) # 预测未来销量 future_months = pd.DataFrame({\u0026#39;Month\u0026#39;: range(1, 13)}) predictions = model.predict(future_months) # 输出预测结果 future_months[\u0026#39;Predicted Sales\u0026#39;] = predictions print(future_months) 通过构建线性回归模型，我们可以预测未来的销售趋势，为业务决策提供有力支持。\n结语 # 掌握了这些技巧，你已经能够在Python中熟练地处理CSV文件了。无论是简单的数据读写，还是复杂的分析任务，这些技能都将助你一臂之力。\n","date":"2024-10-26","externalUrl":null,"permalink":"/software/14-efficient-techniques-to-process-csv-files-by-python/","section":"Softwares","summary":"\u003cp\u003e今天咱们聊聊如何用Python高效地处理CSV文件。无论你是数据分析新手还是资深开发者，这些技巧都能让你的工作更加得心应手。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e使用csv模块读取CSV文件 \n    \u003cdiv id=\"%E4%BD%BF%E7%94%A8csv%E6%A8%A1%E5%9D%97%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BD%BF%E7%94%A8csv%E6%A8%A1%E5%9D%97%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003ePython自带的csv模块是处理CSV文件的利器。先来看看基本用法：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecsv\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;data.csv\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;r\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enewline\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eencoding\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;utf-8\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003efile\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ereader\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecsv\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ereader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efile\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003erow\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003ereader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这段代码会逐行读取data.csv中的数据并打印出来。\u003c/p\u003e","title":"Python处理CSV文件的14个高效技巧","type":"software"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/genai/","section":"Tags","summary":"","title":"GenAI","type":"tags"},{"content":"现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。\n如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。\n本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。\n数据湖 # 企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。\n这些数据湖必须支持流处理工作负载，具备高效的加密和纠删码能力，能够将元数据与对象原子性地存储，并支持Lambda计算等技术。由于这些现代对象存储是云原生的，它们能与其他云原生技术栈（从防火墙到可观测性再到用户和访问管理）无缝集成。\n基于OTF的数据仓库 # 对象存储同样是基于OTF的数据仓库的底层存储方案。虽然用对象存储构建数据仓库听起来有些反常，但这种方式代表了新一代数据仓库。Netflix、Uber和Databricks制定的OTF规范使得在数据仓库中使用对象存储变得简单可行。\n这些OTF包括Apache Iceberg、Apache Hudi和Delta Lake，是因为市场上缺乏能够满足创建者数据需求的产品而开发的。它们的核心功能（尽管实现方式不同）是定义一个可以构建在对象存储之上的数据仓库。对象存储提供了其他存储方案无法比拟的可扩展容量和高性能的结合。\n作为现代规范，它们具备传统数据仓库所不具备的高级功能，如分区演进、模式演进和零拷贝分支。\n能够在MinIO之上运行基于OTF的数据仓库的是Dremio和Starburst。\nDremio Sonar（数据仓库处理引擎） Dremio Arctic（数据仓库目录） 开放数据湖仓 | Starburst（目录和处理引擎） 机器学习运维（MLOps） # MLOps之于机器学习，犹如DevOps之于传统软件开发。两者都是一套旨在提升工程团队（开发或机器学习团队）与IT运维团队之间协作的实践和原则。其目标是通过自动化来简化开发生命周期，涵盖从规划、开发到部署和运维的各个阶段。其中一个主要优势是实现持续改进。\nMLOps的技术和功能在不断演进。选择一个有大厂支持的工具至关重要，以确保工具能持续开发和改进，并提供长期支持。这些工具底层都使用MinIO来存储模型生命周期中的各种工件。\nMLRun（Iguazio，现已被麦肯锡公司收购） MLflow（Databricks） Kubeflow（Google） 机器学习框架 # 机器学习框架是用于创建模型和编写训练代码的库（通常是Python库）。这些库功能丰富，提供多种损失函数、优化器、数据转换工具和神经网络的预构建层。其中最重要的功能之一是张量（Tensor）。张量是可以被移至GPU上的多维数组，在模型训练过程中具有自动微分功能。\n当前最流行的两个机器学习框架是PyTorch（来自Meta）和TensorFlow（来自Google）。\nPyTorch TensorFlow 分布式训练 # 分布式模型训练是指在多个计算设备或节点上同时训练机器学习模型的过程。这种方法能够加速训练过程，尤其在使用大型数据集训练复杂模型时效果显著。\n在分布式模型训练中，数据集被分割为更小的子集，每个子集由不同的节点并行处理。这些节点可以是集群中的独立机器、独立进程或Kubernetes集群中的独立Pod，并可能具备GPU访问权限。每个节点独立处理其子集数据，并相应地更新模型参数。以下五个库屏蔽了分布式训练的大部分复杂性。虽然可以在本地运行这些库，但要显著减少训练时间，仍需要一个集群。\nDeepSpeed（来自Microsoft） Horovod（来自Uber） Ray（来自Anyscale） Spark PyTorch Distributor（来自Databricks） Spark TensorFlow Distributor（来自Databricks） 模型中心 # 虽然模型中心并非严格属于现代数据湖参考架构的一部分，但由于其对快速启动生成式AI至关重要，仍将其纳入其中。Hugging Face已成为大型语言模型的首选平台。它托管了一个模型中心，工程师可以在此下载预训练模型并分享自己创建的模型。Hugging Face还开发了Transformers和Datasets库，这些库与大型语言模型（LLM）以及用于训练和微调它们的数据协同工作。\n当然，还有其他模型中心。所有主要的云供应商都提供了上传和分享模型的途径，但Hugging Face凭借其丰富的模型和库，已成为该领域的领导者。\nHugging Face 应用框架 # 应用框架帮助将LLM集成到应用程序中。使用LLM与使用标准API有所不同，需要进行大量工作将用户请求转换为LLM可以理解和处理的内容。例如，如果你构建一个聊天应用程序，并希望使用检索增强生成（RAG），你需要将请求标记化，将标记转换为向量，集成向量数据库（如下所述），创建提示，然后调用你的LLM。生成式AI的应用框架允许你将这些操作串联在一起。\n当前最广泛使用的应用框架是LangChain。它可以与其他技术集成，如Hugging Face的Transformer库和Unstructured的文档处理库。它功能丰富，使用起来可能有些复杂，因此对于那些需求不复杂并希望使用比LangChain更简单工具的用户，下面列出了一些替代方案。\nLangChain AgentGPT Auto-GPT BabyAGI Flowise GradientJ LlamaIndex Langdock TensorFlow（Keras API） 文档处理 # 大多数组织并没有一个统一的、包含清晰准确文档的存储中心，而是将文档散落在各个团队的门户中，且格式多样。在为生成式AI准备数据时，首要任务是建立一条管道，筛选出已获批用于生成式AI的文档，并将它们导入向量数据库。对于大型跨国企业而言，这通常是最具挑战性的环节。\n文档管道应将文档转化为文本，将长文本分割成更小的片段，并利用嵌入模型对这些片段进行处理，从而获得它们的向量表示，以便存储在向量数据库中。一些开源库可以处理多种常见的文档格式，并能与LangChain无缝结合，构建完整的文档处理流程。\nUnstructured Open-Parse 向量数据库 # 向量数据库支持语义搜索。理解其工作原理需要大量的数学背景，较为复杂。然而，语义搜索在概念上很容易理解。假设你想找到所有讨论“artificial intelligence”相关内容的文档。要在传统数据库中实现这一点，你需要搜索“artificial intelligence”的每一个可能的缩写、同义词和相关术语。你的查询可能会像这样：\nSELECT snippet FROM MyCorpusTable WHERE (text like \u0026#39;%artificial intelligence%\u0026#39; OR text like \u0026#39;%ai%\u0026#39; OR text like \u0026#39;%machine learning%\u0026#39; OR text like \u0026#39;%ml%\u0026#39; OR ... and on and on ... 这种手动的相似性搜索既繁琐又容易出错，而且搜索本身也非常缓慢。向量数据库可以接收类似下面的请求，运行查询更快且更准确。如果你希望使用检索增强生成，快速而准确地运行语义查询至关重要。\n{ Get { MyCorpusTable(nearText: {concepts: [\u0026#34;artificial intelligence\u0026#34;]}) {snippet} } } 以下列出了四个流行的向量数据库。\nMilvus Pgvector Pinecone Weaviate 数据探索与可视化 # 拥有能够处理数据并以不同方式可视化的工具始终是明智之选。以下列出的Python库，正是提供了这样的能力。它们不仅适用于传统的AI，在生成式AI中同样大有用武之地。比如，在情感分析中，通过可视化工具，我们可以直观地检查数据集的分布，确保各个情感类别的样本均衡。\nPandas Matplotlib Seaborn Streamlit 结论 # 以上是现代数据湖参考架构中的十项关键能力，以及对应的具体供应商产品和库。\n以下是这些工具的汇总表。\n数据湖： MinIO、AWS、GCP、Azure 基于OTF的数据仓库： Dremio Dremio Sonar Dremio Arctic Starburst Open Data Lakehouse | Starburst 机器学习框架： PyTorch TensorFlow 机器学习运维（MLOps）： MLRun（麦肯锡公司） MLflow（Databricks） Kubeflow（Google） 分布式训练： DeepSpeed（Microsoft） Horovod（Uber） Ray（Anyscale） Spark PyTorch Distributor（Databricks） Spark TensorFlow Distributor（Databricks） 模型中心： Hugging Face 应用框架： LangChain AgentGPT Auto-GPT BabyAGI Flowise GradientJ LlamaIndex Langdock TensorFlow（Keras API） 文档处理： Unstructured Open-Parse 向量数据库： Milvus Pgvector Pinecone Weaviate 数据探索与可视化： Pandas Matplotlib Seaborn Streamlit ","date":"2024-10-26","externalUrl":null,"permalink":"/ai/the-architects-guide-to-the-genai-tech-stack-10-tools/","section":"Ais","summary":"\u003cp\u003e现代数据湖，有时也被称为数据湖仓（data lakehouse），是数据湖与基于开放表格式规范（OTF，Open Table Format）的数据仓库各占一半的结合体。两者均建立在现代对象存储之上。\u003c/p\u003e\n\u003cp\u003e如何构建全面支持AI/ML需求的AI数据基础设施，不仅要包含存储训练集、验证集和测试集的原始数据，还应涵盖训练大型语言模型所需的计算资源、MLOps工具链以及分布式训练等功能。\u003c/p\u003e\n\u003cp\u003e本文探讨如何利用现代数据湖参考架构来满足AI/ML需求。下图展示了现代数据湖参考架构，并重点标出了支持生成式AI所需的能力。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./GenAI-Tech-Stack.jpg\" alt=\"GenAI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e数据湖 \n    \u003cdiv id=\"%E6%95%B0%E6%8D%AE%E6%B9%96\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%95%B0%E6%8D%AE%E6%B9%96\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e企业级数据湖以对象存储为基础。这里所指的并非传统的、以设备为基础的对象存储（主要用于大规模低成本归档），而是现代的、高性能的、软件定义的、Kubernetes原生的对象存储，它是现代生成式AI技术栈的基石。这类存储可作为服务提供（如AWS、Google Cloud Platform（GCP）、Microsoft Azure），也可在本地部署或采用混合模式，例如MinIO。\u003c/p\u003e","title":"生成式AI技术栈架构师指南","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/h100/","section":"Tags","summary":"","title":"H100","type":"tags"},{"content":"据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。\n云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。\n这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。\n并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。\n无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。\n如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。 而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。\n","date":"2024-10-26","externalUrl":null,"permalink":"/ai/the-lifespan-of-a-datacenter-gpu-is-only-3-years/","section":"Ais","summary":"\u003cp\u003e据Alphabet（谷歌母公司）一位高级专家称，数据中心GPU的使用寿命可能仅为1到3年，具体则取决于其利用率。由于GPU几乎承担了AI训练和推理的所有负载，所以其性能下降的速度比其他任何组件更快。\u003c/p\u003e\n\u003cp\u003e云巨头们运营的数据中心中，GPU在AI工作负载中的利用率在60%到70%之间。据Tech Fund援引Alphabet一位首席GenAI架构师的观点称，在这种程度的利用率下，GPU的寿命通常只有一到两年，最多只有三年。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Google-Engineer-GenAI-GPU.webp\" alt=\"Google GenAI\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e这位架构师将这一言论发表在美国社交媒体X上，引发一系列讨论。尽管GPU仅1-3年的寿命看似有些夸张，但却有其合理性，因为用于AI和HPC应用的数据中心GPU的TDP达到甚至超过了700W，这对于硅芯片是实实在在的压力。\u003c/p\u003e\n\u003cp\u003e并且，这位GenAI架构师还表示，延长GPU使用寿命的方法之一就是降低其利用率，这能让GPU性能下降的速度变慢，但投资回报率的周期也会拉长，并不能满足业务对快速敏捷的要求，因此云巨头们通常选择了让GPU保持更高的利用率。\u003c/p\u003e\n\u003cp\u003e无独有偶，此前Mete也发布了一项研究(《AI训练54天，每3小时就故障一次，GPU故障率是CPU的120倍！》)，详细描述了其在16384个Nvidia H100 80GB GPU组成的AI集群上训练Llama 3 405B模型的故障率情况。据数据显示，该AI集群训练模型时的利用率约为38%（基于BF16精度训练），在419次突发故障导致的训练停顿中，148次（30.1%）是由于各种GPU故障（包括NVLink故障）导致的，72次（17.2%）是由HBM3高带宽内存故障引发的。HBM3通常也是GPU上的必备核心组件之一，如果两者相加的话，那么在利用率为30%左右时，GPU的故障率约为47.3%。\u003c/p\u003e\n\u003cp\u003e如果以Meta的数据来看，H100的质量似乎还不错，其年化故障率大约在9%左右，三年内的年化故障率为27%，尽管GPU的故障率会随着使用时间的延长而不断增加。\n而另外需要注意的是，Meta训练集群中的利用率为30%，如果按照Alphabet公司GenAI架构师的观点，GPU以60%-70%利用率（2倍于Meta）运行，那么GPU的故障率也会成倍增加。\u003c/p\u003e","title":"数据中心GPU的寿命最多只有3年","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/meta/","section":"Tags","summary":"","title":"Meta","type":"tags"},{"content":"作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。\n我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。\n这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。\n引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。\nMeta的大规模AI集群 # Meta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。\n虽然我们在构建AI基础设施方面有着悠久的历史，但我们在2022年首次分享了我们的AI研究超级集群（ AI Research SuperCluster，简称RSC）的细节，该集群拥有16,000个NVIDIA A100 GPU。RSC通过帮助我们建立第一代先进的AI模型，加速了开放AI研究。它在Llama和Llama 2的开发中发挥了重要作用，并将继续发挥重要作用，以及用于计算机视觉、自然语言处理、语音识别、图像生成甚至编码等应用的先进AI模型。\n揭开面纱 # 我们新的AI集群建立在RSC的成功和经验教训之上。我们专注于构建端到端的人工智能系统，主要强调研究人员和开发人员的经验和生产力。这些集群中的高性能网络结构的效率，一些关键的存储决策，结合每个集群中的24,576个NVIDIA Tensor Core H100 GPU，允许两个集群版本支持比RSC支持更大更复杂的模型，并为GenAI产品开发和AI研究的进步铺平道路。\n网络 # 在Meta，我们每天处理数以万亿计的AI模型。大规模交付这些服务需要高度先进和灵活的基础设施。定制设计我们自己的硬件、软件和网络结构，使我们能够优化AI研究人员的端到端体验，同时确保我们的数据中心高效运行。\n考虑到这一点，我们基于带有Wedge400和Minipack2 OCP机架交换机的Arista 7800构建了一个基于融合以太网（RoCE）网络结构解决方案的远程直接内存访问（RDMA）集群。另一个集群采用NVIDIA Quantum2 InfiniBand结构。这两种解决方案都将400 Gbps的端点互连起来。有了这两个，我们能够评估这些不同类型的互连在大规模训练中的适用性和可扩展性，为我们提供更多的见解，这将有助于我们在未来如何设计和构建规模更大的集群。通过仔细设计网络、软件和模型架构，我们已经成功地将RoCE和InfiniBand集群用于大型GenAI工作负载（包括在RoCE集群上正在进行的Llama 3培训），没有任何网络瓶颈。\n计算 # 这两个集群都是使用Grand Teton构建的，这是我们内部设计的开放GPU硬件平台，我们已经为开放计算项目（OCP）做出了贡献。Grand Teton基于多代AI系统，将电源、控制、计算和结构接口集成到单个机箱中，以获得更好的整体性能、信号完整性和热性能。它以简化的设计提供了快速的可扩展性和灵活性，使其能够快速部署到数据中心中，并且易于维护和扩展。结合其他内部创新，如我们的 Open Rack电源和Rack架构，Grand Teton允许我们以一种专门为Meta当前和未来应用程序构建的方式构建新的集群。\n从2015年的Big Sur平台开始，我们已经公开设计了我们的GPU硬件平台。\n存储 # 存储在AI训练中扮演着重要的角色，但却是最少被提及的方面之一。随着时间的推移，GenAI训练工作变得越来越多，需要大量的图像、视频和文本数据，因此对数据存储的需求迅速增长。然而，将所有数据存储放入高性能且节能的需求并没有消失，这使得问题变得更加有趣。\n我们的存储部署通过本地的Linux Filesystem in Userspace (FUSE) API解决了AI集群的数据和检查点需求，该API由Meta的“构造”分布式存储解决方案版本支持，该解决方案针对Flash进行了优化。该解决方案使数千个GPU能够以同步方式保存和加载检查点（对任何存储解决方案来说都是一个挑战），同时还提供数据加载所需的灵活且高吞吐量的exabyte级存储。\n我们还与Hammerspace合作，共同开发并行网络文件系统（NFS）部署，以满足该AI集群的开发人员经验要求。Hammerspace的优点之一是，工程师可以使用数千个GPU对作业进行交互式调试，因为环境中的所有节点都可以立即访问代码更改。当组合在一起时，我们的构造分布式存储解决方案和Hammerspace的组合可以在不影响规模的情况下实现快速迭代速度。\nGenAI集群中的存储部署，包括构造和hammerspace支持，都基于YV3 Sierra Point服务器平台，并升级了最新的高容量E1.S SSD。除了更高的SSD容量之外，还定制了每个机架的服务器，以实现每个服务器的吞吐量、机架数量和功耗之间的适当平衡。利用OCP服务器作为乐高积木，我们的存储层能够灵活地扩展到该集群以及未来更大的AI集群需求，同时对日常基础设施维护操作具有容错能力。\n性能 # 我们在构建大规模AI集群时的原则之一是最大化性能和易用性，而不牺牲其中一个。这是创建一流AI模型的重要原则。\n当我们不断挑战AI系统的极限时，我们测试自己扩展设计能力的最佳方式就是简单地构建一个系统，对其进行优化，并进行实际测试（虽然模拟器可以提供帮助，但它们也只能做到这一点）。在这个设计过程中，我们比较了小型集群和大型集群的性能，以了解瓶颈在哪里。下面图表显示了AllGather的总体性能（按0-100的标准带宽表示）。\n与优化后的小集群性能相比，我们在大型集群上的开箱性能最初很差，而且不一致。为了解决这个问题，我们对内部作业调度器在网络拓扑感知的情况下调度作业的方式进行了一些更改——这带来了延迟方面的好处，并最大限度地减少了流向网络上层的流量。我们还结合NVIDIA集体通信库（NCCL）的变化优化了网络路由策略，以实现最佳的网络利用率。这有助于推动大型集群实现与小型集群一样的出色性能。\n除了针对内部基础设施的软件变更之外，我们还与编写训练框架和模型的团队密切合作，以适应不断发展的基础设施。例如，NVIDIA H100 GPU开启了利用8位浮点（FP8）等新数据类型进行训练的可能性。充分利用更大的集群需要在额外的并行化技术和新的存储解决方案上进行投资，从而提供在数千个队列中高度优化检查点以在数百毫秒内运行的机会。\n我们也认识到可调试性是大规模训练中的主要挑战之一。在大规模的情况下，识别一个阻碍整个训练工作的GPU变得非常困难。我们正在构建诸如设计调试或分布式集体记录器之类的工具，以公开分布式训练的细节，用更快更容易的方式识别出问题。\n最后，我们将继续发展PyTorch，这是为AI工作负载提供动力的基础AI框架，使其为数万甚至数百，数千个GPU训练做好准备。我们已经确定了进程组初始化的多个瓶颈，并将启动时间从有时几小时减少到几分钟。\n致力于开放AI创新 # Meta将继续致力于AI软硬件的开放式创新。我们相信，开源硬件和软件将永远是帮助行业大规模解决问题的宝贵工具。\n今天，我们作为OCP的创始成员继续支持开放硬件创新，在那里我们为OCP社区提供Grand Teton和开放机架等设计。我们还将继续成为PyTorch的最大和主要贡献者，PyTorch是推动行业发展的AI软件框架。\n我们还将继续致力于AI研究领域的开放式创新。我们已经启动了开放创新AI研究社区，这是一个学术研究人员的合作项目，旨在加深我们对如何负责任地开发和分享AI技术的理解——特别是LLM。\n对Meta来说，开放的AI方法并不新鲜。我们还启动了AI联盟，这是一个由AI行业的领先组织组成的团体，致力于在一个开放的社区内加速AI领域的创新。我们的AI工作建立在开放科学和交叉合作的理念之上。一个开放的生态系统为AI的发展带来了透明度、审查和信任，并让每个人都能从中受益。\nMeta AI基础设施的未来 # 当我们展望未来时，我们认识到昨天或今天行之有效的方法可能不足以满足明天的需要。这就是为什么我们不断评估和改进基础设施的各个方面，从物理和虚拟层到软件层等等。我们的目标是创建灵活可靠的系统，以支持快速发展的新模型和研究。\n","date":"2024-10-26","externalUrl":null,"permalink":"/ai/building-metas-genai-infrastructure/","section":"Ais","summary":"\u003cp\u003e作为Meta对未来AI的重大投资，我们宣布了两个2.4万卡GPU集群。我们正在分享有关硬件、网络、存储、设计、性能和软件的详细信息，以帮助各种AI工作负载提取高吞吐量和可靠性。这种集群设计被用于Llama3的训练。\u003c/p\u003e\n\u003cp\u003e我们坚定地致力于开放计算和开源。在Grand Teton、OpenRack和PyTorch的基础上构建了这些集群，并继续推动整个行业的开放式创新。\u003c/p\u003e\n\u003cp\u003e这一宣布是我们基础设施路线图的一步。到2024年底，我们的目标是继续扩大基础设施建设，将包括作为产品组合部分的350,000个NVIDIA H100 GPU，具有相当于近600,000个H100的计算能力。\u003c/p\u003e\n\u003cp\u003e引领AI发展意味着引领硬件基础设施的投资。硬件基础设施在AI未来扮演着重要的角色。今天，我们在Meta上分享两个版本的24,576 GPU数据中心规模集群的细节。这些集群支持我们当前和下一代AI模型，包括Llama 3， Llama 2的继承者，公开发布的LLM，以及GenAI和其他领域的AI研究和开发。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eMeta的大规模AI集群 \n    \u003cdiv id=\"meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#meta%E7%9A%84%E5%A4%A7%E8%A7%84%E6%A8%A1ai%E9%9B%86%E7%BE%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eMeta的长期愿景是建立开放和负责任的AGI（general intelligence），以便每个人都可以广泛使用，并从中受益。在我们努力实现AGI的同时，我们也在努力扩展集群，以实现这一目标。我们在AGI方面取得的进展创造了新产品，为我们的应用程序家族创造了新的AI功能，以及新的以AI为中心的计算设备。\u003c/p\u003e","title":"Meta的AI大模型基础设施","type":"ai"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/epyc/","section":"Tags","summary":"","title":"Epyc","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/granite-rapids/","section":"Tags","summary":"","title":"Granite Rapids","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/turin/","section":"Tags","summary":"","title":"Turin","type":"tags"},{"content":"2017 年，AMD 推出代号为 Naples 的第一代 Epyc 处理器后不久，英特尔就打趣说，其竞争对手为了保持相关性，已经沦落到只能将一堆台式机芯片粘在一起的地步。\n不幸的是，对于英特尔来说，这句评论已经过时了，短短几年后，这家 x86 巨头就开始自己寻找粘合剂了。\n英特尔的Xeon 6处理器于今年开始分阶段推出，这是其第三代多芯片 Xeon 处理器，也是其首款采用与AMD自己的异构芯片架构类似的数据中心芯片。\n虽然英特尔最终认识到了AMD小芯片战略的明智之处，但其方法却截然不同。\n突破标线限制 # 快速回顾一下为什么这么多 CPU 设计正在远离单片架构，这主要归结为两个因素：掩模版限制和产量。\n一般而言，在工艺技术没有重大改进的情况下，更多内核必然意味着更多硅片。然而，芯片实际尺寸存在实际限制 - 我们称之为光罩极限 - 大约为 800 平方毫米。一旦达到极限，继续扩展计算的唯一方法就是使用更多芯片。\n我们现在看到许多产品（不仅仅是 CPU）都采用了这种技术，它们将两个大型芯片塞进一个封装中。Gaudi 3、Nvidia的Blackwell和英特尔的Emerald Rapids Xeons 只是其中几个例子。\n多芯片的问题在于，它们之间的桥梁往往是带宽方面的瓶颈，并且有可能引入额外的延迟。这通常不像将工作负载分散到多个插槽那么糟糕，但这也是一些芯片设计师倾向于使用较少数量的较大芯片来扩展计算的原因之一。\n然而，制造更大的芯片确实成本高昂，因为芯片越大，缺陷率就越高。这使得使用大量较小的芯片成为一个有吸引力的提议，并解释了为什么AMD的设计使用了如此多的芯片——最新的Epycs芯片多达 17 个。\n了解了这些基础知识后，让我们深入探讨一下英特尔和AMD最新Xeons和Epyc处理器的不同设计理念。\nAMD的做法 # 我们将从AMD的第五代Epyc Turin处理器开始。具体来说，我们正在研究该芯片的 128 核 Zen 5 版本，它具有 16 个4nm核心复合芯片 (CCD)，这些芯片围绕着基于台积电 6nm 工艺技术制造的单个 I/O 芯片 (IOD)。\nAMD 最新的Epycs配备多达 16 个计算芯片 如果这听起来很熟悉，那是因为 AMD 在其第二代 Epyc 处理器上使用了相同的基本公式。作为参考，第一代Epyc缺乏独特的 I/O 芯片。\n正如我们前面提到的，使用大量较小的计算芯片意味着 AMD 可以获得更高的产量，但这也意味着他们可以在 Ryzen 和 Epyc 处理器之间共享硅片。\n此外，使用八核或十六核 CCD（每个 CCD 具有 32 MB 的 L3 缓存），AMD 在按缓存和内存比例扩展核心数量时可以获得额外的灵活性。\n例如，如果您想要一个具有 16 个内核的 Epyc（由于许可限制，这是 HPC 工作负载的常见 SKU），最明显的实现方法是使用两个八核 CCD，两个 CCD 之间有 64 MB 的 L3 缓存。但是，您也可以使用 16 个 CCD，每个 CCD 只有一个内核处于活动状态，但板载缓存为 512 MB。这听起来可能很疯狂，但这两种芯片确实存在。\nAMD 的第五代Epycs遵循熟悉的模式，即16个计算芯片围绕一个中央 I/O 芯片 另一方面，I/O 芯片负责除计算之外的几乎所有功能，包括内存、安全性、PCIe、CXL 和其他 I/O（如 SATA），并且还充当芯片 CCD 与其他插槽之间通信的骨干。\n将内存控制器放置在I/O芯片上确实有一些优点和缺点。从好的方面来说，这意味着内存带宽在很大程度上独立于核心数量而扩展。缺点是某些工作负载的内存和缓存访问延迟可能会更高。我们强调“可能”，因为这种事情高度依赖于工作负载。\n英特尔Xeon的chiplet 之旅 # 谈到英特尔，这家芯片制造商对多芯片硅片的处理方式与 AMD 有很大不同。虽然现代 Xeon 处理器采用具有不同计算和 I/O 芯片的异构架构，但情况并非总是如此。\n英特尔首款多芯片 Xeon 处理器，代号为Sapphire Rapids，采用一块单片、中等核心数芯片或四块极端核心数芯片，每块芯片都有自己的内存控制器和板载 I/O。Emerald Rapids采用了类似的模式，但为芯片核心数较高的 SKU 选择了两块更大的芯片。\n正如您在 Sapphire 和 Emerald Rapids 之间看到的，英特尔从四个中型芯片转换为一对近乎网状的有限芯片 所有这一切都随着 Xeon 6 的推出而发生了改变，英特尔将I /O、UPI 链接和加速器移至基于英特尔 7 工艺节点制造的一对芯片上，这对芯片位于基于英特尔 3 制造的中心的一到三个计算芯片之间。\n出于稍后会讲到的原因，我们将主要关注英特尔更主流的 Granite Rapids Xeon 6 处理器，而不是其多核 Sierra Forest 部件。\n看看英特尔的计算芯片，我们就能发现它与 AMD 的第一个重大区别。每个计算模块至少有 43 个板载核心，可根据 SKU 开启或关闭融合。这意味着英特尔实现 128 个核心所需的芯片数量比 AMD 少得多，但由于面积较大，因此成品率可能会更低。\n根据 SKU，Granite Rapids 使用夹在一对 I/O 芯片之间的一到三个计算芯片 除了增加内核之外，英特尔还选择将这些芯片的内存控制器放在计算芯片上，每个芯片支持 4 个通道。理论上，这应该可以降低访问延迟，但这也意味着，如果你想要所有 12 个内存通道，就需要填充所有 3 个芯片。\n对于我们上个月看过的 6900P 系列部件，你不必担心这一点，因为每个 SKU 都配有三个计算芯片。然而，这意味着 72 核版本只利用了封装中一小部分硅片。同样，我们之前讨论过的 16 核 HPC 中心 Epyc 也是如此。\n另一方面，英特尔将于明年初推出的 6700P 系列部件将配备一个或两个计算芯片，具体取决于所需的内存带宽和核心数量，这意味着内存通道在高端将限制为 8 个，在板载单个计算芯片的配置中可能只有 4 个。我们目前还不清楚 HCC 和 LCC 芯片上的内存配置，因此英特尔有可能增强了这些部件上的内存控制器。\n与 AMD 的 Epyc 一样，英特尔的 Xeon 现在采用带有计算和 I/O 芯片的异构芯片架构 英特尔的 I/O 芯片也相当薄，并包含 PCIe、CXL 和 UPI 链路组合，用于与存储、外围设备和其他插槽进行通信。除此之外，我们还发现了许多用于直接流 (DSA)、内存分析 (IAA)、加密/解密 (QAT) 和负载平衡的加速器。\n我们得知，在 I/O 芯片上放置加速器的部分原因是为了让它们更靠近进出芯片的数据。\n我们接下来要去哪里？ # 从表面上看，英特尔的下一代多核处理器代号为 Clearwater Forest，预计将于明年上半年推出，其型号与 Granite Rapids 类似，具有两个 I/O 模块和三个计算模块。\n它可能看起来像缩小版的 Granite Rapids，但显然那只是隐藏着更多芯片的结构硅 然而，外表是会骗人的。据我们了解，这三个计算芯片实际上只是隐藏着许多较小计算芯片的结构硅片，而这些较小的计算芯片本身位于有源硅片中介层之上。\n根据英特尔今年早些时候展示的效果图，Clearwater Forest 每个封装最多可使用 12 个计算芯片。使用硅中介层绝不是新鲜事，它提供了许多好处，包括芯片间带宽更高、延迟比有机基板中通常看到的更低。这与英特尔核心数最高的 Sierra Forest 部件上的一对 144 核计算芯片大不相同。\n如果英特尔今年早些时候发布的渲染图有任何可参考之处，那么 Clearwater Forest 隐藏的芯片数量要比 Granite Rapids 多得多 当然，讨论 Clearwater 森林将使用的技术的效果图并不意味着明年到达时我们将会得到完全相同的技术。\n也许更大的问题是 AMD 下一步将把其小芯片架构带向何方。看看 AMD 的 128 核 Turin 处理器，封装上没有太多空间容纳更多硅片，但 House of Zen 仍有一些选择。\n首先，AMD 可以选择更大的封装，为额外的芯片腾出空间。或者，该芯片制造商也可以将更多内核封装到更小的芯片上。然而，我们怀疑 AMD 的第六代 Epycs 最终可能看起来更像其 Instinct MI300 系列加速器。\nMI300A 将 24 个 Zen 4 核心、6 个 CDNA 3 GPU 芯片和 128GB HBM3 内存整合到一个封装中，旨在满足 HPC 工作负载的需求 您可能还记得，与 MI300X GPU 一起推出的还有一款 APU，它将芯片的两个 CDNA3 模块换成了三个 CCD，中间有 24 个 Zen 4 核心。这些计算模块堆叠在四个 I/O 芯片上，并连接到一组八个 HBM3 模块。\n现在，这只是猜测，但不难想象 AMD 会做类似的事情，将所有内存和 GPU 芯片换成额外的 CCD。这样的设计可能也会受益于更高的带宽和更低的芯片间通信延迟。\n这是否真的会实现，只有时间才能证明。我们预计AMD的第6 代Epycs 将于 2026 年底上市。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/different-approach-for-intel-and-amd-to-gluing-together-cpus/","section":"Hardwares","summary":"\u003cp\u003e2017 年，AMD 推出代号为 Naples 的第一代 Epyc 处理器后不久，英特尔就打趣说，其竞争对手为了保持相关性，已经沦落到只能将一堆台式机芯片粘在一起的地步。\u003c/p\u003e\n\u003cp\u003e不幸的是，对于英特尔来说，这句评论已经过时了，短短几年后，这家 x86 巨头就开始自己寻找粘合剂了。\u003c/p\u003e\n\u003cp\u003e英特尔的Xeon 6处理器于今年开始分阶段推出，这是其第三代多芯片 Xeon 处理器，也是其首款采用与AMD自己的异构芯片架构类似的数据中心芯片。\u003c/p\u003e\n\u003cp\u003e虽然英特尔最终认识到了AMD小芯片战略的明智之处，但其方法却截然不同。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e突破标线限制 \n    \u003cdiv id=\"%E7%AA%81%E7%A0%B4%E6%A0%87%E7%BA%BF%E9%99%90%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AA%81%E7%A0%B4%E6%A0%87%E7%BA%BF%E9%99%90%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e快速回顾一下为什么这么多 CPU 设计正在远离单片架构，这主要归结为两个因素：掩模版限制和产量。\u003c/p\u003e","title":"英特尔和AMD封装CPU的不同做法","type":"hardware"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/5600t/","section":"Tags","summary":"","title":"5600T","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/5600xt/","section":"Tags","summary":"","title":"5600XT","type":"tags"},{"content":"","date":"2024-10-26","externalUrl":null,"permalink":"/tags/am4/","section":"Tags","summary":"","title":"AM4","type":"tags"},{"content":"AMD在发布全新Ryzen 9000系列处理器几周后，再次推出了两款价格实惠的AM4 CPU——Ryzen 5 5600T和Ryzen 5 5600XT。这两款芯片现已在美亚上架，Ryzen 5 5600T售价为186.58美元，Ryzen 5 5600XT截至本文撰写时售价为192.08美元。这个定价使它们成为AMD最实惠的处理器之一。\n新发布的Ryzen 5 5600T和5600XT依然采用6核12线程设计，与将要被取代的Ryzen 5 5600和5600X类似。不过Ryzen 5 5600T的基础频率提高到了3.7 GHz，比Ryzen 5 5600高出200 MHz；Ryzen 5 5600XT的基础频率达到3.8 GHz，比Ryzen 5 5600X高出100 MHz。除此之外，它们的TDP仍为65瓦，L3缓存也保持在32MB。\n以下是部分Ryzen处理器的规格对比：\n虽然这些处理器不是定位顶级游戏性能的X3D芯片，但对于想要组装台式机且需要控制预算的用户来说，它们还是不错的选择。如果您正在搭建新电脑，此次发布为您提供了三代Ryzen处理器可供选择。\n此次发布使AM4成为市场上使用时间最长的插槽之一，自2016年推出以来，已历经八年多。尽管AM5已经问世，AMD仍在继续为AM4平台推出新处理器。\n","date":"2024-10-26","externalUrl":null,"permalink":"/hardware/amd-launch-2-am4-cpu-5600t-and-5600xt/","section":"Hardwares","summary":"\u003cp\u003eAMD在发布全新Ryzen 9000系列处理器几周后，再次推出了两款价格实惠的AM4 CPU——Ryzen 5 5600T和Ryzen 5 5600XT。这两款芯片现已在美亚上架，Ryzen 5 5600T售价为186.58美元，Ryzen 5 5600XT截至本文撰写时售价为192.08美元。这个定价使它们成为AMD最实惠的处理器之一。\u003c/p\u003e\n\u003cp\u003e新发布的Ryzen 5 5600T和5600XT依然采用6核12线程设计，与将要被取代的Ryzen 5 5600和5600X类似。不过Ryzen 5 5600T的基础频率提高到了3.7 GHz，比Ryzen 5 5600高出200 MHz；Ryzen 5 5600XT的基础频率达到3.8 GHz，比Ryzen 5 5600X高出100 MHz。除此之外，它们的TDP仍为65瓦，L3缓存也保持在32MB。\u003c/p\u003e","title":"AMD推出两款AM4 CPU：5600T和5600XT","type":"hardware"},{"content":"HBM是传统内存类型的重大飞跃。更高的内存带宽和容量、更低的功耗和快速的传输速率等关键特性使HBM区别于它的前辈。了解这些特征对于了解这项尖端技术至关重要。\n通过这个终极指南，读者可以了解HBM的发展，它在各个行业中的重要应用，与传统DRAM相比提供的优势，以及计算世界中内存配置的未来。欢迎来到HBM知识之门。\nHBM市场规模在2022年价值28亿美元。HBM市场行业预计将从2023年的35.3亿美元增长到2032年的225.73亿美元，在预测期内（2024 - 2032年）的复合年增长率（CAGR）为26.10%。\nHBM主要特性 # HBM已经彻底改变了高性能计算系统管理数据流的方式。与传统内存解决方案相比，其最显著的特性之一是带宽显著增加。HBM通过使用TSV和微凸点连接的堆叠DRAM芯片来实现这一目标。这种创新的设计允许更短的数据路径，从而提高数据速度和能效。\n将多个存储芯片集成到一个封装中，不仅可以提高电源效率，还可以减少内存在PCB上的面积。通过利用宽接口架构，HBM有助于提高传输速率和降低功耗。与努力平衡性能和功率预算的传统内存系统不同，HBM提供了针对高性能计算、图形卡和机器学习应用程序的功率效率和性能需求量身定制的内存解决方案。\n内存带宽 # HBM技术的核心在于其一流的存储带宽。内存带宽指的是在内存和处理器之间快速移动大量数据的能力。HBM利用更宽的内存总线，通过独立通道同时访问数据，大大提高了每个周期传输的数据量。这种特性有利于需要高速数据处理的应用程序，如高级图形渲染或复杂的科学计算。\n功耗 # HBM的高效架构使其在功耗方面脱颖而出。传统的DRAM需要更高的功率来长距离驱动信号，而HBM的垂直堆叠IC和更短的连接路径显著降低了传输每比特所需的能量。这意味着更高的功率效率，这对于控制功率预算至关重要，特别是在高性能计算环境和半导体工程中的先进节点中经常出现的密集封装中。\n内存容量 # HBM专注于垂直堆叠和硅中间体的使用，与传统的平面内存解决方案相比，HBM可以在单个封装中实现更大的内存容量。通过将多个DRAM芯片堆叠在一起，HBM不仅节省了空间，而且还提供了更多的空间可以根据需要扩展内存容量，同时不会受到PCB设计人员所面临的典型面积限制。HBM的这一特性使它成为在有限的功率和空间范围内需要大内存容量系统的一个有吸引力的存储设备。\n传输速率 # HBM拥有惊人的传输速率，这是依赖数据快速传输系统的关键考虑因素。HBM的设计允许使用宽接口总线，这样可以使传输速率大大超过传统内存。利用HBM的传输速率，系统可以从更快的加载时间、更流畅的数据处理和整体性能提升中受益，使其适用于涉及高数据吞吐量的任务，例如视频处理和神经网络训练。\nHBM技术的发展 # 内存技术的发展一直在不懈地追求多个方面的平衡：容量、速度、功率效率和面积。在这段旅程的每个关键时刻，创新都解决了前几代的局限性。这种演变推动了HBM的出现，HBM是一个技术飞跃，重塑了内存解决方案的性能格局。\n传统内存解决方案 # 在传统内存解决领域，系统通常依赖于DDR SDRAM，其后续迭代(DDR2、DDR3、DDR4)在性能和功率效率方面提供了渐进式的进步。然而，这些传统存储器采用并行总线接口，随着带宽和容量需求的增加，面临着信号完整性和布线拥挤等挑战。此外，更宽的内存总线需要更多的物理空间和功耗，这反过来又影响了系统设计和热管理。\nHBM介绍 # HBM的引入代表了一个重大的范式转变。HBM通过实现堆叠存储器架构重新定义了数据传输，多个DRAM芯片堆叠在一起，通过TSV互连，实现超高速信号传输。这种3D封装技术显著拓宽了数据接口，而不增加面积，允许与处理单元直接相邻的高速通信。通过这一创新，HBM消除了困扰传统平面内存设计的限制，提供了更大的带宽并降低了功耗。\nHBM进展 # 随着HBM技术的进步，每次迭代都带来了令人敬畏的进步。例如，HBM2将每个引脚的带宽提高了一倍，并提高了密度。此后，HBM2E进一步扩展了容量和速度。这些进步使得HBM对于最新的图形密集型任务和AI及机器学习等新兴领域至关重要，这些领域需要快速和强大的存储能力。HBM无缝集成到硅中间体中，与半导体工程中的先进节点一起提高计算能力，同时坚守严格的功率预算。\n下表总结了HBM的进化里程碑：\n随着不断的进步，HBM继续推动技术的发展，为下一代计算应用提供前所未有的性能。\nHBM应用 # HBM已经成为一种变革性的存储器解决方案，在速度、效率和容量等关键节点交叉的一系列领域中找到了应用。它能够以令人印象深刻的速度处理大量数据，同时又节能，这使它成为各种计算范例的理想选择。我们将探讨它在高性能计算、图形、人工智能和数据中心应用程序中的重要作用，说明它的独特属性如何满足快速数据处理和传输的不断增长的需求。\n高性能计算 # 高性能计算（HPC）涵盖了广泛的系统，这些系统提供了强大的计算能力，可以完成复杂的任务，如科学模拟、气候建模和先进材料研究。HPC系统需要能够与其强大的处理能力保持同步的内存，而HBM巧妙地满足了这一需求。\n性能驱动：HBM的堆叠配置提供并行工作的多个通道，最大限度地提高数据吞吐量。 节能：尽管HBM具有高速数据传输速率，但HBM仍保持较低的功耗，这在高性能计算环境中至关重要，因为高性能计算环境中功耗是一个关键的问题。 密度：通过提高每个芯片的密度，HBM允许HPC系统在不影响物理空间的情况下管理更广泛的数据集。 图形应用程序 # HBM和图形应用程序之间的相关性特别强，因为对内存带宽的需求随着图形分辨率和复杂性的提高而增强。\n高分辨率和帧率：具有HBM的GPU可以以更高的帧率渲染高分辨率图像和视频，这是现代游戏、虚拟现实和专业可视化所必需的。 平滑的性能：高带宽可以实现稳定的数据流，这样即使在高图形负载下也可以实现平滑的性能。 紧凑的外形因素：HBM的小占地面积允许紧凑和高效的图形卡设计，这是时尚消费电子设备的一个重要特点。 AI # AI和ML模型通常需要较大的内存带宽才能有效地训练大型数据集。HBM提供了支持AI应用程序的密集工作负载所需的功能。\n快速数据访问：快速访问内存对于AI和ML算法的迭代过程至关重要，而HBM以其优越的传输速率保证了这一点。 并行处理支持：HBM促进了复杂AI计算所需的并行处理能力。 高效扩展：随着AI模型在规模和复杂性上的增长，HBM的可扩展性确保内存不会成为开发的瓶颈。 数据中心的应用程序 # 数据中心是数字经济的支柱，支持云计算、内容交付和企业服务。HBM可以在优化数据中心操作方面发挥不可或缺的作用。\n用于虚拟化的带宽：当运行多个虚拟机或容器时，数据中心可以从增加的带宽中受益，因为它允许并发处理更多数据而不会延迟。 节能：HBM的能效为数据中心节省了大量成本，而数据中心的功耗是一项重要的运营支出。 低延迟：HBM的低延迟特性缩短了响应时间，有助于更快地提供服务并改善用户体验。 总之，HBM的广泛应用强调了其作为推动未来复杂计算任务的核心技术的重要性。随着每一代HBM的出现，潜在的应用程序不断扩展，有望满足对更快、更高效和更密集的内存解决方案的不断需求。\nHBM的优点 # HBM已经成为存储器技术的重要创新，主要是因为它比传统的DRAM解决方案具有明显的优势。通过解决传统内存面临的一些关键限制，例如数据传输速率瓶颈和能源效率低下，HBM已成为要求高速数据处理和最小延迟的应用程序的基石。让我们深入研究使HBM与众不同的具体优势，重点介绍增加的内存带宽、改进的电源效率、高内存容量和更快的传输速率。\n增加内存带宽 # 高带宽内存的定义特征是其扩展的内存带宽能力。与传统存储设备在繁重的工作负载下挣扎不同，HBM采用了通过堆叠多个DRAM芯片构建的宽接口，并使用硅通孔进行互连。这种方法可以使大量的独立通道同时运行，从而大大增加了可用的总内存带宽。实际上，这意味着对大量数据的快速处理，这是许多当代应用程序（从高性能计算到最新显卡）的关键因素。\n高内存容量 # 除了带宽和功率效率，HBM还拥有紧凑的物理外形因素内的高内存容量。DRAM芯片与HBM的垂直堆叠导致内存解决方案提供更高的密度，从而在单个封装中提供更大的容量。这种配置适用于空间有限但需要大量内存的系统，例如工作站笔记本电脑和小型设备中的紧凑高性能GPU。\n更快的传输速率 # 最后，HBM提供了极快的传输速率——这是其架构设计的直接结果。由于多个存储库在配备高速TSV的宽接口上协同工作，数据传输的速度比传统存储解决方案要快得多。这种改进的传输性能确保了数据密集型操作，特别是在像机器学习这样的领域，速度是一个成败因素。\n总之，高带宽存储器代表了一种突破性的存储器类型，它解决了各种类型存储器面临的关键挑战。它的架构是精心定制的，以提供符合当代高级计算需求的高性能内存解决方案。由于这些固有的优势，HBM作为新兴技术和高端计算平台寻求向未来飞跃的重要组成部分脱颖而出。\nHBM配置 # HBM以其高速、大容量和高能效而闻名，能够满足现代高性能计算环境的需求。HBM的独特配置使其能够提供数倍于传统存储器的带宽。HBM背后的独创性在于其创新的布局，它有各种配置，以最大限度地提高性能和最大限度地减少空间使用。这些HBM配置包括3D堆叠存储器设计和先进的5D多模封装系统。\n5D多模封装系统 # 5D多模封装系统是封装技术的顶峰，旨在实现无与伦比的性能。作为3D堆叠的进化，这些系统增加了额外的集成维度，将多层3D堆叠芯片组合在一起，形成一个非常强大和高效的存储解决方案。“5D”指的是三个空间维度加上两个额外的集成维度，包括互连和封装级组装。这种方法精心协调每个芯片的操作，实现更快的传输速率和更低的功耗，同时保持在硬件板上的小面积。\n3D堆叠DRAM # 当谈到HBM时，3D堆叠DRAM是一项关键技术。它通过TSV连接将多层DRAM芯片堆叠在一起。这些TSV穿过硅片，使堆叠的不同层之间实现垂直电连接。这种3D堆叠不仅节省了空间，而且有助于闪电般的数据传输速率和增强的带宽，实现高性能计算场景中的实时数据处理。\n3D堆叠内存架构 # 3D堆叠存储器架构代表了存储器设计的飞跃，将多层IC组合到单个封装中。通过堆叠内存芯片，HBM有效地减少了信号距离，并且与2D配置相比，在延迟和能效方面有了巨大的改进。这些架构采用微凸点和TSV来实现密集的芯片间连接，从而简化了存储单元之间的通信路径。这种紧凑的安排显著提高了每个芯片的可用带宽，使HBM成为带宽密集型应用程序的最佳内存解决方案。\n高带宽内存与传统DRAM解决方案 # 目前，HBM已经成为存储技术领域的领跑者，特别是与传统的DRAM解决方案相比。这种形式的存储技术在设计时考虑到了当代高性能计算、图形渲染和先进机器学习算法的强烈要求，这些要求不仅需要更高的速度，还需要更大的带宽和能源效率。HBM通过创新的设计配置（如3D堆叠和先进的封装技术）实现了这些目标，将其与传统DRAM的传统平面布局区分开来。\n内存带宽比较 # 与传统DRAM相比，HBM最突出的优点之一是它提供了大量的带宽。HBM具有宽接口存储器总线和并行工作的多个独立通道，极大地增强了数据传输能力。为了说明这一点，典型的HBM配置可以提供大约256 GB/s或更高的带宽，这是传统DRAM提供的带宽的几倍，传统DRAM可能在32 GB/s左右徘徊。这种明显的差异允许更快的数据处理，在带宽饥渴的场景中被证明是必不可少的。\n功耗对比 # 与传统DRAM相比，功耗效率是HBM的另一个亮点。HBM的分层设计意味着数据传输距离更短，内存工作电压更低，从而降低了总体功耗。虽然传统DRAM的功耗可能是一个限制因素，特别是在功率敏感型应用中，但HBM的架构可以在更低的功耗预算下保持高性能。具体的节能效果可能会有所不同，但是与传统方法相比，HBM通常可以显著降低每千兆字节的功耗。\n内存容量比较 # 在内存容量方面，HBM通过其堆叠能力引入了一种范式转变，允许芯片的垂直集成，并在相同甚至更小的占地面积内实现更密集的内存配置。因此，HBM可以实现更高的密度，从而在单个堆栈内实现更高的内存容量，而无需增加内存设备的物理大小。\n传输速率比较 # 传输速率，或从内存中读取或写入数据的速度，对整个系统性能至关重要。HBM由于其3D堆叠架构和高速TSV的短数据路径提供了卓越的传输速率。传统DRAM的传输速率可能达到8到14 Gbps，而HBM的传输速率可以远远超过100 Gbps。这允许更有效地处理数据密集型任务，推动计算机图形学、科学计算和实时分析的进步。\n","date":"2024-10-24","externalUrl":null,"permalink":"/hardware/high-bandwidth-memory-hbm-ultimate-guide/","section":"Hardwares","summary":"\u003cp\u003eHBM是传统内存类型的重大飞跃。更高的内存带宽和容量、更低的功耗和快速的传输速率等关键特性使HBM区别于它的前辈。了解这些特征对于了解这项尖端技术至关重要。\u003c/p\u003e\n\u003cp\u003e通过这个终极指南，读者可以了解HBM的发展，它在各个行业中的重要应用，与传统DRAM相比提供的优势，以及计算世界中内存配置的未来。欢迎来到HBM知识之门。\u003c/p\u003e\n\u003cp\u003eHBM市场规模在2022年价值28亿美元。HBM市场行业预计将从2023年的35.3亿美元增长到2032年的225.73亿美元，在预测期内（2024 - 2032年）的复合年增长率（CAGR）为26.10%。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eHBM主要特性 \n    \u003cdiv id=\"hbm%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#hbm%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eHBM已经彻底改变了高性能计算系统管理数据流的方式。与传统内存解决方案相比，其最显著的特性之一是带宽显著增加。HBM通过使用TSV和微凸点连接的堆叠DRAM芯片来实现这一目标。这种创新的设计允许更短的数据路径，从而提高数据速度和能效。\u003c/p\u003e","title":"HBM终极指南","type":"hardware"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/computing-power/","section":"Tags","summary":"","title":"Computing Power","type":"tags"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/flops/","section":"Tags","summary":"","title":"FLOPS","type":"tags"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/tops/","section":"Tags","summary":"","title":"TOPS","type":"tags"},{"content":"算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：\n算力的计算方式 # FLOPS # FLOPS（Floating Point Operations Per Second）来衡量算力通常以每秒钟可以执行的浮点运算次数。常见的FLOPS的计算算力单位根据数量级还有不同的表达，具体如下：\nKFLOPS-kilo Floating Point Operations Per Second（千次浮点运算每秒） MFLOPS-Mega Floating Point Operations Per Second（百万次浮点运算每秒） GFLOPS-Giga Floating Point Operations Per Second（十亿次浮点运算每秒） TFLOPS-Tera Floating Point Operations Per Second（万亿次浮点运算每秒） PFLOPS-Peta Floating Point Operations Per Second（千万亿次浮点运算每秒） FLOPS的计算方式：计算机的算力取决于处理器的性能、核心数量、频率以及并行计算能力等因素。一般来说，可以通过以下公式来计算处理器的FLOPS数值：算力 = 处理器核心数量 x 每个核心的频率 x 每个时钟周期的指令数量 x 每个指令的执行\n例如，如果一台处理器有4个核心，每个核心的频率为3.5 GHz，每个时钟周期执行4条指令，每条指令的执行时间为0.5纳秒，则该处理器的算力为：算力 = 4核 x 3.5 GHz x 4 x (0.5 ns) = 56 GFLOPS\nTOPS # TOPS（Tera Operations Per Second）是指每秒进行的万亿次运算，是衡量人工智能（AI）处理器性能的重要指标，也是评估处理器在深度学习和神经网络推理任务中的计算能力的重要指标。\n计算TOPS的基本原理是根据处理器的时钟频率、每个时钟周期执行的指令数量以及每个指令的计算量来计算。一般来说，可以使用以下公式来计算处理器的TOPS：TOPS = 处理器时钟频率 x 每个时钟周期的指令数量 x 每个指令的计算量\n其中，处理器时钟频率表示处理器的工作频率，每个时钟周期的指令数量表示每个时钟周期处理器执行的指令数量，每个指令的计算量表示每个指令的浮点运算量。\n某些情况下我们也是通过TOPS/W来评价处理器算力的一个性能指标，表达的含义是在1W功耗的情况下处理器可以执行多少亿万次操作。\nMIPS # MIPS（Million Instructions Per Second）是指每秒钟能够执行的指令数，单位为百万条指令每秒（Million Instructions Per Second）。\n计算MIPS的方法如下：\n首先，确定在一个特定时间段内处理器执行的总指令数（例如1秒内）。 将总指令数除以1,000,000（即1百万），得到每秒钟能够执行的指令数，即MIPS值。 举例说明：\n假设一个处理器在1秒钟内执行了总共500,000条指令，那么它的MIPS值为：\nMIPS = 500,000 / 1,000,000 = 0.5 MIPS这表示该处理器每秒钟能够执行0.5百万条指令。通过计算MIPS值，可以评估处理器的指令执行速度和性能表现，但是对于特定的应用场景和任务可能不是最准确的性能指标。\nDMIPS # DMIPS（Dhrystone Million Instructions Per Second）是指每秒钟能够执行的Dhrystone基准测试指令数，单位为百万条指令每秒。Dhrystone是一种通用的CPU性能测试工具，DMIPS是基于Dhrystone测试结果计算得出的性能指标。DMIPS更适用于衡量通用处理器在特定测试条件下的性能，可以提供更具体的性能评估结果。\n计算DMIPS的方法如下：\n首先，进行Dhrystone基准测试，得到处理器在测试条件下执行的总指令数（例如1秒内）。 将总指令数除以1,000,000（即1百万），得到每秒钟能够执行的Dhrystone基准测试指令数，即DMIPS值。 举例说明：\n假设一个处理器在进行Dhrystone基准测试时，在1秒钟内执行了总共800,000条指令，那么它的DMIPS值为：\nDMIPS = 800,000 / 1,000,000 = 0.8 DM\n这表示该处理器在Dhrystone基准测试条件下，每秒钟能够执行0.8百万条指令。通过计算DMIPS值，可以评估处理器在特定测试条件下的性能现。\nHash/ # \u0026ldquo;hash/s\u0026quot;通常用来衡量计算机或网络设备的哈希计算速度，特别是在加密货币挖矿等领域常被使用。基本原理是通过计算机执行哈希函数并输出哈希值的速度来衡量设备的计算能力。\n哈希函数是一种将任意长度的输入数据（消息）转换为固定长度的输出数据（哈希值）的函数。在加密货币挖矿中，通常会使用哈希函数来寻找符合特定条件的哈希值，这需要大量的计算。\n计算\u0026quot;hash/s\u0026quot;的算力通常是通过以下步骤进行估算：\n选择哈希函数：确定要使用的哈希函数，如SHA-256（比特币挖矿中常用的哈希函数）。 执行哈希计算：在设备上执行哈希函数，将输入数据进行哈希运算，得到哈希值。 计算速度：记录设备在单位时间内执行哈希计算的次数，即\u0026quot;hash/s\u0026rdquo;。 例如，如果一个计算机在1秒内执行了100,000次SHA-256哈希计算，那么它的哈希计算速度就是100,000 hash/s。这个速度可以用来衡量设备的计算能力，特别是在加密货币挖矿等需要\n总结 # ","date":"2024-10-24","externalUrl":null,"permalink":"/ai/computer-computing-power-unit-introduction/","section":"Ais","summary":"\u003cp\u003e算力也被称之为计算能力（Computing Power），算力既然是一种“能力”——即其执行计算任务的速度和效率，那么算力就会有大小的衡量指标，同时对于算力的衡量就需要依托于芯片的类别来进行，但是无论怎样算力是需要有一个基准的单位的，常见具体的请见下表：\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e算力的计算方式 \n    \u003cdiv id=\"%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%97%E5%8A%9B%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Computing-Power-1.png\" alt=\"Computer Computing Power\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"计算机算力单位简介","type":"ai"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/blackwell/","section":"Tags","summary":"","title":"Blackwell","type":"tags"},{"content":"最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。\n微软 # 微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。\n看上去右边三分之二的区域用于冷却。\n谷歌 # 谷歌也是通过社交网络X发布的图片，谷歌表示这是在实验室中正在进行的定制GB200 NVL机架，更多信息将在10月30日的举行的谷歌云应用开发和基础设施峰会展示。\n谷歌没有披露采用了什么样的网络，可能不是Infiniband网络。\n相比微软的机架方案，这个只占有两个机架的空间。\nMeta # 在上周的2024 年开放计算项目 (OCP) 峰会上，Meta展示了基于NVIDIA Blackwell 平台全机架解决方案Catalina。其重点关注模块化和灵活性，旨在支持最新的 NVIDIA GB200 Grace Blackwell Superchip，确保满足现代 AI 基础设施日益增长的需求。\n这款机架能够支持高达140kW的功率。完整的解决方案采用液冷，由支持计算托盘、交换机托盘、Orv3 HPR、Wedge 400结构交换机、管理交换机、电池备用单元和机架管理控制器的电源架组成。\n下面是Catalina的正面图和后视图，我们可以看到，这个机架解决方案只用了一个机架空间。\n","date":"2024-10-24","externalUrl":null,"permalink":"/ai/several-rack-solutions-for-nvidia-blackwell-platform/","section":"Ais","summary":"\u003cp\u003e最近几周，微软、谷歌以及Meta相继展示了基于Nvidia Blackwell平台的机架解决方案，我们来看一下这几款机架解决方案。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e微软 \n    \u003cdiv id=\"%E5%BE%AE%E8%BD%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BE%AE%E8%BD%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e微软10月8日在社交网络X的账号表示：微软Azure成为首个运行Nvidia Blackwell系统的云平台，搭载了GB200驱动的AI服务器。通过在各层级进行优化，该平台能够支持世界上最先进的AI模型，特别是利用了Infiniband网络和创新的闭环液冷技术来提高性能和散热效果。有关更多信息将在Microsoft Ignite大会上公布。\u003c/p\u003e","title":"Nvidia Blackwell的几款机架服务器解决方案","type":"ai"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/arm/","section":"Tags","summary":"","title":"ARM","type":"tags"},{"content":"据彭博社报道，Arm已正式向高通发出通知，将取消双方之间的架构许可协议。这一决定正值两家公司之间的法律纠纷愈演愈烈之际，引发了业界的广泛关注。\n报道称，Arm已向高通发出了60天的强制通知，取消允许高通基于Arm拥有的标准设计并制造自己的芯片的许可协议。\n高通每年销售的处理器数量高达数亿片，其技术被广泛应用于大多数安卓智能手机中。一旦该终止生效，高通可能不得不停止销售占其总收入约390亿美元重要份额的产品，否则将面临巨额的赔偿风险。\n双方关系的恶化可追溯到2021年高通宣布的14亿美元收购芯片设计公司Nuvia的交易。2022年8月，Arm在特拉华州提起诉讼，指控高通在未进行新许可谈判的情况下，利用从Nuvia收购的技术进行开发，这违反了双方的授权协议，并要求赔偿。\n对于Arm的这一举措，高通发言人通过电子邮件声明表示：“这是Arm的一贯伎俩，其不断发出毫无根据的威胁，试图强迫长期合作伙伴，干扰我们性能领先的CPU，并提高专利费率，而不顾我们根据架构许可所享有的权利。随着12月审判的临近，Arm的行为似乎是在试图破坏法律程序。其终止诉讼的要求完全没有根据。我们相信，高通根据与Arm的协议所享有的权利将得到肯定。Arm的反竞争行为是不能容忍的。”\n然而，Arm方面拒绝对此报道发表评论。\n这场法律战定于12月在特拉华州联邦法院开庭。如果Arm在诉讼中胜诉，可能会迫使高通及其约20家合作伙伴（包括微软）停止出货新笔记本电脑。此外，这也将使高通近年来最大的战略收购之一——对Nuvia的收购功亏一篑。\n尽管两家公司在公开场合争斗激烈，但一些投资者和分析师仍相信，他们有可能在审判前达成和解。毕竟，这两家公司相互依赖，且都面临着巨大的收入和利润压力。未来，这场法律战的结果将如何影响整个半导体行业，仍值得我们密切关注。\n","date":"2024-10-24","externalUrl":null,"permalink":"/hardware/arm-holdings-to-cancel-qualcomm-chip-design-license/","section":"Hardwares","summary":"\u003cp\u003e据彭博社报道，Arm已正式向高通发出通知，将取消双方之间的架构许可协议。这一决定正值两家公司之间的法律纠纷愈演愈烈之际，引发了业界的广泛关注。\u003c/p\u003e\n\u003cp\u003e报道称，Arm已向高通发出了60天的强制通知，取消允许高通基于Arm拥有的标准设计并制造自己的芯片的许可协议。\u003c/p\u003e\n\u003cp\u003e高通每年销售的处理器数量高达数亿片，其技术被广泛应用于大多数安卓智能手机中。一旦该终止生效，高通可能不得不停止销售占其总收入约390亿美元重要份额的产品，否则将面临巨额的赔偿风险。\u003c/p\u003e\n\u003cp\u003e双方关系的恶化可追溯到2021年高通宣布的14亿美元收购芯片设计公司Nuvia的交易。2022年8月，Arm在特拉华州提起诉讼，指控高通在未进行新许可谈判的情况下，利用从Nuvia收购的技术进行开发，这违反了双方的授权协议，并要求赔偿。\u003c/p\u003e\n\u003cp\u003e对于Arm的这一举措，高通发言人通过电子邮件声明表示：“这是Arm的一贯伎俩，其不断发出毫无根据的威胁，试图强迫长期合作伙伴，干扰我们性能领先的CPU，并提高专利费率，而不顾我们根据架构许可所享有的权利。随着12月审判的临近，Arm的行为似乎是在试图破坏法律程序。其终止诉讼的要求完全没有根据。我们相信，高通根据与Arm的协议所享有的权利将得到肯定。Arm的反竞争行为是不能容忍的。”\u003c/p\u003e\n\u003cp\u003e然而，Arm方面拒绝对此报道发表评论。\u003c/p\u003e\n\u003cp\u003e这场法律战定于12月在特拉华州联邦法院开庭。如果Arm在诉讼中胜诉，可能会迫使高通及其约20家合作伙伴（包括微软）停止出货新笔记本电脑。此外，这也将使高通近年来最大的战略收购之一——对Nuvia的收购功亏一篑。\u003c/p\u003e\n\u003cp\u003e尽管两家公司在公开场合争斗激烈，但一些投资者和分析师仍相信，他们有可能在审判前达成和解。毕竟，这两家公司相互依赖，且都面临着巨大的收入和利润压力。未来，这场法律战的结果将如何影响整个半导体行业，仍值得我们密切关注。\u003c/p\u003e","title":"Arm将取消高通架构许可协议","type":"hardware"},{"content":"","date":"2024-10-24","externalUrl":null,"permalink":"/tags/qualcomm/","section":"Tags","summary":"","title":"Qualcomm","type":"tags"},{"content":"在Linux中，竖线（|，也称为管道符）是一个非常强大的工具，尤其在命令行操作中。它允许将一个命令的输出传递给另一个命令作为输入，从而实现将多个命令组合成一个流式的操作。本文将通过一些例子，展示竖线的作用和实际应用，带你更好地理解如何利用它提升工作效率。\n管道的基本概念 # Linux中的管道是一种将一个命令的标准输出（stdout）连接到另一个命令的标准输入（stdin）的方式。通俗点说，就是把第一个命令的“结果”直接交给第二个命令处理，而不是中途保存到文件。\n例如，使用管道可以将文件内容通过cat命令输出，并通过grep命令进行筛选：\ncat file.txt | grep \u0026#34;keyword\u0026#34; 这里，cat file.txt将文件内容显示出来，而竖线将内容交给grep，它会搜索包含“keyword”的行。这种方式避免了多次存储临时文件，让命令更加简洁流畅。\n统计特定日志出现的次数 # 在服务器维护过程中，我们经常需要分析日志文件，看看某个错误信息出现了多少次。假设我们有一个日志文件error.log，我们想统计其中包含\u0026quot;ERROR\u0026quot;的行数。\ncat error.log | grep \u0026#34;ERROR\u0026#34; | wc -l cat error.log：显示日志文件的内容。 grep \u0026quot;ERROR\u0026quot;：从日志中筛选出包含\u0026quot;ERROR\u0026quot;的行。 wc -l：统计行数，即\u0026quot;ERROR\u0026quot;出现的次数。 这个命令通过三步操作轻松实现了日志分析，非常实用。\n显示当前目录中文件最多的前三个扩展名 # 在开发中，我们可能会遇到一个目录里有大量不同类型的文件，想要统计其中哪个文件类型最多。通过管道组合命令，我们可以快速得出结果：\nls -l | awk \u0026#39;{print $NF}\u0026#39; | rev | cut -d. -f1 | rev | sort | uniq -c | sort -nr | head -n 3 ls -l：列出当前目录的文件。 awk '{print $NF}'：提取文件名。 rev | cut -d. -f1 | rev：通过cut和rev组合，获取文件的扩展名。 sort：对扩展名排序。 uniq -c：统计每个扩展名出现的次数。 sort -nr：按出现次数排序，次数多的排在前面。 head -n 3：取前3个扩展名。 通过管道的组合，一行命令完成了一个较为复杂的统计分析任务。\n查看端口占用情况并杀掉对应进程 # 服务器上有时候需要检查某个端口是否被占用并结束对应的进程。例如，我们需要查看80端口的占用情况并终止相应的进程：\nsudo netstat -tuln | grep \u0026#39;:80\u0026#39; | awk \u0026#39;{print $7}\u0026#39; | cut -d/ -f1 | xargs sudo kill -9 netstat -tuln：显示所有监听的TCP/UDP端口。 grep ':80'：筛选出80端口的相关信息。 awk '{print $7}'：提取出对应的进程ID（PID）。 cut -d/ -f1：进一步提取出纯数字的PID。 xargs sudo kill -9：通过xargs将PID传递给kill -9命令，终止该进程。 这个命令可以快速解决端口占用问题。\n将命令输出保存到文件并统计行数 # 有时，我们不仅想查看某个命令的输出，还想将其保存到文件中并进一步处理。比如，我们可以将一个ps命令的输出保存到文件，然后统计文件中的行数：\nps aux | tee output.txt | wc -l ps aux：列出当前系统的所有进程。 tee output.txt：将输出同时保存到文件output.txt中，并继续传递给下一个命令。 wc -l：统计行数，显示当前运行的进程数。 tee命令在这里的作用是让输出同时保存到文件和传递给管道的下一个命令，实现了一石二鸟的效果。\n管道符|在Linux中极大地增强了命令行的灵活性，它使得多个命令可以串联在一起工作，避免了使用临时文件或重复操作。在实际开发、运维过程中，通过巧妙地使用管道，能极大提高工作效率。例如日志分析、数据统计、进程管理等常见任务，都可以通过组合简单的命令行工具快速完成。\n管道的魅力在于它的简单性与可组合性——每个命令只需专注于自己的输入和输出，管道则负责将这些命令连接起来，形成强大的操作链。每个人都可以根据自己的需求和场景，创建独特的管道组合，让Linux的命令行变成真正的“魔法棒”。\n","date":"2024-10-23","externalUrl":null,"permalink":"/software/introduction-to-linux-pipe/","section":"Softwares","summary":"\u003cp\u003e在Linux中，竖线（\u003ccode\u003e|\u003c/code\u003e，也称为管道符）是一个非常强大的工具，尤其在命令行操作中。它允许将一个命令的输出传递给另一个命令作为输入，从而实现将多个命令组合成一个流式的操作。本文将通过一些例子，展示竖线的作用和实际应用，带你更好地理解如何利用它提升工作效率。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e管道的基本概念 \n    \u003cdiv id=\"%E7%AE%A1%E9%81%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%A1%E9%81%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux中的管道是一种将一个命令的标准输出（stdout）连接到另一个命令的标准输入（stdin）的方式。通俗点说，就是把第一个命令的“结果”直接交给第二个命令处理，而不是中途保存到文件。\u003c/p\u003e\n\u003cp\u003e例如，使用管道可以将文件内容通过\u003ccode\u003ecat\u003c/code\u003e命令输出，并通过\u003ccode\u003egrep\u003c/code\u003e命令进行筛选：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat file.txt \u003cspan class=\"p\"\u003e|\u003c/span\u003e grep \u003cspan class=\"s2\"\u003e\u0026#34;keyword\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这里，\u003ccode\u003ecat file.txt\u003c/code\u003e将文件内容显示出来，而竖线将内容交给\u003ccode\u003egrep\u003c/code\u003e，它会搜索包含“keyword”的行。这种方式避免了多次存储临时文件，让命令更加简洁流畅。\u003c/p\u003e","title":"Linux 管道Pipe简介","type":"software"},{"content":"","date":"2024-10-23","externalUrl":null,"permalink":"/tags/router/","section":"Tags","summary":"","title":"Router","type":"tags"},{"content":" Router是什么 # 路由器（Router）是一个用于连接不同网络的设备，它的主要作用是连接不同网络。路由器通常工作在 OSI 模型的第三层（网络层），负责管理数据包的路径选择和转发。\n主要特性 # IP 转发：Linux 内核支持 IP 包的转发功能，能够将数据包从一个网络接口转发到另一个接口。通过简单的配置可以实现基本的路由器功能。 流量控制和管理：Linux 路由器可以使用 tc（Traffic Control）工具来管理网络带宽，限制流量，进行流量优先级排序，防止网络拥塞。 VPN 支持：Linux 路由器可以通过 OpenVPN、IPsec 等协议实现虚拟专用网（VPN）功能，建立安全的网络隧道，保护数据在公网上传输。 QoS（服务质量）：可以使用 tc 或类似的工具实现 QoS 功能，优先处理特定类型的网络流量，确保关键应用的带宽和延迟需求得到满足。 动态路由协议：Linux 支持动态路由协议，如 OSPF（开放式最短路径优先协议）、BGP（边界网关协议）等。通过使用软件如 Quagga 或 FRRouting（FRR），可以实现复杂的大规模动态路由环境。 DHCP 和 DNS 服务：Linux 路由器可以配置为 DHCP 服务器，自动为内部网络分配 IP 地址。同时，它也可以运行 DNS 服务（如 dnsmasq），提供 DNS 解析和缓存功能。 工作机制 # IP 包的转发： Linux 路由器的核心工作机制是 IP 包的转发功能。启用 IP 转发后，Linux 内核会在接收到数据包时根据路由表决定下一跳。 内核查找路由表，确定数据包的目的地，并根据路由表中的信息将数据包从一个接口转发到下一个网络。 路由表的管理： 路由器使用路由表来决定数据包的转发路径。Linux 系统通过 ip route 命令可以配置和查看路由表。路由表中包含目标网络、下一跳设备和出口接口等信息。 路由表可以通过手动静态配置，也可以通过动态路由协议（如 OSPF 或 BGP）自动更新。 动态路由协议： 动态路由协议（如 OSPF、BGP）可在多台路由器之间动态交换路由信息。通过 FRRouting 等软件实现，Linux 可以参与动态路由网络，自动调整路由表，适应网络变化。 常见应用场景 # Linux 路由器通常应用于网络虚拟化中。如：虚拟专用网络（VPN）网关、流量控制和负载均衡、动态路由器和核心路由器。\n实现步骤 # 路由器的核心功能是转发数据包，因此需要在 Linux 上开启 IP 转发功能。\n临时启用 IP 转发（物理机重启后失效） echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 永久开启 IP 转发（物理机重启后仍然生效） 修改系统配置\nsudo vim /etc/sysctl.conf 将以下内容取消注释或条件\nnet.ipv4.ip_forward = 1 使配置生效\nsudo sysctl -p ","date":"2024-10-23","externalUrl":null,"permalink":"/software/how-to-implement-router-function-on-linux/","section":"Softwares","summary":"\u003ch2 class=\"relative group\"\u003eRouter是什么 \n    \u003cdiv id=\"router%E6%98%AF%E4%BB%80%E4%B9%88\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#router%E6%98%AF%E4%BB%80%E4%B9%88\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e路由器（Router）是一个用于连接不同网络的设备，它的主要作用是连接不同网络。路由器通常工作在 OSI 模型的第三层（网络层），负责管理数据包的路径选择和转发。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e主要特性 \n    \u003cdiv id=\"%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eIP 转发：Linux 内核支持 IP 包的转发功能，能够将数据包从一个网络接口转发到另一个接口。通过简单的配置可以实现基本的路由器功能。\u003c/li\u003e\n\u003cli\u003e流量控制和管理：Linux 路由器可以使用 tc（Traffic Control）工具来管理网络带宽，限制流量，进行流量优先级排序，防止网络拥塞。\u003c/li\u003e\n\u003cli\u003eVPN 支持：Linux 路由器可以通过 OpenVPN、IPsec 等协议实现虚拟专用网（VPN）功能，建立安全的网络隧道，保护数据在公网上传输。\u003c/li\u003e\n\u003cli\u003eQoS（服务质量）：可以使用 tc 或类似的工具实现 QoS 功能，优先处理特定类型的网络流量，确保关键应用的带宽和延迟需求得到满足。\u003c/li\u003e\n\u003cli\u003e动态路由协议：Linux 支持动态路由协议，如 OSPF（开放式最短路径优先协议）、BGP（边界网关协议）等。通过使用软件如 Quagga 或 FRRouting（FRR），可以实现复杂的大规模动态路由环境。\u003c/li\u003e\n\u003cli\u003eDHCP 和 DNS 服务：Linux 路由器可以配置为 DHCP 服务器，自动为内部网络分配 IP 地址。同时，它也可以运行 DNS 服务（如 dnsmasq），提供 DNS 解析和缓存功能。\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e工作机制 \n    \u003cdiv id=\"%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eIP 包的转发：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eLinux 路由器的核心工作机制是 IP 包的转发功能。启用 IP 转发后，Linux 内核会在接收到数据包时根据路由表决定下一跳。\u003c/li\u003e\n\u003cli\u003e内核查找路由表，确定数据包的目的地，并根据路由表中的信息将数据包从一个接口转发到下一个网络。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e路由表的管理：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e路由器使用路由表来决定数据包的转发路径。Linux 系统通过 \u003ccode\u003eip route\u003c/code\u003e 命令可以配置和查看路由表。路由表中包含目标网络、下一跳设备和出口接口等信息。\u003c/li\u003e\n\u003cli\u003e路由表可以通过手动静态配置，也可以通过动态路由协议（如 OSPF 或 BGP）自动更新。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e动态路由协议：\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e动态路由协议（如 OSPF、BGP）可在多台路由器之间动态交换路由信息。通过 FRRouting 等软件实现，Linux 可以参与动态路由网络，自动调整路由表，适应网络变化。\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e常见应用场景 \n    \u003cdiv id=\"%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux 路由器通常应用于网络虚拟化中。如：虚拟专用网络（VPN）网关、流量控制和负载均衡、动态路由器和核心路由器。\u003c/p\u003e","title":"如何在 Linux 上实现 Router 功能","type":"software"},{"content":"TFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于局域网中的小文件传输，如嵌入式系统的固件更新。以下是在Linux系统中配置TFTP服务器的详细步骤。\n安装TFTP服务 # 首先，您需要安装TFTP服务器软件。在基于Debian的系统（如Ubuntu）上，您可以使用以下命令安装tftpd-hpa：\nsudo apt-get update sudo apt-get install tftpd-hpa 对于基于RPM的系统（如CentOS），使用以下命令：\nsudo yum install tftp-server 配置TFTP服务器 # 安装完成后，您需要配置TFTP服务器。配置文件通常位于/etc/default/tftpd-hpa。\n编辑配置文件：\nsudo nano /etc/default/tftpd-hpa 在配置文件中，您可以设置以下参数：\nTFTP_USERNAME: 运行TFTP服务的用户，通常是tftp TFTP_DIRECTORY: TFTP服务的根目录，通常是/srv/tftp或/var/lib/tftpboot TFTP_ADDRESS: TFTP服务监听的地址和端口，通常是0.0.0.0:69 TFTP_OPTIONS: TFTP服务的额外选项，如--secure --create 例如：\nTFTP_USERNAME=\u0026#34;tftp\u0026#34; TFTP_DIRECTORY=\u0026#34;/srv/tftp\u0026#34; TFTP_ADDRESS=\u0026#34;0.0.0.0:69\u0026#34; TFTP_OPTIONS=\u0026#34;--secure --create\u0026#34; 创建TFTP根目录 # 创建TFTP服务的根目录，并设置适当的权限：\nsudo mkdir -p /srv/tftp sudo chmod 777 /srv/tftp 重启TFTP服务 # 配置完成后，重启TFTP服务以应用更改：\nsudo systemctl restart tftpd-hpa 测试TFTP服务 # 要测试TFTP服务器，您可以使用TFTP客户端软件。在客户端机器上，使用以下命令连接到TFTP服务器：\ntftp \u0026lt;服务器IP地址\u0026gt; 然后，您可以使用get命令下载文件，或使用put命令上传文件。\n注意事项 # TFTP协议不提供任何身份验证或加密，因此请确保只在受信任的网络内使用 出于安全考虑，您可以在TFTP_OPTIONS中使用--secure选项，以防止目录遍历攻击 如果需要允许客户端上传文件，可以在TFTP_OPTIONS中添加--create选项 通过以上步骤，您可以在Linux系统上成功配置TFTP服务器，以便在局域网中进行简单的文件传输。\n","date":"2024-10-22","externalUrl":null,"permalink":"/software/how-to-configure-tftp-server-in-linux/","section":"Softwares","summary":"\u003cp\u003eTFTP（Trivial File Transfer Protocol）是一个简单的文件传输协议，常用于局域网中的小文件传输，如嵌入式系统的固件更新。以下是在Linux系统中配置TFTP服务器的详细步骤。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e安装TFTP服务 \n    \u003cdiv id=\"%E5%AE%89%E8%A3%85tftp%E6%9C%8D%E5%8A%A1\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%AE%89%E8%A3%85tftp%E6%9C%8D%E5%8A%A1\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e首先，您需要安装TFTP服务器软件。在基于Debian的系统（如Ubuntu）上，您可以使用以下命令安装tftpd-hpa：\u003c/p\u003e","title":"Linux下如何配置tftp服务器","type":"software"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/tftp/","section":"Tags","summary":"","title":"Tftp","type":"tags"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/9800x3d/","section":"Tags","summary":"","title":"9800X3D","type":"tags"},{"content":"最新的 AMD Ryzen 7 9800X3D 基准测试泄露显示，这款新游戏 CPU 的时钟速度比其前身 7800X3D 快得多。尽管 AMD 3D V 缓存提供了强大的游戏能力，但后者却因 5GHz 的时钟速度而受到限制。然而，这次泄露显示，新款八核 Ryzen 9000X3D 游戏 CPU 的运行速度超过 5.6GHz。\n从CPU-Z的截图可以看到，该处理器达到了惊人的5643.14MHz。在Cinebench R23的基准测试中，有效时钟频率更是达到了5598.4MHz和5689MHz。这表明，在合适的散热条件下，该处理器有可能突破5.7GHz的频率。\n据报道，Ryzen 7 9800X3D的加速时钟频率将达到5.2GHz，比Ryzen 7 7800X3D高出200MHz。在Cinebench R23多核测试中，该处理器取得了25258分的高分，单核得分为2261分。相比之下，Ryzen 7 7800X3D的多核得分在18000-19000分之间，这意味着9800X3D在时钟频率提升至5.6-5.7GHz时，性能提升了约35%。单核性能也比7800X3D高出至少25%。\n虽然目前尚不清楚这些分数在游戏性能上意味着什么，但令人惊讶的是，Ryzen 7 9800X3D的综合性能甚至可能超过Ryzen 7 9700X。通常情况下，非X3D系列的处理器由于更高的时钟频率，在综合基准测试中表现更佳。然而在这次测试中，9800X3D在单核和多核性能上都表现出色，打破了以往的规律。\n根据最新的价格信息，Ryzen 7 9800X3D的售价预计在450至500美元之间，但在正式发布前价格可能会有所调整。此前的传言显示，该处理器将于11月7日正式上市，距离现在大约还有两周时间。\n总体上，AMD Ryzen 7 9800X3D有望在性能和超频能力上带来显著提升，对于追求高性能的用户来说，这无疑是一个令人期待的选择。\n","date":"2024-10-22","externalUrl":null,"permalink":"/hardware/amd-ryzen-7-9800x3d-benchmark-leaked/","section":"Hardwares","summary":"\u003cp\u003e最新的 AMD Ryzen 7 9800X3D 基准测试泄露显示，这款新游戏 CPU 的时钟速度比其前身 7800X3D 快得多。尽管 AMD 3D V 缓存提供了强大的游戏能力，但后者却因 5GHz 的时钟速度而受到限制。然而，这次泄露显示，新款八核 Ryzen 9000X3D 游戏 CPU 的运行速度超过 5.6GHz。\u003c/p\u003e","title":"AMD 锐龙7 9800X3D 核心参数泄露","type":"hardware"},{"content":"","date":"2024-10-22","externalUrl":null,"permalink":"/tags/ryzen-7/","section":"Tags","summary":"","title":"Ryzen 7","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/cpu/","section":"Tags","summary":"","title":"CPU","type":"tags"},{"content":"GPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。\n设计目的与功能 # CPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。\nGPU：设计目的是为了快速渲染图像和视频，以及进行大规模的并行计算。它专注于图像处理及大型矩阵运算等方面，并凭借强大的并行处理能力在这些领域展现出巨大的优势。\n处理器结构 # CPU：通常拥有少量的处理核心，但每个核心的性能较高。其架构是基于冯·诺依曼体系结构的，包含控制单元、算术逻辑单元、缓存等部分。这种结构使得CPU适合于顺序计算和复杂的控制任务。\nGPU：拥有大量的处理核心（通常以数百甚至数千计），但每个核心的性能较低。其架构是基于数据流体系结构的，包含许多流处理器和专用硬件单元。这种结构使得GPU适合于并行计算和大规模数据处理。\n适用领域 # CPU：广泛应用于各种需要复杂逻辑运算和数据处理的场景中，如操作系统管理、应用软件运行、武器装备运动控制等。\nGPU：在游戏娱乐、影视制作、科学研究和人工智能等领域发挥着重要作用。例如，在游戏娱乐领域，GPU能够为玩家提供流畅、逼真的3D游戏画面和高质量的音频效果；在人工智能领域，GPU则能够加速神经网络的训练和推理过程，提高人工智能系统的性能和效率。\n功耗与散热 # CPU：由于处理核心较少，功耗和散热相对较低。\nGPU：由于拥有大量的处理核心和高性能特性，通常需要较高的功耗和散热设计。显卡通常需要配备强大的散热系统来保持稳定的性能。\n编程模型与框架 # CPU：编程通常使用标准的编程语言和库，如C++和OpenMP。\nGPU：编程通常使用特定的编程模型，如CUDA和OpenCL。这些编程模型允许开发人员编写并行代码，以便可以在GPU上执行。\n性能与效率 # CPU：在处理顺序计算和控制任务时具有较高的性能和效率。\nGPU：在处理并行计算和大规模数据处理时具有更高的性能和效率。其并行计算能力可以大大提高计算速度，从而加快应用程序的执行速度。\n结语 # 综上所述，GPU和CPU在设计目的、处理器结构、适用领域、功耗与散热、编程模型与框架以及性能与效率等方面都存在显著的区别。它们各自承担着不同的任务并发挥着不可替代的作用，共同协作以确保计算机能够高效地运行各种应用程序和任务。\n","date":"2024-10-21","externalUrl":null,"permalink":"/ai/difference-between-cpu-and-gpu/","section":"Ais","summary":"\u003cp\u003eGPU（图形处理器）和CPU（中央处理器）是计算机硬件中的两大核心组件，它们在计算机系统中发挥着不同的作用，并具有显著的区别。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./cpu-vs-gpu.webp\" alt=\"CPU vs GPU\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e设计目的与功能 \n    \u003cdiv id=\"%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E7%9A%84%E4%B8%8E%E5%8A%9F%E8%83%BD\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eCPU：设计目的是为了高效地处理各种不同的任务，是计算机系统的中枢。它擅长顺序处理和分支预测，能够与各种设备和内存进行交互，并负责操作系统、应用程序、网络通信等的运行。CPU的作用偏向于调度、协调和管理，同时也具备一定的计算能力。\u003c/p\u003e","title":"CPU与GPU的区别","type":"ai"},{"content":"AMD正式发布了面向嵌入式系统的新一代EPYC处理器，即EPYC Embedded 8004系列。该系列采用了AMD密度优化的Zen 4c内核，核心数量从12个到64个不等。\nEPYC Embedded 8004系列支持单路处理器配置，通过六个内存通道可支持高达1.152TB的DDR5内存，热设计功耗（TDP）范围在70W到225W之间。AMD表示，该系列的目的是在紧凑且功耗受限的环境中，为高需求的工作负载提供卓越的性能。其目标应用包括网络系统、路由器、安全设备和工业边缘应用等。\n具体型号和规格如下：\nEPYC Embedded 8534P：基础频率2.3GHz，加速频率3.1GHz，64核心128线程，TDP为200W。 EPYC Embedded 8434P：基础频率2.5GHz，加速频率3.1GHz，48核心96线程，TDP为200W。 EPYC Embedded 8324P：基础频率2.65GHz，加速频率3.0GHz，32核心64线程，TDP为180W。 EPYC Embedded 8224P：基础频率2.55GHz，加速频率3.0GHz，24核心48线程，TDP为180W。 EPYC Embedded 8124P：基础频率2.45GHz，加速频率3.0GHz，16核心32线程，TDP为125W。 EPYC Embedded 8C24P：基础频率2.45GHz，加速频率3.0GHz，12核心24线程，TDP为100W。 EPYC Embedded 8004系列是首款采用AMD Zen 4c内核的EPYC处理器。Zen 4c是一种密度优化且注重性能功耗比的架构，将Zen 4架构缩小到更紧凑的封装，并通过降低时钟频率来提高能效。这使得AMD能够在更小的芯片尺寸中集成更多的核心。\n相比采用常规Zen 4内核的EPYC Embedded 9004系列，8004系列更注重功耗管理。Zen 4c系列的规格相比Zen 4有大幅缩减，例如，旗舰型号EPYC Embedded 8534P拥有3.1GHz的加速频率、64个Zen 4c核心和200W的TDP，而EPYC Embedded 9654P则拥有3.7GHz的加速频率、96个核心和360W的TDP。\n8004系列的核心数量更少、频率更低、总体TDP也更低。这种优化还体现在其他方面：由于Zen 4c的密度优化，L3缓存减少了多达三倍，PCIe通道数量减半（64条对比128条），内存通道数量也从12个减少到6个。值得注意的是，虽然AMD在公告中提到TDP低至70W，但规格中最低的是100W。\nAMD表示，EPYC Embedded 8004系列非常适合那些需要在性能、能效、热管理和平台密度之间取得平衡的客户。由于引入了Zen 4c核心，AMD指出8004系列比9004系列的Zen 4芯片尺寸小了19%，更适合用于更小、更紧凑的设备中。\n","date":"2024-10-21","externalUrl":null,"permalink":"/hardware/amd-releases-new-generation-of-epyc-processors-for-embedded-systems/","section":"Hardwares","summary":"\u003cp\u003eAMD正式发布了面向嵌入式系统的新一代EPYC处理器，即\u003ccode\u003eEPYC Embedded 8004\u003c/code\u003e系列。该系列采用了AMD密度优化的\u003ccode\u003eZen 4c\u003c/code\u003e内核，核心数量从12个到64个不等。\u003c/p\u003e\n\u003cp\u003eEPYC Embedded 8004系列支持单路处理器配置，通过六个内存通道可支持高达1.152TB的DDR5内存，热设计功耗（TDP）范围在70W到225W之间。AMD表示，该系列的目的是在紧凑且功耗受限的环境中，为高需求的工作负载提供卓越的性能。其目标应用包括网络系统、路由器、安全设备和工业边缘应用等。\u003c/p\u003e\n\u003cp\u003e具体型号和规格如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEPYC Embedded 8534P：基础频率2.3GHz，加速频率3.1GHz，64核心128线程，TDP为200W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8434P：基础频率2.5GHz，加速频率3.1GHz，48核心96线程，TDP为200W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8324P：基础频率2.65GHz，加速频率3.0GHz，32核心64线程，TDP为180W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8224P：基础频率2.55GHz，加速频率3.0GHz，24核心48线程，TDP为180W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8124P：基础频率2.45GHz，加速频率3.0GHz，16核心32线程，TDP为125W。\u003c/li\u003e\n\u003cli\u003eEPYC Embedded 8C24P：基础频率2.45GHz，加速频率3.0GHz，12核心24线程，TDP为100W。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEPYC Embedded 8004系列是首款采用AMD Zen 4c内核的EPYC处理器。Zen 4c是一种密度优化且注重性能功耗比的架构，将Zen 4架构缩小到更紧凑的封装，并通过降低时钟频率来提高能效。这使得AMD能够在更小的芯片尺寸中集成更多的核心。\u003c/p\u003e","title":"AMD发布面向嵌入式系统的新一代EPYC处理器","type":"hardware"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/epyc-embedded-8004/","section":"Tags","summary":"","title":"EPYC Embedded 8004","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/zen-4c/","section":"Tags","summary":"","title":"Zen 4c","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/apo/","section":"Tags","summary":"","title":"APO","type":"tags"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/intel/","section":"Tags","summary":"","title":"Intel","type":"tags"},{"content":"英特尔近日宣布，其专属应用程序优化软件（APO）现已支持多达26款游戏，包括众多电子竞技类和3A大作。这些游戏在最新的第14代酷睿处理器和Core Ultra 200S系列上将获得更佳的性能优化。\nAPO软件与英特尔动态调优技术（DTT）相结合，可以提升硬件的性能、电池寿命和温度管理。通过实时识别并将资源分配给最需要的应用程序，APO能够为游戏带来更流畅的运行体验。\n新增支持的游戏名单包括：\n《英雄连3》 《反恐精英2》 《赛博朋克2077》 《尘埃5》 《Dota 2》 《梦幻三国2》（中国） 《F1 22》 《最终幻想14：终局之诗》 《Fortnite》 《银河护卫队》 《地铁：离去》 《永劫无间》 《荒野大镖客2》 《裂隙破坏者》 《英雄萨姆4》 《古墓丽影：暗影》 《奇异旅程》（VLK） 《小缇娜的奇幻之地》 《汤姆·克兰西的彩虹六号：围攻》 《全面战争：法老》 《全面战争：三国》 《全面战争：战锤3》 《看门狗：军团》 《坦克世界》 《魔兽世界》 《僵尸世界大战》 其中，《反恐精英2》和《Dota 2》等游戏在Steam平台上拥有数十万的实时在线玩家，是最受欢迎的游戏之一。新增的《赛博朋克2077》、《荒野大镖客2》、《古墓丽影：暗影》等3A大作，将在最新的英特尔硬件上运行得更加顺畅，特别是Core Ultra 200S系列芯片。\n目前，只有第12代、第13代和第14代酷睿处理器可以充分利用英特尔APO，许多用户已成功提升了性能。需要注意的是，APO与Core Ultra 200S（Ultra 7和Ultra 9）以及第14代Core i7和Core i9处理器的兼容性最佳。\n对于移动端处理器，只有Core i7-14700HX和Core i9-14900HX完全支持APO。其他处理器，包括Core Ultra 5、第14代及以后的Core i5，以及所有第12代和第13代处理器，仅提供有限的高级模式支持。\n以下是经过验证的支持英特尔APO的处理器：\n桌面处理器： # Core Ultra 9 处理器 285K Core Ultra 7 处理器 265K Core Ultra 7 处理器 265KF Core i9 处理器 14900KS Core i9 处理器 14900K Core i9 处理器 14900KF Core i7 处理器 14700K Core i7 处理器 14700KF 移动处理器： # Core i9 处理器 14900HX Core i7 处理器 14700HX 英特尔APO的更新将为广大游戏玩家带来更佳的体验，充分发挥最新处理器的性能潜力。可以看出英特尔在优化硬件性能和满足用户需求方面的不懈努力。\n","date":"2024-10-21","externalUrl":null,"permalink":"/software/intel-announces-apo-supports-26-games/","section":"Softwares","summary":"\u003cp\u003e英特尔近日宣布，其专属应用程序优化软件（APO）现已支持多达26款游戏，包括众多电子竞技类和3A大作。这些游戏在最新的第14代酷睿处理器和Core Ultra 200S系列上将获得更佳的性能优化。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eAPO\u003c/code\u003e软件与英特尔动态调优技术（\u003ccode\u003eDTT\u003c/code\u003e）相结合，可以提升硬件的性能、电池寿命和温度管理。通过实时识别并将资源分配给最需要的应用程序，APO能够为游戏带来更流畅的运行体验。\u003c/p\u003e\n\u003cp\u003e新增支持的游戏名单包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e《英雄连3》\u003c/li\u003e\n\u003cli\u003e《反恐精英2》\u003c/li\u003e\n\u003cli\u003e《赛博朋克2077》\u003c/li\u003e\n\u003cli\u003e《尘埃5》\u003c/li\u003e\n\u003cli\u003e《Dota 2》\u003c/li\u003e\n\u003cli\u003e《梦幻三国2》（中国）\u003c/li\u003e\n\u003cli\u003e《F1 22》\u003c/li\u003e\n\u003cli\u003e《最终幻想14：终局之诗》\u003c/li\u003e\n\u003cli\u003e《Fortnite》\u003c/li\u003e\n\u003cli\u003e《银河护卫队》\u003c/li\u003e\n\u003cli\u003e《地铁：离去》\u003c/li\u003e\n\u003cli\u003e《永劫无间》\u003c/li\u003e\n\u003cli\u003e《荒野大镖客2》\u003c/li\u003e\n\u003cli\u003e《裂隙破坏者》\u003c/li\u003e\n\u003cli\u003e《英雄萨姆4》\u003c/li\u003e\n\u003cli\u003e《古墓丽影：暗影》\u003c/li\u003e\n\u003cli\u003e《奇异旅程》（VLK）\u003c/li\u003e\n\u003cli\u003e《小缇娜的奇幻之地》\u003c/li\u003e\n\u003cli\u003e《汤姆·克兰西的彩虹六号：围攻》\u003c/li\u003e\n\u003cli\u003e《全面战争：法老》\u003c/li\u003e\n\u003cli\u003e《全面战争：三国》\u003c/li\u003e\n\u003cli\u003e《全面战争：战锤3》\u003c/li\u003e\n\u003cli\u003e《看门狗：军团》\u003c/li\u003e\n\u003cli\u003e《坦克世界》\u003c/li\u003e\n\u003cli\u003e《魔兽世界》\u003c/li\u003e\n\u003cli\u003e《僵尸世界大战》\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e其中，《反恐精英2》和《Dota 2》等游戏在Steam平台上拥有数十万的实时在线玩家，是最受欢迎的游戏之一。新增的《赛博朋克2077》、《荒野大镖客2》、《古墓丽影：暗影》等3A大作，将在最新的英特尔硬件上运行得更加顺畅，特别是Core Ultra 200S系列芯片。\u003c/p\u003e","title":"英特尔宣布APO支持26款游戏","type":"software"},{"content":"","date":"2024-10-21","externalUrl":null,"permalink":"/tags/xscape/","section":"Tags","summary":"","title":"Xscape","type":"tags"},{"content":"据传言，Nvidia 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 NVLink 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。\n由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。\n无论你是否知道，哥伦比亚大学都是互连和光子学的温床。\nAl Gara 教授和 Norman Christ 教授构建了一台采用 DSP 驱动的超级计算机，该计算机具有专有互连功能，可运行量子色动力学应用程序，并于 1998 年荣获戈登贝尔奖。这项 QCDSP 系统研究为 IBM 的 BlueGene 大规模并行超级计算机奠定了基础，Gara 是该超级计算机的首席架构师。（Gara 转投英特尔，也是其假定继任者——阿贡国家实验室的“Aurora”超级计算机的架构师。）\n哥伦比亚大学有一组完全不同的研究人员致力于硅光子学研究，他们中的许多人联手创建了 Xscape Photonics。该公司联合创始人之一、光波研究实验室负责人 Keren Bergman一直在利用光子学降低系统中数据传输的能量。联合创始人 Alex Gaeta 是这家初创公司的总裁，他最初担任首席执行官，在量子和非线性光子学方面做了基础性工作，即参量放大器和光频梳发生器。联合创始人 Michal Lipson 发明了一些关键的光子学元件，例如微环调制器和纳米锥耦合器。联合创始人 Yoshi Okawachi 是光频梳这一特殊激光器的专家。\n有趣的是，当这些哥伦比亚大学的研究人员决定将他们的光互连理念商业化时，他们选择了 Xscape 的联合创始人之一、并非来自哥伦比亚大学的维韦克·拉古纳坦 (Vivek Raghunathan) 担任首席执行官，因为加埃塔 (Gaeta) 决定减少自己的职责，重返大学教授职位。\nRaghunathan 来自麻省理工学院，在那里获得了材料科学与工程学位，Xscape 的一些同事也曾在此工作过；他在麻省理工学院担任了六年的研究助理，参与了各种硅光子学项目，并于 2013 年加入英特尔，担任亚利桑那州钱德勒代工厂的高级封装研发工程师。Raghunathan 一步步晋升，领导开发了英特尔首款 100 Gb/秒以太网光收发器，并致力于其 GPU 到 HBM 互连。Raghunathan 曾在 Rockley Photonics 担任工程师，然后于 2019 年加入博通，担任“Humbolt”共封装光学器件的负责人，该器件用于 25.6 Tb/秒的 Tomahawk 4 交换机 ASIC 变体，由腾讯和字节跳动在中国部署。Raghunathan 启动了 52.6 Tb/秒 Tomahawk 5 代“Bailly”后续 CPO 项目，但在完成之前离开并加入了 Xscape。\n本周的重磅新闻是，Xscape 在 A 轮风险投资中筹集了 4400 万美元，此前该公司于 2022 年成立后进行了 1300 万美元的种子轮融资。此次融资由 IAG Capital Partners 领投。有趣的是，HyperWorks 计算机辅助工程工具的创造者 Altair 是投资者之一，其创始人之一也是哥伦比亚大学的校友，也是工程学院的董事会成员。思科投资、Fathom Fund、Kyra Ventures、LifeX Ventures、Nvidia 和 Osage University Partners 也参与了投资。\nNvidia 的投资很有意思，因为需要将大量的 GPU 连接在一起，而这家 GPU 巨头在 3 月份宣布使用“Blackwell”B100 GPU 加速器推出的 GB200 NVL72 机架式系统中使用铜基 NVLink-NVSwitch 互连能够做到这一点。通过在 GPU 及其内存之间使用光导管，Nvidia 可以将数据中心真正变成一个巨大的虚拟 GPU。你可以打赌，这正是 Nvidia 想要做的事情，并且早在 2022 年，它就暗示了其带有 CPO 概念设计的 NVSwitch。\n无论人工智能加速器的架构如何，它的问题在于，一旦超出给定设备的边缘，计算元素或内存之间的带宽就会开始逐渐减小，而且速度相当快。\n对于任何加速器来说，都需要使用电信号将 HBM堆叠内存放置在非常靠近计算引擎的位置，这意味着你只能在芯片给定的周长内封装这么多东西。（并且你只能将内存堆叠得这么高才能增加容量，即使这样做，也不会增加带宽。只有更快的内存和更多的内存端口才能增加带宽。而且由于 HBM 价格昂贵且供应不足，我们看到 GPU 加速器路线图做了一些奇怪的事情，以匹配有限的内存容量和带宽，以应对有时性能过强的 GPU。\nRaghunathan 说，归根结底，就是数据从加速器中出来的“逃逸速度”，这也是 Xscape Photonics 这个名字的由来。（不要太拘泥于字面意思。）\n这些是我们经常谈论的数字，但最好将它们全部放在一个地方以显示逐渐减小的情况，当您查看 Nvidia GB200 混合集群时，该逐渐减小大约为 160 倍，每个“Grace”CG100 Arm 服务器 CPU 都有两个“Blackwell”GB100 GPU 加速器。带宽逐渐减小是将其中一个 GPU 与 400 Gb/秒 Quantum 2 InfiniBand 端口进行比较，该端口通常用于让 GPU 与集群中及其自身节点之外的其他 GPU 进行通信。\n那么带宽减少会产生什么影响呢？这意味着数据无法足够快地进出 GPU。这会导致非常昂贵的设备的利用率低。\n对于 AI 训练和推理，Raghunathan 引用了 Alexis Bjorlin 的数据，他曾经负责 Meta Platforms 的基础设施，但现在已转任 Nvidia 的 DGX Cloud 总经理。请看：\nRaghunathan 告诉The Next Platform ：“因此，对于训练来说，随着 GPU 的不断扩展，问题已经从 GPU 设备级性能转变为系统级网络问题。根据工作负载，你最终会花费大量时间在 GPU 之间的通信上。在 Meta 展示的图表中，他们讨论了某些工作负载，其中几乎 60% 的时间都花在了网络上。同样，当你考虑推理时，你会看到最先进的 GPU 在进行 ChatGPT 搜索时利用率在 30% 到 40% 之间。这种低 GPU 利用率是我们的客户想要解决的根本问题，因为他们会继续购买数十亿美元的 GPU。”\n这个数学很简单。利用率为 50% 时，峰值计算的百分比是由有限的 GPU 进出带宽预先决定和限制的，这意味着 GPU 的成本是你认为的两倍，这意味着你浪费了一半的钱。\n现在，公平地说，我们非常怀疑全世界的平均 CPU 利用率是否会高于 50%。但平均 CPU 成本也不会达到 30,000 美元。每年大约 1500 万台服务器的平均成本可能接近 1,000 美元。但这仍然是每年数百亿美元的低效浪费。GPU 的浪费比“损失”的资金多出一个数量级，这就是每个人都感到恐慌的原因。\n“我们真正想在 Xscape Photonics 解决的就是带宽逐渐减少的问题，”Raghunathan 说道，他与我们听到的Ayar Labs、Lightmatter、Eliyan、Celestial AI 、 Ultra Accelerator Link 联盟成员等许多公司的意见一致。“我们如何解决这个问题？我们认为，将所有从 GPU 中逸出的电信号直接转换为同一封装中的光信号，并在我们将 GPU 和内存池连接在一起时最大化利用光信号，这是扩展 GPU 性能最具成本效益和能源效率的方法。”\nXscape 团队想出的诀窍是，使用一种激光器，它可以同时从光纤中驱动多种波长，比如多达 128 种不同的颜色，这意味着带宽可能比驱动四种不同颜色的光互连中使用的激光器高 32 倍。此外，Raghunathan 表示，Xscape 的 ChromX 平台方法将使用更简单的调制方案，如 NRZ，它不会像 PAM-4 等高阶调制方案那样影响延迟，近年来，这种方案已用于提高 InfiniBand 和以太网的带宽。\n或许同样重要的是，ChromX 光子平台是可编程的，因此提供的波长数量与特定 AI 训练或推理工作负载的需求以及加速器与其 HBM 内存之间的连接需求相匹配，所有这些都在交换结构基础设施内完成。可编程激光器将率先问世，其概念如下：\n该图表左侧显示了 CWDM4 收发器用于创建 AI 训练集群互连的激光器所需的四种波长。\n中间是制造 LR4 光纤收发器所需的四种不同波长，这种光纤收发器通常用于当您必须使用光纤链路跨越两个数据中心并同步链接它们时，以便可以在两个数据中心上进行训练，就好像它们是一个更大的数据中心一样。\n右边是一个推理引擎，它有一个交换加速器和 HBM 内存复合体，与 Nvidia 对 NVLink 和 NVSwitch 所做的有很大不同，并且有 16 种不同的波长。\n不同的波长对应于设备之间的预期距离。根据 Raghunathan 的说法，设备之间的训练距离通常为 2 公里或更短，跨数据中心边缘用例预计在 20 公里到 40 公里之间，但有些人说的是 10 公里到 20 公里。推理具有更多波长，设备之间的距离预计在 10 米到 200 米之间，并且需要更多的带宽才能使这些设备高效运行。\n后一点与计算和内存的分解结构架构有关，我们认为这对于训练和推理都有效，这很有趣。让我们来看看：\n这种架构下，HBM 内存不连接到 GPU，而是粘合在一起，这些存储体可能位于机架中物理上不同的架子上，或跨整个机架。GPU（或任何类型的 AI 或 HPC 加速器）都存储在一起，因此它们可以在一致性域中共享缓存中的本地数据，但它们都通过交换机连接，该交换机将加速器池与内存池交叉连接。上述每条管道都是一条光链路，其属性可以由 ChromX 平台编程，使用适当数量的波长和适当的频率来满足带宽和距离（以及延迟）要求。\n“我们的技术几乎打破了成本障碍和规模障碍，并且非常可靠，因为我们只需要一个激光器就可以泵送一块硅片，而且我们可以从单个设备生成多达数百个波长，”Raghunathan 说。“我们提供了一个全新的带宽扩展向量。核心 IP 由哥伦比亚大学独家授权，完全归我们所有。我们的愿景是将封装内通信带宽与封装外通信逃逸带宽相匹配。我们认为，当我们使用多色方法时，我们可以匹配这一点，以便大型数据中心（或多个数据中心）可以像一个大型 GPU 一样运行。”\n目前，Xscape Photonics 并未试图制造支持这种分解式光子结构的网络接口或交换机，而是试图制造其他人想要购买的适合的低功率、多色激光器，以制造这些设备。他们拥有一台激光器，可以实现所有这些频率，而市场上其他人则必须使用多台激光器来实现这一点。他们的想法是将加速器及其内存的互连总功耗降低 10 倍，同时将带宽提高 10 倍，从而将每个带宽的能量降低 100 倍。\n看看谁会采用这款 Xscape 激光以及如何采用它，将会很有趣。\n","date":"2024-10-21","externalUrl":null,"permalink":"/ai/one-laser-to-pump-up-ai-interconnect-bandwidth-by-10x/","section":"Ais","summary":"\u003cp\u003e据传言，\u003ccode\u003eNvidia\u003c/code\u003e 预计要到 2027 年的“Rubin Ultra” GPU 计算引擎才会为其 GPU 内存绑定 \u003ccode\u003eNVLink\u003c/code\u003e 协议提供光学互连。这意味着每个设计加速器的人——尤其是超大规模和云构建者内部设计的加速器——都希望通过在 Big Green 之前部署光学互连来在 AI 计算方面胜过 Nvidia，从而获得优势。\u003c/p\u003e\n\u003cp\u003e由于加速器到加速器和加速器到内存的带宽瓶颈巨大，因此对光互连的需求如此之高，以至于筹集风险投资资金不成问题。我们看到这方面的行动越来越多，今天我们将讨论 Xscape Photonics，这是一家从哥伦比亚大学的研究机构分离出来的光互连初创公司。\u003c/p\u003e","title":"英伟达投资光芯片公司，将互联带宽提高10倍","type":"ai"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/pcie-5.0/","section":"Tags","summary":"","title":"PCIe 5.0","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/ssd/","section":"Tags","summary":"","title":"SSD","type":"tags"},{"content":"较旧、速度较慢的 SATA SSD 正在逐渐消失，取而代之的是 NVMe SSD，后者的速度快很多倍，而且不需要任何杂乱的布线，因为它们可以直接插入现代主板上的 M.2 插槽。市场上正开始出现基于更快的 PCIe 5.0 标准的驱动器，它们可以为用户提供超过 14 GB/s 的惊人连续读写速度。\n这里测试了七款 NVMe SSD，包括四款最受欢迎的 PCIe 4.0 选项，以及三款全新的 PCIe 5.0 SSD，它们将存储性能推向了极限。这组 SSD 经过了 Gigabyte Aorus Elite X WiFi 7 主板的测试，该主板顶部有一个 PCIe 5.0 M.2 插槽。\n2024 年最佳工作站 SSD # 三星 990 Pro # 三星是 NAND 闪存领域的全球领导者，在推出性能卓越的 SSD 方面拥有悠久的历史。990 Pro 延续了这一趋势，成为目前性能最佳的 PCIe 4.0 NVMe 驱动器。\n它使用三星设计的 Pascal 控制器，基于 8nm 工艺制造，而不是目前许多其他 SSD 中使用的各种 12nm 控制器。它使用最新的三星设计的 V8 TLC 3D 闪存。这种组合意味着它提供较高的产品规格，具有 7,450 MB/s 的读取速度和 6,900 MB/s 的写入速度，160 万次随机 4K 读取和 150 万次写入 IOPS。此外，如果您需要它，990 Pro 还提供 TCG Opal 硬件加密，这是您在每个 SSD 上都找不到的。\n除此之外，还有三星的 Magician 软件，它无疑是执行低级任务（例如检查驱动器的健康状况或安全擦除驱动器）的最佳软件工具。值得注意的是，三星 990 Pro 在所有容量下的耐久性相对较低；4TB 型号仅为 2,400 TBW。无论是否配备优秀的散热器。\n同时，在性能方面，笔者的测试显示其性能略低于三星的说法，达到 7,140 MB/s 的连续读取速度，IOPS 比广告宣传的低约 10%。但令人惊讶的是，即便如此，990 Pro 仍然比任何 PCIe 4.0 竞争对手都快，IOPS 几乎与 PCIe 5.0 SSD 相匹配。特别是，它在所有测试的 PCIe 4.0 驱动器中获得了最高的 PCMark 10 分数和最低的延迟（36ms）。\n因此，尽管耐久性数据较低，但如果您只追求高性能，而不考虑成本，990 Pro 仍然是我们的 PCIe 4.0 SSD 首选。虽然它肯定不是市场上最实惠的 SSD，但如果您货比三家，仍然应该可以找到一些不错的选择。\nCrucial T705 # 竞争对手高端 Crucial T705 和 Corsair MP700 Pro SE（如下所示）PCIe 5.0 SSD 几乎是相同的 SSD，性能几乎相同，在误差范围内。它们都基于 Phison PS5026-E26 控制器，都使用 Micron TLC NAND，都具有相似的配置，而且都非常昂贵，要价大约是 PCIe 4.0 驱动器的两倍。如果没有散热器，这两款 SSD 也会变得非常热，从而导致性能下降。但稍后会详细介绍。\n尽管本文已经提到了成本和散热方面的考虑，但 T705 在存储性能方面绝对胜出。使用 PCIe 5.0，笔者测量的连续传输速度为 14,088 MB/s 读取和 12,005 MB/s 写入，这大约是 PCIe 4.0 SSD 的两倍。\n但 T705 的领先优势并不仅仅在于这个结果。我们测量了 160 万 IOPS，击败了所有 PCIe 4.0 SSD，并且在 PCMark 10 中笔者记录的延迟仅为 26ms，这是所测试过的所有 SSD 中的最佳结果。\n但是，您需要为这种额外的速度付出高昂的代价。4TB T705 轻松突破了 600 英镑的价格障碍，当 Lexar NM790 等 PCIe 4.0 驱动器的价格不到其一半时，这个价格实在是太高了。PCIe 5.0 目前显然是一项高级功能，专为那些真正的高端工作站保留。\n笔者测试了一款配备 Crucial 提供的集成散热器的 2TB 型号。散热器运行良好，在测试系统中将温度稳定保持在 45°C 左右，不会妨碍设置中的任何其他组件。 T705 的超高速度在很多情况下都非常有用。但对于其他人来说，这可能是一个棘手的选择。如果您想要最快的 SSD 性能，请购买 T705，或者选择仍然足够的 PCIe 4.0，而是将额外的现金投资于直接加快 3D 渲染时间的硬件。\nCorsair MP700 Pro SE # 鉴于 Crucial T705 和 Corsair MP700 Pro SE 非常相似，笔者预计两者的结果会几乎相同，Corsair 提供同样先进的存储性能。\nCorsair 发送了顶级的 4TB MP700 Pro SE 进行评测，代表了当今市场上最高端的消费级 SSD 规格。笔者在 CrystalDiskMark 中测得的读取性能为 14,088 MB/s，写入性能为 11,958 MB/s，IOPS 高达 160 万。29ms 的延迟几乎与 Crucial 的 T705 相同，但略长，而 PCMark 10 和 AS SSD 的总体得分相同，除了百分之几的微小差异。\n笔者收到的用于测试的 SSD 是没有散热器的准系统型号，但在这方面 Corsair 可能比其他任何供应商都走得更远。你可以买到一个带有被动散热器的版本，还有另一个带有自己风扇的版本。这听起来很疯狂，但似乎系统中单个 SSD 的主动冷却现在已经成为现实。值得注意的是，这可能是最高效的 MP700 Pro SE 冷却系统。\n它也是必需的，因为在没有它的情况下进行测试时我们遇到了一些问题。在 AS SSD 测试中，一旦驱动器开始旋转，性能就会减半至 PCIe 4.0 水平以下，而温度会飙升至 85C 以上。需要澄清的是，并非每次测试都是这种情况，或者在不将 MP700 Pro SE 推到极限时也是如此。如果没有散热器，每个 PCIe 5.0 SSD 都可能发生这种情况。一旦测试时在技嘉的 Aorus 主板上应用了隔热罩，问题就消失了。\n但除此之外，MP700 Pro SE 是另一个具有惊人存储性能的绝佳选择。它比 Seagate 的 FireCuda 540 更快，如果您对 PCIe 5.0 存储提供的优势感兴趣，它是 Corsair 和 Crucial 之间的选择。由于这两个驱动器非常相似，因此决定很可能归结为成本。\nLexar NM790 # NM790 是最为有趣的 NVMe SSD 之一。其价格比竞争对手的 PCIe 4.0 SSD 低约 50%，同时具备出色性能，拥有可观的 7400MB/s 读取速度、6500MB/s 写入速度以及高达 100 万 IOPS 的随机 4K 读取速度。这些数值相当出色，几乎与价格高得多的高端 PCIe 4.0 驱动器性能相当。\n由于 NM790 价格便宜得多，在亚马逊上可以以大约 240 英镑的价格购买 4TB 型号，此价格与一些品牌对 2TB 的近期定价相近。这非常划算，尤其考虑到 2024 年 SSD 价格略有上涨。\nNM790 与其他一些 NVMe SSD 有一个主要区别：它没有板载 DRAM 缓存，而是使用 HMB 3.0（主机内存缓冲区）技术，利用工作站系统内存的一小部分来替代板载 DRAM。没有 DRAM 意味着整体功耗更低，在某些系统中具有显著好处。\nNM790 搭载 Maxiotech MAP1602A 控制器，仍使用三级单元（TLC）闪存和小型单级单元（SLC）缓存，而非通过采用速度慢得多的四级单元（QLC）NAND 类型来进一步降低成本。因此，它在大多数测试中表现优异，可与其他可用的 PCIe 4.0 SSD 相媲美。事实上，尽管价格较低，但需仔细观察才能发现真正差异。\n测量的 IOPS 和连续传输速度与三星 990 Pro 等驱动器不相上下，且在所有测试中仍符合 Lexar 的要求。PCMark 10 得分（包括延迟）与竞争对手相当甚至超越竞争对手。仅在 AS SSD 中，NM790 略有下降，在所有测试的 SSD 中得分最低。\n若想用尽可能多的高性能 NVMe SSD 填充主板上的所有 M.2 插槽，NM790 无疑是最经济实惠的方式。\n金士顿 KC3000 # 金士顿是 2021 年最早推出 PCIe 4.0 NVMe SSD 的供应商之一。在没有 PCIe 5.0 产品的情况下，KC3000 仍是其性能最佳的旗舰消费级 NVMe SSD。\n其宣称的性能高达 7000MB/s 的连续读写速度以及 100 万 IOPS。三年后，KC3000 依然是市场上最好的 PCIe 4.0 SSD。在内部构造上，KC3000 由 Phison E18 控制器驱动，配备 1GB DRAM 缓存，并使用 3D TLC NAND 闪存。两侧的 NAND 芯片均覆盖有石墨烯散热器，以使其在使用时保持较低的平均温度。\nKC3000 的额定耐久性为 0.4 DWPD（每日驱动器写入次数），对于 4TB 型号来说为 3200TBW。值得注意的是，这一耐久性远高于其他竞争 NVMe SSD 的通常额定值。它享有五年保修和 2000000 小时 MTBF（平均故障间隔时间）。\n刚推出时，KC3000 是市场上性能最好的 SSD 之一。但如今，它面临着一些激烈的竞争。在我们的测试中，4TB KC3000 完全符合金士顿宣称的 7000MB/s 连续读写速度，这是一个非常好的结果。在我们的 IOPS 测试中，KC3000 超过了宣称的数据，因为我们测量到近 150 万次随机 4K 写入 IOPS，这个数字表明小文件的传输速度很快。同样，KC3000 在 AS SSD 基准测试中也取得了不错的成绩，击败了其他 PCIe 4.0 NVMe SSD。\n然而，这对金士顿来说并非全是好消息。KC3000 在 PCMark 10 中获得了最高的延迟分数，为 45ms，而配备更现代控制器的 SSD 则超过了这一数字。 尽管如此，考虑到 KC3000 现在可以在网上以极其合理的价格买到，并且具有出色的耐用性，它仍然是一个引人注目的选择。\n西部数据 Black SN850X # 西部数据或许是全球最为多元化的存储品牌，在固态硬盘和硬盘领域皆占据领先地位。西部数据旗下还有 SanDisk 品牌，通过对两种存储格式以及 NAS、DAS、云、监控、存储卡等进行投资，对未来进行了押注。\n其一系列精巧的彩色产品名称能够让人一眼辨认出来。不同的颜色代表不同的使用场景，红色、蓝色、绿色和黑色突出显示经过调整的规格，以优先处理特定的存储工作负载。例如，其红色驱动器适用于 NAS 设备，而黑色代表高性能。WD_Black SN850X 是该公司目前销售的最快的消费级 NVMe SSD。\n它由 Kioxia TLC NAND 和西部数据的内部控制器构建而成。附加功能包括简洁的 WD 管理软件仪表板，可显示驱动器运行状况和其他低层级信息。若选择该产品，还有一个特别简洁、厚实的散热器，自然是黑色的。\n额定读取速度为 7300MB/s，写入速度为 6300MB/s，其更高容量型号可达到 120 万 IOPS，所有规格均符合快速存储性能的要求。\n即便如此，其标称的耐用性评级略低，4TB 型号仅为 2400TBW，与三星 990 Pro 相同，但低于金士顿的 KC3000 或 Lexar 的 NM790 的相同容量。\n在我们的测试中，性能数据基本符合预期。6962MB/s 的连续读取性能略低于标称速度。我们测试的 1TB 型号的读取 IOPS 为 800000，容量越高，IOPS 越高。同时，写入性能在两次测试中都表现出色。SN850X 的延迟为 41ms，位于 PCIe 4.0 产品的中间位置，这是一款符合所有要求的 SSD。\n希捷 FireCuda 540 # 2023 年，希捷是首批推出 PCIe 5.0 SSD 的公司之一。基于 Phison PS5026-E26 控制器的 FireCuda 540 超越了 PCIe 4.0，令存储领域为之惊叹。\n然而，到了 2024 年，与较新的 Crucial T705 和 Corsair MP700 Pro SSD 相比，它所提供的性能如今看来略显不足，而后者将 PCIe 5.0 标准推向了更接近极限的水平。 FireCuda 540 的规格与其他 PCIe 5.0 SSD 类似。它有 1TB 和 2TB 两种版本，4TB 型号似乎尚未推出。2TB 型号采用 232 层 Micron NAND 闪存，可提供可观的 2000TBW 耐用性。\nFireCuda 540 的性能不可小觑，总体而言是一款出色的存储设备。在我们的测试中，测得的读取速度为 10077MB/s，写入速度为 10195MB/s，读取 IOPS 为 150 万，延迟为 30 毫秒，其得分全面击败了我们测试过的所有 PCIe 4.0 SSD。\n尽管如此，这些结果确实比我们从 Crucial 和 Corsair 的较新 PCIe 5.0 SSD 测得的速度低了约 40%。鉴于希捷的定价几乎与他们的 1TB 和 2TB 型号相匹配，这使得 FireCuda 540 的性价比降低。如果要花费额外的资金来获得最快的性能存储，那么就需要最好的。\n虽然 FireCuda 540 在各方面都是一款出色的 SSD，但较低的性能使我们无法将其列为首选推荐。希望希捷能推出更新的型号，使其再次成为 SSD 军备竞赛的引领者。 Image 如何为工作站选择最佳 SSD？\nPCIe 5.0 是超高速 SSD 性能的下一步，测试结果表明，它提供了比任何 PCIe 4.0 SSD 都更快的顺序性能、更快的 IOPS 和更低的延迟。毫不夸张地说，为了获得最快的工作站存储性能，您会想要选择 PCIe 5.0 SSD 型号。\n是否应该使用取决于您的预算和个人使用情况。如果钱不是问题，PCIe 5.0 是明智之举。然而，考虑到我们遇到的散热问题和高昂的成本，我们很乐意暂时不在我们的工作站上使用 PCIe 5.0，而是将多余的钱用于 GPU 升级，或更多系统内存和更好的整体渲染时间。\n由于 NVMe 存储速度实在是太快了，我们很难在这里挑选出赢家。即使是价格仅为高端 4TB PCIe 4.0 驱动器三分之一的 Lexar NM790 也表现出色。由于金士顿的 KC3000 提供了顶级耐用性，而三星的 990 Pro 则优于其他 PCIe 4.0 驱动器，因此坚持使用旧标准似乎并不是一个没有吸引力的选择。\n毫不怀疑 PCIe 5.0 是 SSD 的未来，但目前它仍然是尖端的存储技术，在很多方面还未准备好进入主流市场。\n","date":"2024-10-20","externalUrl":null,"permalink":"/hardware/the-best-ssds-for-workstation/","section":"Hardwares","summary":"\u003cp\u003e较旧、速度较慢的 SATA SSD 正在逐渐消失，取而代之的是 NVMe SSD，后者的速度快很多倍，而且不需要任何杂乱的布线，因为它们可以直接插入现代主板上的 M.2 插槽。市场上正开始出现基于更快的 PCIe 5.0 标准的驱动器，它们可以为用户提供超过 14 GB/s 的惊人连续读写速度。\u003c/p\u003e\n\u003cp\u003e这里测试了七款 NVMe SSD，包括四款最受欢迎的 PCIe 4.0 选项，以及三款全新的 PCIe 5.0 SSD，它们将存储性能推向了极限。这组 SSD 经过了 Gigabyte Aorus Elite X WiFi 7 主板的测试，该主板顶部有一个 PCIe 5.0 M.2 插槽。\u003c/p\u003e","title":"适合工作站使用的最佳SSD","type":"hardware"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/ffmpeg/","section":"Tags","summary":"","title":"FFmpeg","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/m3u8/","section":"Tags","summary":"","title":"M3u8","type":"tags"},{"content":"随着互联网技术的飞速发展，越来越多的人选择在线观看视频。无论是直播还是点播，流畅的视频体验离不开背后的技术支持。其中，m3u8文件是一个非常重要的概念。本文将帮助你了解m3u8文件是什么，以及如何使用FFmpeg下载这些视频。\nm3u8文件概述 # m3u8文件是一种文本文件，主要用于支持HLS（HTTP Live Streaming）协议。简单来说，HLS是一种流媒体传输协议，可以让用户在不同的设备上流畅地观看视频。m3u8文件就像一个目录，记录了视频的不同片段在哪里，浏览器或播放器通过读取这个目录来逐步加载视频。\nm3u8文件通常包含以下几个部分：\n文件头：以#EXTM3U开始，表示这是一个m3u8文件 媒体段信息：以#EXTINF开始，后面跟着该媒体段的时长和标题 媒体段URI：指向媒体文件（通常是.ts文件）的路径或URL 文件结尾：以#EXT-X-ENDLIST结束，表示一个完整的m3u8文件 当用户请求观看视频时，播放器首先会读取m3u8文件，然后根据文件中的URL逐个下载视频片段，这样可以实现视频的分段加载，即使网络不稳定也能保证视频的流畅播放。\nm3u8文件的优点：\n支持断点续传：如果网络中断，播放器可以从上次停止的地方继续下载，不会影响观看体验 良好的跨平台兼容性：m3u8文件可以在多种设备和平台上使用，包括手机、电脑和智能电视 适应不同的网络条件：m3u8文件可以根据网络状况动态调整视频质量，确保用户始终获得最佳观看体验 使用FFmpeg下载m3u8视频 # 打开命令行工具（如Windows的CMD/WSL或Mac/Linux的终端），输入以下命令：\nffmpeg -i \u0026#34;m3u8 URL\u0026#34; -c copy output.mp4 -i \u0026quot;m3u8 URL\u0026quot;：指定m3u8文件的URL -c copy：表示直接复制视频和音频流，不进行重新编码，这样可以加快下载速度 output.mp4：指定输出文件的名称和格式 例如，如果你要下载的m3u8文件URL是https://example.com/video.m3u8，命令如下：\nffmpeg -i \u0026#34;https://example.com/video.m3u8\u0026#34; -c copy output.mp4 实战演练 # 首先，你需要找到待下载视频的m3u8链接。这通常可以通过查看网页源代码或使用浏览器的开发者工具（通常可通过按F12键打开）来定位。切换到网络选项卡，在搜索框中输入“.m3u8”过滤出m3u8链接，然后右键点击链接复制URL。\n如果通过上述方式找不到m3u8链接，一般是由于加密了，可以使用浏览器扩展“猫抓”（cat-catch，是github上的开源项目，已经有不少加上广告代码后上架的伪猫抓，请注意自己的数据安全。所有安装地址以github上的为准）。\n打开命令行，输入ffmpeg的下载命令，并粘贴m3u8链接。\n等待ffmpeg下载完成，并保存为mp4文件。\n结语 # m3u8文件在现代流媒体服务中扮演着重要角色，它使得视频可以在不同设备上流畅播放。FFmpeg作为一个强大的开源工具，可以帮助我们轻松下载和处理这些视频。希望本文能够帮助你更好地理解和使用m3u8文件及FFmpeg。\n","date":"2024-10-20","externalUrl":null,"permalink":"/software/download-m3u8-videos-efficiently-with-ffmpeg/","section":"Softwares","summary":"\u003cp\u003e随着互联网技术的飞速发展，越来越多的人选择在线观看视频。无论是直播还是点播，流畅的视频体验离不开背后的技术支持。其中，m3u8文件是一个非常重要的概念。本文将帮助你了解m3u8文件是什么，以及如何使用FFmpeg下载这些视频。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003em3u8文件概述 \n    \u003cdiv id=\"m3u8%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#m3u8%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003em3u8文件是一种文本文件，主要用于支持HLS（HTTP Live Streaming）协议。简单来说，HLS是一种流媒体传输协议，可以让用户在不同的设备上流畅地观看视频。m3u8文件就像一个目录，记录了视频的不同片段在哪里，浏览器或播放器通过读取这个目录来逐步加载视频。\u003c/p\u003e\n\u003cp\u003em3u8文件通常包含以下几个部分：\u003c/p\u003e","title":"用FFmpeg高效下载m3u8视频","type":"software"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/godlike/","section":"Tags","summary":"","title":"GODLIKE","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/msi/","section":"Tags","summary":"","title":"MSI","type":"tags"},{"content":"","date":"2024-10-20","externalUrl":null,"permalink":"/tags/z790/","section":"Tags","summary":"","title":"Z790","type":"tags"},{"content":"MSI近日在其官方YouTube频道进行了超过两小时的直播，正式公布了旗舰级主板MEG Z890 GODLIKE的售价。这款顶级主板在美国市场的售价为1,264美元，欧洲市场的售价则高达1,379.99欧元，成为MSI迄今为止最昂贵的主板产品。\n相比前代产品MEG Z790 GODLIKE的1,200美元定价，新款Z890 GODLIKE的价格进一步提升，打破了之前的记录。在北美市场，Z890 GODLIKE的售价已超过1,250美元，若将官方价格转换为欧盟地区的含税价格，甚至达到1,510美元。MSI的GODLIKE系列一直是其主板产品线中的旗舰，专为追求极致性能的发烧友和超频玩家设计。\nMEG Z890 GODLIKE采用了适用于Intel Arrow Lake CPU的LGA 1851插槽，支持Intel Core Ultra系列处理器（第2代）。主板配备了30相电源VRM和110A SPS，拥有10层PCB设计和服务器级材料，搭配密集的散热器，确保在高负载下仍能保持稳定的性能和被动散热效果。\n主要特点：\n内存支持：主板支持双通道DDR5内存，最高可达DDR5 9200+ MT/s（OC），为用户提供了强大的内存超频潜力。\n动态仪表板III：配备3.99英寸LCD屏幕，可实时监控硬件状态、故障排除、BIOS更新，并提供个性化显示选项，提升整体用户体验。\nM.2 XPANDER-Z SLIDER GEN5：单插槽厚度的M.2扩展卡，具有双高速Gen5 M.2插槽，采用EZ Slide设计，方便SSD的升级和更换。\nThunderbolt 5支持：附带的Thunderbolt 5配件卡拥有双Thunderbolt 5端口，提供高达160Gbps的总带宽和高达27W的快速充电能力。\n超级性能配置：采用26+2+1+1双轨电源系统、110A SPS、OC引擎、双8针CPU电源连接器、Core Boost和Memory Boost等高级配置，由2盎司加厚铜和服务器级材料制成的10层PCB，确保主板的稳定性和性能。\nFrozr Guard散热系统：包含波浪形散热片设计、直触交叉热管、MOSFET底板、9W/mK导热垫、双面M.2 Shield Frozr和Frozr AI软件，确保在低温下实现最佳性能。\nEZ DIY设计：提供EZ Link、EZ PCIe Release、EZ Magnetic M.2 Shield Frozr II、EZ M.2 Clip II和EZ Antenna等功能，方便用户自行安装和升级硬件。\n卓越的连接性：配备双Thunderbolt 4端口、10G LAN和5G LAN，以及全速的Intel Killer Wi-Fi 7解决方案，满足专业和多媒体用途的高要求，提供安全、稳定和高速的网络和数据传输。\n极速游戏体验：支持PCIe 5.0插槽，拥有总共8个M.2接口（带有Lightning Gen 5解决方案），以及带有60W USB供电的前置USB 20G接口，满足高速存储和外设连接需求。\nAudio Boost 5 HD音频系统：采用最新的高级ALC4082音频处理器，结合ESS音频DAC和放大器，提供令人惊叹的音频体验。\n尽管MEG Z890 GODLIKE拥有顶级的规格和功能，但其高昂的价格注定了这款主板并非面向大众市场。它主要吸引那些希望利用Intel Arrow Lake CPU（如Core Ultra 9 285K）打破超频世界纪录的专业超频玩家和硬件发烧友。\n除了这款旗舰主板外，MSI的其他Z890芯片组主板价格都未超过1,000美元。其中，次旗舰型号MEG Z890 ACE售价为689美元，约为Z890 GODLIKE价格的一半，提供了更为实惠的高端选择。\n随着Intel Arrow Lake Core Ultra系列处理器的即将推出，众多主板厂商纷纷发布了Z890芯片组主板。MSI作为一线大厂，提供了涵盖不同价位和需求的多款产品。对于追求极致性能和无与伦比配置的用户而言，MEG Z890 GODLIKE无疑是当前市场上的顶尖之选。\n","date":"2024-10-20","externalUrl":null,"permalink":"/hardware/msi-releases-the-most-expensiv-motherboard-ever/","section":"Hardwares","summary":"\u003cp\u003eMSI近日在其官方YouTube频道进行了超过两小时的直播，正式公布了旗舰级主板MEG Z890 GODLIKE的售价。这款顶级主板在美国市场的售价为1,264美元，欧洲市场的售价则高达1,379.99欧元，成为MSI迄今为止最昂贵的主板产品。\u003c/p\u003e\n\u003cp\u003e相比前代产品MEG Z790 GODLIKE的1,200美元定价，新款Z890 GODLIKE的价格进一步提升，打破了之前的记录。在北美市场，Z890 GODLIKE的售价已超过1,250美元，若将官方价格转换为欧盟地区的含税价格，甚至达到1,510美元。MSI的GODLIKE系列一直是其主板产品线中的旗舰，专为追求极致性能的发烧友和超频玩家设计。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./MSI-MEG-Z890-GODLIKE-2.png\" alt=\"MSI Release MEG Z790 GODLIKE\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eMEG Z890 GODLIKE采用了适用于Intel Arrow Lake CPU的LGA 1851插槽，支持Intel Core Ultra系列处理器（第2代）。主板配备了30相电源VRM和110A SPS，拥有10层PCB设计和服务器级材料，搭配密集的散热器，确保在高负载下仍能保持稳定的性能和被动散热效果。\u003c/p\u003e","title":"微星发布了一块史上最昂贵主板","type":"hardware"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/gdb/","section":"Tags","summary":"","title":"GDB","type":"tags"},{"content":"在软件开发的复杂世界里，高效的调试工具是解决问题的关键利器。今天，我们将深入探讨强大的调试工具 —— GDB（GNU Debugger）。GDB 为开发者提供了一种深入程序内部运行机制、查找错误和优化性能的有效途径。让我们一同开启 GDB 的调试之旅，解锁代码中的奥秘。\nGDB调试工具 # GDB（GNU Debugger）是强大的调试工具，在软件开发过程中起着至关重要的作用。它可以帮助开发者快速定位和解决程序中的问题。\nGDB做以下4 件主要的事情来帮助您捕获程序中的bug：\n在程序启动之前指定一些可以影响程序行为的变量或条件 在某个指定的地方或条件下暂停程序 在程序停止时检查已经发生了什么 在程序执行过程中修改程序中的变量或条件，这样就可以体验修复一个 bug 的成果，并继续了解其他 bug 启动 GDB 主要有以下两种方法：\n直接启动 gdb：单独输入此命令启动 GDB，启动后需借助file或者exec-file命令指定要调试的程序 gdb test.out：如果有一个名为test.out的可执行文件，可以直接使用这个命令启动 GDB 并加载该程序进行调试 gdb test.out core：当程序发生错误并生成core文件时，可以使用这个命令启动 GDB，以便对错误进行分析 动态链接：gdb test.out pid，这种方式可以将 GDB 链接到一个正在运行中的进程中去，其中pid就是进程号，可以使用ps aux命令查看对应程序的进程号。 要准备调试的程序，首先需要用gcc的-g参数生成可执行文件。这样才能在可执行文件中加入源代码信息以便调试，但这并不是将源文件嵌入到可执行文件中，所以调试时必须保证 GDB 能找到源文件。例如，编译程序时可以使用gcc -g main.c -o test.out这样的命令来生成带有调试信息的可执行文件。\nGDB调试技巧 # 条件断点 条件断点在调试过程中非常实用。设置条件断点可以利用break if命令，例如(gdb)break 666 if testsize==100123123。条件断点的优势在于可以在特定条件满足时才使程序停止，这对于排查异常情况非常有帮助。比如在一个循环中，当某个变量达到特定值时才中断程序，这样可以更精准地定位问题。\n断点命令 断点命令不仅可以让程序在特定位置停止，还可以编写对到达断点响应的脚本，实现更复杂的调试功能。例如，可以在断点处设置一些打印变量值、检查特定条件等操作，以更好地了解程序的运行状态。\n转储二进制内存 GDB 提供了多种方式查看内存。内置支持的x命令可以查看内存地址中的值，其语法为x/\u0026lt;n/f/u\u0026gt; \u0026lt;addr\u0026gt;，其中n是显示内存的长度，f表示显示的格式，u表示从当前地址往后请求的字节数。例如(gdb) x/16xw 0x7FFFFFFFE0F8可以以十六进制、四字节为单位显示从地址0x7FFFFFFFE0F8开始的 16 个单位的内存内容。此外，也可以使用自定义的hexdump命令来查看内存，更加灵活地控制输出格式。\n行内反汇编 使用disassemble/s命令可以查看与函数源代码对应的指令，这有助于了解程序在 CPU 指令级别上的情况。例如，disas main可以显示main函数对应的汇编代码。通过查看汇编代码，可以更深入地理解程序的执行过程，对于分析性能问题、理解底层实现等非常有帮助。\n反向调试 反向调试是 GDB 的一个强大功能。它可以让程序实现上一步上一步的操作，即反向运行。反向调试在一些情况下非常有用，比如调试过程中不小心多执行了一次命令，或者想再次查看刚刚程序执行的过程。反向调试不适用 IO 操作，并且需要 GDB7.0 以上的版本。相关指令有rc或reverse-continue反向运行程序，直到碰到一个能使程序中断的事件；rs或reverse-step反向运行程序到上一次被执行的源代码行等。通过查看寄存器值等方式，可以深入了解程序在反向运行过程中的状态变化。\nGDB调试方法 # 编译及启动调试 在编译代码时，加上 -g 选项是非常重要的，这可以确保在可执行文件中包含调试信息，以便在使用 GDB 进行调试时能够获取更多的程序内部状态信息。例如，使用 gcc -g main.c -o main.out 这样的命令编译代码，生成的 main.out 可执行文件就可以被 GDB 有效地调试。\n启动调试代码有多种方式。可以直接使用 gdb main.out 来启动调试一个可执行文件，然后在 GDB 环境中使用 run 命令来运行程序。如果程序在启动时需要命令行参数，可以在进入 GDB 后使用 run arg1 arg2... 的方式来提供参数并启动调试。\n另外，还可以调试正在运行的程序。\n首先找到程序的进程号，可以使用 ps aux | grep program_name 或 pidof program_name 来获取进程号。 然后使用 gdb attach pid 或者 gdb -p pid 命令将 GDB 附加到正在运行的程序上进行调试。 调试命令 GDB 有许多强大的调试命令。比如 list 命令可以显示源代码：\nlist 会打印当前行后面的代码 list - 显示当前行前面的代码 list lineNumber 打印出行第 lineNumber 行前后的代码 list FunctionName 打印出行函数 FunctionName 前后的代码 break 命令用于设置断点，可以在指定的行号或函数处设置断点:\nbreak \u0026lt;function\u0026gt; 在进入指定函数时停止运行 break \u0026lt;lineNumber\u0026gt; 在指定代码行打断点 break filename:lineNumber 在指定文件的特定行设置断点 break filename:function 在指定文件的函数入口处设置断点 还可以设置条件断点，如 break... if \u0026lt;condition\u0026gt;，当条件成立时程序停止运行。\nnext 命令执行下一条语句，如果该语句为函数调用，不会进入函数内部执行。\nstep 命令执行下一条语句，如果该语句为函数调用，则进入函数执行其中的第一条语句。\ncontinue 命令继续程序的运行，直到遇到下一个断点。\nprint 和 display 命令用于打印变量 / 表达式的值，print 只输出一次，display 跟踪查看某个变量，每次停下来都显示它的值。可以以不同格式打印变量，如 p /f variable，其中 f 可以是 x（十六进制格式）、d（十进制格式）、u（十六进制格式显示无符号整型）等。\nwatch 命令在程序运行过程中监视变量值的变化，如果有变化，马上停止程序运行，如 watch variable 当变量 variable 有变化时，停止程序运行，还有 rwatch 和 awatch 分别在变量被读取和被读或被写时停止程序运行。\n调试段错误 调试段错误的一种快捷方法是生成 core 文件并使用 GDB 加载分析。首先，可以使用 ulimit -c unlimited 命令将 core 文件生成设置为不限制大小。这样，当程序发生段错误时，会生成 core 文件。\n然后，使用 GDB 加载这个 core 文件进行调试。可以使用 gdb program core 的方式，其中 program 是可执行程序名称，core 是生成的 core 文件。在 GDB 中，可以使用 backtrace 命令查看函数调用栈，找到出错的位置。还可以使用 frame 命令查看特定栈帧的信息，使用 print 命令打印变量的值，以确定问题所在。例如，如果在调试过程中发现某个变量的值为空指针，可能是内存分配失败导致的，可以进一步检查相关的内存分配代码。\nGDB使用其他要点 # 调试参数列表 # GDB 拥有丰富的调试参数，以下是一些常见的命令及其用途：\n启动程序：使用 gdb [可执行文件名] 启动 GDB 并加载要被调试的可执行文件。例如 gdb test.out。还可以使用 gdb file [可执行文件名] 的方式启动，如 gdb file test.out。另外，若要调试正在运行的程序，可以使用 gdb attach [进程号] 或 gdb -p [进程号]。\n设置断点： break [行号]：在指定行设置断点，如 break 10。 break [函数名]：在函数入口处设置断点，如 break main。 break [文件名:行号]：在指定文件的特定行设置断点，如 break test.c:20。 break\u0026hellip; if [条件]：设置条件断点，当条件成立时程序停止运行，如 break 666 if testsize==100123123。 info breakpoints：显示当前程序的断点设置情况。 delete breakpoints [断点号]：删除指定断点，不指定断点号则删除所有断点。 disable [断点号]：暂停指定断点。 enable [断点号]：开启指定断点。 clear [行号]：清除指定行的断点。 单步执行： next（简写为 n）：逐过程调试，执行下一行，当遇到函数调用时，会一次性执行完该函数，不进入函数体内部。 step（简写为 s）：单步调试，执行下一行，当遇到函数调用时，会进入函数体内部。 continue（简写为 c）：继续执行程序，直到下一个断点处或程序结束。 until：当厌倦在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。until+行号：运行至某行，可用于跳出循环。 finish：运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。 call [函数(参数)]：调用程序中可见的函数，并传递参数，如 call gdb_test(55)。 查看信息： info registers：显示所有寄存器的内容，可查看特定寄存器，如 info registers rbp 显示 rbp 寄存器的值，info registers rsp 显示 rsp 寄存器的值。 info stack：显示堆栈信息。 info args：显示当前函数的参数列表。 info locals：显示当前函数的局部变量列表。 info function：查询函数。 info breakpoints：显示当前程序的断点设置情况。 info watchpoints：列出当前所设置的所有观察点。 info line [行号/函数名/文件名:行号/文件名:函数名]：查看源代码在内存中的地址。 查看内存单元值 # 在 GDB 中，可以使用 examine 命令（简写是 x）来查看内存地址中的值。其格式为 x/\u0026lt;n/f/u\u0026gt; \u0026lt;addr\u0026gt;，其中：n是一个正整数，表示显示内存的长度，从当前地址向后显示几个地址的内容。例如 x/16xb 0x7FFFFFFFE0F8 表示以单字节为单位显示从地址 0x7FFFFFFFE0F8 开始的 16 个字节的内容。\nf表示显示的格式，可取如下值：\nx：按十六进制格式显示变量。 d：按十进制格式显示变量。 u：按十进制格式显示无符号整型。 o：按八进制格式显示变量。 t：按二进制格式显示变量。 a：按十六进制格式显示变量。 i：指令地址格式。 c：按字符格式显示变量。 f：按浮点数格式显示变量。 u表示一个地址单元的长度，可用以下字符代替：\nb表示单字节。 h表示双字节。 w表示四字节。 g表示八字节。 查看源程序 # 在 GDB 中，可以使用 list（简写为 l）命令查看源程序，有以下几种方式：\nlist：显示当前行后面的源程序，默认每次显示 10 行，按回车键继续看余下的。 list [行号]：将显示当前文件以 “行号” 为中心的前后 10 行代码，如 list 12。 list [函数名]：将显示 “函数名” 所在函数的源代码。 栈帧相关 # GDB 中有一些与栈帧相关的命令：\ninfo frame：打印当前栈帧的详细信息，包括当前函数、参数和局部变量等。例如：(gdb) info frame会显示诸如 Stack level 0, frame at [地址]: pc = [程序计数器值] in [函数名] ([文件名]:[行号]); saved pc [保存的程序计数器值]等信息。 up和down：在栈帧之间上下移动。up命令将切换到上一个栈帧，而down命令将切换到下一个栈帧。 info locals：显示当前函数的局部变量列表，帮助开发者了解当前栈帧中的局部变量情况。 GDB多线程调试 # GDB 多线程调试基础 # 基本命令介绍 在 GDB 多线程调试中，有许多常用命令。例如设置断点可以使用 (gdb) break function_name，通过这个命令可以在特定的函数处设置断点，当程序执行到该函数时会暂停。删除断点则可以使用 (gdb) delete breakpoints。查看线程信息可以使用 (gdb) info threads，这个命令会列出所有可调试的线程信息，包括 GDB 分配的线程 ID、系统级的线程标识符以及线程的栈信息等。切换线程可以使用 (gdb) thread thread_id，通过指定线程 ID 可以快速切换到对应的线程进行调试。此外，设置监视点可以使用 (gdb) watch variable_name，用于观察某个变量的值是否有变化，一旦变化程序会立即暂停。删除监视点则是 (gdb) delete watchpoints。\n编译多线程程序 在进行多线程调试之前，我们需要先编译多线程程序。通常，我们可以使用 gcc 编译器来编译多线程程序。例如，对于以下多线程程序代码：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define NUM_THREADS 5 void * thread_func(void * thread_id) { long tid = (long)thread_id; printf(\u0026#34;Hello World! It\u0026#39;s me, thread #%ld!\u0026#34;, tid); pthread_exit(NULL); } int main() { pthread_t threads[NUM_THREADS]; int rc; long t; for (t = 0; t \u0026lt; NUM_THREADS; t++) { printf(\u0026#34;In main: creating thread %ld\u0026#34;, t); rc = pthread_create(\u0026amp;threads[t], NULL, thread_func, (void *)t); if (rc) { printf(\u0026#34;ERROR; return code from pthread_create() is %d\u0026#34;, rc); return -1; } } pthread_exit(NULL); } 我们可以将上述代码保存至一个名为 multithread.c 的文件中，并使用以下命令进行编译：$ gcc -g -pthread -o multithread multithread.c。其中，-g 选项用于在可执行文件中加入调试信息，这样在使用 GDB 进行调试时可以获取更多的程序信息；-pthread 选项则用于引入多线程库，确保程序能够正确地使用多线程功能。\n多线程调试案例分析 # 简单多线程程序调试 假设我们有一个如下的简单多线程程序：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void *printNumbers(void *arg) { int i; for (i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;Thread: %d\\n\u0026#34;, i); } return NULL; } int main() { pthread_t thread1, thread2; pthread_create(\u0026amp;thread1, NULL, printNumbers, NULL); pthread_create(\u0026amp;thread2, NULL, printNumbers, NULL); pthread_join(thread1, NULL); pthread_join(thread2, NULL); return 0; } 我们可以使用以下步骤进行 GDB 调试：\n首先，编译程序：$ gcc -g -pthread -o simple_thread simple_thread.c 然后启动 GDB：$ gdb simple_thread 在 main 函数处设置断点：(gdb) break main 运行程序：(gdb) run，程序会停在 main 函数的断点处。 接着，我们可以使用 (gdb) info threads 查看当前的线程信息。可以看到有两个线程正在运行，一个是主线程，一个是其中一个子线程。 使用 (gdb) thread thread_id 切换到子线程，然后进行单步执行操作，如 (gdb) next，可以观察到子线程的执行过程。 复杂多线程程序调试 对于更复杂的多线程程序，比如多个线程之间存在交互和同步问题的程序，调试会更加具有挑战性。\n例如，有一个多线程程序，多个线程同时对一个共享资源进行读写操作，可能会出现竞争条件和数据不一致的问题。\n在这种情况下，我们可以使用 GDB 的以下技巧来处理：\n使用 (gdb) break function_name 在关键的同步函数处设置断点，如互斥锁的加锁和解锁函数。 通过 (gdb) info threads 随时查看线程状态，确定哪个线程正在持有共享资源，哪个线程在等待资源。 使用 (gdb) thread apply all bt 查看所有线程的调用堆栈，以了解每个线程的执行路径和当前状态。 设置条件断点，例如 (gdb) break function_name if condition，当特定条件满足时才触发断点，以便在复杂的交互场景中更精确地定位问题。 例如，假设我们有一个多线程的银行账户管理程序，多个线程同时进行存款和取款操作，我们可以在存款和取款函数处设置断点，并根据账户余额等条件设置条件断点，以便在出现异常情况时能够快速定位问题所在。\n多线程调试技巧 # 线程锁定与并发控制 在 GDB 中，可以使用 set scheduler-locking 命令来控制线程的执行顺序和并发程度。这个命令有三个值，分别是 on、step 和 off。\nset scheduler-locking on：可以用来锁定当前线程，只观察这个线程的运行情况，锁定这个线程时，其他线程处于暂停状态。在当前线程执行 next、step、until、finish、return 命令时，其他线程是不会运行的。需要注意的是，在使用这个选项时要确认当前线程是否是我们期望锁定的线程，如果不是，则可以使用 thread + 线程编号 切换到我们需要的线程，再调用 set scheduler-locking on 锁定。 set scheduler-locking step：也用来锁定当前线程，当且仅当使用 next 或 step 命令做单步调试时会锁定当前线程，如果使用 until、finish、return 等线程内的调试命令（它们不是单步控制命令），则其他线程还是有机会运行的。与 on 选项的值相比，step 选项的值为单步调试提供了更加精细化的控制，因为在某些场景下，我们希望单步调试时其他线程不要对所属的当前线程的变量值造成影响。 set scheduler-locking off：用于释放锁定当前线程。 我们还可以使用 show scheduler-locking 命令来显示线程的 scheduler-locking 状态。\n命令组合与高效调试 一些常用的 GDB 命令组合可以提高多线程调试的效率。例如：\ninfo threads + thread thread_id + bt：先使用 info threads 查看当前进程的所有线程信息，然后使用 thread thread_id 切换到特定线程，再使用 bt 查看该线程的函数调用堆栈，以便分析该线程的执行逻辑。 break function_name + condition + run + next/step：先使用 break function_name if condition 在特定函数处设置条件断点，然后使用 run 运行程序，当条件满足时程序会停在断点处，接着使用 next 或 step 进行单步调试。 thread apply all command：可以让所有被调试线程执行特定的 GDB 命令，例如 thread apply all bt 可以查看所有线程的调用堆栈。 常见问题与解决方案 在多线程调试过程中，可能会遇到以下常见问题：\n线程死锁：如果程序出现死锁，可以使用 GDB 的以下步骤进行分析。\n首先，使用 gdb 启动程序，然后在程序死锁处按 ctrl+c 暂停程序。接着，使用 info threads 查看当前节点上线程状态，使用 thread thread_id 切换线程，使用 bt 查看线程堆栈，并查处死锁位置。多切换几个线程，全面分析死锁的原因。一般来说，首先检查使用频率最高的锁在所有函数出口上是否已解锁。如果是第一轮出现死锁，则可检查锁配对和可能的程序出口上是否进行了开锁。如果多轮运行后出现，且基本确认函数出口均解锁，则需要判断是否是内存越界，可以使用工具 valgrind 进行内存越界诊断。\n无法确定当前调试的线程：可以使用 info threads 命令查看当前可调试的所有线程，每个线程会有一个 GDB 为其分配的 ID，前面有 * 的是当前调试的线程。也可以使用 thread thread_id 切换到特定线程进行确认。\n多线程程序调试效率低下：可以使用前面提到的命令组合和线程锁定功能，有针对性地调试特定线程或在特定条件下进行调试，提高调试效率。同时，可以将程序中的线程数量减少至 1 进行调试，观察是否正确，然后逐步增加线程数量，调试线程的同步是否正确。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/gdb-debugging-multi-threads-case-analysis/","section":"Softwares","summary":"\u003cp\u003e在软件开发的复杂世界里，高效的调试工具是解决问题的关键利器。今天，我们将深入探讨强大的调试工具 —— GDB（GNU Debugger）。GDB 为开发者提供了一种深入程序内部运行机制、查找错误和优化性能的有效途径。让我们一同开启 GDB 的调试之旅，解锁代码中的奥秘。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eGDB调试工具 \n    \u003cdiv id=\"gdb%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#gdb%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGDB（GNU Debugger）是强大的调试工具，在软件开发过程中起着至关重要的作用。它可以帮助开发者快速定位和解决程序中的问题。\u003c/p\u003e","title":"GDB调试多线程案例分析","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/multi-threads/","section":"Tags","summary":"","title":"Multi Threads","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/https/","section":"Tags","summary":"","title":"HTTPS","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/network/","section":"Tags","summary":"","title":"Network","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/series/software/","section":"Series","summary":"","title":"Software","type":"series"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/tcp/","section":"Tags","summary":"","title":"TCP","type":"tags"},{"content":" HTTP # 超文本传输协议 超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII形式给出；而消息内容则具有一个类似MIME的格式。这个简单模型是早期Web成功的有功之臣，因为它使开发和部署非常地直截了当。\nHTTP/3 # HTTP/3 是 HTTP 的下一个主要修订版本。它基于 QUIC 运行，QUIC 是一种专为移动互联网使用量大而设计的新传输协议。它依赖于 UDP 而不是 TCP，从而可以实现更快的网页响应速度。VR 应用需要更多带宽来渲染虚拟场景的复杂细节，并且可能会从迁移到由 QUIC 支持的 HTTP/3 中受益。\nHTTPS # 超文本传输协议安全版 HTTPS（Hypertext Transfer Protocol Secure），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。HTTPS 在HTTP 的基础下加入SSL，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP与 TCP 之间）。这个系统提供了身份验证与加密通讯方法。它被广泛用于万维网上安全敏感的通讯，例如交易支付等方面。\nWebSocket # WebSocket 是独立的、创建在 TCP 上的协议。Websocket 通过HTTP/1.1 协议的101状态码进行握手。为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手”（handshaking）。\nTCP # 传输控制协议 传输控制协议（TCP，Transmission Control Protocol）是为了在不可靠的互联网络上提供可靠的端到端字节流而专门设计的一个传输协议\nUDP # 用户数据报协议 UDP是一种无连接的、不可靠的、基于数据报的传输层通信协议。它追求的是传输速度而非可靠性，适用于对实时性要求较高但对数据完整性要求不高的场景。\nSMTP # 简单邮件传输协议 SMTP是一种用于发送电子邮件的协议，它规定了电子邮件在发送过程中的格式和传输方式。\nFTP # 文件传输协议 文件传输协议（File Transfer Protocol，FTP）是用于在网络上进行文件传输的一套标准协议，它工作在 OSI 模型的第七层，TCP 模型的第四层， 即应用层， 使用 TCP 传输而不是 UDP， 客户在和服务器建立连接前要经过一个“三次握手”的过程， 保证客户与服务器之间的连接是可靠的， 而且是面向连接， 为数据传输提供可靠保证。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/8-popular-network-protocols/","section":"Softwares","summary":"\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./8-Popular-Network-Protocols.gif\" alt=\"8 Popular Network Protocols\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eHTTP \n    \u003cdiv id=\"http\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#http\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cblockquote\u003e超文本传输协议\u003c/blockquote\u003e\n\u003cp\u003e超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII形式给出；而消息内容则具有一个类似MIME的格式。这个简单模型是早期Web成功的有功之臣，因为它使开发和部署非常地直截了当。\u003c/p\u003e","title":"一张图解释 8 种流行网络协议","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/space/","section":"Tags","summary":"","title":"Space","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/windows-11/","section":"Tags","summary":"","title":"Windows 11","type":"tags"},{"content":"是不是经常看到“C盘空间不足”的烦人提示？C盘满了，不仅会影响系统的运行速度，还可能导致更新失败或软件崩溃。其实，只需要几步简单设置，就能大大减少C盘的压力，让你的电脑快起来！下面就分享如何让系统不再占用C盘空间，轻松释放宝贵C盘空间！\n转移用户文件夹到其他分区 # C盘不仅安装系统，许多用户文件（如桌面、文档、下载等）也都默认保存在这里，久而久之占用大量空间。解决办法很简单，直接把这些文件夹挪到D盘或其他分区就好。\n操作步骤： # 在桌面上找到“文档”或“下载”文件夹，右键选择“属性”。\n切换到“位置”选项卡，点击“移动”按钮。\n选择一个其他分区的文件夹（如D盘的某个文件夹），点击“确定”。\n系统会提示是否将已有文件移动到新位置，点击“是”即可。\n这样，今后保存到桌面、文档、下载等地方的文件都会自动放在D盘，再也不用担心C盘空间不够用了！\n改变软件默认安装位置 # 很多软件在安装时，都会默认装到C盘的 Program Files 文件夹，特别是游戏或设计类软件，一装就是好几GB！其实我们可以改变软件的安装路径，让软件装到D盘。\n操作步骤： # 按下 Win + I 打开“设置”。\n点击“系统” -\u0026gt; “存储”，选择“更改新内容的保存位置”。\n在“新应用将保存到”选项中，将C盘改为其他分区，如D盘。\n此后，安装的软件会默认放在D盘，而不是C盘。不过，注意某些软件安装时仍然会让你手动选择安装位置，请记得检查一下！\n将虚拟内存和临时文件转移到其他分区 # Windows为了提高性能，会使用虚拟内存文件以及存储大量的临时文件，它们默认都放在C盘，逐渐占据了不少空间。我们可以轻松将这些文件转移到其他分区。\n转移虚拟内存 # 操作步骤： # 右键点击“此电脑”，选择“属性”。\n在左侧选择“高级系统设置”。\n在“性能”部分点击“设置”，切换到“高级”选项卡，点击“更改”。\n取消“自动管理所有驱动器的分页文件大小”，选择C盘，设置为“无分页文件”，再选择其他分区，设置为“系统管理的大小”。\n点击“确定”并重启电脑。\n转移临时文件 # 操作步骤： # 按下 Win + R 打开“运行”，输入 sysdm.cpl 并回车\n在“高级”选项卡中，点击“环境变量”\n在“用户变量”部分找到 TEMP 和 TMP，分别点击“编辑”\n将它们的路径修改到D盘或其他分区的文件夹，比如 D:\\Temp\n这样，虚拟内存和临时文件都会存储在其他分区，C盘的空间将大大节省。\n关闭休眠功能释放C盘空间 # Windows的休眠功能会在C盘创建一个巨大的文件 hiberfil.sys，有时候这个文件甚至能占用几GB空间。如果你平时很少用休眠功能，可以直接关闭它，释放这块空间。\n操作步骤： # 按下 Win + X，选择“命令提示符（管理员）”。\n在窗口中输入以下命令并按回车：\npowercfg -h off 完成后，休眠功能将被关闭，并且 hiberfil.sys 文件会被删除，立马释放出几个GB的C盘空间。 定期清理系统垃圾文件 # 即使我们做了上述优化，Windows系统在使用过程中仍会产生各种缓存和垃圾文件，定期清理这些文件能让C盘更干净。\n操作步骤： # 打开“此电脑”，右键C盘，选择“属性”。\n点击“磁盘清理”，系统会扫描可清理的文件。\n勾选“临时文件”、“回收站”等选项，点击“确定”进行清理。\n你还可以点击“清理系统文件”，这样能清理到更多的系统缓存和无用文件。\n通过这几步简单设置，C盘不再是系统的唯一战场。转移用户文件、改变软件安装路径、管理虚拟内存和临时文件，再加上定期清理，C盘空间告急的烦恼就能轻松解决。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/free-up-space-on-c-drive-in-windows/","section":"Softwares","summary":"\u003cp\u003e是不是经常看到“C盘空间不足”的烦人提示？C盘满了，不仅会影响系统的运行速度，还可能导致更新失败或软件崩溃。其实，只需要几步简单设置，就能大大减少C盘的压力，让你的电脑快起来！下面就分享如何让系统不再占用C盘空间，轻松释放宝贵C盘空间！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e转移用户文件夹到其他分区 \n    \u003cdiv id=\"%E8%BD%AC%E7%A7%BB%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%E5%85%B6%E4%BB%96%E5%88%86%E5%8C%BA\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%BD%AC%E7%A7%BB%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%B0%E5%85%B6%E4%BB%96%E5%88%86%E5%8C%BA\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eC盘不仅安装系统，许多用户文件（如桌面、文档、下载等）也都默认保存在这里，久而久之占用大量空间。解决办法很简单，直接把这些文件夹挪到D盘或其他分区就好。\u003c/p\u003e\n\n\n\u003ch3 class=\"relative group\"\u003e操作步骤： \n    \u003cdiv id=\"%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e在桌面上找到“文档”或“下载”文件夹，右键选择“属性”。\u003c/p\u003e","title":"如何释放Windows 的C 盘空间","type":"software"},{"content":"本文介绍20个能够大大提升Windows 11操作效率的快捷键，掌握这些快捷键能让你的工作和学习事半功倍！\n启动文件资源管理器 # Windows键 + E 如果你像我一样，经常使用文件资源管理器。使用键盘快捷键，只需按Windows键 + E，就可以在你需要时随时启动一个新的文件资源管理器窗口。\n直接进入任务管理器 # Ctrl + Shift + Esc 你可能知道基本的Ctrl + Alt + Delete快捷键，但如果你用它来打开任务管理器，实际上有一个更好的方法：使用Ctrl + Shift + Esc快捷键。\n打开设置 # Windows键 + I 想要更改操作系统中的设置吗？不必在开始菜单中搜索，实际上有一个你可以使用的键盘快捷键：Windows键 + I，然后，你可以在设置应用中直接搜索你需要的内容。\n查阅剪贴板历史 # Windows键 + V 你知道每次你将图像或文本复制到剪贴板时，Windows都会保存它们的运行历史吗？通常的Ctrl + V快捷键只粘贴你最后复制的项目——但如果你想要粘贴你很久以前复制的东西， 你所要做的只是用Windows键 + V快捷键调出剪贴板历史。如果你以前从未打开过，系统会提示你授予权限以激活该功能。\n剪贴板历史的优点在于，你甚至可以将某些复制的项目固定到面板上，使它们在将来更容易找到。\n在任何地方插入表情符号 # Windows键 + 分号 表情符号已经成为现代通信的一部分——微软知道这一点， 你所要做的只是按Windows键 + 分号快捷键。\n语音输入 # Windows键 + H Windows允许你在几乎任何应用程序中使用语音输入。要调出语音输入界面，只需按Windows键 + H，你会看到一个浮动的窗口（在Windows 11上）或一个栏（在Windows 10上）。\n你可以在窗口/栏的设置菜单中激活自动标点等功能。\n超级用户菜单 # Windows键 + X 当微软在Windows 8中取消了开始菜单时，他们至少还给了超级用户一个面子：隐藏的“超级用户菜单”，可以快速访问各种系统设置。\n在Windows 11，也有超级用户菜单。要打开它，可以使用按Windows键 + X\n锁定你的电脑 # Windows键 + L 为了保护你的电脑免受未经授权的访问——特别是在办公室环境中——你应该在离开时锁定电脑。只需按Windows键 + L快捷键。\n控制声音设置 # Ctrl + Windows键 + V 如果你有多个声音输出设备（例如，扬声器、耳机、无线耳塞）或多个声音输入设备（例如，笔记本麦克风、耳机、外部麦克风），你可能经常在它们之间切换。\n实际上，只需按Ctrl + Windows键 + V 快捷键即可调出声音设置菜单。\n这也可以用来调整系统音量和每个应用的音量（使用滑块），并且是快速进入设置应用的声音部分（通过点击更多音量设置）的一种方式。\n拖拽窗口 # Windows键 +箭头 Snap功能是Windows 11中进行多任务处理的窗口管理工具。你可以轻松地将应用程序窗口“拖拽”到屏幕边缘。\n首先，使用Windows键 + 左箭头和Windows键 + 右箭头将当前聚焦的窗口拖拽到屏幕的左半边或右半边。类似地，使用Windows键 + Alt + 上箭头和Windows键 + Alt + 下箭头将窗口拖拽到屏幕的上方或下方的一半。\n你还可以使用快捷键将窗口移动到屏幕的四个象限。例如，在使用上述快捷键将窗口拖拽到左侧一半后，保持按住Windows键并点击上箭头，将其拖拽到左上象限。\n激活Snap布局 # Windows键 + Z 就像Snap本身已经很有用一样，Windows 11还有一个额外的Snap布局功能，可以更容易地将窗口拖拽到各种配置中。\n要激活Snap布局，使用Windows键 + Z 快捷键。你会看到一个带有编号的弹出窗口——只需按相应的数字键选择该窗口布局。\n你还可以通过将鼠标指针悬停在窗口的最大化按钮上来查看Snap布局。或者，将任何窗口拖拽到屏幕中心顶部的边缘以查看Snap选项。\n在PC游戏中在窗口模式和全屏模式之间切换 # Alt + Enter 许多PC游戏提供窗口模式和全屏模式。如果你想要在这两种模式之间切换，频繁地导航到游戏设置菜单可能会相当麻烦。\n以下是在许多PC游戏中快速在窗口模式和全屏模式之间切换的方法：只需按Alt + Enter，这并不适用于所有游戏，但在许多游戏中都有效。\n在虚拟桌面之间切换 # Windows 11有一个名为任务视图的功能，让你可以创建可以切换的“虚拟桌面”。虚拟桌面就像是“桌面”的单独实例，每个虚拟桌面可以容纳自己的一组运行中的应用窗口。\n任务视图体验有几个键盘快捷键，如Windows键 + Tab，可以轻松创建新的虚拟桌面，删除现有的虚拟桌面，并在它们之间切换。\n但是一旦你创建了一些虚拟桌面，更简单的方法是使用Windows键 + Ctrl + 左箭头和Windows键 + Ctrl + 右箭头 快捷键在它们之间切换。\n在显示器之间移动窗口 # Windows键 + Shift + 箭头 你可以通过按Windows键 + Shift + 左箭头（将当前聚焦的窗口移动到左侧显示器）或Windows键 + Shift + 右箭头（将当前聚焦的窗口移动到右侧显示器）来在显示器之间移动窗口。\n打开经典的文件资源管理器上下文菜单 # 在Windows 11上，文件资源管理器从以前的版本改变了很多，特别是有一个简化的上下文菜单。但有些选项只有在那个经典的、老式的上下文菜单中才能找到。\n你可以实际上使用键盘快捷键立即打开旧的上下文菜单：在文件资源管理器中右键点击时按住Shift键以查看经典上下文菜单。\n快速编辑文本 # 按住Ctrl键可以使大多数键对整个单词而不是单个字符起作用。\n例如，Backspace键删除前一个字符，但Ctrl + Backspace删除前一个单词。另一个例子，左箭头和右箭头键将光标移动一个字符，但Ctrl + 左箭头和Ctrl + 右箭头将光标从单词移动到单词。\n它与Shift键也一起工作。按住Shift键时，你可以随着光标的移动高亮文本——所以，如果你想要快速高亮多个连续的单词，只需按住Ctrl + Shift，然后点击左箭头和右箭头键。（尝试与Home和End键一起按Shift键，就高亮整行文本！）\n重新打开已关闭的浏览器标签页 # Ctrl + Shift + T 所有浏览器——包括Chrome、Firefox、Opera和Edge——都允许你快速重新打开已关闭的标签页。也很容易记住：如果Ctrl + T键盘快捷键创建一个新标签页，那么Ctrl + Shift + T快捷键重新打开最后一个关闭的标签页。\n反向Alt + Tab # Alt + Tab是Windows中最经典的键盘快捷键之一。但是，如果你有很多打开的窗口要循环浏览，有时反向循环可能更有意义。在这种情况下，只需按Shift + Alt + Tab以反向浏览打开窗口的列表。\n当Alt + Tab对话框打开时，你还可以使用箭头键立即跳转到所选缩略图窗口。\n快速重命名文件 # 在文件资源管理器中选择文件后，只需按F2，输入名称，然后按Enter。\n我喜欢使用箭头键在文件之间导航，然后使用F2键快速重命名它们。或者更好的方法是：按下F2并输入文件名后，按Tab键（而不是Enter键），立即开始重命名文件夹中的下一个文件。\n将屏幕截图保存为文件 # 内置的Windows屏幕截图工具已经变得更好了，但有时你可能想要跳过工具，立即保存为图像文件。\n要直接将屏幕截图保存到本地，按Windows键 + Print Screen，屏幕会闪烁，Windows会将屏幕截图保存下来。之后，你可以在图片文件夹中的Screenshots文件夹找到屏幕截图。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/20-very-useful-windows-11-shortcuts/","section":"Softwares","summary":"\u003cp\u003e本文介绍20个能够大大提升Windows 11操作效率的快捷键，掌握这些快捷键能让你的工作和学习事半功倍！\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e启动文件资源管理器 \n    \u003cdiv id=\"%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWindows键 + E\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e如果你像我一样，经常使用文件资源管理器。使用键盘快捷键，只需按\u003ccode\u003eWindows键 + E\u003c/code\u003e，就可以在你需要时随时启动一个新的文件资源管理器窗口。\u003c/p\u003e","title":"20 个非常有用的Windows 11快捷键","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/shortcut/","section":"Tags","summary":"","title":"Shortcut","type":"tags"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/gitui/","section":"Tags","summary":"","title":"GitUI","type":"tags"},{"content":"在软件开发的世界中，版本控制是不可或缺的一部分。Git，作为最流行的版本控制系统之一，已经深入到每个开发者的日常工作中。\n尽管 Git 命令行工具功能强大，但有时候，我们也需要一个更直观、更易用的用户界面来提高效率。\n今天，我们将探索一个名为 gitui 的项目，它旨在为 Git 用户提供一个快速、直观且完全在终端内操作的界面。\ngitui：不仅仅是一个界面 # gitui 是一个用 Rust 语言编写的终端界面程序，专为 Git 设计。它不仅仅是一个简单的图形界面，而是一个全面的工具，旨在提供以下特性：\n快速且直观的键盘控制：gitui 允许用户完全通过键盘操作，无需鼠标，大大提高了操作速度。 基于上下文的帮助系统：用户无需记忆复杂的快捷键，gitui 提供了即时的上下文帮助，让操作变得简单直观。 全面的 Git 功能支持：包括提交、暂存、回滚、分支管理、日志浏览等，几乎涵盖了 Git 的所有核心功能。 性能：不仅仅是快速 # 在大型仓库中，传统的 Git 图形界面可能会变得缓慢甚至无响应。gitui 通过异步 Git API 和优化的内存管理，确保了即使在处理大型项目时也能保持流畅的操作体验。在一次性能测试中，gitui 在解析包含超过 900k 提交的 Linux 仓库时，表现出了卓越的性能。\n安装：简单快捷 # gitui 的安装过程非常简单。用户可以通过 Rust 的包管理工具 cargo 轻松安装。此外，gitui 还提供了预编译的二进制文件，支持 Linux、macOS 和 Windows 系统，使得安装过程更加快捷。\n定制：个性化你的工作流 # gitui 支持用户自定义配置，包括颜色主题和按键绑定。用户可以根据自己的喜好和习惯，调整界面和操作方式，使其更加符合个人的工作流。\n社区与支持 # gitui 是一个开源项目，拥有活跃的社区支持。用户可以通过 GitHub 提交问题、参与讨论或贡献代码。\n结语 # gitui 为 Git 用户提供了一个强大而灵活的工具，它不仅提高了工作效率，还增强了用户体验。无论是新手还是资深开发者，gitui 都能成为你日常工作中的得力助手。如果你还没有尝试过 gitui，现在是时候给它一个机会，体验 Git 的全新世界了。\n","date":"2024-10-19","externalUrl":null,"permalink":"/software/gitui-terminal-ui-for-git/","section":"Softwares","summary":"\u003cp\u003e在软件开发的世界中，版本控制是不可或缺的一部分。Git，作为最流行的版本控制系统之一，已经深入到每个开发者的日常工作中。\u003c/p\u003e\n\u003cp\u003e尽管 Git 命令行工具功能强大，但有时候，我们也需要一个更直观、更易用的用户界面来提高效率。\u003c/p\u003e\n\u003cp\u003e今天，我们将探索一个名为 gitui 的项目，它旨在为 Git 用户提供一个快速、直观且完全在终端内操作的界面。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003egitui：不仅仅是一个界面 \n    \u003cdiv id=\"gitui%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E4%B8%80%E4%B8%AA%E7%95%8C%E9%9D%A2\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#gitui%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E4%B8%80%E4%B8%AA%E7%95%8C%E9%9D%A2\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003egitui 是一个用 Rust 语言编写的终端界面程序，专为 Git 设计。它不仅仅是一个简单的图形界面，而是一个全面的工具，旨在提供以下特性：\u003c/p\u003e","title":"GitUI: Git 在终端下的UI","type":"software"},{"content":"","date":"2024-10-19","externalUrl":null,"permalink":"/tags/rust/","section":"Tags","summary":"","title":"Rust","type":"tags"},{"content":"","date":"2024-10-18","externalUrl":null,"permalink":"/tags/antivirus/","section":"Tags","summary":"","title":"Antivirus","type":"tags"},{"content":"","date":"2024-10-18","externalUrl":null,"permalink":"/tags/clamav/","section":"Tags","summary":"","title":"ClamAV","type":"tags"},{"content":"虽然 Linux 系统因其安全性和稳健性而被广泛使用，但安装杀毒软件依然是明智的，尤其是在与 Windows 系统共享文件或经常下载未知文件时。\n本文主要介绍如何在 Linux 系统上安装免费的杀毒软件。\n选择合适的免费杀毒软件 # Linux 上流行的免费杀毒软件：\nClamAV：最为知名的开源免费杀毒软件，支持多种 Linux 发行版。它可以扫描病毒、恶意软件以及 Windows 系统上的威胁。 Sophos Antivirus for Linux：虽然是商业软件，但 Sophos 提供了 Linux 版本的免费版，能够检测到多平台的威胁。 Chkrootkit 和 Rkhunter：用于检测系统中的 rootkit 威胁，这些工具可以与其他杀毒软件结合使用，增强系统的安全性。 本文以 ClamAV 为例进行安装和使用的演示，因为它开源且易于配置，适合个人用户和企业环境。\n安装 ClamAV # 首先，更新系统的软件包，并安装 ClamAV。\nUbuntu/Debian 系统：\nsudo apt update sudo apt install clamav clamav-daemon CentOS/RHEL 系统：\n如果使用的是 CentOS 或 RHEL，请执行以下命令：\nsudo yum install epel-release sudo yum install clamav clamav-update Arch Linux 系统：\nArch Linux 用户，执行以下命令：\nsudo pacman -S clamav 更新病毒库 # ClamAV 的病毒库是需要定期更新的，这样它才能识别最新的威胁。安装完 ClamAV 后，首先要更新病毒库。\nsudo freshclam 将下载最新的病毒定义数据库。在大多数系统中，freshclam 会自动更新病毒库，也可以将其添加到定时任务中确保持续更新。\n配置和启动 ClamAV # 为了让 ClamAV 在后台自动扫描文件，我们需要启动 clamav-daemon 服务。\nsudo systemctl start clamav-daemon sudo systemctl enable clamav-daemon 查看运行状态：\nsudo systemctl status clamav-daemon 当我们想要手动扫描时，也可以使用 clamdscan 工具，它会与 clamav-daemon 一起工作，从而减少扫描时间。\n执行手动扫描 # ClamAV 允许你扫描特定目录或文件。以下是一些常用的扫描命令：\n扫描整个系统：\nsudo clamscan -r / 扫描指定目录：\nsudo clamscan -r /path/to/directory -r 参数表示递归扫描文件夹，扫描会包含文件夹内的所有文件。如果希望 ClamAV 在检测到感染文件后自动删除它们，可以使用 `--remove` 参数： sudo clamscan -r --remove /path/to/directory 扫描后的报告输出到文件：\n如果你希望保存扫描结果，可以通过以下命令将报告输出到文件中：\nsudo clamscan -r /path/to/directory \u0026gt; /path/to/report.txt 定时自动扫描 # 可以设置定时任务，让 ClamAV 每天自动扫描指定目录。使用 crontab 进行设置：\nsudo crontab -e 在文件中添加以下内容，设置每天凌晨 2 点自动扫描 /home 目录：\n0 2 * * * /usr/bin/clamscan -r /home --log=/var/log/clamav-scan.log 安全增强（可选） # 还可以结合使用 chkrootkit 或 rkhunter 来检测系统中潜在的 rootkit 威胁：\n安装 Chkrootkit： # sudo apt install chkrootkit sudo chkrootkit 安装 Rkhunter： # sudo apt install rkhunter sudo rkhunter --check 这些工具可以与 ClamAV 配合使用，提供更加全面的安全防护。\n监控与日志 # ClamAV 会在 /var/log/clamav 中生成日志文件，可以通过以下命令查看最近的扫描日志：\ncat /var/log/clamav/clamav.log 根据日志文件中的信息，可以进一步分析潜在的威胁。\n在 Linux 系统上安装杀毒软件，尤其是 ClamAV，是一个简单而有效的安全措施。虽然 Linux 本身相对安全，但额外的防护手段可以减少潜在的安全威胁，特别是在与其他系统共享文件时。通过定期更新病毒库、手动或自动扫描文件、并结合其他安全工具，用户可以确保其系统得到最全面的保护。\n按照本指南，您现在可以在 Linux 系统上有效地安装并运行 ClamAV，确保系统的安全性。\n","date":"2024-10-18","externalUrl":null,"permalink":"/software/installing-free-antivirus-software-on-linux/","section":"Softwares","summary":"\u003cp\u003e虽然 Linux 系统因其安全性和稳健性而被广泛使用，但安装杀毒软件依然是明智的，尤其是在与 Windows 系统共享文件或经常下载未知文件时。\u003c/p\u003e\n\u003cp\u003e本文主要介绍如何在 Linux 系统上安装免费的杀毒软件。\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e选择合适的免费杀毒软件 \n    \u003cdiv id=\"%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%85%8D%E8%B4%B9%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%85%8D%E8%B4%B9%E6%9D%80%E6%AF%92%E8%BD%AF%E4%BB%B6\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLinux 上流行的免费杀毒软件：\u003c/p\u003e","title":"在 Linux 系统上安装免费杀毒软件","type":"software"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/gddr/","section":"Tags","summary":"","title":"GDDR","type":"tags"},{"content":" 什么是GDDR内存？ # GDDR代表Graphics Double Data Rate ，是一种专门为显卡设计的内存。GDDR内存与大多数计算机使用的DDR内存相似，但它针对显卡的使用进行了优化。GDDR内存通常比DDR内存带宽更高，这意味着它可以一次传输更多数据。\nGDDR6是GPU的最新内存标准，per-pin数据速率峰值为16Gb/s。GDDR6在包括NVIDIA RTX 6000 Ada和AMD Radeon PRO W7900在内的大多数GPU中使用，仍然用于2024年的GPU。\nNVIDIA还与美光合作开发GDDR6X，这是GDDR6的继任者。我们这样说是因为除了从NRZ到PAM4的编码外，两者之间没有任何硬件变化，并且由于NVIDIA是唯一的用户，JEDEC行业标准化没有认可。DDR6X将per-pin带宽提高到21Gb/s。GDDR7是下一个应该被所有人广泛采用的GDDR标准。\n截至2024年，GDDR6和GDDR6X的最大内存总线为384位。GDDR内存是焊接到GPU芯片周围的PCB上的单个芯片。\n什么是HBM内存？ # HBM代表高带宽内存，是一种专门为GPU开发的新型内存。\nHBM内存旨在提供比GDDR内存更大的内存总线宽度，这意味着它可以一次传输更多数据。单个HBM内存芯片不如单个GDDR6芯片快，但这使得它比GDDR内存更节能，这对移动设备来说是一个重要的考虑因素。\nHBM内存位于GPU封装内并堆叠——例如，HBM有四个DRAM（4-Hi）的堆栈，每个有两个128位通道，总宽度为1024位（4个2个通道128位）。由于HBM内存作为内存芯片模块内置在GPU芯片中，因此错误和空间更少。因此，单个GPU不容易像配备GDDR的GPU那样易于扩展内存配置。\n最新采用最多的HBM内存是NVIDIA H100中的HBM3，具有5120位总线和超过2TB/s的内存带宽。HBM3也存在于竞争对手的AMD Instinct MI300X中，具有8192位总线和超过5.3TB/s的内存带宽。英伟达还在其GH200和H200中引入了新的HBM3e内存，作为第一批使用HBM3e的加速器和处理器，具有更大的内存带宽。这些配备HBM内存的硬件正在快速翻新。H100和MI300X等加速器GPU需要HBM的一个重要原因是多个GPU之间的互连性；为了相互通信，宽总线宽度和快速的数据传输速率对于减少将数据从一个GPU传输到另一个GPU的瓶颈至关重要。\nGDDR与HBM内存 # 那么，哪种类型的内存更适合GPU？答案是，这取决于具体的场景。\n配备GDDR内存的GPU通常是：\n更容易访问，因为它们是主流的GPU类型 更便宜，因为GDDR直接焊接在PCB上，而不是GPU封装上。 大多数主流应用程序不会最大化内存带宽。 但GDDR通常消耗更多的能源，效率不那么高。 配备HBM内存的GPU通常是：\n更不容易获得，更利基 非常昂贵，在H100等旗舰加速器中发现。 仅用于需要最多带宽的HPC和高利基工作负载 高效，并提供更大的总线宽度，以并行化每引脚速率。 大多数应用程序不需要HBM内存。对于利用大量数据的工作负载来说，更高的内存带宽是最重要的。仿真、实时分析、密集的人工智能训练、复杂的人工智能推理等工作负载都可以从使用更多的内存带宽中受益。\n同样重要的是要考虑，如果工作负载相互并行，配备GDDR的最快GPU可以正常工作。NVIDIA RTX 6000 Ada是一款功能强大的旗舰GPU，非常适合中小型人工智能训练、渲染、分析、模拟和数据密集型工作负载，内存带宽为960GB/s。插槽具有多GPU设置的服务器或工作站，工作可以并行化和拆分，以获得更高的性能。\n然而，像NVIDIA H100这样的HBM配备GPU可以显著提高企业部署的生产力（尽管成本很高）。更高的性能和更少的等待可以实现更快的突破。ChatGPT等部署利用H100集群协同工作，在给定时间为数百万用户执行实时推理和生成人工智能功能，处理提示并交付实时输出。\n如果没有快速的高带宽内存和峰值性能，企业部署可能会变得非常缓慢，几乎无法使用。一个很好的例子是ChatGPT的发布月份。ChatGPT和OpenAI可能认为他们有足够的HBM启用的NVIDIA GPU来处理大量并发用户，但不知道他们新的生成式AI聊天机器人将有多受欢迎。他们不得不对并发用户数量设置上限，要求网站访问者在扩展基础设施时对服务保持耐心。然而，从这个角度来看，如果没有使用这些高带宽内存互连的GPU，ChatGPT甚至可能是不可能的。\n结论 # 总之，GDDR内存和HBM内存都有其优点和缺点。GDDR内存更便宜，对于需要高带宽但不需要绝对最高性能的应用程序来说是一个不错的选择。另一方面，HBM内存更昂贵，但提供更高的带宽，是需要高性能的应用程序的不二之选。在这两种类型的内存之间进行选择时，重要的是要考虑场景和成本。\n","date":"2024-10-17","externalUrl":null,"permalink":"/hardware/difference-between-gddr-memory-vs-hbm-memory/","section":"Hardwares","summary":"\u003ch2 class=\"relative group\"\u003e什么是GDDR内存？ \n    \u003cdiv id=\"%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AFgddr%E5%86%85%E5%AD%98\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eGDDR代表Graphics Double Data Rate ，是一种专门为显卡设计的内存。GDDR内存与大多数计算机使用的DDR内存相似，但它针对显卡的使用进行了优化。GDDR内存通常比DDR内存带宽更高，这意味着它可以一次传输更多数据。\u003c/p\u003e","title":"GDDR 与 HBM 内存之间的区别","type":"hardware"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/series/hardware/","section":"Series","summary":"","title":"Hardware","type":"series"},{"content":"AMD经常详细介绍已经发布了一段时间的产品。在Hot Chips 2024上，AMD详细介绍了Instinct MI300X。我们知道MI325X很快就会发布。尽管如此，这仍然是NVIDIA GPU之外唯一一个在AI行业每年销售达到数十亿美元的GPU。AMD上周刚刚收购了生产Microsoft Azure MI300X平台的ZT系统公司。\nHot Chips 2024上展示的AMD Instinct MI300X架构 # AMD 的幻灯片看起来很不错，因此让大家阅读它们，并在讲解过程中添加一些色彩。\nMI300A主要应用于惠普的El Capitan等超级计算机。看起来MI300X是今年该系列40多亿美元收入的主要来源。\nAMD有一个有192MB的HBM3，用于计算等应用的multi-chiplet芯片：\n这是AMD CDNA 3结构的演变：\nAMD拥有8-stack HBM3内存阵列，容量达到192GB。\n下面是用于计算的XCD、Infinity Cache、Infinity Fabric和8个HBM封装的框图。\n下面是缓存和内存层次结构。我们不仅可以看到192GB的HBM3，还可以看到256MB的Infinity缓存，8*4MB的L2缓存等。\nMI300X可以作为单个分区运行，也可以在不同的内存和计算分区中运行。\nAMD目前的大平台是8路MI300X OAM平台。\n这是Instinct系统路线图。MI200在OAM板上也看到了，但它为单个GPU。\n以下是AMD对NVIDIA HGX平台的回答。\n每个GPU有7条链路用于直接连接以及主机链路。\nRAS在大规模AI集群中是一件大事。\n这是AMD的服务器。微软/ ZT系统的MI300平台在这里没有提到。令人失望的是，戴尔仍然没有在其AI平台中提供EPYC。同样明显缺失的还有Wiwynn平台。\nAMD谈论ROCm，它正在变得越来越好。\n在某些情况下，AMD可以击败NVIDIA H100。当然，现在人们开始更频繁地部署NVIDIA H200，AMD方面也致力于MI325X。所以两家公司产品性能的对比可以交给时间来检验。\n这是MPT微调，据AMD称和H100性能相当。\n总结 # MI300X是AMD 2023年的设计，现在它将与H100正面交锋，我们预计两者将在不久的将来被更高内存的版本所取代。据了解，该公司今年会推出MI325X，2025年将推出Instinct MI350 288GB GPU。\n尽管如此，AMD凭借数十亿美元的产品线，已经巩固了自己在AI GPU领域仅次于NVIDIA的地位。\n","date":"2024-10-17","externalUrl":null,"permalink":"/hardware/amd-instinct-mi300x-architecture-at-hot-chips-2024/","section":"Hardwares","summary":"\u003cp\u003eAMD经常详细介绍已经发布了一段时间的产品。在Hot Chips 2024上，AMD详细介绍了Instinct MI300X。我们知道MI325X很快就会发布。尽管如此，这仍然是NVIDIA GPU之外唯一一个在AI行业每年销售达到数十亿美元的GPU。AMD上周刚刚收购了生产Microsoft Azure MI300X平台的ZT系统公司。\u003c/p\u003e\n\n\n\u003ch1 class=\"relative group\"\u003eHot Chips 2024上展示的AMD Instinct MI300X架构 \n    \u003cdiv id=\"hot-chips-2024%E4%B8%8A%E5%B1%95%E7%A4%BA%E7%9A%84amd-instinct-mi300x%E6%9E%B6%E6%9E%84\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#hot-chips-2024%E4%B8%8A%E5%B1%95%E7%A4%BA%E7%9A%84amd-instinct-mi300x%E6%9E%B6%E6%9E%84\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\u003cp\u003eAMD 的幻灯片看起来很不错，因此让大家阅读它们，并在讲解过程中添加一些色彩。\u003c/p\u003e","title":"AMD Instinct MI300X 架构亮相 Hot Chips 2024","type":"hardware"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/instinct/","section":"Tags","summary":"","title":"Instinct","type":"tags"},{"content":"","date":"2024-10-17","externalUrl":null,"permalink":"/tags/mi300x/","section":"Tags","summary":"","title":"Mi300X","type":"tags"},{"content":"AMD、Intel之间的服务器与数据中心处理器大战硝烟再起，战况空前！\nIntel正在陆续发布全新设计的第六代至强6系列，AMD则祭出了同样全新的第五代EPYC 9005系列，可谓针尖对麦芒。\n曾经，AMD在服务器与数据中心市场上几近消失；曾经，Intel几乎完全垄断了整个行业。\n七年来，双方进行了一次又一次激烈交锋，AMD无疑气势更盛，无论产品发布节奏还是规格性能提升，都步步为营，一点一点改变了行业格局，第三方机构统计显示市场份额已经达到34％，合作生态也日渐繁荣。\nIntel在对手的强势挑战之下，也是一路马不停蹄，一度因产品延期导致的混乱也终于过去，正在重新起航。\n这一次，双方都是有备而来，都是气势如虹，究竟谁更胜一筹呢？\n架构设计：都是“大小核” 但又截然不同 # 有趣的是，AMD、Intel都将所谓的“大小核”架构设计引入到了数据中心，但具体做法是完全不同的，这也直接导致双方产品的实际表现迥异。\nAMD的做法是“同构大小核”，之前的第四代EPYC率先吃螃蟹，首次划分出了Zen 4、Zen 4c两个版本，分别对应Genoa EPYC 9004系列、Bergamo EPYC 97x4系列两条产品线。\nZen 4、Zen 4c都基于完全相同的底层微架构，拥有完全相同的IPC性能、ISA指令集、技术特性，唯一的不同就是后者三级缓存更少一些，主频更低一些，同样的5nm工艺下核心面积缩小了大约35％之多。\n对于操作系统和应用软件来说，不需要考虑二者的不同，也不需要专门的适配与优化，可一视同仁，只是将它们用在不同的负载和场景而已，其中Zen 4是常规的通用计算，Zen 4c则主攻高密度云计算。\n第五代EPYC延续了这一理念，并进行了全面升级。\n其中，Zen 5部分升级为4nm工艺，CCD模块从12个增至16个，整体从96核心192线程增至128核心256线程(每CCD还是8个)，三级缓存也从384MB增至512MB(每核心还是4MB)。\nZen 5c部分更是升级为3nm工艺，使得核心面积进一步缩小，可以容纳更多核心，CCD模块从8个增至12个，整体从128核心256线程增至192核心384线程(每CCD还是16个)，三级缓存则从256MB增至384MB(每核心还是2MB)。\nAMD暂未公布Zen 5、Zen 5c的具体核心面积，但相信会和上代类似，至少也得差个1/3。\nIntel走的则是“异构大小核”，在至强历史上首次兵分两路，为此放弃了延续五代的“至强可扩展”的名号，改为更简单直接的“至强6”。\n至强6 6000E系列代号Sierra Forest，首次将E核(能效核)引入数据中心，而且只有E核，专门针对高密度运算、可扩展负载。\n至强6 6000P系列代号Granite Rapids，只使用传统的P核(性能核)，主打高性能计算、AI负载场景。\n它们都延续了以往的分离式模块化架构，其中核心计算模块升级为Intel 3制造工艺(可以粗略地认为大致等于3nm)。\n至强6 E系列首发只有一种计算模块，144核心144线程——是的不支持超线程。\n至强6 P系列则有四种计算模块配置：单个小模块16核心32线程、单个大模块48核心96线程、两个大模块96核心192线程、三个大模块128核心256线程(理论上应该是屏蔽了4个核心以保证良品率)。\n至强6两条线的架构设计截然不同，规格、性能自然差异极大，不过还好，二者共享统一的软件开发平台，从而便于部署。\n有趣的是，这是AMD EPYC诞生七年来，Intel第一次在核心数量上追平了AMD，当然只是说完整大核版本，都是128核心。\n在“小核”方面，AMD仍然多出48个，还是高性能架构，还有超线程，还有更多……\n产品布局：128核心大战128核心、384线程大战288线程 # 接下来，我们看看双方第一批新品的产品线布局，也是很有趣，同样走了截然不同的路线。\n上一代EPYC将Zen 4、Zen 4c分成两条不同的子产品线，各有各的代号，命名规则都不一样，客户可以一眼看出区别。\n这一次，EPYC 9005系列将Zen 5、Zen 5c纳入了统一管理，甚至共用一个代号Turin，就在型号命名上都完全混合在一起。\n事实上这一代两种核心对应的内存、PCIe规格都完全一致，不像上代Zen 4c的精简了不少，自然没必要再区分开。\nAMD也希望通过此举消弭Zen 5、Zen 5c之间的鸿沟，简化客户的选择，毕竟它们是同样的架构、性能、指令、功能，不需要差异对待。\n客户根本不用考虑一款产品到底用了Zen 5还是Zen 5c，只需要根据自己的应用需求，选择不同的核心、频率、缓存、功耗等指标组合，即可找到最适合自己的型号。\n非要区分的话，Zen 5的有22款，Zen 5c的有5款。\n8-72个核心的只有Zen 5，144-192核心的只有Zen 5c，96-128核心的两种都有，其中9x55编号的为Zen 5，9x45编号的为Zen 5c。\n另外值得一提的是，AMD首次将最高频率提升到了惊人的5GHz，对比上代的最高值一下子提升了足足600MHz。\n这对于多核心的数据中心处理器来说是非常难得的，而且一次就有两款做到了，分别是16核心的EPYC 9175F、64核心的EPYC 9575F，非常适合对频率非常敏感的应用。\nIntel则是分成了完全不同的两部分，分别冠以P、E的后缀，一眼就能看出谁是大核、谁是小核。\n至强6900P系列都是大核，最高做到了128核心256线程，最少也有72核心144线程。\n至强6700E系列最多144核心144线程，最少则是64核心64线程。\n规格性能：AMD气势如虹 全面碾压 # 对比来看，五代EPYC 9005在纸面规格参数上就远胜于六代至强6，下边逐一对比下：\n核心数： # EPYC 9005 Zen 5最多128核心256线程，与至强6900P持平。\nZen 5c的最多更是192核心384线程，遥遥领先至强6700E 144核心144线程。\n另外，双方都支持最多双路并行，Intel这次也没有四路、八路。\n频率： # EPYC 9005最高达到了空前的5.0GHz，Zen 5c最高也有3.7GHz。\n至强6就差多了，甚至都没迈过4GHz的门槛，6900P最高统一都是3.9GHz，6700E系列更是只有3.2GHz。\n三级缓存： # EPYC 9005 Zen 5、Zen 5c最多分别做到了512MB、384MB，平均每个核心分别4MB、2MB。\n至强6900P最多504MB，只输了一点点；至强6700E则是最多108MB，还不到对手的三分之一，平均每个核心还不到1MB。\nDDR5内存： # EPYC 9005系列全部统一支持12通道DDR5-6000，最低端也没有阉割。\n至强6900P系列也是12通道，频率更高一些DDR5-6400，还支持新型MRDIMM内存，频率高达8800MHz——这几乎是至强6唯一的优势了。\n至强6700E系列只有8个内存通道，而且只有部分型号保留DDR5-6400的频率，还有一部分降级为DDR5-5600。\nPCIe 5.0通道： # EPYC 9005系列都是128条PCIe 5.0通道，和上代相同。\n至强6900P系列只有96条，至强6700E系列进一步减少到88条。\n热设计功耗： # 双方最高都达到了500W，尤其是完整核心都是在128核心的情况下做到的，彼此彼此。\n不过，Zen 5c 192核心时也有500W，至强6700E 144核心时则是330W，平均到每个核心后者更低一些为2.3W，前者是2.6W。\n平台： # EPYC 9005系列延续了上代的SP5封装接口，客户可以无缝升级，而且按照AMD的做法，这一接口还会延续下去，可能要等到支持DDR6内存的时候才会改变。\n至强6系列不但用了新接口，还分为两种，至强6900P系列是LGA7529，至强6700E系列是LGA4710，不仅上代无法升级，大小核之间也无法通用。\n其他： # EPYC 9005系列全部支持AVX-512指令集，这本来是Intel的独门绝技，但异构大小核的设计让它消失了，至强6也没有。\nEPYC 9005系列全部支持多线程，至强6900P也有，至强6700E就没了。\n至强6内置了一系列的AI加速器，可以让某些特定负载大大加速，EPYC 9005系列则没有，不过AMD有更强大的Instinct加速卡，强调二者搭档发挥各自的优势，Intel GPU加速卡则没能做起来。\n当然，纸面得来终觉浅，最终还要看跑分。\nPhoronix网站进行了多型号的全方位测试，Ubuntu系统下跑了多达140个数据中心测试项目，总结如上。\n可以看出，EPYC 9005系列对比至强6呈现一边倒的压倒性优势，可以说是全程吊打。\n旗舰之争中，EPYC 9755面对MRDIMM-8000高频内存加持的至强6980P，双路、单路优势分别高达40.0％、18.4％，如果将后者换成普通的DDR5-6400，领先幅度更是能进一步提升到41.7％、19.3％。\n夸张的是，只需要一颗EPYC 9755，就能干掉两颗搭配DDR5-6400内存的至强6980P！\n同时，192核心的EPYC 9965、5GHz频率的EPYC 9575F，也都超越了至强6980P，后者领先超过20％。\n有趣的是，EPYC的双路并行效率要高得多。\n遗憾的是没有加入至强6700E系列的测试，但不难想象，即便加上也是被欺负的命。\n功耗方面，五代EPYC也有着绝对优势，远远低于至强6。\n无论是192核心的EPYC 9965，还是5GHz频率的EPYC 9575F，实际功耗都没有超过400W的热设计功耗指标。\n即便是128核心旗舰的EPYC 9755，功耗也只有450W左右，远低于500W的热设计功耗。\n至强6980P则正好达到了500W，这就是官方标称的热设计功耗。\n展望未来：只是刚刚开始 都还有杀手锏 # 通过前述种种对比可是看出，EPYC 9005系列在至强6系列面前相当霸道，无论是规格参数、技术，还是实际性能、能效，又或者平台便利性，都实现了全方位的碾压，甚至可以说是吊打，Intel依然毫无还手之力。\n而且，这只是双方新一代平台的开端，各自都还有杀手锏级的后招。\nAMD没有透露具体情况，但显然会有适合极高性能计算的第三代3D缓存版本。\n上一代就做到了768MB 3D缓存，加上原生的384MB合计达1152MB，也是史上第一次超过1GB。\n这一代随着CCD模块数量的增加，3D缓存有望增至1024MB，加上原生的512MB，合计可达1536MB，也就是整整1.5GB！\nIntel方面，明年一季度会发布至强 6900E系列，两个计算模块，最高达288核心288线程，在核心数量上创造新纪录。\n但是因为不支持多线程技术，它的线程数还是稍逊一筹，再考虑到AMD多线程技术的效率，192核心384线程超过它问题不大。\n另外还有至强6700P、6500P、6300P系列，显然核心数不会超过128个。\n按照AMD的说法，EPYC平台已经拥有超过350个OEM平台、超过950个云实例，无论是大规模云厂商还是大型科技/行业企业，都有大量的深度合作伙伴，是实至名归的“超大规模数据中心第一处理器”。\nIntel方面没有明确数据，但凭借长期以来雄厚的积累，以及依然把持住2/3的市场，合作案例肯定更多、更深入。\n仅仅七年，AMD EPYC就吃下了超过1/3的市场，对于一向看重产品和平台品质、看重长期稳定性的服务器与数据中心客户来说，能做到这种程度只能说是一个奇迹。\n更可怕的是，AMD EPYC在产品力上几乎找不到缺点和短板，几乎每一个点都让对手望尘莫及，相信还会拿到更多的市场。\n七年五代产品，AMD将核心数量提升了6倍，性能更是提升了几乎11倍，一路狂奔根本停不下来的架势。\n","date":"2024-10-16","externalUrl":null,"permalink":"/hardware/amd-fifth-gen-epyc-vs-intel-sixth-gen-xeon/","section":"Hardwares","summary":"\u003cp\u003eAMD、Intel之间的服务器与数据中心处理器大战硝烟再起，战况空前！\u003c/p\u003e\n\u003cp\u003eIntel正在陆续发布全新设计的第六代至强6系列，AMD则祭出了同样全新的第五代EPYC 9005系列，可谓针尖对麦芒。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-epyc-vs-intel-xeon-1.png\" alt=\"AMD fifth Gen epyc vs Intel Sixth Gen Xeon\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./amd-epyc-vs-intel-xeon-2.png\" alt=\"AMD fifth Gen epyc vs Intel Sixth Gen Xeon\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"AMD五代EPYC对决Intel六代至强","type":"hardware"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/epyc-9005/","section":"Tags","summary":"","title":"EPYC 9005","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/xeon-6/","section":"Tags","summary":"","title":"Xeon 6","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/zen-5/","section":"Tags","summary":"","title":"Zen 5","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/amd/","section":"Tags","summary":"","title":"AMD","type":"tags"},{"content":"","date":"2024-10-16","externalUrl":null,"permalink":"/tags/ecosystem/","section":"Tags","summary":"","title":"Ecosystem","type":"tags"},{"content":"英特尔与AMD一直是业界两大强劲的竞争对手，然而，近日这两家公司却罕见地携手合作，共同宣布成立一个新的x86咨询小组，旨在确保未来x86指令集架构（ISA）的统一和兼容性。这一举措在2024年OCP峰会上正式公布，引起了广泛关注。该小组的成员包括博通、Meta、Oracle、微软、戴尔、HPE、联想、谷歌、红帽等。\nx86指令集架构自诞生以来已有46年历史，已成为个人电脑和数据中心通用计算的最普遍标准。英特尔和AMD作为仅有的两家大批量生产新处理器的主要x86架构授权商，形成了双头垄断的格局。然而，随着x86生态系统在消费者和数据中心市场面临来自Arm和RISC-V的巨大压力，两家公司意识到加强合作、减少定制ISA实现带来的问题至关重要。\n当前消费科技巨头苹果、移动芯片设计商高通以及云计算巨头如AWS、微软和谷歌等都在为PC和云市场设计自己的基于Arm的CPU。此外，另一家移动芯片设计商联发科已公开表示计划为Windows PC推出基于Arm的CPU，并正在与Nvidia合作。这进一步加剧了英特尔和AMD的压力。在过去一年中，这两家公司都推出了自己的高核心密度和高效率处理器。AMD去年推出了其EPYC“Bergamo”芯片，英特尔最近推出了其Xeon 6 E核心芯片。\n在联合声明中，英特尔和AMD表示，该小组将专注于寻找扩展x86生态系统的新方法，实现跨平台兼容性，简化软件开发，并为开发者提供一个平台来识别架构需求和功能。英特尔首席执行官帕特·基辛格表示：“我们正面临x86架构和生态系统几十年来最重大的转变之一，需要达到新的定制化、兼容性和可扩展性水平，以满足当前和未来的客户需求。”\nAMD董事长兼首席执行官苏姿丰在声明中表示：“成立x86生态系统咨询小组将确保x86架构继续发展成为开发人员和客户的首选计算平台。”\n新组织打算对 x86 ISA 的一些新增和修改进行标准化，其中包括几项已经在进行的简化工作。修改和协作领域尚未确定，但有很多明确的候选方案可以进行讨论。\n例如，AMD 有其 Supervisor Entry Extensions，旨在清除 ISA 中的一些旧垃圾，而英特尔有其灵活返回和事件传递 (FRED)代码，其目标类似。英特尔甚至已经开始开发 X86S，这是一种简化的 64 位实现，旨在清除更多遗留垃圾。\n此外x86 ISA 也在不断推进新的功能，在这方面，英特尔和 AMD 之间的合作可能变得更加重要。例如，英特尔最近推出了 AMX，这是一种矩阵数学扩展，可显著提高 AI 推理工作负载的性能。未来肯定会有更新的和尚未预见到的新增功能，特别是关于支持 AI 操作的各种扩展。\n在以动态AI工作负载、定制芯片以及3D封装和系统架构进步为特征的当今环境中，强大且不断扩展的x86生态系统比以往任何时候都更为重要。该顾问小组将团结行业领导者，通过一套更加统一的指令和架构接口来塑造x86的未来，促进开发者的创新。这一举措将增强x86产品的兼容性、可预测性和一致性。\n预期成果包括：\n增强客户在硬件和软件方面的选择和兼容性，加速他们从新功能中获益的能力。 简化架构指南，增强英特尔和AMD的x86产品之间的软件一致性和接口。 使新功能能够更好、更高效地集成到操作系统、框架和应用程序中。 英特尔和AMD虽然是竞争对手，但也有着合作的历史，例如PCIe、ACPI和USB等标准正是整个行业紧密协作的结果。\n总的来说，英特尔与AMD携手成立x86咨询小组是一个重要的里程碑，标志着两家公司在推动x86架构统一和兼容性方面迈出了重要一步。未来，随着更多公司和功能的加入，x86生态系统将更加开放、统一和强大。然而，考虑到现代处理器的设计周期较长，想要咨询小组立马发挥关键作用应该很难，但至少这是一个积极的开始。\n","date":"2024-10-16","externalUrl":null,"permalink":"/hardware/intel-and-amd-launch-x86-ecosystem-advisory-group/","section":"Hardwares","summary":"\u003cp\u003e英特尔与AMD一直是业界两大强劲的竞争对手，然而，近日这两家公司却罕见地携手合作，共同宣布成立一个新的x86咨询小组，旨在确保未来x86指令集架构（ISA）的统一和兼容性。这一举措在2024年OCP峰会上正式公布，引起了广泛关注。该小组的成员包括博通、Meta、Oracle、微软、戴尔、HPE、联想、谷歌、红帽等。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./x86-ecosystem-advisory-group.png\" alt=\"Intel and AMD Launch x86 Ecosystem Advisory Group\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003ex86指令集架构自诞生以来已有46年历史，已成为个人电脑和数据中心通用计算的最普遍标准。英特尔和AMD作为仅有的两家大批量生产新处理器的主要x86架构授权商，形成了双头垄断的格局。然而，随着x86生态系统在消费者和数据中心市场面临来自Arm和RISC-V的巨大压力，两家公司意识到加强合作、减少定制ISA实现带来的问题至关重要。\u003c/p\u003e\n\u003cp\u003e当前消费科技巨头苹果、移动芯片设计商高通以及云计算巨头如AWS、微软和谷歌等都在为PC和云市场设计自己的基于Arm的CPU。此外，另一家移动芯片设计商联发科已公开表示计划为Windows PC推出基于Arm的CPU，并正在与Nvidia合作。这进一步加剧了英特尔和AMD的压力。在过去一年中，这两家公司都推出了自己的高核心密度和高效率处理器。AMD去年推出了其EPYC“Bergamo”芯片，英特尔最近推出了其Xeon 6 E核心芯片。\u003c/p\u003e\n\u003cp\u003e在联合声明中，英特尔和AMD表示，该小组将专注于寻找扩展x86生态系统的新方法，实现跨平台兼容性，简化软件开发，并为开发者提供一个平台来识别架构需求和功能。英特尔首席执行官帕特·基辛格表示：“我们正面临x86架构和生态系统几十年来最重大的转变之一，需要达到新的定制化、兼容性和可扩展性水平，以满足当前和未来的客户需求。”\u003c/p\u003e\n\u003cp\u003eAMD董事长兼首席执行官苏姿丰在声明中表示：“成立x86生态系统咨询小组将确保x86架构继续发展成为开发人员和客户的首选计算平台。”\u003c/p\u003e\n\u003cp\u003e新组织打算对 x86 ISA 的一些新增和修改进行标准化，其中包括几项已经在进行的简化工作。修改和协作领域尚未确定，但有很多明确的候选方案可以进行讨论。\u003c/p\u003e","title":"英特尔 和 AMD 宣布合作，共同成立生态小组","type":"hardware"},{"content":"Intel前脚刚发布至强6 6000系列，AMD就带来了Zen 5/5c架构的五代EPYC 9005系列，彼此针锋相对，后者显然更胜一筹。\nPhoronix提前测试了多颗EPYC 9005的样品，结果自然不出所料，丝毫不对手任何情面。\n测试的新SKU一共三颗，分别是：\nEPYC 9965： Zen 5c顶级旗舰，192核心384线程，384MB三级缓存，2.25-3.7GHz频率，500W热设计功耗。 EPYC 9575F： 最高频率型号之一，Zen 5，64核心128线程，256MB三级缓存，3.3-5.0GHz频率，400W热设计功耗。 EPYC 9755： Zen 5顶级旗舰，128核心256线程，512MB三级缓存，2.7-4.1GHz频率，500W热设计功耗。 至强6980P也是新一代旗舰，P性能核设计，128核心256线程，504MB三级缓存，2.0-3.9GHz频率，500W热设计功耗。\n测试系统是Ubuntu 24.04 LTS，系统内核6.12。测试项目多达140个。\n直接看结果汇总：\n无论双路还是单路，EPYC 9755都是一马当先，优势大到不可思议，面对搭配超高频率MRDIMM 8000MHz内存的至强6980P，优势分别高达40.0％、18.4％，后者换成普通的DDR5-6400，领先幅度还会略微提高到41.7％、19.3％。\n事实上，只需一颗EPYC 9755，就能干掉两颗至强6980P DDR5-6400！\nEPYC 9965、EPYC 9575F同样也是一骑绝尘，全都能将至强6980斩落马下，双路EPYC 9575F对比双路至强6980P(MR-DIMM 8000)，优势仍有22.6％，单路对比也只落后8.4％。\n这从另一方面可以看出，五代EPYC的双路效率非常高，远胜于至强6。\n对比上代产品，128核心EPYC 9755相比于96核心EPYC 9654，都是旗舰，提升幅度高达恐怖的63.1％。\n192核心、Zen 5c架构的EPYC 9965对比128核心、Zen 4c架构的EPYC 9754，提升幅度同样有不可思议的47.6％。\n有趣的是，一颗EPYC 9965就能超过两颗EPYC 9754/9654，领先幅度分别为8.4％、17.7％。\n功耗方面，五代EPYC也有着绝对优势，远远低于至强6。\n无论是192核心的EPYC 9965，还是5GHz频率的EPYC 9575F，实际上都控制在了400W之内，128核心的EPYC 9755也只有450W左右，可以说热设计功耗留足了空间。\n至强6980P则刚好达到了500W。\n可以说，AMD EPYC在性能、功耗、能效等指标上已经处于绝对的统治地位，Intel至强短期内一点办法都没有。\n后续，Intel会推出288核心288线程的顶级型号，不过采用能效核设计，192核心384线程的EPYC 9965领先之目测不会有什么压力。\n","date":"2024-10-15","externalUrl":null,"permalink":"/hardware/amd-zen5-epyc-first-test-result-review/","section":"Hardwares","summary":"\u003cp\u003eIntel前脚刚发布至强6 6000系列，AMD就带来了Zen 5/5c架构的五代EPYC 9005系列，彼此针锋相对，后者显然更胜一筹。\u003c/p\u003e\n\u003cp\u003ePhoronix提前测试了多颗EPYC 9005的样品，结果自然不出所料，丝毫不对手任何情面。\u003c/p\u003e\n\u003cp\u003e测试的新SKU一共三颗，分别是：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEPYC 9965：\n\u003cul\u003e\n\u003cli\u003eZen 5c顶级旗舰，192核心384线程，384MB三级缓存，2.25-3.7GHz频率，500W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eEPYC 9575F：\n\u003cul\u003e\n\u003cli\u003e最高频率型号之一，Zen 5，64核心128线程，256MB三级缓存，3.3-5.0GHz频率，400W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eEPYC 9755：\n\u003cul\u003e\n\u003cli\u003eZen 5顶级旗舰，128核心256线程，512MB三级缓存，2.7-4.1GHz频率，500W热设计功耗。\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-EPYC-9005-SKU-1.png\" alt=\"AMD EPYC 9005 SKU\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e","title":"AMD Zen5 EPYC首测","type":"hardware"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/eypc/","section":"Tags","summary":"","title":"EYPC","type":"tags"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/mrdimm/","section":"Tags","summary":"","title":"MRDIMM","type":"tags"},{"content":"","date":"2024-10-15","externalUrl":null,"permalink":"/tags/gaudi-3/","section":"Tags","summary":"","title":"Gaudi 3","type":"tags"},{"content":"早在4月份，Intel就宣布了新一代AI加速器Gaudi 3，现在它终于发布了，详细的规格参数也已出炉，竞争对手直指NVIDIA H100 GPU加速器，当然后者的Blackwell系列也要上量了。\n数据显示，预计到2030年，全球半导体市场规模将达1万亿美元，AI是主要推动力，不过在2023年，只有10％的企业能够成功将其AIGC项目产品化。\nIntel现有的Gaudi 2诞生于2022年5月，并于2023年7月正式引入中国，拥有极高的深度学习性能、效率，以及极高的性价比。\n它采用台积电7nm工艺制造，集成24个可编程的Tenor张量核心(TPC)、48MB SRAM缓存、21个10万兆内部互连以太网接口(ROCEv2 RDMA)、96GB HBM2E高带宽内存(总带宽2.4TB/s)、多媒体引擎等，支持PCIe 4.0 x16，最高功耗800W，可满足大规模语言模型、生成式AI模型的强算力需求。\nGaudi 3的规格提升幅度堪称跨越式的，制造工艺从台积电7nm来到台积电5nm，MME(矩阵乘法引擎)从2个增加到8个，虽然每个MME内部的TPC(张量处理核心)从12个减少到8个，但是总数从24个大幅增加到了64个，另外媒体解码器差从8个增至14个。\n内置SRAM缓存容量翻番至96MB，带宽翻倍至12.8TB/s。\n核心性能方面，MME BF16/FP8都是1835 TFlops(每秒1.835千万亿次)，矢量BF16则是28.8 TFlops(每秒28.8万亿次)，分别提升了3.2倍、1.1倍、1.6倍。\nHBM2E高带宽内存容量从96GB增加到128GB(八颗)，带宽也顺应增加来到惊人的3.7TB/s。\n24个200Gb RDMA网络接口，双向网络互连带宽1.2TB/s，主机接口峰值双向带宽128GB/s，系统总线升级为PCIe 5.0 x16。\n按照官方说法，Gaudi 3对比NVIDIA H100，LLM大模型推理性能领先50％、训练时间快40％，性价比则是对手的2倍。\n开发方面，无缝兼容PyTorch框架、Hugging Face Transformer和扩散模型。\nGaudi 3还可大幅缩短70亿和130亿参数Llama2模型、1750亿参数GPT-3模型的训练时间。\n在Llama 70亿/700亿参数、Falcon 1800亿参数大型语言模型上，Gaudi 3的推理吞吐量和能效也都非常出色。\nGaudi 3还提供开放的、基于社区的软件，以及行业标准以太网网络，可以灵活地从单个节点扩展到拥有数千个节点的集群、超级集群和超大集群，支持大规模的推理、微调和训练。\nGaudi 3加速器提供三种部署形态，一是OAM 2.0标准夹层卡，被动散热峰值功耗900W，液冷散热峰值功耗1200W，支持48个112Gb PAM4SerDes网络链接。\n二是HLB-325通用基板，支持八颗Gaudi 3，具体功耗未披露。\n三是HL-338扩展卡，PCIe 5.0 x16接口，被动散热峰值功耗600W，还可以四卡互连。\n目前，Intel Gaudi加速器的行业客户及合作伙伴有NAVER、博世(Bosch)、IBM、Ola/Krutrim、NielsenIQ、Seekr、IFF、CtrlS Group、Bharti Airtel、Landing AI、Roboflow、Infosys，等等。\nIntel此前已宣布，IBM将会在其云服务中部署Gaudi 3加速器。\n另有消息称，Gaudi 3加速器也有中国特供版，其中OAM模组、PCIe模组的峰值功耗都限制至450W，算力自然也会大打折扣，但暂无更进一步说法。\n","date":"2024-10-15","externalUrl":null,"permalink":"/hardware/intel-gaudi-3-ai-accelerator/","section":"Hardwares","summary":"\u003cp\u003e早在4月份，Intel就宣布了新一代AI加速器Gaudi 3，现在它终于发布了，详细的规格参数也已出炉，竞争对手直指NVIDIA H100 GPU加速器，当然后者的Blackwell系列也要上量了。\u003c/p\u003e\n\u003cp\u003e数据显示，预计到2030年，全球半导体市场规模将达1万亿美元，AI是主要推动力，不过在2023年，只有10％的企业能够成功将其AIGC项目产品化。\u003c/p\u003e\n\u003cp\u003eIntel现有的Gaudi 2诞生于2022年5月，并于2023年7月正式引入中国，拥有极高的深度学习性能、效率，以及极高的性价比。\u003c/p\u003e\n\u003cp\u003e它采用台积电7nm工艺制造，集成24个可编程的Tenor张量核心(TPC)、48MB SRAM缓存、21个10万兆内部互连以太网接口(ROCEv2 RDMA)、96GB HBM2E高带宽内存(总带宽2.4TB/s)、多媒体引擎等，支持PCIe 4.0 x16，最高功耗800W，可满足大规模语言模型、生成式AI模型的强算力需求。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./Intel-Gaudi-3-AI-Accelerator-2.png\" alt=\"Intel Gaudi 3 AI Accelerator\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eGaudi 3的规格提升幅度堪称跨越式的，制造工艺从台积电7nm来到台积电5nm，MME(矩阵乘法引擎)从2个增加到8个，虽然每个MME内部的TPC(张量处理核心)从12个减少到8个，但是总数从24个大幅增加到了64个，另外媒体解码器差从8个增至14个。\u003c/p\u003e","title":"Intel正式发布Gaudi 3 AI加速器","type":"hardware"},{"content":"","date":"2024-10-13","externalUrl":null,"permalink":"/tags/hbm4/","section":"Tags","summary":"","title":"HBM4","type":"tags"},{"content":"","date":"2024-10-13","externalUrl":null,"permalink":"/tags/tsmc/","section":"Tags","summary":"","title":"TSMC","type":"tags"},{"content":"台积电HBM4内存的推出将带来多项重大变革，其中最引人注目的就是其内存接口的大幅扩展。第四代内存技术接口从1024位扩展到2048位，这标志着HBM4内存的设计和生产将面临新的挑战，为了适应这一变化，芯片制造商必须采用更新、更高级的封装技术。\n在2024年的欧洲技术研讨会上，台积电透露了其为HBM4制造的base die一些细节，这些芯片将采用逻辑工艺制造，台积电计划利用其N12和N5工艺的改进版本来生产这些芯片。这将使台积电在HBM4的生产领域占据优势，因为现有的内存制造设施均无法做到经济高效地生产这种先进逻辑芯片。\n对于HBM4的首批产品封装，台积电将采用N12FFC+和N5两种不同的制造工艺。尽管这两种工艺都是为了将HBM4E内存与新一代的AI和高性能计算处理器相结合，但它们在连接AI和高性能计算应用的高性能处理器的内存方面发挥着不同的作用。\n台积电的设计和技术平台高级总监透露：“公司正与美光、三星和SK海力士等主要HBM内存供应商合作，利用先进的工艺节点推进HBM4内存技术的全面整合。N12FFC+工艺的基础芯片在成本效益上具有优势，能够满足HBM的性能需求，而N5工艺的基础芯片则能在保持HBM4速度的同时，提供更复杂的逻辑功能并大幅降低能耗。\n台积电的N12FFC+工艺（12纳米FinFET Compact Plus，虽然归类于12纳米技术，但技术基础源自其成熟的16纳米FinFET生产线）生产的基础芯片，将用于在系统级芯片（SoCs）旁的硅中介层上安装HBM4内存堆栈。台积电相信，其12FFC+工艺非常适合实现HBM4的性能，使内存制造商能够构建12-Hi（48GB）和16-Hi（64GB）堆栈，每个堆栈的带宽超过2TB/秒。\n台积电高级总监提到：“我们也在为HBM4优化CoWoS-L和CoWoS-R技术，CoWoS-L和CoWoS-R技术都采用超过八层的布线设计以确保HBM4超过2000个的互连和信号完整性。”\n使用N12FFC+工艺的HBM4基础芯片对于采用台积电CoWoS-L或CoWoS-R先进封装技术构建系统级封装（SiPs）至关重要，这些技术提供的中介层面积可达8倍光罩尺寸，足以容纳多达12个HBM4内存堆栈。据报道，HBM4能够以 14mA的电流实现6GT/s的数据传输速率。\n台积电还与Cadence、Synopsys和Ansys等EDA公司合作，确保HBM4通道的信号完整性、IR/EM和热准确性。\n与此同时，内存制造商还可以选择使用台积电的N5工艺来生产HBM4 base die。N5工艺制造的基础芯片将集成更多逻辑功能，减少功耗并提供更高的性能。最重要的是，这种先进的工艺技术将实现非常小的互连间距，约为6到9微米，这将使N5基础芯片能够与直接键合技术结合使用，允许HBM4直接3D堆叠在逻辑芯片上从而大幅提升内存性能，这将为不断追求更高内存带宽的AI和HPC芯片带来巨大的提升。\n据悉，台积电与SK海力士在HBM4 base die上已有合作，并且台积电也可能为美光生产HBM4 base die。至于三星拥有自己的先进逻辑生产线，台积电与其合作的可能性相对较小。\n","date":"2024-10-13","externalUrl":null,"permalink":"/hardware/tsmc-readies-hbm4-base-dies-at-12nm-and-5nm/","section":"Hardwares","summary":"\u003cp\u003e台积电HBM4内存的推出将带来多项重大变革，其中最引人注目的就是其内存接口的大幅扩展。第四代内存技术接口从1024位扩展到2048位，这标志着HBM4内存的设计和生产将面临新的挑战，为了适应这一变化，芯片制造商必须采用更新、更高级的封装技术。\u003c/p\u003e\n\u003cp\u003e在2024年的欧洲技术研讨会上，台积电透露了其为HBM4制造的base die一些细节，这些芯片将采用逻辑工艺制造，台积电计划利用其N12和N5工艺的改进版本来生产这些芯片。这将使台积电在HBM4的生产领域占据优势，因为现有的内存制造设施均无法做到经济高效地生产这种先进逻辑芯片。\u003c/p\u003e\n\u003cp\u003e对于HBM4的首批产品封装，台积电将采用N12FFC+和N5两种不同的制造工艺。尽管这两种工艺都是为了将HBM4E内存与新一代的AI和高性能计算处理器相结合，但它们在连接AI和高性能计算应用的高性能处理器的内存方面发挥着不同的作用。\u003c/p\u003e\n\u003cp\u003e台积电的设计和技术平台高级总监透露：“公司正与美光、三星和SK海力士等主要\u003ca href=\"https://www.kad8.com/hardware/difference-between-gddr-memory-vs-hbm-memory/\" target=\"_blank\"\u003eHBM\u003c/a\u003e内存供应商合作，利用先进的工艺节点推进HBM4内存技术的全面整合。N12FFC+工艺的基础芯片在成本效益上具有优势，能够满足HBM的性能需求，而N5工艺的基础芯片则能在保持HBM4速度的同时，提供更复杂的逻辑功能并大幅降低能耗。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./TSMC-Logic-for-HBM4-Base-Die.png\" alt=\"TSMC Logic for HBM4 Base Die\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e台积电的N12FFC+工艺（12纳米FinFET Compact Plus，虽然归类于12纳米技术，但技术基础源自其成熟的16纳米FinFET生产线）生产的基础芯片，将用于在系统级芯片（SoCs）旁的硅中介层上安装HBM4内存堆栈。台积电相信，其12FFC+工艺非常适合实现HBM4的性能，使内存制造商能够构建12-Hi（48GB）和16-Hi（64GB）堆栈，每个堆栈的带宽超过2TB/秒。\u003c/p\u003e\n\u003cp\u003e台积电高级总监提到：“我们也在为HBM4优化CoWoS-L和CoWoS-R技术，CoWoS-L和CoWoS-R技术都采用超过八层的布线设计以确保HBM4超过2000个的互连和信号完整性。”\u003c/p\u003e\n\u003cp\u003e使用N12FFC+工艺的HBM4基础芯片对于采用台积电CoWoS-L或CoWoS-R先进封装技术构建系统级封装（SiPs）至关重要，这些技术提供的中介层面积可达8倍光罩尺寸，足以容纳多达12个HBM4内存堆栈。据报道，HBM4能够以 14mA的电流实现6GT/s的数据传输速率。\u003c/p\u003e\n\u003cp\u003e台积电还与Cadence、Synopsys和Ansys等EDA公司合作，确保HBM4通道的信号完整性、IR/EM和热准确性。\u003c/p\u003e\n\u003cp\u003e与此同时，内存制造商还可以选择使用台积电的N5工艺来生产HBM4 base die。N5工艺制造的基础芯片将集成更多逻辑功能，减少功耗并提供更高的性能。最重要的是，这种先进的工艺技术将实现非常小的互连间距，约为6到9微米，这将使N5基础芯片能够与直接键合技术结合使用，允许HBM4直接3D堆叠在逻辑芯片上从而大幅提升内存性能，这将为不断追求更高内存带宽的AI和HPC芯片带来巨大的提升。\u003c/p\u003e","title":"台积电要用5nm先进封装HBM4内存芯片","type":"hardware"},{"content":"AMD正式发布了第五代EPYC处理器“Turin”，采用全新的Zen 5核心架构，带来了全面的重大提升，再次巩固了其在数据中心领域的领先地位。新一代处理器被命名为“EPYC 9005”系列，目的是扩大服务器CPU的领先地位，推动高效现代化，并提供端到端的AI平台。\nTurin处理器有两种版本。第一种是基于4nm工艺的标准版，搭载多达16个“Zen 5”CCD，提供最多128个核心和256个线程，被称为“Scale-Up”版本。第二种是“Scale-Out”版本，采用3nm“Zen 5C”核心，配备多达12个CCD，提供最多192个核心和384个线程。新一代处理器最多可容纳17个芯片，总计拥有1500亿个晶体管。CPU支持AVX-512，具有完整的512b数据路径，时钟频率高达5 GHz，可配置在单路或双路服务器中。\n在性能方面，AMD表示Zen 5在企业和云平台上IPC提升高达17%，在高性能计算（HPC）和人工智能（AI）平台上提升高达37%。EPYC Zen 5C提供最多192个核心和384 MB的L3缓存，与Zen 4C相比，核心数和L3缓存增加了50%。EPYC Zen 5提供最多128个核心和512 MB的L3缓存，与Zen 4相比，核心数和L3缓存增加了33%。\nTurin继续使用与之前Genoa和Bergamo“Zen 4”版本相同的SP5插槽，方便用户直接升级。平台提供12通道内存解决方案，DDR5速度提升至最高6400 MT/s，支持ECC，每个插槽容量达6 TB。还提供128个PCIe 5.0/CXL 2.0通道，支持x4和x8 ECC RDIMM的PPR或动态后封装修复。在安全性方面，支持可信I/O、FIPS 140-3进程和硬件信任根。\n第五代AMD EPYC“Turin”产品线包含27个SKU，包括192核的旗舰产品EPYC 9965、128核的EPYC 9755，以及首款达到5 GHz的EPYC 9575F。旗舰型号EPYC 9965拥有192个核心、384个线程和384 MB的L3缓存，基本时钟频率为2.25 GHz，加速频率为3.7 GHz，TDP为500W，售价14,813美元。相比之下，英特尔的顶级Xeon 6900P售价为17,800美元，AMD的产品在核心数和价格上都具有明显优势。\n在实测方面，AMD宣称在SPEC CPU 2017整数吞吐量测试中，EPYC 9965领先英特尔同类产品2.7倍，较上一代EPYC提升近60%。在每核性能方面，Zen 5处理器比英特尔第五代Xeon提高了40%，比第四代EPYC SKU提高了27%。在虚拟化领域，以相同的许可成本实现了更强的性能。\n在多种工作负载下，EPYC 9965的表现都超越了竞争对手。例如，在视频转码（FFMPEG raw到vp9）中性能提高了4倍，商业应用程序性能（Specjbb）提高了2.3倍，开源数据库（MySQL OLTP）性能提高了3.9倍，图像渲染（vRay 5）性能提高了3倍。即使在相同核心数的比较中，64核的EPYC 9575F在多项企业HPC工作负载中仍领先高达1.6倍。\n在AI性能方面，借助AVX-512 512b功能，性能提升高达3.8倍。更高频率的SKU如EPYC 9575F，可将GPU编排任务的速度提高28%。在能源效率方面，数据中心可以从1000台旧服务器迁移到仅131台搭载EPYC 9965的新服务器，功耗需求降低68%，服务器空间减少87%，三年内总拥有成本（TCO）降低67%。\nAMD还推出了适用于AMD Instinct和NVIDIA MGX/HGX平台的EPYC处理器，作为AI主机CPU。该解决方案可配备多达8个OAM MI300X或MI325X GPU，使用EPYC 9575F 5 GHz芯片，AI推理性能提升20%，训练性能提升15%。对于NVIDIA，MGX解决方案最多可配备16个AI加速器（Hopper/Blackwell），而HGX配置最多可配备8个加速器和2个EPYC CPU。\n综上所述，AMD第五代EPYC“Turin”系列在性能、能效和性价比方面都有显著提升，再次确立了其在数据中心和服务器市场的领先地位。随着这些芯片的广泛应用，我们期待在未来看到更多实际性能的数据和反馈。\n","date":"2024-10-11","externalUrl":null,"permalink":"/hardware/amd-officially-releases-the-fifth-generation-epyc-processor/","section":"Hardwares","summary":"\u003cp\u003eAMD正式发布了第五代EPYC处理器“Turin”，采用全新的\u003ccode\u003eZen 5\u003c/code\u003e核心架构，带来了全面的重大提升，再次巩固了其在数据中心领域的领先地位。新一代处理器被命名为“EPYC 9005”系列，目的是扩大服务器CPU的领先地位，推动高效现代化，并提供端到端的AI平台。\u003c/p\u003e\n\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"./AMD-Turin-1.webp\" alt=\"AMD EPYC Turin\" /\u003e\n      \n    \u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eTurin\u003c/code\u003e处理器有两种版本。第一种是基于4nm工艺的标准版，搭载多达16个“Zen 5”CCD，提供最多128个核心和256个线程，被称为“Scale-Up”版本。第二种是“Scale-Out”版本，采用3nm“Zen 5C”核心，配备多达12个CCD，提供最多192个核心和384个线程。新一代处理器最多可容纳17个芯片，总计拥有1500亿个晶体管。CPU支持AVX-512，具有完整的512b数据路径，时钟频率高达5 GHz，可配置在单路或双路服务器中。\u003c/p\u003e\n\u003cp\u003e在性能方面，AMD表示Zen 5在企业和云平台上IPC提升高达17%，在高性能计算（HPC）和人工智能（AI）平台上提升高达37%。EPYC Zen 5C提供最多192个核心和384 MB的L3缓存，与Zen 4C相比，核心数和L3缓存增加了50%。EPYC Zen 5提供最多128个核心和512 MB的L3缓存，与Zen 4相比，核心数和L3缓存增加了33%。\u003c/p\u003e","title":"AMD正式发布第五代EPYC处理器","type":"hardware"},{"content":" Kontronn is a global leader in IoT/Embedded Computing Technology (ECT). Kontronn offers individual solutions in the areas of Internet of Things (IoT) and Industry 4.0 through a combined portfolio of hardware, software and services.\n嵌入式工业主板 # Kontronn工业主板是嵌入式应用的理想选择。随着嵌入式计算领域的不断扩展，选择最佳方案正变得更加复杂和关键。在需要极长产品寿命以及低运行风险的应用领域，Kontronn 长期以来的经验可帮助客户找出最适合他们需求以及运行成本的解决方案。\n","date":"2024-10-04","externalUrl":null,"permalink":"/","section":"Kontronn Overview","summary":"\u003cblockquote\u003e\nKontronn is a global leader in IoT/Embedded Computing Technology (ECT).\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://www.kontronn.com\" target=\"_blank\"\u003eKontronn\u003c/a\u003e offers individual solutions in the areas of Internet of Things (IoT) and Industry 4.0 through a combined portfolio of hardware, software and services.\u003c/p\u003e","title":"Kontronn Overview","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]