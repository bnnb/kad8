<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
  
  <entry>
    <title>人工智能简史</title>
    <url>/post/a-short-history-of-AI.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>History</tag>
    </tags>
    <content type="html"><![CDATA[ 人工智能  自1956年达特茅斯会议起历经波折，至2019年基于变换器的大型语言模型（LLMs）如GPT-2引发关注，展示了未经明确训练的“涌现”能力。2022年 GPT-3.5  以聊天机器人形式出现，标志着AI从识别转向生成，不仅能完成语言任务，还能创作图像、视频等，实现技术与应用的双重飞跃，使AI更接近麦卡锡“使用语言、形成抽象”的愿景。
In the first of six weekly briefs, we ask how AI overcame decades of underdelivering
Over the summer of 1956 a small but illustrious group gathered at Dartmouth College in New Hampshire; it included Claude Shannon, the begetter of information theory, and Herb Simon, the only person ever to win both the Nobel Memorial Prize in Economic Sciences awarded by the Royal Swedish Academy of Sciences and the Turing Award awarded by the Association for Computing Machinery. They had been called together by a young researcher, John McCarthy, who wanted to discuss “how to make machines use language, form abstractions and concepts” and “solve kinds of problems now reserved for humans”. It was the first academic gathering devoted to what McCarthy dubbed “artificial intelligence”. And it set a template for the field’s next 60-odd years in coming up with no advances on a par with its ambitions.
在1956年夏天，一小群杰出但规模不大的人士聚集在新罕布什尔州的达特茅斯学院；其中包括信息理论的创始人克劳德·香农和唯一同时获得瑞典皇家科学院颁发的诺贝尔经济学纪念奖和计算机协会颁发的图灵奖的赫伯特·西蒙。他们是由一位年轻的研究员约翰·麦卡锡召集的，他想讨论“如何让机器使用语言，形成抽象和概念”以及“解决现在只留给人类的问题”。这是第一次学术聚会，专门讨论麦卡锡所说的“人工智能”。它为该领域接下来60多年的发展设定了一个模板，即在与它的雄心壮志相匹配的进步上没有取得任何进展。
The Dartmouth meeting did not mark the beginning of scientific inquiry into machines which could think like people. Alan Turing, for whom the Turing prize is named, wondered about it; so did John von Neumann, an inspiration to McCarthy. By 1956 there were already a number of approaches to the issue; historians think one of the reasons McCarthy coined the term artificial intelligence, later ai, for his project was that it was broad enough to encompass them all, keeping open the question of which might be best. Some researchers favoured systems based on combining facts about the world with axioms like those of geometry and symbolic logic so as to infer appropriate responses; others preferred building systems in which the probability of one thing depended on the constantly updated probabilities of many others.
达特茅斯会议并不是科学探究能够像人类一样思考的机器的开始。图灵奖的命名者艾伦·图灵思考过这个问题；麦卡锡的灵感来源之一约翰·冯·诺伊曼也思考过。到1956年，已经有多种方法来解决这个问题；历史学家认为麦卡锡为他的项目创造了“人工智能”，后来简称为AI，这个词的原因之一是它足够广泛，可以包含所有这些方法，保持哪种方法最好的问题开放。一些研究人员青睐基于将关于世界的事实与几何学和符号逻辑的公理结合起来，以便推断出适当的响应；其他人则更喜欢构建系统，其中一件事的概率取决于许多其他事情不断更新的概率。
The following decades saw much intellectual ferment and argument on the topic, but by the 1980s there was wide agreement on the way forward: “expert systems” which used symbolic logic to capture and apply the best of human know-how. The Japanese government, in particular, threw its weight behind the idea of such systems and the hardware they might need. But for the most part such systems proved too inflexible to cope with the messiness of the real world. By the late 1980s ai had fallen into disrepute, a byword for overpromising and underdelivering. Those researchers still in the field started to shun the term.
接下来的几十年中，关于这个话题有许多智力上的激动和争论，但到了1980年代，人们普遍认同了前进的方向：使用符号逻辑的“专家系统”，以捕捉和应用人类知识的最佳成果。特别是日本政府，大力支持这类系统及其可能需要的硬件。但大多数情况下，这些系统证明过于僵化，无法应对现实世界的混乱。到了1980年代末，人工智能已经声名狼藉，成为了过度承诺和未达预期的代名词。那些仍然在这个领域的研究人员开始避免使用这个术语。
It was from one of those pockets of perseverance that today’s boom was born. As the rudiments of the way in which brain cells—a type of neuron—work were pieced together in the 1940s, computer scientists began to wonder if machines could be wired up the same way. In a biological brain there are connections between neurons which allow activity in one to trigger or suppress activity in another; what one neuron does depends on what the other neurons connected to it are doing. A first attempt to model this in the lab (by Marvin Minsky, a Dartford attendee) used hardware to model networks of neurons. Since then, layers of interconnected neurons have been simulated in software.
正是从那些坚持不懈的小团体中，今天的繁荣诞生了。当20世纪40年代人们开始逐渐理解脑细胞——一种神经元——的工作方式时，计算机科学家开始思考机器是否也能以相同的方式连接起来。在生物大脑中，神经元之间有连接，这些连接允许一个神经元的活动触发或抑制另一个神经元的活动；一个神经元的行为取决于与之相连的其他神经元在做什么。第一次尝试在实验室模拟这一点（由达特茅斯会议的参与者马文·明斯基进行）使用了硬件来模拟神经元网络。从那时起，软件中模拟了多层互联的神经元。
These artificial neural networks are not programmed using explicit rules; instead, they “learn” by being exposed to lots of examples. During this training the strength of the connections between the neurons (known as “weights”) are repeatedly adjusted so that, eventually, a given input produces an appropriate output. Minsky himself abandoned the idea, but others took it forward. By the early 1990s neural networks had been trained to do things like help sort the post by recognising handwritten numbers. Researchers thought adding more layers of neurons might allow more sophisticated achievements. But it also made the systems run much more slowly.
这些人工神经网络不是通过显式规则来编程的；相反，它们通过接触大量示例来“学习”。在训练过程中，神经元之间的连接强度（称为“权重”）会不断调整，以便最终，给定的输入产生适当的输出。明斯基本人放弃了这个想法，但其他人将其向前推进。到了1990年代初，神经网络已经被训练出来帮助通过识别手写数字来分拣邮件。研究人员认为增加更多的神经元层可能会实现更复杂的成就。但这也让系统运行得更慢。
A new sort of computer hardware provided a way around the problem. Its potential was dramatically demonstrated in 2009, when researchers at Stanford University increased the speed at which a neural net could run 70-fold, using a gaming pc in their dorm room. This was possible because, as well as the “central processing unit” (cpu) found in all pcs, this one also had a “graphics processing unit” (gpu) to create game worlds on screen. And the gpu was designed in a way suited to running the neural-network code.
一种新型的计算机硬件提供了解决这个问题的方法。其潜力在2009年得到了戏剧性的展示，当时斯坦福大学的研究人员使用宿舍里的游戏PC，将神经网络的运行速度提高了70倍。这之所以可能，是因为除了所有PC中都能找到的“中央处理单元”（CPU）之外，这台PC还拥有一个“图形处理单元”（GPU），用于在屏幕上创建游戏世界。而GPU的设计非常适合运行神经网络代码。
Coupling that hardware speed-up with more efficient training algorithms meant that networks with millions of connections could be trained in a reasonable time; neural networks could handle bigger inputs and, crucially, be given more layers. These “deeper” networks turned out to be far more capable.
将硬件加速与更高效的训练算法相结合意味着具有数百万连接的网络可以在合理的时间内进行训练；神经网络能够处理更大的输入，并且关键的是，可以增加更多的层。这些“更深层”的网络被证明要强大得多。
The power of this new approach, which had come to be known as “deep learning”, became apparent in the ImageNet Challenge of 2012. Image-recognition systems competing in the challenge were provided with a database of more than a million labelled image files. For any given word, such as “dog” or “cat”, the database contained several hundred photos. Image-recognition systems would be trained, using these examples, to “map” input, in the form of images, onto output in the form of one-word descriptions. The systems were then challenged to produce such descriptions when fed previously unseen test images. In 2012 a team led by Geoff Hinton, then at the University of Toronto, used deep learning to achieve an accuracy of 85%. It was instantly recognised as a breakthrough.
这种新方法的力量，后来被称为“深度学习”，在2012年的ImageNet挑战赛中变得明显。参加挑战赛的图像识别系统提供了一个超过一百万标记图像文件的数据库。对于任何给定的词，比如“狗”或“猫”，数据库中包含了数百张照片。图像识别系统将使用这些示例进行训练，将输入（以图像形式）“映射”到输出（以单字描述的形式）。然后，系统被挑战在输入以前未见过的测试图像时产生这样的描述。2012年，由当时在多伦多大学的杰夫·辛顿领导的团队使用深度学习达到了85%的准确率。这立刻被公认为是一个突破。
By 2015 almost everyone in the image-recognition field was using deep learning, and the winning accuracy at the ImageNet Challenge had reached 96%—better than the average human score. Deep learning was also being applied to a host of other “problems…reserved for humans” which could be reduced to the mapping of one type of thing onto another: speech recognition (mapping sound to text), face-recognition (mapping faces to names) and translation.
到2015年，几乎所有图像识别领域的人员都在使用深度学习，ImageNet挑战赛的获胜准确率已经达到了96%——比平均人类得分还要好。深度学习也被应用于其他许多可以归结为将一种事物映射到另一种事物的“为人类保留的问题”：语音识别（将声音映射到文本）、面部识别（将面部映射到名字）和翻译。
In all these applications the huge amounts of data that could be accessed through the internet were vital to success; what was more, the number of people using the internet spoke to the possibility of large markets. And the bigger (ie, deeper) the networks were made, and the more training data they were given, the more their performance improved.
在所有这些应用中，通过互联网可以访问的大量数据对成功至关重要；更重要的是，使用互联网的人数表明了大市场的可能性。而且，网络做得越大（即，更深层），它们被给予的训练数据越多，它们的性能就越好。
Deep learning was soon being deployed in all kinds of new products and services. Voice-driven devices such as Amazon’s Alexa appeared. Online transcription services became useful. Web browsers offered automatic translations. Saying such things were enabled by ai started to sound cool, rather than embarrassing, though it was also a bit redundant; nearly every technology referred to as ai then and now actually relies on deep learning under the bonnet.
深度学习很快就被部署在各种新产品和服务中。像亚马逊的Alexa这样的语音驱动设备出现了。在线转录服务变得有用。网络浏览器提供了自动翻译。说这些事物是由人工智能实现的开始听起来很酷，而不是尴尬，尽管这也有点多余；几乎所有当时和现在被称为人工智能的技术实际上都依赖于深度学习。
Chatgpt and its rivals really do seem to “use language and form abstractions”
ChatGPT及其竞争对手确实似乎能够“使用语言并形成抽象概念”。
In 2017 a qualitative change was added to the quantitative benefits being provided by more computing power and more data: a new way of arranging connections between neurons called the transformer. Transformers enable neural networks to keep track of patterns in their input, even if the elements of the pattern are far apart, in a way that allows them to bestow “attention” on particular features in the data.
2017年，随着更多计算能力和更多数据提供的定量优势，又增加了一种定性变化：一种新的神经元连接方式，称为“变换器”（transformer）。变换器使神经网络能够跟踪其输入中的模式，即使模式的元素相隔很远，也能以一种使它们能够对数据中的特定特征赋予“注意力”的方式进行。
Transformers gave networks a better grasp of context, which suited them to a technique called “self-supervised learning”. In essence, some words are randomly blanked out during training, and the model teaches itself to fill in the most likely candidate. Because the training data do not have to be labelled in advance, such models can be trained using billions of words of raw text taken from the internet.
变换器赋予了网络更好的上下文理解能力，这使它们适合一种称为“自监督学习”的技术。本质上，在训练过程中，一些单词会被随机屏蔽，模型自学填充最有可能的候选词。由于训练数据不需要事先标记，因此可以使用从互联网获取的数十亿个单词的原始文本来训练这些模型。
Mind your language model
注意你的语言模型
Transformer-based large language models (llms) began attracting wider attention in 2019, when a model called gpt-2 was released by Openai, a startup (gpt stands for generative pre-trained transformer). Such llms turned out to be capable of “emergent” behaviour for which they had not been explicitly trained. Soaking up huge amounts of language did not just make them surprisingly adept at linguistic tasks like summarisation or translation, but also at things—like simple arithmetic and the writing of software—which were implicit in the training data. Less happily it also meant they reproduced biases in the data fed to them, which meant many of the prevailing prejudices of human society emerged in their output.
基于变换器的大型语言模型（LLMs）在2019年开始引起更广泛的关注，当时一家初创公司OpenAI发布了一个名为gpt-2的模型（gpt代表生成预训练变换器）。这些LLMs被证明能够表现出它们未被明确训练的“涌现”行为。吸收大量语言不仅使它们在诸如摘要或翻译等语言任务上出人意料地熟练，而且也使它们在训练数据中隐含的事物——如简单的算术和编写软件——表现出色。不那么令人高兴的是，这也意味着它们复制了输入数据中的偏见，这意味着许多人类社会的普遍偏见在它们的输出中显现出来。
In November 2022 a larger Openai model, gpt-3.5, was presented to the public in the form of a chatbot. Anyone with a web browser could enter a prompt and get a response. No consumer product has ever taken off quicker. Within weeks Chatgpt was generating everything from college essays to computer code. ai had made another great leap forward.
2022年11月，一个更大的OpenAI模型——gpt-3.5以聊天机器人的形式向公众展示。任何拥有网络浏览器的人都可以输入提示并得到响应。没有任何消费产品比这更快地起飞。几周之内，ChatGPT就生成了从大学论文到计算机代码的所有内容。人工智能再次迈出了巨大的飞跃。
Where the first cohort of ai-powered products was based on recognition, this second one is based on generation. Deep-learning models such as Stable Diffusion and dall-e, which also made their debuts around that time, used a technique called diffusion to turn text prompts into images. Other models can produce surprisingly realistic video, speech or music.
第一代人工智能驱动的产品基于识别，而这第二代产品则基于生成。像Stable Diffusion和dall-e这样的深度学习模型也大约在那时首次亮相，它们使用了一种称为“扩散”的技术将文本提示转化为图像。其他模型可以生成令人惊讶地逼真的视频、语音或音乐。
The leap is not just technological. Making things makes a difference. Chatgpt and rivals such as Gemini (from Google) and Claude (from Anthropic, founded by researchers previously at Openai) produce outputs from calculations just as other deep-learning systems do. But the fact that they respond to requests with novelties makes them feel very unlike software which recognises faces, takes dictation or translates menus. They really do seem to “use language” and “form abstractions”, just as McCarthy had hoped.
这一飞跃不仅仅是技术上的。创造事物会带来变化。ChatGPT及其竞争对手如Google的Gemini和Anthropic（由之前在OpenAI的研究人员创立）的Claude，像其他深度学习系统一样，从计算中产生输出。但它们以新颖性响应请求的事实使它们感觉非常不同于识别面孔、进行口述或翻译菜单的软件。它们确实似乎“使用语言”并“形成抽象概念”，正如麦卡锡所希望的那样。
This series of briefs will look at how these models work, how much further their powers can grow, what new uses they will be put to, as well as what they will not, or should not, be used for.
这一系列的简报将探讨这些模型是如何工作的，它们的能力还能扩展多远，它们将被用于什么新用途，以及它们不会或不应该被用于什么用途。
This article appeared in the Schools brief section of the print edition under the headline “A short history of AI”From the July 20th 2024 edition
]]></content>
  </entry>
  
  <entry>
    <title>成年人，一定要学会独立思考</title>
    <url>/post/adults-must-learn-to-think-independently.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>独立思考</tag>
    </tags>
    <content type="html"><![CDATA[我们每天都会接触到大量的信息和观点。这些信息和观点并非都是真实、客观的，有些甚至是误导性的。在面对问题时，要主动思考、分析、判断，而不是盲目跟从或随波逐流。只有独立思考，才能形成自己的观点和看法，进而在生活中做出符合自己利益的决策。
在与他人交流或讨论时，总会遇到不同的意见和看法。要时刻保持清醒的头脑，要有足够的勇气和自信坚持自己的想法，不要被他人的观点所左右。要知道自己想要什么，要判断信息的可靠性和价值，从而能够有针对性地去筛选和判断。
当然，独立思考并不是一味地否定他人或固执己见。相反，应该在尊重他人的基础上，进行平等、理性的交流，从中汲取有益的信息，进一步完善自己的观点。只有拥有了有主见的内心时，才能够真正地独立思考、自主决策，才能在复杂多变的世界中保持清醒和坚定。
]]></content>
  </entry>
  
  <entry>
    <title>揭示大脑学习奥秘的前沿探索</title>
    <url>/post/the-backprop-in-the-brain.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>Brain</tag>
    </tags>
    <content type="html"><![CDATA[在当今科技飞速发展的时代， 人工智能（AI）  已经成为驱动社会变革的核心力量。
然而，随着AI模型在各个领域的成功应用，科学家们开始探讨一个更加深奥的问题：AI的学习机制能否揭示人类大脑的工作原理？从赫布学习理论到前瞻性配置的新兴理论，揭开大脑学习的奥秘。
AI scientists are producing new theories of how the brain learns AI科学家正在提出大脑如何学习的新理论
The challenge for neuroscientists is how to test them 神经科学家面临的挑战是如何验证这些理论
一种关于神经元学习和连接机制的理论，由加拿大心理学家唐纳德·赫布（Donald Hebb）在1949年提出，因此得名。这个理论的核心思想是：如果两个神经元在相同的时间内被激活，那么它们之间的连接就会变得更强。简单来说，这一机制可以用一句通俗的话来概括：“一起发火的神经元会连接在一起”（&ldquo;Cells that fire together, wire together&rdquo;）。
基本原理：在大脑中，神经元通过突触连接相互通信。当一个神经元的激活导致另一个神经元的激活，并且这种激活反复发生时，这两个神经元之间的突触连接会被加强。这种连接的增强意味着，这两个神经元在未来更有可能一起被激活，从而形成更牢固的神经回路。这种学习机制解释了大脑如何通过经验和反复的刺激来调整和强化神经连接，从而实现学习和记忆的过程。
文章主要内容涵盖了以下几点：
 AI模型与大脑的学习机制：  Geoffrey Hinton博士通过发展人工神经网络，推动了当前AI模型的发展，其初衷是揭示大脑如何通过神经网络学习复杂任务。
文章指出，虽然反向传播算法在人工神经网络中表现出色，但在生物神经网络中的实现存在重大挑战。
反向传播算法的生物适用性挑战：  生物神经元和人工神经元在信息传递方式上的差异，使得反向传播算法在人脑中实施变得困难。尽管存在这些挑战，研究人员仍在探索如何使反向传播算法更符合生物学现实。
新兴的替代理论：  一些科学家提出了新理论，如“前瞻性配置”（prospective configuration），这与传统的反向传播算法截然不同，并且在测试中表现出更接近人类学习的特点。
实验验证的难度：  验证这些理论在大脑中是否起作用需要复杂的实验设计。斯坦福大学的研究团队利用AI模型尝试解决这一难题，他们开发的元模型可以从神经元活动记录中识别出使用的学习算法，这为将来研究大脑的学习机制提供了新思路。
重点词组  &ldquo;The challenge for neuroscientists is how to test them&rdquo;  这句话简洁明了地表述了神经科学家面临的核心问题。短句结构，突出重点，是地道的英语表达。
&ldquo;Five decades of research into artificial neural networks have earned Geoffrey Hinton the moniker of the Godfather of artificial intelligence (AI).&rdquo;  &ldquo;moniker&rdquo;: 意为“绰号”，用来描述一个人因某一成就或特点而被赋予的称呼。
这句话展示了如何在学术写作中使用有力的短语来强调某人的地位和贡献。
&ldquo;Brains learn by being subtly rewired&rdquo;  &ldquo;subtly rewired&rdquo;: 这个短语将大脑学习的过程比作电路重组，“subtly”这个词用得非常精妙，表示微妙而难以察觉的变化。
&ldquo;integral to this learning process is the so-called backpropagation-of-error algorithm&rdquo;  &ldquo;integral to&rdquo;: 表示“对……是必不可少的”，是学术和正式写作中非常有用的表达。
&ldquo;so-called&rdquo;: 用来引入一个特定术语或广为人知的名称，是常用的英语表达。
&ldquo;reverse-engineer&rdquo;  这个动词通常用于描述从现有产品倒推回去，试图了解其工作原理。文章用它来形容试图解析大脑学习过程，非常形象生动。
文章结构 文章的结构逻辑非常清晰。它从引出话题开始，逐步深入探讨，最终总结观点。具体来说：
 引入话题：文章一开始介绍了人工智能和神经科学的交汇点，通过Geoffrey Hinton的研究引出人工神经网络与大脑学习机制之间的关系。 背景铺垫：接着，文章解释了大脑学习的复杂性和当前科学家面临的挑战，为后续讨论奠定基础。 核心讨论：文章详细探讨了反向传播算法、赫布学习理论以及最新的前瞻性配置理论，展示了科学界的多样性思考。 实验和实践：然后，文章介绍了具体的实验和研究，展示了理论在实际应用中的探索。 总结和前景：最后，文章总结了这些理论的重要性，并指出未来研究的方向。  ]]></content>
  </entry>
  
  <entry>
    <title>一个家变好的最快方式：好好说话</title>
    <url>/post/talk-nicely-to-make-family-better.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>好好说话</tag>
      <tag>毒舌</tag>
    </tags>
    <content type="html"><![CDATA[不要总觉得自己对，不要总站在自己的立场上想问题。一个家，不要总想着在语言上争高低，力求压对方一头。吵赢不是目的，解决问题才是。在自己发脾气之前，一定要想清楚，你是在发泄情绪，还是在解决问题。强烈的语言攻击，真的能令人心悸、腿发软。
有一种家庭，一说话就吵架，明明是关心，明明是小事，偏偏要上纲上线，还要翻旧账。有时候，压根不为任何事，就是自己心情不好，想要找事，让别人不痛快。不要总觉得自己没坏心，一个人一旦不会好好说话，再好的心也会让人厌恶。
活干得最多，还不落好，全坏在一张嘴上。好好说话，是一个家变好的最快方式，一旦你的心态平和了，你的语言不带情绪了，对方的情绪也就平和了。别一说话，就想反驳，给彼此留余地。多赞美，多聆听，别逞强，别揭短。
]]></content>
  </entry>
  
  <entry>
    <title>无需比较，我独我</title>
    <url>/post/no-need-to-compare-I-am-alone.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>自我认同</tag>
    </tags>
    <content type="html"><![CDATA[每个人都是独一无二的存在，每个人的生命轨迹也都是独一无二的，要以自己的节奏和方式前行。不要下意识地和他人比较，要把自己的真实感受和需求放在首位。你越是比较，就会越焦虑。别人优秀，无需羡慕；别人落魄，也不要出言奚落。
坚持走自己想走的路，要不畏风雨、砥砺前行。即使自己不堪，那也是自己，独一无二的自己。只要努力地做了自己，就会自成一道风景，吸引那些真正同类的人。不敢做自己的人，一生难觅真情和知己，因为自己是假的，事事都会虚假。
人生在世，不求事事如意，但求事事甘心。要有“事出自愿，情过无悔”的淡定从容，不随波逐流，亦不妄自菲薄。去修复自己的样子，精进自己的样子，让自己成为自己最希望的样子，然后珍惜自己的样子。那份由内而外散发的自信与光芒，是任何外在的比较都无法企及的。
]]></content>
  </entry>
  
  <entry>
    <title>北南南北</title>
    <url>/about.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[北南南北 是众多使用 VxWorks 嵌入式实时操作系统的网友分享经验的平台，为的就是让 VxWorks 的学习和应用变得相对开放一些，在此也欢迎你的加入！
我们的愿景 技术创新是技术持续发展的生命力，紧跟技术的发展趋势，研究最新的技术，保持对新技术的热情和好奇心，让技术为生产和生活服务。
使用反馈  加入 VxWorks Club   或 Google AI TPU     欢迎你的加入
 ]]></content>
  </entry>
  
  <entry>
    <title>友情链接</title>
    <url>/flinks.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: VxWorks俱乐部 desc: VxWorks实时操作系统 avatar: https://www.vxworks.net/images/vxworks-club-logo.png link: https://www.vxworks.net ]]></content>
  </entry>
  
</search>