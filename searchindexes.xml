<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
  
  <entry>
    <title>闭嘴，你认为的不重要</title>
    <url>/post/what-you-think-is-not-important.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>指手画脚</tag>
    </tags>
    <content type="html"><![CDATA[最讨厌一些人，总是把自己的意志强加给别人。总是觉得自己高高在上，觉得自己以为的都是对的，还要打着为他人好的名义，对他人的人生、行为、语言，指手画脚，评头论足。可其实，他自己压根做不到，他只是喜欢通过批评打压别人，来显示自己的优越性。
人不能总是把自己看得太高，把他人看得太低。每个人都是一个单独的、值得尊重的个体，哪怕他是个孩子，哪怕他穷困潦倒，哪怕他人生失败，那也是他值得尊重的人生。你可以不认可，但你要尊重，因为允许他人与自己不同，是人最基本的善良。
不要总是你认为。这个世界上的事情，从来不是非黑即白，不同的角度，不同的立场，事件的感观完全不同。更不要，浅薄地觉得你认为的都是对的，未见事件全貌，最好的做法是闭嘴。闭嘴，你认为的不重要。改变自己，是上进，改变他人，是愚蠢。
]]></content>
  </entry>
  
  <entry>
    <title>让自己快乐起来</title>
    <url>/post/make-yourself-happy.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>快乐</tag>
    </tags>
    <content type="html"><![CDATA[让自己快乐起来，就要学会放下。生活中总有太多包袱，让我们步履维艰。那些过去的遗憾、未竟的梦想、人际的纠葛……像一道道枷锁，困扰着我们的心灵。每一次放下，都是一次重生。勇敢地面对自己的不足，学会释怀与原谅，便会豁然开朗，快乐也就随之而来。
快乐，不需要太多的物质条件。心情不好了，不妨走出户外，去感受大自然。春日里繁花似锦的绚烂，夏日里绿树成荫的清凉，秋日里硕果累累的丰饶，冬日里银装素裹的静谧。每一处风景，都是大自然赋予我们的礼物，值得去发现、去欣赏、去珍惜。
打开心扉，去感受生活中的美好与温暖，去拥抱每一个当下，快乐就会陪伴在我们左右。清晨，当第一缕阳光悄悄探进窗棂，轻柔地拂过你的脸颊，那便是快乐在轻轻敲门。不妨在这宁静的时刻，给自己一个微笑，告诉自己：新的一天，从快乐开始。
]]></content>
  </entry>
  
  <entry>
    <title>英国科技巨头迈克·林奇海上遇难</title>
    <url>/post/british-tech-mogul-mike-lynch-dies-at-sea.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>Mike Lynch</tag>
    </tags>
    <content type="html"><![CDATA[“英国知名软件技术企业家迈克·林奇搭载的豪华游艇19日凌晨在意大利西西里岛附近海域沉没，这起海难引发广泛关注。林奇所乘游艇在“几分钟内”快速沉没，而附近类似船只却免于遇难，舆论认为其中疑点颇多，对事故原因推测说法不一。”
迈克·林奇：英国软件巨头的崛起与沉沦
在1991年12月25日苏联解体后，美国成为了全球唯一的超级大国，以其无可匹敌的军事力量统治着世界。然而，故事的另一面却在英国上演，一个名叫迈克·林奇的英国科技企业家，凭借着对概率的深刻理解，逆势崛起，成为英国首位软件亿万富翁。
林奇在剑桥大学攻读博士学位时，研究了贝叶斯定理，这一18世纪的公式揭示了在正确理解概率的前提下，大多数结果都是可预测的。林奇将这一思想应用于他于1996年创立的公司——Autonomy，并在2011年将其以117亿美元的价格卖给了惠普公司。这一交易让他赚取了8亿美元的财富，也让他被誉为“英国的比尔·盖茨”。
然而，命运的转折出现在Autonomy的出售后。惠普指控林奇在公司账目中存在严重的会计违规行为，导致公司估值被人为抬高。林奇被捕并被引渡到美国，面临15项欺诈和共谋指控。在美国，联邦法庭的审判几乎没有失败的先例，99%以上的案件最终都会判定有罪。然而，林奇选择了抗争，他的辩护律师团队坚称，Autonomy的会计方式是业界的常规做法。经过漫长的法律拉锯战，林奇最终被判无罪。
林奇从未停止过对创新的追求。他在摆脱法律纠纷后，计划继续他的创业之路，并誓言要为改变英美之间不公正的引渡法而奋斗。然而，命运再一次对他开了玩笑。在西西里岛北部海域的一场突如其来的风暴中，林奇和他的几位朋友在游艇上庆祝他法庭上的胜利时，不幸遭遇了龙卷风，游艇翻覆，林奇与其他四人的遗体在数日后被找到。
林奇的故事是一部充满戏剧性的传奇，他从一个普通家庭出身，通过个人的奋斗和卓越的智慧，达到了事业的巅峰，却在命运的转折点上遭遇了意外的沉沦。这不仅是一个科技巨头的兴衰史，更是一曲关于人类在不可预测的世界中，努力掌控命运的壮丽悲歌。
原文 Mike Lynch was Britain’s first software billionaire 迈克·林奇是英国的首位软件亿万富翁
He was celebrating his freedom when his yacht sank in a freak storm 他在庆祝自己重获自由时，他的游艇却在一场罕见的风暴中沉没。
Bayes’s theorem, an 18th-century formula, holds that with the right understanding of probabilities, most outcomes are predictable. But sometimes freak events occur. In the early hours of August 19th, a superyacht owned by the wife of Mike Lynch, a British tech entrepreneur who only months ago was cleared in a vast American fraud case, was struck by a waterspout, a form of tornado, off the north coast of Sicily, and capsized. On August 22nd it was confirmed that Mr Lynch was among five bodies recovered from the sunken yacht; rescue teams continued to search for a missing woman. It was a tragic end to an extraordinary story. 贝叶斯定理是一种18世纪的公式，认为在正确理解概率的情况下，大多数结果是可以预测的。但有时会发生极其罕见的事件。8月19日凌晨，英国科技企业家迈克·林奇的妻子所拥有的一艘超级游艇在西西里岛北海岸被一种名为水龙卷的龙卷风袭击后翻覆。8月22日，救援队确认从沉没的游艇中找到了包括林奇在内的五具遗体，救援队仍在寻找一名失踪的女性。这是一个非凡故事的悲惨结局。
Bayesian thinking was at the heart of Mr Lynch’s astonishing rise. It was the subject of his phd thesis at Cambridge and formed the basis of Autonomy, the company he founded in 1996 and sold to Hewlett-Packard (hp) for $11.7bn in 2011, earning him $800m. Mr Lynch named his now-submerged yacht Bayesian. Some called him the “British Bill Gates” as he racked up accolades: an obe, board seats at the bbc and the British Library, an advisory role in Downing Street. Few could have predicted that he would find himself arrested and facing more than two decades behind bars. 贝叶斯思维是林奇惊人崛起的核心。他在剑桥大学攻读博士学位时就研究了这一理论，并将其作为他在1996年创立的公司Autonomy的基础。2011年，林奇将Autonomy以117亿美元的价格卖给了惠普公司（HP），赚取了8亿美元的财富。林奇将他现在沉没的游艇命名为“贝叶斯”（Bayesian）。有人称他为“英国的比尔·盖茨”，因为他获得了无数荣誉：如大英帝国勋章（OBE）、BBC和大英图书馆的董事席位、唐宁街的顾问角色。很少有人能预测到他会被逮捕，并面临超过二十年的监禁。
Mr Lynch’s years-long legal battle, sparked by the sale of Autonomy, is regarded as one of Silicon Valley’s biggest-ever fraud cases. Accused by hp of using “serious accounting improprieties” to inflate Autonomy’s value, Mr Lynch was taken into custody and extradited to America in chains. Facing 15 counts of fraud and conspiracy, he was kept under house arrest in San Francisco. hp, which took an $8.8bn write-down on the value of Autonomy within a year of its purchase, was eventually broken up in 2015. 林奇的法律纠纷源于他出售Autonomy的交易，这场旷日持久的法律战被认为是硅谷历史上最大的欺诈案件之一。惠普指控林奇使用“严重的会计不当行为”来夸大Autonomy的价值，林奇因此被捕并戴着镣铐被引渡到美国。面对15项欺诈和共谋指控，他被软禁在旧金山。惠普在购买Autonomy一年内就为其减记了88亿美元的价值，该公司最终在2015年解散。
The odds were stacked against Mr Lynch. Less than 1% of federal cases end in acquittal. The vast majority of defendants plead guilty in return for more lenient sentences. To make matters worse, Charles Breyer, the judge who would hear Mr Lynch’s case, had already jailed Sushovan Hussain, Autonomy’s former chief financial officer. A British judge had also ruled in favour of hp in a separate civil lawsuit. 林奇的胜算并不大。联邦案件中，少于1%的案件以无罪结案，绝大多数被告选择认罪以换取较轻的判罚。更糟糕的是，负责审理林奇案件的法官查尔斯·布雷耶此前已将Autonomy的前首席财务官苏绍万·侯赛因送进了监狱。英国的一位法官在另一场民事诉讼中也判惠普胜诉。
His decision to take the stand was another gamble. Federal prosecutors depicted Mr Lynch as a “controlling, dominating, intimidating boss”. He was, his lawyers admitted, a “hard charger”. But they insisted that he delegated most of the accounting, and was a prototypical “startup guy” who enjoyed inventing things. hp’s botched deal, they argued, was simply a case of buyer’s remorse. In June Mr Lynch and his co-defendant, Stephen Chamberlain, were cleared by a jury of all charges. 林奇决定上庭作证，这又是一次赌博。联邦检察官将他描绘成一个“控制欲强、具有威吓力的老板”。林奇的律师承认他是一个“强硬的人”，但坚称他将大部分会计工作交给了他人处理，并强调他是一个典型的“创业者”，热衷于发明创造。林奇的律师团队还辩称，惠普的交易失败只是买家的悔意使然。最终，在2023年6月，林奇和他的共同被告斯蒂芬·张伯伦被陪审团宣判无罪。
Mr Lynch had beaten the odds before. Born to a fireman and nurse in London, he spent holidays working as a cleaner at his mother’s hospital. A gifted student, he won a scholarship to Bancroft’s, a private school in London, and later read natural sciences at Cambridge. There he immersed himself in adaptive pattern recognition, an early form of artificial intelligence (ai) that later fuelled Autonomy’s growth. Both Autonomy and Darktrace, a cyber-security firm he co-founded, were headquartered in the market town. 林奇早在学生时代就展现出了战胜困难的毅力。他出生在伦敦的一个消防员和护士家庭，在母亲工作的医院打工清洁卫生。他是一个天才学生，获得了伦敦私立学校Bancroft’s的奖学金，后来在剑桥大学学习自然科学。在那里，他沉浸于自适应模式识别的研究，这是一种早期的人工智能形式，后来推动了Autonomy的发展。Autonomy和他共同创立的网络安全公司Darktrace的总部都设在这座市场小镇。
The entrepreneur had always maintained his innocence. “Software accounting is complex,” he said after his acquittal. He called his company’s methods of record-keeping the norm across the industry. Having returned to Britain, he was keen to get back to innovating and vowed to campaign against what he saw as unjust extradition laws between Britain and America. He told reporters he had been looking forward to his “second life” as a free man. 林奇始终坚持自己的清白。在被判无罪后，他说：“软件会计是复杂的。”他认为公司采用的记录方式在行业中是标准做法。回到英国后，他渴望重新开始创新，并发誓要反对他认为不公正的英美引渡法。他告诉记者，他一直期待着作为一个自由人的“第二次生命”。
Mr Lynch had been celebrating his court victory aboard Bayesian when the violent gale struck. His guests included Chris Morvillo, the partner who led Mr Lynch’s defence team at Clifford Chance, a law firm, and Jonathan Bloomer, a key witness in the court case, and the chairman of the international arm at Morgan Stanley, a bank, who are both thought to be among the bodies recovered. Freakishly, just days before the yacht sank Mr Lynch’s co-defendant, Stephen Chamberlain, also died after being hit by a car in Britain. That Mr Lynch’s life has been cut short, too, is a cruel, final twist. ■ 然而，林奇的胜利庆祝会却被突如其来的风暴打断。他的游艇上有包括为林奇辩护的律师团队领导人克里斯·莫维洛、案件中的关键证人、摩根士丹利国际部主席乔纳森·布鲁默在内的几位客人，他们都被认为是被找到的遗体之一。令人难以置信的是，就在游艇沉没前几天，林奇的共同被告斯蒂芬·张伯伦也在英国被车撞死。林奇的生命同样被无情地终结，这实在是一个残酷的结局。
高级词汇和术语  Freak storm - 罕见的风暴，指极其少见且通常具有破坏性的天气现象。  例句: &ldquo;He was celebrating his freedom when his yacht sank in a freak storm.&rdquo;
 Bayes’s theorem - 贝叶斯定理，18世纪的一个公式，用于在概率推断中进行计算。  例句: &ldquo;Bayes’s theorem, an 18th-century formula, holds that with the right understanding of probabilities, most outcomes are predictable.&rdquo;
 Extradition - 引渡，指将被指控或定罪的人从一个司法辖区移交给另一个司法辖区的法律程序。  例句: &ldquo;Accused by hp of using &lsquo;serious accounting improprieties&rsquo; to inflate Autonomy’s value, Mr Lynch was taken into custody and extradited to America in chains.&rdquo;
 House arrest - 软禁，指被法律限制在家中不得自由活动的状态。  例句: &ldquo;Facing 15 counts of fraud and conspiracy, he was kept under house arrest in San Francisco.&rdquo;
 Acquittal - 无罪释放，指通过法律程序正式宣布被告无罪。  例句: &ldquo;Less than 1% of federal cases end in acquittal.&rdquo;
 Buyer’s remorse - 购买后的懊悔，指消费者在购买后感到的后悔，尤其是当花费了大量金钱时。  例句: &ldquo;hp’s botched deal they argued was simply a case of buyer’s remorse.&rdquo;
 Adaptive pattern recognition - 自适应模式识别，一种早期的人工智能形式，可以识别模式并适应新的数据。  例句: &ldquo;There he immersed himself in adaptive pattern recognition, an early form of artificial intelligence (AI)   that later fuelled Autonomy’s growth.&rdquo;
复杂句型结构  “Bayes’s theorem, an 18th-century formula, holds that with the right understanding of probabilities, most outcomes are predictable.”  解析: 这是一个复杂的复合句，主句是“Bayes’s theorem&hellip;holds&hellip;”，中间插入了同位语“an 18th-century formula”，用来解释Bayes’s theorem是什么。逗号后面的从句“that with the right understanding of probabilities, most outcomes are predictable”进一步解释了该定理的含义。
 “Accused by hp of using &lsquo;serious accounting improprieties&rsquo; to inflate Autonomy’s value, Mr Lynch was taken into custody and extradited to America in chains.”  解析: 这是一个复杂的复合句，主句是“Mr Lynch was taken into custody and extradited to America”，前面的现在分词短语“Accused by hp of using &lsquo;serious accounting improprieties&rsquo; to inflate Autonomy’s value”用来描述Lynch被捕的原因。
 “hp’s botched deal, they argued, was simply a case of buyer’s remorse.”  解析: 这是一个复杂的复合句，主句是“hp’s botched deal was&hellip;”，中间插入了“they argued”作为插入语，表示这是别人提出的论点。
 “There he immersed himself in adaptive pattern recognition, an early form of artificial intelligence (AI) that later fuelled Autonomy’s growth.”  解析: 这是一个复杂的复合句，主句是“He immersed himself in adaptive pattern recognition”，后面的同位语“an early form of artificial intelligence (AI)”进一步解释了adaptive pattern recognition的含义，同时从句“that later fuelled Autonomy’s growth”补充说明了其对Autonomy发展的影响。
]]></content>
  </entry>
  
  <entry>
    <title>真正的自由，是情绪自由</title>
    <url>/post/true-freedom-is-emotional-freedom.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>是情绪自由</tag>
    </tags>
    <content type="html"><![CDATA[只要不伤害他人，就应该让自己的情绪自由一点。压抑了，崩溃了，想哭了，就哭一场。哭是一种宣泄，也是一种自救。哭过之后，心静了，也就轻松了。偶尔麻木，偶尔沉沦，没什么大不了。情绪自由了，才是真正的自由。
情绪自由，不是放纵自己的情感，任由它们如脱缰的野马般肆意奔腾；也不是冷漠无情，对世间万物都无动于衷。而是在理解自己情绪的基础上，能够自如地接纳并化解这些情绪。长期压抑自己，真的会生大病。人活着，就要活一个顺心。
没有任何一种情绪，是你不该拥有的。真正的情绪自由，是由内而外，接受自己情绪的各种状态。情绪来了，最好的方法不是无限制地压制，而是平和的接受，发自内心的接受，然后找到方法，化解负面情绪。真正的自由，不仅仅是外在的解脱与释放，更是内在的觉醒与成长。
]]></content>
  </entry>
  
  <entry>
    <title>什么可能终结一万亿美元的人工智能繁荣</title>
    <url>/post/what-could-kill-the-1trn-artificial-intelligence-boom.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>Nvidia</tag>
    </tags>
    <content type="html"><![CDATA[本文讨论了 人工智能（AI）  产业的巨大投资热潮及其潜在风险。尽管AI数据中心的投资金额巨大，科技巨头们仍然继续大规模投资，导致供应链中的相关公司也在迅速扩展。然而，文章指出了这种投资热潮中的多个风险，包括对Nvidia的高度依赖、电力供应瓶颈以及需求可能减弱的风险。这些因素可能会影响整个AI供应链的稳定性。读者可以了解到AI行业的现状和未来面临的挑战，激发对AI产业发展的兴趣。
“The risk of under-investing is dramatically greater than the risk of over-investing,” said Sundar Pichai, the boss of Alphabet, on an earnings call last week. He, like lots of executives nowadays, was talking about artificial intelligence (ai). More specifically, he was talking about building more ai data centres to serve the customers of the tech giant’s cloud-computing arm. The sums involved are eye-popping. Alphabet’s capital spending is expected to grow by about half this year, to $48bn. Much of that will be spent on ai-related gear.
“低投资的风险远大于高投资的风险”，Alphabet的老板Sundar Pichai在上周的财报电话会议上说道。像很多高管一样，他在谈论人工智能（AI）。更具体地说，他在谈论为这家科技巨头的云计算部门客户建设更多的AI数据中心。涉及的金额令人瞠目结舌。预计Alphabet的资本支出今年将增长约50%，达到480亿美元，其中大部分将用于AI相关设备。
Mr Pichai is not alone. New Street Research, a firm of analysts, estimates that Alphabet, Amazon, Meta and Microsoft will together splurge $104bn on building ai data centres this year. Add in spending by smaller tech firms and other industries and the total ai data-centre binge between 2023 and 2027 could reach $1.4trn.
Pichai并不孤单。分析公司New Street Research估计，Alphabet、Amazon、Meta和Microsoft今年将共同花费1040亿美元建设AI数据中心。加上小型科技公司和其他行业的支出，2023年至2027年间的AI数据中心狂潮总支出可能达到1.4万亿美元。
The scale of this investment, and uncertainty over if and when it will pay off, is giving shareholders the jitters. The day after Alphabet’s results the nasdaq, a tech-heavy index, fell by 4%, the biggest one-day drop since October 2022. This week analysts will pore over the quarterly results of Amazon and Microsoft, the world’s two biggest cloud companies, for clues as to how their ai businesses are faring.
这种投资规模和不确定性让股东们感到不安。Alphabet发布业绩的第二天，科技重的纳斯达克指数下跌了4%，这是自2022年10月以来最大的一天跌幅。本周，分析师们将细读Amazon和Microsoft这两家全球最大的云公司季度业绩，以寻找其AI业务表现的线索。
For now, the tech giants show little inclination to pare back their investments, as Mr Pichai’s remarks show. That is good news for the myriad suppliers that are benefiting from the boom. Nvidia, a maker of ai chips that in June briefly became the world’s most valuable company, has grabbed most of the headlines. But the ai supply chain is far more sprawling. It spans hundreds of firms, from Taiwanese server manufacturers and Swiss engineering outfits to American power utilities. Many have seen a surge in demand since the launch of Chatgpt in 2022, and are themselves investing accordingly. In time, supply bottlenecks or waning demand could leave them over-extended.
目前，科技巨头们显示出削减投资的意愿不大，正如Pichai的言论所示。这对于从繁荣中受益的无数供应商来说是个好消息。AI芯片制造商Nvidia在6月短暂成为世界上最有价值的公司，吸引了大多数头条新闻。但AI供应链要广泛得多。它涵盖了从台湾服务器制造商和瑞士工程公司到美国电力公司的数百家公司。自从2022年推出ChatGPT以来，许多公司看到了需求激增，并相应地进行了投资。随着时间的推移，供应瓶颈或需求减弱可能会使它们过度扩展。
ai investment can broadly be split into two. Half of it goes to chipmakers, with Nvidia the main beneficiary. The rest is spent on makers of equipment that keeps the chips whirring, ranging from networking gear to cooling systems. To assess the goings-on along the ai supply chain, The Economist has examined a basket of 60-odd such companies. Since the start of 2023 the mean share price of firms in our universe has risen by 106%, compared with a 42% increase in the s&amp;p 500 index of American stocks (see chart). Over that time their expected sales for 2025 climbed by 14%, on average. That compares with a 1% increase across non-financial firms, excluding tech companies, in the s&amp;p 500.
AI投资大致可以分为两部分。一半用于芯片制造商，主要受益者是Nvidia。其余部分用于制造保持芯片运行的设备，从网络设备到冷却系统。为了评估AI供应链的动向，《经济学人》研究了一篮子大约60家此类公司。自2023年初以来，我们观察的公司平均股价上涨了106%，而同期标准普尔500指数上涨了42%。同期，这些公司2025年的预期销售额平均增长了14%。相比之下，标准普尔500指数中的非金融企业（不包括科技公司）预期销售额仅增长了1%。
The biggest gainers were chipmakers and server manufacturers (see chart). Nvidia accounted for almost a third of the rise in the group’s expected sales. It is forecast to sell $105bn of ai chips and related equipment this year, up from $48bn in its latest fiscal year. amd, its nearest rival, will probably sell about $12bn of data-centre chips this year, up from $7bn. In June Broadcom, another chipmaker, said that its quarterly ai revenues jumped by 280%, year on year, to $3.1bn. It helps customers, including cloud providers, design their own chips, and also sells networking equipment. Two weeks later Micron, a maker of memory chips, said its data-centre revenues had also jumped, thanks to soaring ai demand.
涨幅最大的公司是芯片制造商和服务器制造商。Nvidia占该组预期销售额增长的近三分之一。预计今年将销售1050亿美元的AI芯片及相关设备，而在其最新财政年度，这一数字为480亿美元。其最近的竞争对手AMD今年可能会销售约120亿美元的数据中心芯片，高于去年的70亿美元。6月，另一家芯片制造商Broadcom表示，其季度AI收入同比增长280%，达到31亿美元。它帮助包括云服务提供商在内的客户设计自己的芯片，还销售网络设备。两周后，内存芯片制造商Micron表示，由于AI需求激增，其数据中心收入也大幅增长。
Companies that make servers are also raking it in. Both Dell and Hewlett Packard Enterprise (hpe) said in their most recent earnings calls that sales of ai servers doubled in the past quarter. Foxconn, a Taiwanese manufacturer that assembles lots of Apple’s iPhones, also has a server business. In May it said its ai sales had tripled over the past year.
服务器制造商也在赚钱。Dell和Hewlett Packard Enterprise（HPE）在最近的财报电话会议上表示，AI服务器的销售额在过去一个季度翻了一番。组装大量苹果iPhone的台湾制造商Foxconn也有服务器业务。5月，该公司表示其AI销售额在过去一年增长了三倍。
Other firms are seeing interest spike, even if new sales have not yet materialised. Eaton, an American maker of industrial machinery, said that in the past year it saw more than a four-fold increase in customer enquiries related to its ai data-centre products. ai servers can require up to ten times more power than conventional ones. Earl Austin junior, the boss of Quanta Services, a firm that builds renewable-power and transmission equipment, recently admitted that the surge in demand for its data-centre business had “caught me off guard a little bit”. Vertiv, which sells cooling systems used in data centres, noted in April that its pipeline of ai projects more than doubled within two months.
即使新销售尚未实现，其他公司也看到了兴趣激增。美国工业机械制造商Eaton表示，过去一年中，与其AI数据中心产品相关的客户咨询量增加了四倍。AI服务器可能需要比传统服务器多十倍的电力。Quanta Services的老板Earl Austin Junior最近承认，其数据中心业务的需求激增“让我有点措手不及”。4月，销售数据中心冷却系统的Vertiv表示，其AI项目的管道在两个月内增加了一倍多。
All this interest is setting off a further frenzy of investment. This year around two-thirds of firms in our sample are expected to raise their capital expenditure, relative to sales, above their five-year averages. Many companies are building new factories. They include Wiwynn, a Taiwanese server-maker, Supermicro, an American one, and Lumentum, an American seller of advanced networking cables. Many are also spending more on research and development.
所有这些兴趣引发了进一步的投资狂潮。今年，我们样本中的三分之二的公司预计将提高其资本支出，相对于其五年平均水平。许多公司正在建设新工厂，包括台湾服务器制造商Wiwynn、美国服务器制造商Supermicro和美国高级网络电缆销售商Lumentum。许多公司还在研发上投入更多。
Some companies are investing through acquisitions. This month amd said it was buying Silo ai, a startup, to boost its ai capabilities. In January hpe announced that it would spend $14bn to buy Juniper Networks, a networking firm. In December Vertiv announced its purchase of CoolTera, a liquid-cooling specialist. The firm hopes this will help it scale up its production of liquid-cooling technology 40-fold.
一些公司通过收购进行投资。AMD本月表示正在收购初创公司Silo AI以增强其AI能力。1月，HPE宣布将花费140亿美元收购网络公司Juniper Networks。12月，Vertiv宣布收购液体冷却专家CoolTera。该公司希望这将帮助其将液体冷却技术的生产规模扩大40倍。
Just as the spending ramps up, though, the threats to the ai supply chain are building. One problem is its heavy reliance on Nvidia. Baron Fung, of Dell’Oro Group, a research firm, notes that when Nvidia went from launching a new chip every two years to every year, the entire supply chain had to scramble to build new production lines and meet accelerated timelines. Future sales for lots of firms in the ai supply chain are predicated on keeping the world’s most valuable chipmaker happy.
然而，随着支出增加，AI供应链的威胁也在加剧。一个问题是对Nvidia的高度依赖。研究公司Dell’Oro Group的Baron Fung指出，当Nvidia从每两年发布一款新芯片变为每年发布一款新芯片时，整个供应链不得不拼命建立新的生产线并满足加速的时间表。许多AI供应链公司的未来销售额取决于让这个世界上最有价值的芯片制造商满意。
Another threat stems from supply bottlenecks, most notably in the availability of power. An analysis by Bernstein, a broker, looks at a scenario in which by 2030 ai tools are used roughly as much as Google search is today. That would raise the growth in power demand in America to 7% a year, from 0.2% between 2010 and 2022. It would be hard to build that much power capacity swiftly. Stephen Byrd of Morgan Stanley, a bank, notes that in California, where many ai data centres could be built, it takes six to ten years to get connected to the grid.
另一个威胁来自供应瓶颈，最显著的是电力供应。经纪公司Bernstein的分析看了一种情景，即到2030年，AI工具的使用频率大致与今天的Google搜索相同。这将使美国的电力需求增长从2010年至2022年的0.2%提高到每年7%。快速建立这么多的电力容量将很困难。摩根士丹利银行的Stephen Byrd指出，在许多AI数据中心可能建在的加州，接入电网需要六到十年。
Some companies are already trying to fill the gaps by providing off-grid power. In March Talen Energy, a power company, sold Amazon a data centre connected to a nuclear-power plant for $650m. CoreWeave, a small ai cloud provider, recently struck a deal with Bloom Energy, a fuel-cell maker, to produce on-site power. Others are repurposing sites such as bitcoin-mining locations that already have grid access and power infrastructure. Still, the energy needs for ai are so vast that the risk of a power shortage limiting activity remains.
一些公司已经在尝试通过提供离网电力来填补空白。3月，电力公司Talen Energy以6.5亿美元的价格将一个连接到核电站的数据中心出售给Amazon。一家小型AI云服务提供商CoreWeave最近与燃料电池制造商Bloom Energy达成协议，生产现场电力。其他公司正在改造比特币矿场等已经接入电网并拥有电力基础设施的场所。然而，AI对电力的需求如此巨大，以至于电力短缺限制活动的风险依然存在。
The biggest threat to the ai supply chain would come from waning demand. In June Goldman Sachs, a bank, and Sequoia, a venture-capital firm, published reports questioning the benefits of current generative-ai tools, and—by extension—the wisdom of the cloud-computing giants’ spending bonanza. If ai profits remain elusive, the tech giants could cut capital spending, leaving the supply chain exposed.
AI供应链的最大威胁来自需求减弱。6月，投资银行高盛和风险投资公司红杉资本发布报告，质疑现有生成式AI工具的好处，从而质疑云计算巨头的疯狂支出的合理性。如果AI利润仍然难以捉摸，科技巨头可能会削减资本支出，留下供应链暴露在外。
The build-out of factories has brought higher fixed costs. Across our sample of firms the median spending on property, plants and equipment is expected to jump by 14% between 2023 and 2025. Some investments may start to look suspect if demand is slow to materialise. The price tag on hpe’s purchase of Juniper Networks was two-thirds of the acquirer’s market value when it was announced in January.
工厂建设带来了更高的固定成本。我们样本中的公司预计在2023年至2025年间在房地产、工厂和设备上的支出中值将增长14%。如果需求增长缓慢，一些投资可能开始看起来可疑。1月宣布的HPE收购Juniper Networks的价格标签是收购方市值的三分之二。
Even after the wobbles of last week, market expectations remain bullish. For our sample of firms the median price-to-earnings ratio, a measure of how investors value profits, has climbed by nine percentage points since the start of 2023. If such expectations are to be met, ai tools need to improve quickly, and businesses need to adopt them en masse. For the many companies along the ai supply chain, the stakes are getting uncomfortably high.
尽管上周的动荡，市场预期仍然看好。对于我们样本中的公司，衡量投资者对利润估值的市盈率中值自2023年初以来增长了九个百分点。如果要满足这些期望，AI工具需要迅速改进，企业需要大规模采用。对于许多AI供应链中的公司来说，赌注越来越高。
]]></content>
  </entry>
  
  <entry>
    <title>人工智能简史</title>
    <url>/post/a-short-history-of-AI.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>History</tag>
    </tags>
    <content type="html"><![CDATA[ 人工智能  自1956年达特茅斯会议起历经波折，至2019年基于变换器的大型语言模型（LLMs）如GPT-2引发关注，展示了未经明确训练的“涌现”能力。2022年 GPT-3.5  以聊天机器人形式出现，标志着AI从识别转向生成，不仅能完成语言任务，还能创作图像、视频等，实现技术与应用的双重飞跃，使AI更接近麦卡锡“使用语言、形成抽象”的愿景。
In the first of six weekly briefs, we ask how AI overcame decades of underdelivering
Over the summer of 1956 a small but illustrious group gathered at Dartmouth College in New Hampshire; it included Claude Shannon, the begetter of information theory, and Herb Simon, the only person ever to win both the Nobel Memorial Prize in Economic Sciences awarded by the Royal Swedish Academy of Sciences and the Turing Award awarded by the Association for Computing Machinery. They had been called together by a young researcher, John McCarthy, who wanted to discuss “how to make machines use language, form abstractions and concepts” and “solve kinds of problems now reserved for humans”. It was the first academic gathering devoted to what McCarthy dubbed “artificial intelligence”. And it set a template for the field’s next 60-odd years in coming up with no advances on a par with its ambitions.
在1956年夏天，一小群杰出但规模不大的人士聚集在新罕布什尔州的达特茅斯学院；其中包括信息理论的创始人克劳德·香农和唯一同时获得瑞典皇家科学院颁发的诺贝尔经济学纪念奖和计算机协会颁发的图灵奖的赫伯特·西蒙。他们是由一位年轻的研究员约翰·麦卡锡召集的，他想讨论“如何让机器使用语言，形成抽象和概念”以及“解决现在只留给人类的问题”。这是第一次学术聚会，专门讨论麦卡锡所说的“人工智能”。它为该领域接下来60多年的发展设定了一个模板，即在与它的雄心壮志相匹配的进步上没有取得任何进展。
The Dartmouth meeting did not mark the beginning of scientific inquiry into machines which could think like people. Alan Turing, for whom the Turing prize is named, wondered about it; so did John von Neumann, an inspiration to McCarthy. By 1956 there were already a number of approaches to the issue; historians think one of the reasons McCarthy coined the term artificial intelligence, later ai, for his project was that it was broad enough to encompass them all, keeping open the question of which might be best. Some researchers favoured systems based on combining facts about the world with axioms like those of geometry and symbolic logic so as to infer appropriate responses; others preferred building systems in which the probability of one thing depended on the constantly updated probabilities of many others.
达特茅斯会议并不是科学探究能够像人类一样思考的机器的开始。图灵奖的命名者艾伦·图灵思考过这个问题；麦卡锡的灵感来源之一约翰·冯·诺伊曼也思考过。到1956年，已经有多种方法来解决这个问题；历史学家认为麦卡锡为他的项目创造了“人工智能”，后来简称为AI，这个词的原因之一是它足够广泛，可以包含所有这些方法，保持哪种方法最好的问题开放。一些研究人员青睐基于将关于世界的事实与几何学和符号逻辑的公理结合起来，以便推断出适当的响应；其他人则更喜欢构建系统，其中一件事的概率取决于许多其他事情不断更新的概率。
The following decades saw much intellectual ferment and argument on the topic, but by the 1980s there was wide agreement on the way forward: “expert systems” which used symbolic logic to capture and apply the best of human know-how. The Japanese government, in particular, threw its weight behind the idea of such systems and the hardware they might need. But for the most part such systems proved too inflexible to cope with the messiness of the real world. By the late 1980s ai had fallen into disrepute, a byword for overpromising and underdelivering. Those researchers still in the field started to shun the term.
接下来的几十年中，关于这个话题有许多智力上的激动和争论，但到了1980年代，人们普遍认同了前进的方向：使用符号逻辑的“专家系统”，以捕捉和应用人类知识的最佳成果。特别是日本政府，大力支持这类系统及其可能需要的硬件。但大多数情况下，这些系统证明过于僵化，无法应对现实世界的混乱。到了1980年代末，人工智能已经声名狼藉，成为了过度承诺和未达预期的代名词。那些仍然在这个领域的研究人员开始避免使用这个术语。
It was from one of those pockets of perseverance that today’s boom was born. As the rudiments of the way in which brain cells—a type of neuron—work were pieced together in the 1940s, computer scientists began to wonder if machines could be wired up the same way. In a biological brain there are connections between neurons which allow activity in one to trigger or suppress activity in another; what one neuron does depends on what the other neurons connected to it are doing. A first attempt to model this in the lab (by Marvin Minsky, a Dartford attendee) used hardware to model networks of neurons. Since then, layers of interconnected neurons have been simulated in software.
正是从那些坚持不懈的小团体中，今天的繁荣诞生了。当20世纪40年代人们开始逐渐理解脑细胞——一种神经元——的工作方式时，计算机科学家开始思考机器是否也能以相同的方式连接起来。在生物大脑中，神经元之间有连接，这些连接允许一个神经元的活动触发或抑制另一个神经元的活动；一个神经元的行为取决于与之相连的其他神经元在做什么。第一次尝试在实验室模拟这一点（由达特茅斯会议的参与者马文·明斯基进行）使用了硬件来模拟神经元网络。从那时起，软件中模拟了多层互联的神经元。
These artificial neural networks are not programmed using explicit rules; instead, they “learn” by being exposed to lots of examples. During this training the strength of the connections between the neurons (known as “weights”) are repeatedly adjusted so that, eventually, a given input produces an appropriate output. Minsky himself abandoned the idea, but others took it forward. By the early 1990s neural networks had been trained to do things like help sort the post by recognising handwritten numbers. Researchers thought adding more layers of neurons might allow more sophisticated achievements. But it also made the systems run much more slowly.
这些人工神经网络不是通过显式规则来编程的；相反，它们通过接触大量示例来“学习”。在训练过程中，神经元之间的连接强度（称为“权重”）会不断调整，以便最终，给定的输入产生适当的输出。明斯基本人放弃了这个想法，但其他人将其向前推进。到了1990年代初，神经网络已经被训练出来帮助通过识别手写数字来分拣邮件。研究人员认为增加更多的神经元层可能会实现更复杂的成就。但这也让系统运行得更慢。
A new sort of computer hardware provided a way around the problem. Its potential was dramatically demonstrated in 2009, when researchers at Stanford University increased the speed at which a neural net could run 70-fold, using a gaming pc in their dorm room. This was possible because, as well as the “central processing unit” (cpu) found in all pcs, this one also had a “graphics processing unit” (gpu) to create game worlds on screen. And the gpu was designed in a way suited to running the neural-network code.
一种新型的计算机硬件提供了解决这个问题的方法。其潜力在2009年得到了戏剧性的展示，当时斯坦福大学的研究人员使用宿舍里的游戏PC，将神经网络的运行速度提高了70倍。这之所以可能，是因为除了所有PC中都能找到的“中央处理单元”（CPU）之外，这台PC还拥有一个“图形处理单元”（GPU），用于在屏幕上创建游戏世界。而GPU的设计非常适合运行神经网络代码。
Coupling that hardware speed-up with more efficient training algorithms meant that networks with millions of connections could be trained in a reasonable time; neural networks could handle bigger inputs and, crucially, be given more layers. These “deeper” networks turned out to be far more capable.
将硬件加速与更高效的训练算法相结合意味着具有数百万连接的网络可以在合理的时间内进行训练；神经网络能够处理更大的输入，并且关键的是，可以增加更多的层。这些“更深层”的网络被证明要强大得多。
The power of this new approach, which had come to be known as “deep learning”, became apparent in the ImageNet Challenge of 2012. Image-recognition systems competing in the challenge were provided with a database of more than a million labelled image files. For any given word, such as “dog” or “cat”, the database contained several hundred photos. Image-recognition systems would be trained, using these examples, to “map” input, in the form of images, onto output in the form of one-word descriptions. The systems were then challenged to produce such descriptions when fed previously unseen test images. In 2012 a team led by Geoff Hinton, then at the University of Toronto, used deep learning to achieve an accuracy of 85%. It was instantly recognised as a breakthrough.
这种新方法的力量，后来被称为“深度学习”，在2012年的ImageNet挑战赛中变得明显。参加挑战赛的图像识别系统提供了一个超过一百万标记图像文件的数据库。对于任何给定的词，比如“狗”或“猫”，数据库中包含了数百张照片。图像识别系统将使用这些示例进行训练，将输入（以图像形式）“映射”到输出（以单字描述的形式）。然后，系统被挑战在输入以前未见过的测试图像时产生这样的描述。2012年，由当时在多伦多大学的杰夫·辛顿领导的团队使用深度学习达到了85%的准确率。这立刻被公认为是一个突破。
By 2015 almost everyone in the image-recognition field was using deep learning, and the winning accuracy at the ImageNet Challenge had reached 96%—better than the average human score. Deep learning was also being applied to a host of other “problems…reserved for humans” which could be reduced to the mapping of one type of thing onto another: speech recognition (mapping sound to text), face-recognition (mapping faces to names) and translation.
到2015年，几乎所有图像识别领域的人员都在使用深度学习，ImageNet挑战赛的获胜准确率已经达到了96%——比平均人类得分还要好。深度学习也被应用于其他许多可以归结为将一种事物映射到另一种事物的“为人类保留的问题”：语音识别（将声音映射到文本）、面部识别（将面部映射到名字）和翻译。
In all these applications the huge amounts of data that could be accessed through the internet were vital to success; what was more, the number of people using the internet spoke to the possibility of large markets. And the bigger (ie, deeper) the networks were made, and the more training data they were given, the more their performance improved.
在所有这些应用中，通过互联网可以访问的大量数据对成功至关重要；更重要的是，使用互联网的人数表明了大市场的可能性。而且，网络做得越大（即，更深层），它们被给予的训练数据越多，它们的性能就越好。
Deep learning was soon being deployed in all kinds of new products and services. Voice-driven devices such as Amazon’s Alexa appeared. Online transcription services became useful. Web browsers offered automatic translations. Saying such things were enabled by ai started to sound cool, rather than embarrassing, though it was also a bit redundant; nearly every technology referred to as ai then and now actually relies on deep learning under the bonnet.
深度学习很快就被部署在各种新产品和服务中。像亚马逊的Alexa这样的语音驱动设备出现了。在线转录服务变得有用。网络浏览器提供了自动翻译。说这些事物是由人工智能实现的开始听起来很酷，而不是尴尬，尽管这也有点多余；几乎所有当时和现在被称为人工智能的技术实际上都依赖于深度学习。
Chatgpt and its rivals really do seem to “use language and form abstractions”
ChatGPT及其竞争对手确实似乎能够“使用语言并形成抽象概念”。
In 2017 a qualitative change was added to the quantitative benefits being provided by more computing power and more data: a new way of arranging connections between neurons called the transformer. Transformers enable neural networks to keep track of patterns in their input, even if the elements of the pattern are far apart, in a way that allows them to bestow “attention” on particular features in the data.
2017年，随着更多计算能力和更多数据提供的定量优势，又增加了一种定性变化：一种新的神经元连接方式，称为“变换器”（transformer）。变换器使神经网络能够跟踪其输入中的模式，即使模式的元素相隔很远，也能以一种使它们能够对数据中的特定特征赋予“注意力”的方式进行。
Transformers gave networks a better grasp of context, which suited them to a technique called “self-supervised learning”. In essence, some words are randomly blanked out during training, and the model teaches itself to fill in the most likely candidate. Because the training data do not have to be labelled in advance, such models can be trained using billions of words of raw text taken from the internet.
变换器赋予了网络更好的上下文理解能力，这使它们适合一种称为“自监督学习”的技术。本质上，在训练过程中，一些单词会被随机屏蔽，模型自学填充最有可能的候选词。由于训练数据不需要事先标记，因此可以使用从互联网获取的数十亿个单词的原始文本来训练这些模型。
Mind your language model
注意你的语言模型
Transformer-based large language models (llms) began attracting wider attention in 2019, when a model called gpt-2 was released by Openai, a startup (gpt stands for generative pre-trained transformer). Such llms turned out to be capable of “emergent” behaviour for which they had not been explicitly trained. Soaking up huge amounts of language did not just make them surprisingly adept at linguistic tasks like summarisation or translation, but also at things—like simple arithmetic and the writing of software—which were implicit in the training data. Less happily it also meant they reproduced biases in the data fed to them, which meant many of the prevailing prejudices of human society emerged in their output.
基于变换器的大型语言模型（LLMs）在2019年开始引起更广泛的关注，当时一家初创公司OpenAI发布了一个名为gpt-2的模型（gpt代表生成预训练变换器）。这些LLMs被证明能够表现出它们未被明确训练的“涌现”行为。吸收大量语言不仅使它们在诸如摘要或翻译等语言任务上出人意料地熟练，而且也使它们在训练数据中隐含的事物——如简单的算术和编写软件——表现出色。不那么令人高兴的是，这也意味着它们复制了输入数据中的偏见，这意味着许多人类社会的普遍偏见在它们的输出中显现出来。
In November 2022 a larger Openai model, gpt-3.5, was presented to the public in the form of a chatbot. Anyone with a web browser could enter a prompt and get a response. No consumer product has ever taken off quicker. Within weeks Chatgpt was generating everything from college essays to computer code. ai had made another great leap forward.
2022年11月，一个更大的OpenAI模型——gpt-3.5以聊天机器人的形式向公众展示。任何拥有网络浏览器的人都可以输入提示并得到响应。没有任何消费产品比这更快地起飞。几周之内，ChatGPT就生成了从大学论文到计算机代码的所有内容。人工智能再次迈出了巨大的飞跃。
Where the first cohort of ai-powered products was based on recognition, this second one is based on generation. Deep-learning models such as Stable Diffusion and dall-e, which also made their debuts around that time, used a technique called diffusion to turn text prompts into images. Other models can produce surprisingly realistic video, speech or music.
第一代人工智能驱动的产品基于识别，而这第二代产品则基于生成。像Stable Diffusion和dall-e这样的深度学习模型也大约在那时首次亮相，它们使用了一种称为“扩散”的技术将文本提示转化为图像。其他模型可以生成令人惊讶地逼真的视频、语音或音乐。
The leap is not just technological. Making things makes a difference. Chatgpt and rivals such as Gemini (from Google) and Claude (from Anthropic, founded by researchers previously at Openai) produce outputs from calculations just as other deep-learning systems do. But the fact that they respond to requests with novelties makes them feel very unlike software which recognises faces, takes dictation or translates menus. They really do seem to “use language” and “form abstractions”, just as McCarthy had hoped.
这一飞跃不仅仅是技术上的。创造事物会带来变化。ChatGPT及其竞争对手如Google的Gemini和Anthropic（由之前在OpenAI的研究人员创立）的Claude，像其他深度学习系统一样，从计算中产生输出。但它们以新颖性响应请求的事实使它们感觉非常不同于识别面孔、进行口述或翻译菜单的软件。它们确实似乎“使用语言”并“形成抽象概念”，正如麦卡锡所希望的那样。
This series of briefs will look at how these models work, how much further their powers can grow, what new uses they will be put to, as well as what they will not, or should not, be used for.
这一系列的简报将探讨这些模型是如何工作的，它们的能力还能扩展多远，它们将被用于什么新用途，以及它们不会或不应该被用于什么用途。
This article appeared in the Schools brief section of the print edition under the headline “A short history of AI”From the July 20th 2024 edition
]]></content>
  </entry>
  
  <entry>
    <title>成年人，一定要学会独立思考</title>
    <url>/post/adults-must-learn-to-think-independently.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>独立思考</tag>
    </tags>
    <content type="html"><![CDATA[我们每天都会接触到大量的信息和观点。这些信息和观点并非都是真实、客观的，有些甚至是误导性的。在面对问题时，要主动思考、分析、判断，而不是盲目跟从或随波逐流。只有独立思考，才能形成自己的观点和看法，进而在生活中做出符合自己利益的决策。
在与他人交流或讨论时，总会遇到不同的意见和看法。要时刻保持清醒的头脑，要有足够的勇气和自信坚持自己的想法，不要被他人的观点所左右。要知道自己想要什么，要判断信息的可靠性和价值，从而能够有针对性地去筛选和判断。
当然，独立思考并不是一味地否定他人或固执己见。相反，应该在尊重他人的基础上，进行平等、理性的交流，从中汲取有益的信息，进一步完善自己的观点。只有拥有了有主见的内心时，才能够真正地独立思考、自主决策，才能在复杂多变的世界中保持清醒和坚定。
]]></content>
  </entry>
  
  <entry>
    <title>揭示大脑学习奥秘的前沿探索</title>
    <url>/post/the-backprop-in-the-brain.html</url>
    <categories><category>Science & technology</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>Brain</tag>
    </tags>
    <content type="html"><![CDATA[在当今科技飞速发展的时代， 人工智能（AI）  已经成为驱动社会变革的核心力量。
然而，随着AI模型在各个领域的成功应用，科学家们开始探讨一个更加深奥的问题：AI的学习机制能否揭示人类大脑的工作原理？从赫布学习理论到前瞻性配置的新兴理论，揭开大脑学习的奥秘。
AI scientists are producing new theories of how the brain learns AI科学家正在提出大脑如何学习的新理论
The challenge for neuroscientists is how to test them 神经科学家面临的挑战是如何验证这些理论
一种关于神经元学习和连接机制的理论，由加拿大心理学家唐纳德·赫布（Donald Hebb）在1949年提出，因此得名。这个理论的核心思想是：如果两个神经元在相同的时间内被激活，那么它们之间的连接就会变得更强。简单来说，这一机制可以用一句通俗的话来概括：“一起发火的神经元会连接在一起”（&ldquo;Cells that fire together, wire together&rdquo;）。
基本原理：在大脑中，神经元通过突触连接相互通信。当一个神经元的激活导致另一个神经元的激活，并且这种激活反复发生时，这两个神经元之间的突触连接会被加强。这种连接的增强意味着，这两个神经元在未来更有可能一起被激活，从而形成更牢固的神经回路。这种学习机制解释了大脑如何通过经验和反复的刺激来调整和强化神经连接，从而实现学习和记忆的过程。
文章主要内容涵盖了以下几点：
 AI模型与大脑的学习机制：  Geoffrey Hinton博士通过发展人工神经网络，推动了当前AI模型的发展，其初衷是揭示大脑如何通过神经网络学习复杂任务。
文章指出，虽然反向传播算法在人工神经网络中表现出色，但在生物神经网络中的实现存在重大挑战。
反向传播算法的生物适用性挑战：  生物神经元和人工神经元在信息传递方式上的差异，使得反向传播算法在人脑中实施变得困难。尽管存在这些挑战，研究人员仍在探索如何使反向传播算法更符合生物学现实。
新兴的替代理论：  一些科学家提出了新理论，如“前瞻性配置”（prospective configuration），这与传统的反向传播算法截然不同，并且在测试中表现出更接近人类学习的特点。
实验验证的难度：  验证这些理论在大脑中是否起作用需要复杂的实验设计。斯坦福大学的研究团队利用AI模型尝试解决这一难题，他们开发的元模型可以从神经元活动记录中识别出使用的学习算法，这为将来研究大脑的学习机制提供了新思路。
重点词组  &ldquo;The challenge for neuroscientists is how to test them&rdquo;  这句话简洁明了地表述了神经科学家面临的核心问题。短句结构，突出重点，是地道的英语表达。
&ldquo;Five decades of research into artificial neural networks have earned Geoffrey Hinton the moniker of the Godfather of artificial intelligence (AI).&rdquo;  &ldquo;moniker&rdquo;: 意为“绰号”，用来描述一个人因某一成就或特点而被赋予的称呼。
这句话展示了如何在学术写作中使用有力的短语来强调某人的地位和贡献。
&ldquo;Brains learn by being subtly rewired&rdquo;  &ldquo;subtly rewired&rdquo;: 这个短语将大脑学习的过程比作电路重组，“subtly”这个词用得非常精妙，表示微妙而难以察觉的变化。
&ldquo;integral to this learning process is the so-called backpropagation-of-error algorithm&rdquo;  &ldquo;integral to&rdquo;: 表示“对……是必不可少的”，是学术和正式写作中非常有用的表达。
&ldquo;so-called&rdquo;: 用来引入一个特定术语或广为人知的名称，是常用的英语表达。
&ldquo;reverse-engineer&rdquo;  这个动词通常用于描述从现有产品倒推回去，试图了解其工作原理。文章用它来形容试图解析大脑学习过程，非常形象生动。
文章结构 文章的结构逻辑非常清晰。它从引出话题开始，逐步深入探讨，最终总结观点。具体来说：
 引入话题：文章一开始介绍了人工智能和神经科学的交汇点，通过Geoffrey Hinton的研究引出人工神经网络与大脑学习机制之间的关系。 背景铺垫：接着，文章解释了大脑学习的复杂性和当前科学家面临的挑战，为后续讨论奠定基础。 核心讨论：文章详细探讨了反向传播算法、赫布学习理论以及最新的前瞻性配置理论，展示了科学界的多样性思考。 实验和实践：然后，文章介绍了具体的实验和研究，展示了理论在实际应用中的探索。 总结和前景：最后，文章总结了这些理论的重要性，并指出未来研究的方向。  ]]></content>
  </entry>
  
  <entry>
    <title>一个家变好的最快方式：好好说话</title>
    <url>/post/talk-nicely-to-make-family-better.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>好好说话</tag>
      <tag>毒舌</tag>
    </tags>
    <content type="html"><![CDATA[不要总觉得自己对，不要总站在自己的立场上想问题。一个家，不要总想着在语言上争高低，力求压对方一头。吵赢不是目的，解决问题才是。在自己发脾气之前，一定要想清楚，你是在发泄情绪，还是在解决问题。强烈的语言攻击，真的能令人心悸、腿发软。
有一种家庭，一说话就吵架，明明是关心，明明是小事，偏偏要上纲上线，还要翻旧账。有时候，压根不为任何事，就是自己心情不好，想要找事，让别人不痛快。不要总觉得自己没坏心，一个人一旦不会好好说话，再好的心也会让人厌恶。
活干得最多，还不落好，全坏在一张嘴上。好好说话，是一个家变好的最快方式，一旦你的心态平和了，你的语言不带情绪了，对方的情绪也就平和了。别一说话，就想反驳，给彼此留余地。多赞美，多聆听，别逞强，别揭短。
]]></content>
  </entry>
  
  <entry>
    <title>无需比较，我独我</title>
    <url>/post/no-need-to-compare-I-am-alone.html</url>
    <categories><category>生活感言</category>
    </categories>
    <tags>
      <tag>自我认同</tag>
    </tags>
    <content type="html"><![CDATA[每个人都是独一无二的存在，每个人的生命轨迹也都是独一无二的，要以自己的节奏和方式前行。不要下意识地和他人比较，要把自己的真实感受和需求放在首位。你越是比较，就会越焦虑。别人优秀，无需羡慕；别人落魄，也不要出言奚落。
坚持走自己想走的路，要不畏风雨、砥砺前行。即使自己不堪，那也是自己，独一无二的自己。只要努力地做了自己，就会自成一道风景，吸引那些真正同类的人。不敢做自己的人，一生难觅真情和知己，因为自己是假的，事事都会虚假。
人生在世，不求事事如意，但求事事甘心。要有“事出自愿，情过无悔”的淡定从容，不随波逐流，亦不妄自菲薄。去修复自己的样子，精进自己的样子，让自己成为自己最希望的样子，然后珍惜自己的样子。那份由内而外散发的自信与光芒，是任何外在的比较都无法企及的。
]]></content>
  </entry>
  
  <entry>
    <title>北南南北</title>
    <url>/about.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[北南南北 是众多使用 VxWorks 嵌入式实时操作系统的网友分享经验的平台，为的就是让 VxWorks 的学习和应用变得相对开放一些，在此也欢迎你的加入！
我们的愿景 技术创新是技术持续发展的生命力，紧跟技术的发展趋势，研究最新的技术，保持对新技术的热情和好奇心，让技术为生产和生活服务。
使用反馈  加入 VxWorks Club   或 Google AI TPU     欢迎你的加入
 ]]></content>
  </entry>
  
  <entry>
    <title>友情链接</title>
    <url>/flinks.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: VxWorks俱乐部 desc: VxWorks实时操作系统 avatar: https://www.vxworks.net/images/vxworks-club-logo.png link: https://www.vxworks.net ]]></content>
  </entry>
  
</search>